features:
- custom: true
  kind: dataset_factory
  name: getTitanic
  parameters: []
  source: "@datasets.dataset_provider(origin=\"train.csv\",kind=\"GenericDataSet\"\
    )\ndef getTitanic():\n    return genericcsv.GenericCSVDataSet(\"train.csv\",[\"\
    Sex\",\"Fare\",\"Age\",\"Pclass\"],[\"Survived\"],[],\n                      \
    \                  {\"Sex\":\"binary\",\"Fare\":\"normalized_number\",\"Age\"\
    :\"normalized_number\",\"Pclass\":\"one_hot\",\"Survived\":\"binary\"},input_groups={\"\
    0\":[\"Sex\",\"Fare\",\"Age\",\"Pclass\"]})\n"
  sourcefile: "C:\\Users\\\u041F\u0430\u0432\u0435\u043B\\git\\musket_all\\musket_ml\\\
    examples\\modules\\datasets.py"
- custom: true
  doc: null
  kind: data_analizer
  name: LengthAnalizer
  parameters: []
  source: "class LengthAnalizer:\n\n    def __init__(self):\n        self.shapes={}\n\
    \        self.looksLikeBinary=True\n        self.all=InputShapeAnalizer()\n  \
    \      self.positive=InputShapeAnalizer()\n        self.negative=InputShapeAnalizer()\n\
    \n    def __call__(self, index, p: datasets.PredictionItem):\n        self.all(index,p)\n\
    \        if self.looksLikeBinary:\n            if isinstance(p.y,np.ndarray):\n\
    \               if len(p.y.shape)==1 and p.y.shape[0]==1:\n                  \
    \ if p.y[0]==0:\n                      self.negative(index,p)\n              \
    \     if p.y[0]==1:\n                      self.positive(index,p)\n          \
    \         return\n        self.looksLikeBinary=False\n        pass\n\n    def\
    \ build(self):\n        self.all.build()\n        if self.looksLikeBinary:\n \
    \           self.positive.build()\n            self.negative.build()\n       \
    \ pass\n\n    def results(self):\n        if not self.all._build:\n          \
    \  self.build()\n        return self.all.results()\n\n    def visualizationHints(self):\n\
    \        if not self.all._build:\n            self.build()\n        if not self.looksLikeBinary:\n\
    \            return self.all.visualizationHints()\n        r = [x[0] for x in\
    \ self.all._build]\n        rp = [x[0] for x in self.positive._build]\n      \
    \  rn = [x[0] for x in self.negative._build]\n        if len(r)>0:\n         \
    \   res=[r[0]]\n            if len(rp)>0 and len(rn)>0:\n                res=\
    \ [r[0],rp[0],rn[0]]\n            return {\"type\": \"hist\", \"values\": res}\n\
    \        return None\n"
  sourcefile: D:\Python36\lib\site-packages\musket_core\dataset_analizers.py
- custom: true
  doc: null
  kind: analizer
  name: MultiClassF1Analizer
  parameters: []
  source: "class MultiClassF1Analizer(MultiClassMetricsAnalizer):\n    \n\n    def\
    \ results(self):\n        preds=np.array(self.predictions)\n        gt=np.array(self.ground_truth)\n\
    \        scores=[]\n        for i in range(preds.shape[1]):\n            pri=preds[:,i]\n\
    \            gti=gt[:,i]\n            f1=metrics.f1_score(gti,pri>0.5)\n     \
    \       scores.append(float(f1))\n        self.scores=scores;\n        return\
    \ []\n"
  sourcefile: D:\Python36\lib\site-packages\musket_core\dataset_analizers.py
- custom: true
  doc: null
  kind: data_analizer
  name: MultiClassFrequenceyAnalizer
  parameters: []
  source: "class MultiClassFrequenceyAnalizer:\n\n    def __init__(self):\n      \
    \  self.shapes={}\n        self.looksLikeBinary=True\n        self.freq={}\n \
    \       self.count=0\n        \n\n    def __call__(self, index, p: datasets.PredictionItem=None,prediction:datasets.PredictionItem=None,**args):\n\
    \        self.count=self.count+1\n        for  v in np.where(p.y>0.5)[0]:\n  \
    \          if v in self.freq:\n                self.freq[v].append(index)\n  \
    \          else: self.freq[v]=[p.id]      \n        pass\n\n    \n\n    def results(self):\n\
    \        m=max(self.freq.keys())\n        scores=np.zeros(m)\n        \n     \
    \   for v in range(m):\n            if v in self.freq:\n                scores[v]=len(self.freq[v])\n\
    \            else:\n                scores[v]=0    \n        self.scores=[float(x)/self.count\
    \ for x in scores];\n        return self.freq\n\n    def visualizationHints(self):\n\
    \        return {\"type\": \"hist\", \"values\": self.scores,\"x_axis\":\"Class\"\
    ,\"y_axis\":\"Frequency\"}    \n"
  sourcefile: D:\Python36\lib\site-packages\musket_core\dataset_analizers.py
- custom: true
  doc: null
  kind: analizer
  name: MultiClassPrecisionAnalizer
  parameters: []
  source: "class MultiClassPrecisionAnalizer(MultiClassMetricsAnalizer):\n    \n\n\
    \    def results(self):\n        preds=np.array(self.predictions)\n        gt=np.array(self.ground_truth)\n\
    \        scores=[]\n        for i in range(preds.shape[1]):\n            pri=preds[:,i]\n\
    \            gti=gt[:,i]\n            f1=metrics.precision_score(gti,pri>0.5)\n\
    \            scores.append(float(f1))\n        self.scores=scores;\n        return\
    \ []    \n    \n    def visualizationHints(self):\n        return {\"type\": \"\
    hist\", \"values\": self.scores,\"x_axis\":\"Class\",\"y_axis\":\"Precision\"\
    }    \n"
  sourcefile: D:\Python36\lib\site-packages\musket_core\dataset_analizers.py
- custom: true
  doc: null
  kind: analizer
  name: MultiClassRecallAnalizer
  parameters: []
  source: "class MultiClassRecallAnalizer(MultiClassMetricsAnalizer):\n    \n\n  \
    \  def results(self):\n        preds=np.array(self.predictions)\n        gt=np.array(self.ground_truth)\n\
    \        scores=[]\n        for i in range(preds.shape[1]):\n            pri=preds[:,i]\n\
    \            gti=gt[:,i]\n            f1=metrics.recall_score(gti,pri>0.5)\n \
    \           scores.append(float(f1))\n        self.scores=scores;\n        return\
    \ []    \n    \n    def visualizationHints(self):\n        return {\"type\": \"\
    hist\", \"values\": self.scores,\"x_axis\":\"Class\",\"y_axis\":\"Recall\"}\n"
  sourcefile: D:\Python36\lib\site-packages\musket_core\dataset_analizers.py
- custom: true
  doc: null
  kind: analizer
  name: MultiOutputCategoricalAnalizer
  parameters: []
  source: "class MultiOutputCategoricalAnalizer(MultiClassMetricsAnalizer):\n    \n\
    \n    def results(self):\n        preds=np.array(self.predictions)\n        gt=np.array(self.ground_truth)\n\
    \        scores=[]\n        \n        for i in range(preds.shape[1]):\n      \
    \      pri=preds[:,i]\n            gti=gt[:,i]\n            \n            pri=np.argmax(pri,axis=1)\n\
    \            gti=np.argmax(gti,axis=1)\n            \n            f1=metrics.accuracy_score(gti,pri)\n\
    \            scores.append(float(f1))\n        self.scores=scores;\n        return\
    \ []    \n    \n    def visualizationHints(self):\n        return {\"type\": \"\
    hist\", \"values\": self.scores,\"x_axis\":\"Output\",\"y_axis\":\"Categorical\
    \ Accuracy\"}\n"
  sourcefile: D:\Python36\lib\site-packages\musket_core\dataset_analizers.py
- custom: true
  doc: null
  kind: data_analizer
  name: VocabularyAnalizer
  parameters: []
  source: "class VocabularyAnalizer:\n    def __init__(self):\n        self.components={}\n\
    \        self.words= {}\n        self.doccount=0\n        pass\n\n    def __call__(self,\
    \ index, p: datasets.PredictionItem):\n        self.doccount=self.doccount+1\n\
    \        for a in p.x:\n            if a in self.components:\n               \
    \ self.components[a].add(index)\n                self.words[a]=self.words[a]+1\n\
    \            else:\n                self.components[a] = {index}\n           \
    \     self.words[a]=1\n        pass\n\n    def results(self):\n        sorted_x\
    \ = sorted(self.words.items(), key=operator.itemgetter(1))\n        return  {\
    \ \"vocabulary\": WordDS(sorted_x)}\n\n    def visualizationHints(self):\n   \
    \     sorted_x = sorted(self.words.items(), key=operator.itemgetter(1))\n\n  \
    \      mn:set=set()\n        \n        res={}\n        count=0\n        for i\
    \ in tqdm(range(len(sorted_x))):\n            x=sorted_x[i]\n            word=x[0]\n\
    \            mn|=self.components[word]\n            count=count+1\n          \
    \  res[len(self.words)-count]=len(mn)\n        return {\"type\": \"hist\", \"\
    values\": [res],\"total\":self.doccount,\"x_axis\":\"Size of vocubalary\",\"y_axis\"\
    :\"Fraction of fully covered documents\"}\n"
  sourcefile: D:\Python36\lib\site-packages\musket_core\dataset_analizers.py
- custom: true
  doc: null
  kind: data_analizer
  name: WordFrequencyAnalizer
  parameters:
  - {defaultValue: '5', kind: any, name: min_count, type: int}
  - {defaultValue: 'False', kind: any, name: exclude_stop_words, type: bool}
  - {defaultValue: english, kind: any, name: stopWordsLanguage, type: str}
  - {defaultValue: 'False', kind: any, name: exclude_punctuation, type: bool}
  - {defaultValue: '20', kind: any, name: top_n, type: int}
  source: "class WordFrequencyAnalizer:\n    def __init__(self,min_count:int=5,exclude_stop_words:bool=False,stopWordsLanguage:str=\"\
    english\",exclude_punctuation:bool=False,top_n:int=20):\n        self.analizers={}\n\
    \        self.min_count=min_count\n        self.stopwords=exclude_stop_words\n\
    \        self.analizers[\"all\"]=VocabularyAnalizer()\n        self.exclude_punctuation=exclude_punctuation\n\
    \        self.top_n=top_n\n        if self.stopwords:\n            try:\n    \
    \            from nltk.corpus import stopwords\n                self._stopwords\
    \ = set(stopwords.words(stopWordsLanguage))\n            except:\n           \
    \     import nltk\n                nltk.download('stopwords')\n              \
    \  from nltk.corpus import stopwords\n                self._stopwords = set(stopwords.words(stopWordsLanguage))\n\
    \        else:\n            self._stopwords=None\n        pass\n\n    def __call__(self,\
    \ index, p: datasets.PredictionItem):\n        \n        self.analizers[\"all\"\
    ](index,p)\n        ids=np.where(p.y>0)\n        for k in ids[0]:\n          \
    \  m=int(k)\n            if m not in self.analizers:\n                self.analizers[m]=VocabularyAnalizer()\n\
    \            self.analizers[m](index,p)\n        pass\n\n    def results(self):\n\
    \        allAnalizer=self.analizers[\"all\"]\n        res={}\n        for v in\
    \ self.analizers:\n            if v!=\"all\":\n               analizer=self.analizers[v]\n\
    \               rs=[]\n               for x,y in analizer.words.items():\n   \
    \                if allAnalizer.words[x]>self.min_count:\n                   \
    \    rs.append((x,y/allAnalizer.words[x],allAnalizer.words[x]))\n            \
    \   sorted_x = list(reversed(sorted(rs, key=operator.itemgetter(1))))\n      \
    \         res[v]=WordDS2(sorted_x,len(rs))\n        return res\n\n    def visualizationHints(self):\n\
    \        allAnalizer = self.analizers[\"all\"]\n        sorted_x = reversed(sorted(allAnalizer.words.items(),\
    \ key=operator.itemgetter(1)))\n        res={}\n        for i in sorted_x:\n \
    \           if self.exclude_punctuation and i[0] in string.punctuation:\n    \
    \            continue\n            if self._stopwords is not None:\n         \
    \       if i[0] in self._stopwords or i[0].lower() in self._stopwords:\n     \
    \               continue\n            res[i[0]]=i[1]\n\n            if len(res)>self.top_n:\n\
    \                break\n        return {\"type\": \"bar\", \"values\": [res],\
    \ \"total\": allAnalizer.doccount, \"x_axis\": \"Most Frequent words\",\n    \
    \                 \"y_axis\": \"Usage Count\"}\n"
  sourcefile: D:\Python36\lib\site-packages\musket_core\dataset_analizers.py
- custom: true
  doc: null
  kind: data_analizer
  name: class_num_analizer
  parameters:
  - {kind: any, name: y}
  source: "@visualization.dataset_analizer\ndef class_num_analizer(y):\n    if isinstance(y,\
    \ np.ndarray):\n        return int(y[0])\n    return int(y)\n"
  sourcefile: D:\Python36\lib\site-packages\musket_core\dataset_analizers.py
- custom: true
  doc: null
  kind: data_analizer
  name: constant_analizer
  parameters:
  - {kind: any, name: y}
  source: "@visualization.caption('Simple analyzer for testing purposes, just gving\
    \ value 1 for all samples')\n@visualization.dataset_analizer\ndef constant_analizer(y):\n\
    \    return 1\n"
  sourcefile: D:\Python36\lib\site-packages\musket_core\dataset_analizers.py
- custom: true
  doc: null
  kind: data_filter
  name: contains_string
  parameters:
  - {kind: any, name: y, type: PredictionItem}
  - {kind: any, name: filter, type: str}
  source: "@visualization.dataset_filter\ndef contains_string(y:datasets.PredictionItem,filter:str):\n\
    \    val=y.x\n    return filter in str(val)\n"
  sourcefile: D:\Python36\lib\site-packages\musket_core\dataset_analizers.py
- custom: true
  doc: null
  kind: data_filter
  name: custom_python
  parameters:
  - {kind: any, name: y, type: PredictionItem}
  - {kind: any, name: filter, type: str}
  source: "@visualization.dataset_filter\ndef custom_python(y:datasets.PredictionItem,filter:str):\n\
    \    val=y.x\n    return filter in str(val)\n"
  sourcefile: D:\Python36\lib\site-packages\musket_core\dataset_analizers.py
- custom: true
  doc: null
  kind: data_analizer
  name: dataset_balance
  parameters:
  - {kind: any, name: y}
  source: "@visualization.dataset_analizer\ndef dataset_balance(y):\n    s=(y>0.5).sum()\n\
    \    if s>0:\n        return \"Positive samples\"\n    return \"Negative samples\"\
    \n"
  sourcefile: D:\Python36\lib\site-packages\musket_core\dataset_analizers.py
- custom: true
  doc: null
  kind: analizer
  name: ground_truth_vs_prediction
  parameters:
  - {kind: any, name: x}
  - {kind: any, name: y}
  source: "@visualization.prediction_analizer\ndef ground_truth_vs_prediction(x,y):\n\
    \    \n    allCorrect=np.equal(x>0.5,y>0.5).sum()==len(x)\n    if allCorrect:\n\
    \        return \"Correct\"\n    return \"Incorrect\"\n"
  sourcefile: D:\Python36\lib\site-packages\musket_core\dataset_analizers.py
- custom: true
  doc: null
  kind: data_filter
  name: has_class
  parameters:
  - {kind: any, name: y, type: PredictionItem}
  - {kind: any, name: filter, type: str}
  source: "@visualization.dataset_filter\ndef has_class(y:datasets.PredictionItem,filter:str):\n\
    \    val=y.y\n    if len(val)>1:\n        return val[int(filter)]==1\n    return\
    \ val[0]==int(filter)\n"
  sourcefile: D:\Python36\lib\site-packages\musket_core\dataset_analizers.py
- custom: true
  doc: null
  kind: data_analizer
  name: multi_class_balance
  parameters:
  - {kind: any, name: y}
  source: "@visualization.dataset_analizer\ndef multi_class_balance(y):\n    if isinstance(y,\
    \ np.ndarray):\n        return int(y[0])\n    return int(y)\n"
  sourcefile: D:\Python36\lib\site-packages\musket_core\dataset_analizers.py
- custom: true
  doc: null
  kind: data_analizer
  name: onehot_analizer
  parameters:
  - {kind: any, name: y}
  source: "@visualization.dataset_analizer\ndef onehot_analizer(y):\n    r=np.where(y>0.5)\n\
    \    if len(r[0])>0:\n        return int(r[0][0])\n    return \"Negative sample\"\
    \n"
  sourcefile: D:\Python36\lib\site-packages\musket_core\dataset_analizers.py
- custom: true
  doc: null
  kind: analizer
  name: void_analizer
  parameters:
  - {kind: any, name: x}
  - {kind: any, name: y}
  source: "@visualization.prediction_analizer\ndef void_analizer(x,y):\n    return\
    \ \"Ok\"\n"
  sourcefile: D:\Python36\lib\site-packages\musket_core\dataset_analizers.py
- custom: true
  doc: null
  kind: data_analizer
  name: void_data_analizer
  parameters: []
  source: "@visualization.dataset_analizer\ndef void_data_analizer(*args):\n    return\
    \ \"Ok\"\n"
  sourcefile: D:\Python36\lib\site-packages\musket_core\dataset_analizers.py
- custom: true
  kind: visualizer
  name: default_visualizer
  parameters:
  - {kind: any, name: val, type: PredictionItem}
  source: "@dataset_visualizer\n@visualize_as_text\ndef default_visualizer(val:PredictionItem):\n\
    \    r=str(val.x)+\",\"+str(val.y)\n    if val.prediction is not None:\n     \
    \   r=r+\" - \"+str(val.prediction)\n    return r    \n"
  sourcefile: D:\Python36\lib\site-packages\musket_core\dataset_visualizers.py
  viewer: text
- custom: true
  kind: visualizer
  name: image_visializer
  parameters:
  - {kind: any, name: p, type: PredictionItem}
  source: "@dataset_visualizer\n@visualize_as_image\ndef image_visializer(p:PredictionItem):\n\
    \    cache_path=context().path\n    path = cache_path + str(p.id) + \".png\"\n\
    \    if os.path.exists(path):\n        return path    \n    imageio.imwrite(path,p.x)\
    \    \n    return path\n"
  sourcefile: D:\Python36\lib\site-packages\musket_core\dataset_visualizers.py
  viewer: image
- custom: true
  kind: visualizer
  name: image_with_mask_and_prediction_visializer
  parameters:
  - {kind: any, name: p, type: PredictionItem}
  source: "@dataset_visualizer\n@visualize_as_image\ndef image_with_mask_and_prediction_visializer(p:PredictionItem):\n\
    \    cache_path=context().path\n    path = cache_path + str(p.id) + \"mask.png\"\
    \n    if os.path.exists(path):\n        return path\n    arr=np.copy(p.x)\n  \
    \  res=imgaug.SegmentationMapsOnImage(p.y, p.y.shape).draw()\n    for i in res:\n\
    \        arr[np.mean(i,axis=2)!=0]=i[np.mean(i,axis=2)!=0]\n        \n    res=imgaug.SegmentationMapsOnImage(p.prediction>0.5,\
    \ p.y.shape).draw()\n    arr1=np.copy(p.x)\n    for i in res:\n        arr1[np.mean(i,axis=2)!=0]=i[np.mean(i,axis=2)!=0]\
    \    \n    \n    imgs_comb = np.hstack([arr,arr1])\n    imageio.imwrite(path,imgs_comb)\
    \    \n    return path\n"
  sourcefile: D:\Python36\lib\site-packages\musket_core\dataset_visualizers.py
  viewer: image
- custom: true
  kind: visualizer
  name: image_with_mask_visializer
  parameters:
  - {kind: any, name: p, type: PredictionItem}
  source: "@dataset_visualizer\n@visualize_as_image\ndef image_with_mask_visializer(p:PredictionItem):\n\
    \    cache_path=context().path\n    path = cache_path + str(p.id) + \"mask.png\"\
    \n    if os.path.exists(path):\n        return path\n    arr=np.copy(p.x)\n  \
    \  res=imgaug.SegmentationMapsOnImage(p.y, p.y.shape).draw()\n    for i in res:\n\
    \        arr[np.mean(i,axis=2)!=0]=i[np.mean(i,axis=2)!=0]\n    imageio.imwrite(path,arr)\
    \    \n    return path\n"
  sourcefile: D:\Python36\lib\site-packages\musket_core\dataset_visualizers.py
  viewer: image
- custom: true
  doc: null
  kind: preprocessor
  name: add_random_words
  parameters:
  - {kind: any, name: inp}
  - {kind: any, name: probability}
  source: "@preprocessing.dataset_preprocessor\ndef add_random_words(inp,probability):\n\
    \    rr=np.random.rand(len(inp))\n    result=[]\n    for i in range(len(inp)):\n\
    \        if rr[i]<probability:\n            result.append(np.random.randint(1,2000))\n\
    \            \n            \n        result.append(inp[i])\n    if len(result)>len(inp):\n\
    \        result=result[:len(inp)]      \n    return np.array(result)        \n"
  sourcefile: D:\Python36\lib\site-packages\musket_text\preprocessors.py
- custom: true
  doc: null
  kind: preprocessor
  name: remove_random_words
  parameters:
  - {kind: any, name: inp}
  - {kind: any, name: probability}
  source: "@preprocessing.dataset_preprocessor\ndef remove_random_words(inp,probability):\n\
    \    rr=np.random.rand(len(inp))\n    result=[]\n    count=0\n    for i in range(len(inp)):\n\
    \        if rr[i]<probability:\n            count=count+1\n            continue\n\
    \        result.append(inp[i])\n    result=result+[0]*count\n    return np.array(result)\
    \        \n"
  sourcefile: D:\Python36\lib\site-packages\musket_text\preprocessors.py
- custom: true
  doc: null
  kind: preprocessor
  name: string_to_chars
  parameters:
  - {kind: any, name: maxLen}
  - {defaultValue: utf8, kind: any, name: encoding}
  - {defaultValue: strict, kind: any, name: errors}
  source: "class string_to_chars:\n    \n    def __init__(self,maxLen,encoding=\"\
    utf8\",errors='strict'):\n        self.maxLen=maxLen\n        self.encoding=encoding\n\
    \        self.errors=errors\n        \n    def __call__(self,inp:str):\n     \
    \   vl=np.frombuffer(inp.encode(self.encoding, errors=self.errors),dtype=np.uint8)\n\
    \        if vl.shape[0]<self.maxLen:\n            r= np.pad(vl, (0,self.maxLen-vl.shape[0]),mode=\"\
    constant\")\n            return r\n        return vl[:self.maxLen]\n"
  sourcefile: D:\Python36\lib\site-packages\musket_text\preprocessors.py
- custom: true
  doc: null
  kind: preprocessor
  name: swap_random_words
  parameters:
  - {kind: any, name: inp}
  - {kind: any, name: probability}
  source: "@preprocessing.dataset_preprocessor\ndef swap_random_words(inp,probability):\n\
    \    rr=np.random.rand(len(inp))\n    result=[]\n    continueNext=False\n    for\
    \ i in range(len(inp)-1):\n        if continueNext:\n            continueNext=False\n\
    \            continue\n        if rr[i]<probability:\n            result.append(inp[i+1])\n\
    \            result.append(inp[i])\n            continueNext=True\n          \
    \  continue\n            \n        result.append(inp[i])\n    while len(result)<len(inp):\n\
    \        result.append(0)    \n    if len(result)!=len(inp):\n        raise ValueError()\
    \      \n    return np.array(result)\n"
  sourcefile: D:\Python36\lib\site-packages\musket_text\preprocessors.py
- custom: true
  doc: null
  kind: preprocessor
  name: tokenize
  parameters:
  - {kind: any, name: inp}
  source: "@preprocessing.dataset_preprocessor\ndef tokenize(inp):\n    try:\n   \
    \     return casual_tokenize(inp)\n    except:\n        print(inp)\n        return\
    \ []\n"
  sourcefile: D:\Python36\lib\site-packages\musket_text\preprocessors.py
- custom: true
  doc: null
  kind: preprocessor
  name: tokens_to_indexes
  parameters:
  - {kind: any, name: inp, type: DataSet}
  - {defaultValue: '-1', kind: any, name: maxWords}
  - {defaultValue: '-1', kind: any, name: maxLen}
  source: "@preprocessing.dataset_transformer\ndef tokens_to_indexes(inp:DataSet,maxWords=-1,maxLen=-1)->DataSet:\n\
    \    voc=caches.get_cache_dir()\n    \n    name=voc+caches.cache_name(inp)+\"\
    .\"+str(maxWords)+\".vocab\"\n    # WE SHOULD USE TRAIN VOCABULARY IN ALL CASES\
    \  \n    try:\n        trainName=str(inp.root().cfg.dataset)\n        \n     \
    \   curName=inp.root().name\n        if trainName!=curName:\n            name=utils.load(inp.root().cfg.path+\"\
    .contribution\")            \n    except:\n        pass \n    if os.path.exists(name):\n\
    \        if name in _vocabs:\n            vocabulary= _vocabs[name]\n        else:\
    \    \n            vocabulary=utils.load(name)\n            _vocabs[name]=vocabulary\n\
    \    else:\n        vocabulary=buildVocabulary(inp,maxWords)\n        utils.save(name,vocabulary)\n\
    \        _vocabs[name]=vocabulary    \n    def transform2index(x):\n        ml=maxLen\n\
    \        if ml==-1:\n            ml=len(x)\n        res=np.zeros((ml,),dtype=np.int32)\n\
    \        num=0\n        for v in x:\n            if v in vocabulary.dict:\n  \
    \              res[num]=(vocabulary.dict[v])\n            else:\n            \
    \    res[num]=(vocabulary.unknown)\n            num=num+1\n            if num==ml:\n\
    \                break            \n        return res    \n    rs= preprocessing.PreprocessedDataSet(inp,transform2index,False)\n\
    \    rs.vocabulary=vocabulary\n    rs.contribution=name\n    return rs\n"
  sourcefile: D:\Python36\lib\site-packages\musket_text\preprocessors.py
- custom: true
  doc: null
  kind: preprocessor
  name: vectorize
  parameters:
  - {kind: any, name: path}
  - {defaultValue: '-1', kind: any, name: maxLen}
  source: "class vectorize:\n    def __init__(self,path,maxLen=-1):\n        self.embeddings=embeddings(path)\n\
    \        self.maxLen=maxLen\n        pass\n    def __call__(self,inp):\n     \
    \   ml=self.maxLen\n        if ml==-1:\n            ml=len(inp)\n        ln=min(ml,len(inp))\n\
    \        result=np.zeros((ml,300),dtype=np.float32)        \n        for i in\
    \ range(ln):\n            w=inp[i]\n            if w in self.embeddings:\n   \
    \             result[i]=self.embeddings[w]\n            else:    \n          \
    \      w=w.lower()\n                if w in self.embeddings:\n               \
    \     result[i]=self.embeddings[w]\n        return result\n"
  sourcefile: D:\Python36\lib\site-packages\musket_text\preprocessors.py
- custom: true
  doc: null
  kind: preprocessor
  name: vectorize_indexes
  parameters:
  - {kind: any, name: inp}
  - {kind: any, name: path}
  - {defaultValue: '-1', kind: any, name: maxLen}
  source: "@preprocessing.dataset_transformer\ndef vectorize_indexes(inp,path,maxLen=-1):\n\
    \    embs=embeddings(path)\n    orig=inp\n    while not hasattr(orig, \"vocabulary\"\
    ):\n        orig=orig.parent\n    voc=orig.vocabulary\n    unknown=np.random.randn(300)\
    \    \n    def index2Vector(inp):\n        ml=maxLen\n        if ml==-1:\n   \
    \         ml=len(inp)\n        ln=min(ml,len(inp))\n        result=np.zeros((ml,300),dtype=np.float32)\
    \        \n        for i in range(ln):\n            ind=inp[i]\n            if\
    \ ind==0:\n                break\n            if ind in voc.i2w:\n           \
    \     w=voc.i2w[ind]\n                if w in embs:\n                    result[i]=embs[w]\n\
    \                    continue\n            result[i]=unknown    \n        return\
    \ result                    \n    rs= preprocessing.PreprocessedDataSet(inp,index2Vector,False)\n\
    \    return rs    \n"
  sourcefile: D:\Python36\lib\site-packages\musket_text\preprocessors.py
- custom: true
  doc: null
  kind: model
  name: word_indexes_embedding
  parameters:
  - {kind: any, name: inp}
  - {kind: any, name: path}
  source: "@model.block    \ndef word_indexes_embedding(inp,path):\n    embs=embeddings(path)\n\
    \    v=get_vocab(inp.contribution);\n    embedding_matrix = None\n    try:\n \
    \       for word, i in tqdm.tqdm(v.dict.items()):\n            if word in embs:\n\
    \                if embedding_matrix is None: \n                    embedding_matrix=np.random.randn(len(v.dict)+1,\
    \ len(embs[word]))\n                embedding_matrix[i]=embs[word]\n        return\
    \ keras.layers.Embedding(len(v.dict)+1,embedding_matrix.shape[1],weights=[embedding_matrix],trainable=False)(inp)\
    \    \n    except:\n        import traceback\n        traceback.print_exc()\n\
    \        return None     \n"
  sourcefile: D:\Python36\lib\site-packages\musket_text\preprocessors.py
- doc: null
  kind: losses
  name: kullback_leibler_divergence
  parameters:
  - {kind: any, name: y_true}
  - {kind: any, name: y_pred}
  source: "def kullback_leibler_divergence(y_true, y_pred):\n    y_true = K.clip(y_true,\
    \ K.epsilon(), 1)\n    y_pred = K.clip(y_pred, K.epsilon(), 1)\n    return K.sum(y_true\
    \ * K.log(y_true / y_pred), axis=-1)\n"
  sourcefile: D:\Python36\lib\site-packages\keras\losses.py
- doc: null
  kind: losses
  name: mean_absolute_error
  parameters:
  - {kind: any, name: y_true}
  - {kind: any, name: y_pred}
  source: "def mean_absolute_error(y_true, y_pred):\n    return K.mean(K.abs(y_pred\
    \ - y_true), axis=-1)\n"
  sourcefile: D:\Python36\lib\site-packages\keras\losses.py
- doc: null
  kind: losses
  name: mean_absolute_percentage_error
  parameters:
  - {kind: any, name: y_true}
  - {kind: any, name: y_pred}
  source: "def mean_absolute_percentage_error(y_true, y_pred):\n    diff = K.abs((y_true\
    \ - y_pred) / K.clip(K.abs(y_true),\n                                        \
    \    K.epsilon(),\n                                            None))\n    return\
    \ 100. * K.mean(diff, axis=-1)\n"
  sourcefile: D:\Python36\lib\site-packages\keras\losses.py
- doc: null
  kind: losses
  name: mean_squared_error
  parameters:
  - {kind: any, name: y_true}
  - {kind: any, name: y_pred}
  source: "def mean_squared_error(y_true, y_pred):\n    return K.mean(K.square(y_pred\
    \ - y_true), axis=-1)\n"
  sourcefile: D:\Python36\lib\site-packages\keras\losses.py
- doc: null
  kind: losses
  name: mean_squared_logarithmic_error
  parameters:
  - {kind: any, name: y_true}
  - {kind: any, name: y_pred}
  source: "def mean_squared_logarithmic_error(y_true, y_pred):\n    first_log = K.log(K.clip(y_pred,\
    \ K.epsilon(), None) + 1.)\n    second_log = K.log(K.clip(y_true, K.epsilon(),\
    \ None) + 1.)\n    return K.mean(K.square(first_log - second_log), axis=-1)\n"
  sourcefile: D:\Python36\lib\site-packages\keras\losses.py
- doc: null
  kind: losses
  name: binary_crossentropy
  parameters:
  - {kind: any, name: y_true}
  - {kind: any, name: y_pred}
  source: "def binary_crossentropy(y_true, y_pred):\n    return K.mean(K.binary_crossentropy(y_true,\
    \ y_pred), axis=-1)\n"
  sourcefile: D:\Python36\lib\site-packages\keras\losses.py
- doc: null
  kind: losses
  name: categorical_crossentropy
  parameters:
  - {kind: any, name: y_true}
  - {kind: any, name: y_pred}
  source: "def categorical_crossentropy(y_true, y_pred):\n    return K.categorical_crossentropy(y_true,\
    \ y_pred)\n"
  sourcefile: D:\Python36\lib\site-packages\keras\losses.py
- doc: null
  kind: losses
  name: categorical_hinge
  parameters:
  - {kind: any, name: y_true}
  - {kind: any, name: y_pred}
  source: "def categorical_hinge(y_true, y_pred):\n    pos = K.sum(y_true * y_pred,\
    \ axis=-1)\n    neg = K.max((1. - y_true) * y_pred, axis=-1)\n    return K.maximum(0.,\
    \ neg - pos + 1.)\n"
  sourcefile: D:\Python36\lib\site-packages\keras\losses.py
- doc: null
  kind: losses
  name: cosine_proximity
  parameters:
  - {kind: any, name: y_true}
  - {kind: any, name: y_pred}
  source: "def cosine_proximity(y_true, y_pred):\n    y_true = K.l2_normalize(y_true,\
    \ axis=-1)\n    y_pred = K.l2_normalize(y_pred, axis=-1)\n    return -K.sum(y_true\
    \ * y_pred, axis=-1)\n"
  sourcefile: D:\Python36\lib\site-packages\keras\losses.py
- doc: null
  kind: losses
  name: cosine_proximity
  parameters:
  - {kind: any, name: y_true}
  - {kind: any, name: y_pred}
  source: "def cosine_proximity(y_true, y_pred):\n    y_true = K.l2_normalize(y_true,\
    \ axis=-1)\n    y_pred = K.l2_normalize(y_pred, axis=-1)\n    return -K.sum(y_true\
    \ * y_pred, axis=-1)\n"
  sourcefile: D:\Python36\lib\site-packages\keras\losses.py
- doc: null
  kind: losses
  name: hinge
  parameters:
  - {kind: any, name: y_true}
  - {kind: any, name: y_pred}
  source: "def hinge(y_true, y_pred):\n    return K.mean(K.maximum(1. - y_true * y_pred,\
    \ 0.), axis=-1)\n"
  sourcefile: D:\Python36\lib\site-packages\keras\losses.py
- doc: null
  kind: losses
  name: kullback_leibler_divergence
  parameters:
  - {kind: any, name: y_true}
  - {kind: any, name: y_pred}
  source: "def kullback_leibler_divergence(y_true, y_pred):\n    y_true = K.clip(y_true,\
    \ K.epsilon(), 1)\n    y_pred = K.clip(y_pred, K.epsilon(), 1)\n    return K.sum(y_true\
    \ * K.log(y_true / y_pred), axis=-1)\n"
  sourcefile: D:\Python36\lib\site-packages\keras\losses.py
- doc: null
  kind: losses
  name: kullback_leibler_divergence
  parameters:
  - {kind: any, name: y_true}
  - {kind: any, name: y_pred}
  source: "def kullback_leibler_divergence(y_true, y_pred):\n    y_true = K.clip(y_true,\
    \ K.epsilon(), 1)\n    y_pred = K.clip(y_pred, K.epsilon(), 1)\n    return K.sum(y_true\
    \ * K.log(y_true / y_pred), axis=-1)\n"
  sourcefile: D:\Python36\lib\site-packages\keras\losses.py
- doc: "Logarithm of the hyperbolic cosine of the prediction error.\n\n`log(cosh(x))`\
    \ is approximately equal to `(x ** 2) / 2` for small `x` and\nto `abs(x) - log(2)`\
    \ for large `x`. This means that 'logcosh' works mostly\nlike the mean squared\
    \ error, but will not be so strongly affected by the\noccasional wildly incorrect\
    \ prediction.\n\n# Arguments\n    y_true: tensor of true targets.\n    y_pred:\
    \ tensor of predicted targets.\n\n# Returns\n    Tensor with one scalar loss entry\
    \ per sample."
  kind: losses
  name: logcosh
  parameters:
  - {kind: any, name: y_true}
  - {kind: any, name: y_pred}
  source: "def logcosh(y_true, y_pred):\n    \"\"\"Logarithm of the hyperbolic cosine\
    \ of the prediction error.\n\n    `log(cosh(x))` is approximately equal to `(x\
    \ ** 2) / 2` for small `x` and\n    to `abs(x) - log(2)` for large `x`. This means\
    \ that 'logcosh' works mostly\n    like the mean squared error, but will not be\
    \ so strongly affected by the\n    occasional wildly incorrect prediction.\n\n\
    \    # Arguments\n        y_true: tensor of true targets.\n        y_pred: tensor\
    \ of predicted targets.\n\n    # Returns\n        Tensor with one scalar loss\
    \ entry per sample.\n    \"\"\"\n    def _logcosh(x):\n        return x + K.softplus(-2.\
    \ * x) - K.log(2.)\n    return K.mean(_logcosh(y_pred - y_true), axis=-1)\n"
  sourcefile: D:\Python36\lib\site-packages\keras\losses.py
- doc: null
  kind: losses
  name: mean_absolute_error
  parameters:
  - {kind: any, name: y_true}
  - {kind: any, name: y_pred}
  source: "def mean_absolute_error(y_true, y_pred):\n    return K.mean(K.abs(y_pred\
    \ - y_true), axis=-1)\n"
  sourcefile: D:\Python36\lib\site-packages\keras\losses.py
- doc: null
  kind: losses
  name: mean_absolute_percentage_error
  parameters:
  - {kind: any, name: y_true}
  - {kind: any, name: y_pred}
  source: "def mean_absolute_percentage_error(y_true, y_pred):\n    diff = K.abs((y_true\
    \ - y_pred) / K.clip(K.abs(y_true),\n                                        \
    \    K.epsilon(),\n                                            None))\n    return\
    \ 100. * K.mean(diff, axis=-1)\n"
  sourcefile: D:\Python36\lib\site-packages\keras\losses.py
- doc: null
  kind: losses
  name: mean_absolute_error
  parameters:
  - {kind: any, name: y_true}
  - {kind: any, name: y_pred}
  source: "def mean_absolute_error(y_true, y_pred):\n    return K.mean(K.abs(y_pred\
    \ - y_true), axis=-1)\n"
  sourcefile: D:\Python36\lib\site-packages\keras\losses.py
- doc: null
  kind: losses
  name: mean_absolute_percentage_error
  parameters:
  - {kind: any, name: y_true}
  - {kind: any, name: y_pred}
  source: "def mean_absolute_percentage_error(y_true, y_pred):\n    diff = K.abs((y_true\
    \ - y_pred) / K.clip(K.abs(y_true),\n                                        \
    \    K.epsilon(),\n                                            None))\n    return\
    \ 100. * K.mean(diff, axis=-1)\n"
  sourcefile: D:\Python36\lib\site-packages\keras\losses.py
- doc: null
  kind: losses
  name: mean_squared_error
  parameters:
  - {kind: any, name: y_true}
  - {kind: any, name: y_pred}
  source: "def mean_squared_error(y_true, y_pred):\n    return K.mean(K.square(y_pred\
    \ - y_true), axis=-1)\n"
  sourcefile: D:\Python36\lib\site-packages\keras\losses.py
- doc: null
  kind: losses
  name: mean_squared_logarithmic_error
  parameters:
  - {kind: any, name: y_true}
  - {kind: any, name: y_pred}
  source: "def mean_squared_logarithmic_error(y_true, y_pred):\n    first_log = K.log(K.clip(y_pred,\
    \ K.epsilon(), None) + 1.)\n    second_log = K.log(K.clip(y_true, K.epsilon(),\
    \ None) + 1.)\n    return K.mean(K.square(first_log - second_log), axis=-1)\n"
  sourcefile: D:\Python36\lib\site-packages\keras\losses.py
- doc: null
  kind: losses
  name: mean_squared_error
  parameters:
  - {kind: any, name: y_true}
  - {kind: any, name: y_pred}
  source: "def mean_squared_error(y_true, y_pred):\n    return K.mean(K.square(y_pred\
    \ - y_true), axis=-1)\n"
  sourcefile: D:\Python36\lib\site-packages\keras\losses.py
- doc: null
  kind: losses
  name: mean_squared_logarithmic_error
  parameters:
  - {kind: any, name: y_true}
  - {kind: any, name: y_pred}
  source: "def mean_squared_logarithmic_error(y_true, y_pred):\n    first_log = K.log(K.clip(y_pred,\
    \ K.epsilon(), None) + 1.)\n    second_log = K.log(K.clip(y_true, K.epsilon(),\
    \ None) + 1.)\n    return K.mean(K.square(first_log - second_log), axis=-1)\n"
  sourcefile: D:\Python36\lib\site-packages\keras\losses.py
- doc: null
  kind: losses
  name: poisson
  parameters:
  - {kind: any, name: y_true}
  - {kind: any, name: y_pred}
  source: "def poisson(y_true, y_pred):\n    return K.mean(y_pred - y_true * K.log(y_pred\
    \ + K.epsilon()), axis=-1)\n"
  sourcefile: D:\Python36\lib\site-packages\keras\losses.py
- doc: null
  kind: losses
  name: sparse_categorical_crossentropy
  parameters:
  - {kind: any, name: y_true}
  - {kind: any, name: y_pred}
  source: "def sparse_categorical_crossentropy(y_true, y_pred):\n    return K.sparse_categorical_crossentropy(y_true,\
    \ y_pred)\n"
  sourcefile: D:\Python36\lib\site-packages\keras\losses.py
- doc: null
  kind: losses
  name: squared_hinge
  parameters:
  - {kind: any, name: y_true}
  - {kind: any, name: y_pred}
  source: "def squared_hinge(y_true, y_pred):\n    return K.mean(K.square(K.maximum(1.\
    \ - y_true * y_pred, 0.)), axis=-1)\n"
  sourcefile: D:\Python36\lib\site-packages\keras\losses.py
- doc: null
  kind: metrics
  name: mean_absolute_error
  parameters:
  - {kind: any, name: y_true}
  - {kind: any, name: y_pred}
  source: "def mean_absolute_error(y_true, y_pred):\n    return K.mean(K.abs(y_pred\
    \ - y_true), axis=-1)\n"
  sourcefile: D:\Python36\lib\site-packages\keras\losses.py
- doc: null
  kind: metrics
  name: mean_absolute_percentage_error
  parameters:
  - {kind: any, name: y_true}
  - {kind: any, name: y_pred}
  source: "def mean_absolute_percentage_error(y_true, y_pred):\n    diff = K.abs((y_true\
    \ - y_pred) / K.clip(K.abs(y_true),\n                                        \
    \    K.epsilon(),\n                                            None))\n    return\
    \ 100. * K.mean(diff, axis=-1)\n"
  sourcefile: D:\Python36\lib\site-packages\keras\losses.py
- doc: null
  kind: metrics
  name: mean_squared_error
  parameters:
  - {kind: any, name: y_true}
  - {kind: any, name: y_pred}
  source: "def mean_squared_error(y_true, y_pred):\n    return K.mean(K.square(y_pred\
    \ - y_true), axis=-1)\n"
  sourcefile: D:\Python36\lib\site-packages\keras\losses.py
- doc: null
  kind: metrics
  name: mean_squared_logarithmic_error
  parameters:
  - {kind: any, name: y_true}
  - {kind: any, name: y_pred}
  source: "def mean_squared_logarithmic_error(y_true, y_pred):\n    first_log = K.log(K.clip(y_pred,\
    \ K.epsilon(), None) + 1.)\n    second_log = K.log(K.clip(y_true, K.epsilon(),\
    \ None) + 1.)\n    return K.mean(K.square(first_log - second_log), axis=-1)\n"
  sourcefile: D:\Python36\lib\site-packages\keras\losses.py
- doc: null
  kind: metrics
  name: binary_accuracy
  parameters:
  - {kind: any, name: y_true}
  - {kind: any, name: y_pred}
  source: "def binary_accuracy(y_true, y_pred):\n    return K.mean(K.equal(y_true,\
    \ K.round(y_pred)), axis=-1)\n"
  sourcefile: D:\Python36\lib\site-packages\keras\metrics.py
- doc: null
  kind: metrics
  name: binary_crossentropy
  parameters:
  - {kind: any, name: y_true}
  - {kind: any, name: y_pred}
  source: "def binary_crossentropy(y_true, y_pred):\n    return K.mean(K.binary_crossentropy(y_true,\
    \ y_pred), axis=-1)\n"
  sourcefile: D:\Python36\lib\site-packages\keras\losses.py
- doc: null
  kind: metrics
  name: categorical_accuracy
  parameters:
  - {kind: any, name: y_true}
  - {kind: any, name: y_pred}
  source: "def categorical_accuracy(y_true, y_pred):\n    return K.cast(K.equal(K.argmax(y_true,\
    \ axis=-1),\n                          K.argmax(y_pred, axis=-1)),\n         \
    \         K.floatx())\n"
  sourcefile: D:\Python36\lib\site-packages\keras\metrics.py
- doc: null
  kind: metrics
  name: categorical_crossentropy
  parameters:
  - {kind: any, name: y_true}
  - {kind: any, name: y_pred}
  source: "def categorical_crossentropy(y_true, y_pred):\n    return K.categorical_crossentropy(y_true,\
    \ y_pred)\n"
  sourcefile: D:\Python36\lib\site-packages\keras\losses.py
- doc: null
  kind: metrics
  name: cosine_proximity
  parameters:
  - {kind: any, name: y_true}
  - {kind: any, name: y_pred}
  source: "def cosine_proximity(y_true, y_pred):\n    y_true = K.l2_normalize(y_true,\
    \ axis=-1)\n    y_pred = K.l2_normalize(y_pred, axis=-1)\n    return -K.sum(y_true\
    \ * y_pred, axis=-1)\n"
  sourcefile: D:\Python36\lib\site-packages\keras\losses.py
- doc: null
  kind: metrics
  name: cosine_proximity
  parameters:
  - {kind: any, name: y_true}
  - {kind: any, name: y_pred}
  source: "def cosine_proximity(y_true, y_pred):\n    y_true = K.l2_normalize(y_true,\
    \ axis=-1)\n    y_pred = K.l2_normalize(y_pred, axis=-1)\n    return -K.sum(y_true\
    \ * y_pred, axis=-1)\n"
  sourcefile: D:\Python36\lib\site-packages\keras\losses.py
- doc: null
  kind: metrics
  name: hinge
  parameters:
  - {kind: any, name: y_true}
  - {kind: any, name: y_pred}
  source: "def hinge(y_true, y_pred):\n    return K.mean(K.maximum(1. - y_true * y_pred,\
    \ 0.), axis=-1)\n"
  sourcefile: D:\Python36\lib\site-packages\keras\losses.py
- doc: null
  kind: metrics
  name: kullback_leibler_divergence
  parameters:
  - {kind: any, name: y_true}
  - {kind: any, name: y_pred}
  source: "def kullback_leibler_divergence(y_true, y_pred):\n    y_true = K.clip(y_true,\
    \ K.epsilon(), 1)\n    y_pred = K.clip(y_pred, K.epsilon(), 1)\n    return K.sum(y_true\
    \ * K.log(y_true / y_pred), axis=-1)\n"
  sourcefile: D:\Python36\lib\site-packages\keras\losses.py
- doc: "Logarithm of the hyperbolic cosine of the prediction error.\n\n`log(cosh(x))`\
    \ is approximately equal to `(x ** 2) / 2` for small `x` and\nto `abs(x) - log(2)`\
    \ for large `x`. This means that 'logcosh' works mostly\nlike the mean squared\
    \ error, but will not be so strongly affected by the\noccasional wildly incorrect\
    \ prediction.\n\n# Arguments\n    y_true: tensor of true targets.\n    y_pred:\
    \ tensor of predicted targets.\n\n# Returns\n    Tensor with one scalar loss entry\
    \ per sample."
  kind: metrics
  name: logcosh
  parameters:
  - {kind: any, name: y_true}
  - {kind: any, name: y_pred}
  source: "def logcosh(y_true, y_pred):\n    \"\"\"Logarithm of the hyperbolic cosine\
    \ of the prediction error.\n\n    `log(cosh(x))` is approximately equal to `(x\
    \ ** 2) / 2` for small `x` and\n    to `abs(x) - log(2)` for large `x`. This means\
    \ that 'logcosh' works mostly\n    like the mean squared error, but will not be\
    \ so strongly affected by the\n    occasional wildly incorrect prediction.\n\n\
    \    # Arguments\n        y_true: tensor of true targets.\n        y_pred: tensor\
    \ of predicted targets.\n\n    # Returns\n        Tensor with one scalar loss\
    \ entry per sample.\n    \"\"\"\n    def _logcosh(x):\n        return x + K.softplus(-2.\
    \ * x) - K.log(2.)\n    return K.mean(_logcosh(y_pred - y_true), axis=-1)\n"
  sourcefile: D:\Python36\lib\site-packages\keras\losses.py
- doc: null
  kind: metrics
  name: mean_absolute_error
  parameters:
  - {kind: any, name: y_true}
  - {kind: any, name: y_pred}
  source: "def mean_absolute_error(y_true, y_pred):\n    return K.mean(K.abs(y_pred\
    \ - y_true), axis=-1)\n"
  sourcefile: D:\Python36\lib\site-packages\keras\losses.py
- doc: null
  kind: metrics
  name: mean_absolute_percentage_error
  parameters:
  - {kind: any, name: y_true}
  - {kind: any, name: y_pred}
  source: "def mean_absolute_percentage_error(y_true, y_pred):\n    diff = K.abs((y_true\
    \ - y_pred) / K.clip(K.abs(y_true),\n                                        \
    \    K.epsilon(),\n                                            None))\n    return\
    \ 100. * K.mean(diff, axis=-1)\n"
  sourcefile: D:\Python36\lib\site-packages\keras\losses.py
- doc: null
  kind: metrics
  name: mean_absolute_error
  parameters:
  - {kind: any, name: y_true}
  - {kind: any, name: y_pred}
  source: "def mean_absolute_error(y_true, y_pred):\n    return K.mean(K.abs(y_pred\
    \ - y_true), axis=-1)\n"
  sourcefile: D:\Python36\lib\site-packages\keras\losses.py
- doc: null
  kind: metrics
  name: mean_absolute_percentage_error
  parameters:
  - {kind: any, name: y_true}
  - {kind: any, name: y_pred}
  source: "def mean_absolute_percentage_error(y_true, y_pred):\n    diff = K.abs((y_true\
    \ - y_pred) / K.clip(K.abs(y_true),\n                                        \
    \    K.epsilon(),\n                                            None))\n    return\
    \ 100. * K.mean(diff, axis=-1)\n"
  sourcefile: D:\Python36\lib\site-packages\keras\losses.py
- doc: null
  kind: metrics
  name: mean_squared_error
  parameters:
  - {kind: any, name: y_true}
  - {kind: any, name: y_pred}
  source: "def mean_squared_error(y_true, y_pred):\n    return K.mean(K.square(y_pred\
    \ - y_true), axis=-1)\n"
  sourcefile: D:\Python36\lib\site-packages\keras\losses.py
- doc: null
  kind: metrics
  name: mean_squared_logarithmic_error
  parameters:
  - {kind: any, name: y_true}
  - {kind: any, name: y_pred}
  source: "def mean_squared_logarithmic_error(y_true, y_pred):\n    first_log = K.log(K.clip(y_pred,\
    \ K.epsilon(), None) + 1.)\n    second_log = K.log(K.clip(y_true, K.epsilon(),\
    \ None) + 1.)\n    return K.mean(K.square(first_log - second_log), axis=-1)\n"
  sourcefile: D:\Python36\lib\site-packages\keras\losses.py
- doc: null
  kind: metrics
  name: mean_squared_error
  parameters:
  - {kind: any, name: y_true}
  - {kind: any, name: y_pred}
  source: "def mean_squared_error(y_true, y_pred):\n    return K.mean(K.square(y_pred\
    \ - y_true), axis=-1)\n"
  sourcefile: D:\Python36\lib\site-packages\keras\losses.py
- doc: null
  kind: metrics
  name: mean_squared_logarithmic_error
  parameters:
  - {kind: any, name: y_true}
  - {kind: any, name: y_pred}
  source: "def mean_squared_logarithmic_error(y_true, y_pred):\n    first_log = K.log(K.clip(y_pred,\
    \ K.epsilon(), None) + 1.)\n    second_log = K.log(K.clip(y_true, K.epsilon(),\
    \ None) + 1.)\n    return K.mean(K.square(first_log - second_log), axis=-1)\n"
  sourcefile: D:\Python36\lib\site-packages\keras\losses.py
- doc: null
  kind: metrics
  name: poisson
  parameters:
  - {kind: any, name: y_true}
  - {kind: any, name: y_pred}
  source: "def poisson(y_true, y_pred):\n    return K.mean(y_pred - y_true * K.log(y_pred\
    \ + K.epsilon()), axis=-1)\n"
  sourcefile: D:\Python36\lib\site-packages\keras\losses.py
- doc: null
  kind: metrics
  name: sparse_categorical_accuracy
  parameters:
  - {kind: any, name: y_true}
  - {kind: any, name: y_pred}
  source: "def sparse_categorical_accuracy(y_true, y_pred):\n    # flatten y_true\
    \ in case it's in shape (num_samples, 1) instead of (num_samples,)\n    return\
    \ K.cast(K.equal(K.flatten(y_true),\n                          K.cast(K.argmax(y_pred,\
    \ axis=-1), K.floatx())),\n                  K.floatx())\n"
  sourcefile: D:\Python36\lib\site-packages\keras\metrics.py
- doc: null
  kind: metrics
  name: sparse_categorical_crossentropy
  parameters:
  - {kind: any, name: y_true}
  - {kind: any, name: y_pred}
  source: "def sparse_categorical_crossentropy(y_true, y_pred):\n    return K.sparse_categorical_crossentropy(y_true,\
    \ y_pred)\n"
  sourcefile: D:\Python36\lib\site-packages\keras\losses.py
- doc: null
  kind: metrics
  name: sparse_top_k_categorical_accuracy
  parameters:
  - {kind: any, name: y_true}
  - {kind: any, name: y_pred}
  - {defaultValue: '5', kind: any, name: k}
  source: "def sparse_top_k_categorical_accuracy(y_true, y_pred, k=5):\n    # If the\
    \ shape of y_true is (num_samples, 1), flatten to (num_samples,)\n    return K.mean(K.in_top_k(y_pred,\
    \ K.cast(K.flatten(y_true), 'int32'), k),\n                  axis=-1)\n"
  sourcefile: D:\Python36\lib\site-packages\keras\metrics.py
- doc: null
  kind: metrics
  name: squared_hinge
  parameters:
  - {kind: any, name: y_true}
  - {kind: any, name: y_pred}
  source: "def squared_hinge(y_true, y_pred):\n    return K.mean(K.square(K.maximum(1.\
    \ - y_true * y_pred, 0.)), axis=-1)\n"
  sourcefile: D:\Python36\lib\site-packages\keras\losses.py
- doc: null
  kind: metrics
  name: top_k_categorical_accuracy
  parameters:
  - {kind: any, name: y_true}
  - {kind: any, name: y_pred}
  - {defaultValue: '5', kind: any, name: k}
  source: "def top_k_categorical_accuracy(y_true, y_pred, k=5):\n    return K.mean(K.in_top_k(y_pred,\
    \ K.argmax(y_true, axis=-1), k), axis=-1)\n"
  sourcefile: D:\Python36\lib\site-packages\keras\metrics.py
- doc: "Adadelta optimizer.\n\nAdadelta is a more robust extension of Adagrad\nthat\
    \ adapts learning rates based on a moving window of gradient updates,\ninstead\
    \ of accumulating all past gradients. This way, Adadelta continues\nlearning even\
    \ when many updates have been done. Compared to Adagrad, in the\noriginal version\
    \ of Adadelta you don't have to set an initial learning\nrate. In this version,\
    \ initial learning rate and decay factor can\nbe set, as in most other Keras optimizers.\n\
    \nIt is recommended to leave the parameters of this optimizer\nat their default\
    \ values.\n\n# Arguments\n    lr: float >= 0. Initial learning rate, defaults\
    \ to 1.\n        It is recommended to leave it at the default value.\n    rho:\
    \ float >= 0. Adadelta decay factor, corresponding to fraction of\n        gradient\
    \ to keep at each time step.\n    epsilon: float >= 0. Fuzz factor. If `None`,\
    \ defaults to `K.epsilon()`.\n    decay: float >= 0. Initial learning rate decay.\n\
    \n# References\n    - [Adadelta - an adaptive learning rate method]\n      (https://arxiv.org/abs/1212.5701)"
  kind: Optimizer
  name: Adadelta
  parameters:
  - {defaultValue: '1.0', kind: any, name: lr}
  - {defaultValue: '0.95', kind: any, name: rho}
  - {defaultValue: None, kind: any, name: epsilon}
  - {defaultValue: '0.0', kind: any, name: decay}
  source: "class Adadelta(Optimizer):\n    \"\"\"Adadelta optimizer.\n\n    Adadelta\
    \ is a more robust extension of Adagrad\n    that adapts learning rates based\
    \ on a moving window of gradient updates,\n    instead of accumulating all past\
    \ gradients. This way, Adadelta continues\n    learning even when many updates\
    \ have been done. Compared to Adagrad, in the\n    original version of Adadelta\
    \ you don't have to set an initial learning\n    rate. In this version, initial\
    \ learning rate and decay factor can\n    be set, as in most other Keras optimizers.\n\
    \n    It is recommended to leave the parameters of this optimizer\n    at their\
    \ default values.\n\n    # Arguments\n        lr: float >= 0. Initial learning\
    \ rate, defaults to 1.\n            It is recommended to leave it at the default\
    \ value.\n        rho: float >= 0. Adadelta decay factor, corresponding to fraction\
    \ of\n            gradient to keep at each time step.\n        epsilon: float\
    \ >= 0. Fuzz factor. If `None`, defaults to `K.epsilon()`.\n        decay: float\
    \ >= 0. Initial learning rate decay.\n\n    # References\n        - [Adadelta\
    \ - an adaptive learning rate method]\n          (https://arxiv.org/abs/1212.5701)\n\
    \    \"\"\"\n\n    def __init__(self, lr=1.0, rho=0.95, epsilon=None, decay=0.,\n\
    \                 **kwargs):\n        super(Adadelta, self).__init__(**kwargs)\n\
    \        with K.name_scope(self.__class__.__name__):\n            self.lr = K.variable(lr,\
    \ name='lr')\n            self.decay = K.variable(decay, name='decay')\n     \
    \       self.iterations = K.variable(0, dtype='int64', name='iterations')\n  \
    \      if epsilon is None:\n            epsilon = K.epsilon()\n        self.rho\
    \ = rho\n        self.epsilon = epsilon\n        self.initial_decay = decay\n\n\
    \    @interfaces.legacy_get_updates_support\n    def get_updates(self, loss, params):\n\
    \        grads = self.get_gradients(loss, params)\n        shapes = [K.int_shape(p)\
    \ for p in params]\n        accumulators = [K.zeros(shape) for shape in shapes]\n\
    \        delta_accumulators = [K.zeros(shape) for shape in shapes]\n        self.weights\
    \ = accumulators + delta_accumulators\n        self.updates = [K.update_add(self.iterations,\
    \ 1)]\n\n        lr = self.lr\n        if self.initial_decay > 0:\n          \
    \  lr = lr * (1. / (1. + self.decay * K.cast(self.iterations,\n              \
    \                                        K.dtype(self.decay))))\n\n        for\
    \ p, g, a, d_a in zip(params, grads, accumulators, delta_accumulators):\n    \
    \        # update accumulator\n            new_a = self.rho * a + (1. - self.rho)\
    \ * K.square(g)\n            self.updates.append(K.update(a, new_a))\n\n     \
    \       # use the new accumulator and the *old* delta_accumulator\n          \
    \  update = g * K.sqrt(d_a + self.epsilon) / K.sqrt(new_a + self.epsilon)\n  \
    \          new_p = p - lr * update\n\n            # Apply constraints.\n     \
    \       if getattr(p, 'constraint', None) is not None:\n                new_p\
    \ = p.constraint(new_p)\n\n            self.updates.append(K.update(p, new_p))\n\
    \n            # update delta_accumulator\n            new_d_a = self.rho * d_a\
    \ + (1 - self.rho) * K.square(update)\n            self.updates.append(K.update(d_a,\
    \ new_d_a))\n        return self.updates\n\n    def get_config(self):\n      \
    \  config = {'lr': float(K.get_value(self.lr)),\n                  'rho': self.rho,\n\
    \                  'decay': float(K.get_value(self.decay)),\n                \
    \  'epsilon': self.epsilon}\n        base_config = super(Adadelta, self).get_config()\n\
    \        return dict(list(base_config.items()) + list(config.items()))\n"
  sourcefile: D:\Python36\lib\site-packages\keras\optimizers.py
- doc: "Adagrad optimizer.\n\nAdagrad is an optimizer with parameter-specific learning\
    \ rates,\nwhich are adapted relative to how frequently a parameter gets\nupdated\
    \ during training. The more updates a parameter receives,\nthe smaller the updates.\n\
    \nIt is recommended to leave the parameters of this optimizer\nat their default\
    \ values.\n\n# Arguments\n    lr: float >= 0. Initial learning rate.\n    epsilon:\
    \ float >= 0. If `None`, defaults to `K.epsilon()`.\n    decay: float >= 0. Learning\
    \ rate decay over each update.\n\n# References\n    - [Adaptive Subgradient Methods\
    \ for Online Learning and Stochastic\n       Optimization](http://www.jmlr.org/papers/volume12/duchi11a/duchi11a.pdf)"
  kind: Optimizer
  name: Adagrad
  parameters:
  - {defaultValue: '0.01', kind: any, name: lr}
  - {defaultValue: None, kind: any, name: epsilon}
  - {defaultValue: '0.0', kind: any, name: decay}
  source: "class Adagrad(Optimizer):\n    \"\"\"Adagrad optimizer.\n\n    Adagrad\
    \ is an optimizer with parameter-specific learning rates,\n    which are adapted\
    \ relative to how frequently a parameter gets\n    updated during training. The\
    \ more updates a parameter receives,\n    the smaller the updates.\n\n    It is\
    \ recommended to leave the parameters of this optimizer\n    at their default\
    \ values.\n\n    # Arguments\n        lr: float >= 0. Initial learning rate.\n\
    \        epsilon: float >= 0. If `None`, defaults to `K.epsilon()`.\n        decay:\
    \ float >= 0. Learning rate decay over each update.\n\n    # References\n    \
    \    - [Adaptive Subgradient Methods for Online Learning and Stochastic\n    \
    \       Optimization](http://www.jmlr.org/papers/volume12/duchi11a/duchi11a.pdf)\n\
    \    \"\"\"\n\n    def __init__(self, lr=0.01, epsilon=None, decay=0., **kwargs):\n\
    \        super(Adagrad, self).__init__(**kwargs)\n        with K.name_scope(self.__class__.__name__):\n\
    \            self.lr = K.variable(lr, name='lr')\n            self.decay = K.variable(decay,\
    \ name='decay')\n            self.iterations = K.variable(0, dtype='int64', name='iterations')\n\
    \        if epsilon is None:\n            epsilon = K.epsilon()\n        self.epsilon\
    \ = epsilon\n        self.initial_decay = decay\n\n    @interfaces.legacy_get_updates_support\n\
    \    def get_updates(self, loss, params):\n        grads = self.get_gradients(loss,\
    \ params)\n        shapes = [K.int_shape(p) for p in params]\n        accumulators\
    \ = [K.zeros(shape) for shape in shapes]\n        self.weights = accumulators\n\
    \        self.updates = [K.update_add(self.iterations, 1)]\n\n        lr = self.lr\n\
    \        if self.initial_decay > 0:\n            lr = lr * (1. / (1. + self.decay\
    \ * K.cast(self.iterations,\n                                                \
    \      K.dtype(self.decay))))\n\n        for p, g, a in zip(params, grads, accumulators):\n\
    \            new_a = a + K.square(g)  # update accumulator\n            self.updates.append(K.update(a,\
    \ new_a))\n            new_p = p - lr * g / (K.sqrt(new_a) + self.epsilon)\n\n\
    \            # Apply constraints.\n            if getattr(p, 'constraint', None)\
    \ is not None:\n                new_p = p.constraint(new_p)\n\n            self.updates.append(K.update(p,\
    \ new_p))\n        return self.updates\n\n    def get_config(self):\n        config\
    \ = {'lr': float(K.get_value(self.lr)),\n                  'decay': float(K.get_value(self.decay)),\n\
    \                  'epsilon': self.epsilon}\n        base_config = super(Adagrad,\
    \ self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))\n"
  sourcefile: D:\Python36\lib\site-packages\keras\optimizers.py
- doc: "Adam optimizer.\n\nDefault parameters follow those provided in the original\
    \ paper.\n\n# Arguments\n    lr: float >= 0. Learning rate.\n    beta_1: float,\
    \ 0 < beta < 1. Generally close to 1.\n    beta_2: float, 0 < beta < 1. Generally\
    \ close to 1.\n    epsilon: float >= 0. Fuzz factor. If `None`, defaults to `K.epsilon()`.\n\
    \    decay: float >= 0. Learning rate decay over each update.\n    amsgrad: boolean.\
    \ Whether to apply the AMSGrad variant of this\n        algorithm from the paper\
    \ \"On the Convergence of Adam and\n        Beyond\".\n\n# References\n    - [Adam\
    \ - A Method for Stochastic Optimization]\n      (https://arxiv.org/abs/1412.6980v8)\n\
    \    - [On the Convergence of Adam and Beyond]\n      (https://openreview.net/forum?id=ryQu7f-RZ)"
  kind: Optimizer
  name: Adam
  parameters:
  - {defaultValue: '0.001', kind: any, name: lr}
  - {defaultValue: '0.9', kind: any, name: beta_1}
  - {defaultValue: '0.999', kind: any, name: beta_2}
  - {defaultValue: None, kind: any, name: epsilon}
  - {defaultValue: '0.0', kind: any, name: decay}
  - {defaultValue: 'False', kind: any, name: amsgrad}
  source: "class Adam(Optimizer):\n    \"\"\"Adam optimizer.\n\n    Default parameters\
    \ follow those provided in the original paper.\n\n    # Arguments\n        lr:\
    \ float >= 0. Learning rate.\n        beta_1: float, 0 < beta < 1. Generally close\
    \ to 1.\n        beta_2: float, 0 < beta < 1. Generally close to 1.\n        epsilon:\
    \ float >= 0. Fuzz factor. If `None`, defaults to `K.epsilon()`.\n        decay:\
    \ float >= 0. Learning rate decay over each update.\n        amsgrad: boolean.\
    \ Whether to apply the AMSGrad variant of this\n            algorithm from the\
    \ paper \"On the Convergence of Adam and\n            Beyond\".\n\n    # References\n\
    \        - [Adam - A Method for Stochastic Optimization]\n          (https://arxiv.org/abs/1412.6980v8)\n\
    \        - [On the Convergence of Adam and Beyond]\n          (https://openreview.net/forum?id=ryQu7f-RZ)\n\
    \    \"\"\"\n\n    def __init__(self, lr=0.001, beta_1=0.9, beta_2=0.999,\n  \
    \               epsilon=None, decay=0., amsgrad=False, **kwargs):\n        super(Adam,\
    \ self).__init__(**kwargs)\n        with K.name_scope(self.__class__.__name__):\n\
    \            self.iterations = K.variable(0, dtype='int64', name='iterations')\n\
    \            self.lr = K.variable(lr, name='lr')\n            self.beta_1 = K.variable(beta_1,\
    \ name='beta_1')\n            self.beta_2 = K.variable(beta_2, name='beta_2')\n\
    \            self.decay = K.variable(decay, name='decay')\n        if epsilon\
    \ is None:\n            epsilon = K.epsilon()\n        self.epsilon = epsilon\n\
    \        self.initial_decay = decay\n        self.amsgrad = amsgrad\n\n    @interfaces.legacy_get_updates_support\n\
    \    def get_updates(self, loss, params):\n        grads = self.get_gradients(loss,\
    \ params)\n        self.updates = [K.update_add(self.iterations, 1)]\n\n     \
    \   lr = self.lr\n        if self.initial_decay > 0:\n            lr = lr * (1.\
    \ / (1. + self.decay * K.cast(self.iterations,\n                             \
    \                         K.dtype(self.decay))))\n\n        t = K.cast(self.iterations,\
    \ K.floatx()) + 1\n        lr_t = lr * (K.sqrt(1. - K.pow(self.beta_2, t)) /\n\
    \                     (1. - K.pow(self.beta_1, t)))\n\n        ms = [K.zeros(K.int_shape(p),\
    \ dtype=K.dtype(p)) for p in params]\n        vs = [K.zeros(K.int_shape(p), dtype=K.dtype(p))\
    \ for p in params]\n        if self.amsgrad:\n            vhats = [K.zeros(K.int_shape(p),\
    \ dtype=K.dtype(p)) for p in params]\n        else:\n            vhats = [K.zeros(1)\
    \ for _ in params]\n        self.weights = [self.iterations] + ms + vs + vhats\n\
    \n        for p, g, m, v, vhat in zip(params, grads, ms, vs, vhats):\n       \
    \     m_t = (self.beta_1 * m) + (1. - self.beta_1) * g\n            v_t = (self.beta_2\
    \ * v) + (1. - self.beta_2) * K.square(g)\n            if self.amsgrad:\n    \
    \            vhat_t = K.maximum(vhat, v_t)\n                p_t = p - lr_t * m_t\
    \ / (K.sqrt(vhat_t) + self.epsilon)\n                self.updates.append(K.update(vhat,\
    \ vhat_t))\n            else:\n                p_t = p - lr_t * m_t / (K.sqrt(v_t)\
    \ + self.epsilon)\n\n            self.updates.append(K.update(m, m_t))\n     \
    \       self.updates.append(K.update(v, v_t))\n            new_p = p_t\n\n   \
    \         # Apply constraints.\n            if getattr(p, 'constraint', None)\
    \ is not None:\n                new_p = p.constraint(new_p)\n\n            self.updates.append(K.update(p,\
    \ new_p))\n        return self.updates\n\n    def get_config(self):\n        config\
    \ = {'lr': float(K.get_value(self.lr)),\n                  'beta_1': float(K.get_value(self.beta_1)),\n\
    \                  'beta_2': float(K.get_value(self.beta_2)),\n              \
    \    'decay': float(K.get_value(self.decay)),\n                  'epsilon': self.epsilon,\n\
    \                  'amsgrad': self.amsgrad}\n        base_config = super(Adam,\
    \ self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))\n"
  sourcefile: D:\Python36\lib\site-packages\keras\optimizers.py
- doc: "Adamax optimizer from Adam paper's Section 7.\n\nIt is a variant of Adam based\
    \ on the infinity norm.\nDefault parameters follow those provided in the paper.\n\
    \n# Arguments\n    lr: float >= 0. Learning rate.\n    beta_1/beta_2: floats,\
    \ 0 < beta < 1. Generally close to 1.\n    epsilon: float >= 0. Fuzz factor. If\
    \ `None`, defaults to `K.epsilon()`.\n    decay: float >= 0. Learning rate decay\
    \ over each update.\n\n# References\n    - [Adam - A Method for Stochastic Optimization]\n\
    \      (https://arxiv.org/abs/1412.6980v8)"
  kind: Optimizer
  name: Adamax
  parameters:
  - {defaultValue: '0.002', kind: any, name: lr}
  - {defaultValue: '0.9', kind: any, name: beta_1}
  - {defaultValue: '0.999', kind: any, name: beta_2}
  - {defaultValue: None, kind: any, name: epsilon}
  - {defaultValue: '0.0', kind: any, name: decay}
  source: "class Adamax(Optimizer):\n    \"\"\"Adamax optimizer from Adam paper's\
    \ Section 7.\n\n    It is a variant of Adam based on the infinity norm.\n    Default\
    \ parameters follow those provided in the paper.\n\n    # Arguments\n        lr:\
    \ float >= 0. Learning rate.\n        beta_1/beta_2: floats, 0 < beta < 1. Generally\
    \ close to 1.\n        epsilon: float >= 0. Fuzz factor. If `None`, defaults to\
    \ `K.epsilon()`.\n        decay: float >= 0. Learning rate decay over each update.\n\
    \n    # References\n        - [Adam - A Method for Stochastic Optimization]\n\
    \          (https://arxiv.org/abs/1412.6980v8)\n    \"\"\"\n\n    def __init__(self,\
    \ lr=0.002, beta_1=0.9, beta_2=0.999,\n                 epsilon=None, decay=0.,\
    \ **kwargs):\n        super(Adamax, self).__init__(**kwargs)\n        with K.name_scope(self.__class__.__name__):\n\
    \            self.iterations = K.variable(0, dtype='int64', name='iterations')\n\
    \            self.lr = K.variable(lr, name='lr')\n            self.beta_1 = K.variable(beta_1,\
    \ name='beta_1')\n            self.beta_2 = K.variable(beta_2, name='beta_2')\n\
    \            self.decay = K.variable(decay, name='decay')\n        if epsilon\
    \ is None:\n            epsilon = K.epsilon()\n        self.epsilon = epsilon\n\
    \        self.initial_decay = decay\n\n    @interfaces.legacy_get_updates_support\n\
    \    def get_updates(self, loss, params):\n        grads = self.get_gradients(loss,\
    \ params)\n        self.updates = [K.update_add(self.iterations, 1)]\n\n     \
    \   lr = self.lr\n        if self.initial_decay > 0:\n            lr = lr * (1.\
    \ / (1. + self.decay * K.cast(self.iterations,\n                             \
    \                         K.dtype(self.decay))))\n\n        t = K.cast(self.iterations,\
    \ K.floatx()) + 1\n        lr_t = lr / (1. - K.pow(self.beta_1, t))\n\n      \
    \  shapes = [K.int_shape(p) for p in params]\n        # zero init of 1st moment\n\
    \        ms = [K.zeros(shape) for shape in shapes]\n        # zero init of exponentially\
    \ weighted infinity norm\n        us = [K.zeros(shape) for shape in shapes]\n\
    \        self.weights = [self.iterations] + ms + us\n\n        for p, g, m, u\
    \ in zip(params, grads, ms, us):\n\n            m_t = (self.beta_1 * m) + (1.\
    \ - self.beta_1) * g\n            u_t = K.maximum(self.beta_2 * u, K.abs(g))\n\
    \            p_t = p - lr_t * m_t / (u_t + self.epsilon)\n\n            self.updates.append(K.update(m,\
    \ m_t))\n            self.updates.append(K.update(u, u_t))\n            new_p\
    \ = p_t\n\n            # Apply constraints.\n            if getattr(p, 'constraint',\
    \ None) is not None:\n                new_p = p.constraint(new_p)\n\n        \
    \    self.updates.append(K.update(p, new_p))\n        return self.updates\n\n\
    \    def get_config(self):\n        config = {'lr': float(K.get_value(self.lr)),\n\
    \                  'beta_1': float(K.get_value(self.beta_1)),\n              \
    \    'beta_2': float(K.get_value(self.beta_2)),\n                  'decay': float(K.get_value(self.decay)),\n\
    \                  'epsilon': self.epsilon}\n        base_config = super(Adamax,\
    \ self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))\n"
  sourcefile: D:\Python36\lib\site-packages\keras\optimizers.py
- doc: "Nesterov Adam optimizer.\n\nMuch like Adam is essentially RMSprop with momentum,\n\
    Nadam is Adam RMSprop with Nesterov momentum.\n\nDefault parameters follow those\
    \ provided in the paper.\nIt is recommended to leave the parameters of this optimizer\n\
    at their default values.\n\n# Arguments\n    lr: float >= 0. Learning rate.\n\
    \    beta_1/beta_2: floats, 0 < beta < 1. Generally close to 1.\n    epsilon:\
    \ float >= 0. Fuzz factor. If `None`, defaults to `K.epsilon()`.\n\n# References\n\
    \    - [Nadam report](http://cs229.stanford.edu/proj2015/054_report.pdf)\n   \
    \ - [On the importance of initialization and momentum in deep learning]\n    \
    \  (http://www.cs.toronto.edu/~fritz/absps/momentum.pdf)"
  kind: Optimizer
  name: Nadam
  parameters:
  - {defaultValue: '0.002', kind: any, name: lr}
  - {defaultValue: '0.9', kind: any, name: beta_1}
  - {defaultValue: '0.999', kind: any, name: beta_2}
  - {defaultValue: None, kind: any, name: epsilon}
  - {defaultValue: '0.004', kind: any, name: schedule_decay}
  source: "class Nadam(Optimizer):\n    \"\"\"Nesterov Adam optimizer.\n\n    Much\
    \ like Adam is essentially RMSprop with momentum,\n    Nadam is Adam RMSprop with\
    \ Nesterov momentum.\n\n    Default parameters follow those provided in the paper.\n\
    \    It is recommended to leave the parameters of this optimizer\n    at their\
    \ default values.\n\n    # Arguments\n        lr: float >= 0. Learning rate.\n\
    \        beta_1/beta_2: floats, 0 < beta < 1. Generally close to 1.\n        epsilon:\
    \ float >= 0. Fuzz factor. If `None`, defaults to `K.epsilon()`.\n\n    # References\n\
    \        - [Nadam report](http://cs229.stanford.edu/proj2015/054_report.pdf)\n\
    \        - [On the importance of initialization and momentum in deep learning]\n\
    \          (http://www.cs.toronto.edu/~fritz/absps/momentum.pdf)\n    \"\"\"\n\
    \n    def __init__(self, lr=0.002, beta_1=0.9, beta_2=0.999,\n               \
    \  epsilon=None, schedule_decay=0.004, **kwargs):\n        super(Nadam, self).__init__(**kwargs)\n\
    \        with K.name_scope(self.__class__.__name__):\n            self.iterations\
    \ = K.variable(0, dtype='int64', name='iterations')\n            self.m_schedule\
    \ = K.variable(1., name='m_schedule')\n            self.lr = K.variable(lr, name='lr')\n\
    \            self.beta_1 = K.variable(beta_1, name='beta_1')\n            self.beta_2\
    \ = K.variable(beta_2, name='beta_2')\n        if epsilon is None:\n         \
    \   epsilon = K.epsilon()\n        self.epsilon = epsilon\n        self.schedule_decay\
    \ = schedule_decay\n\n    @interfaces.legacy_get_updates_support\n    def get_updates(self,\
    \ loss, params):\n        grads = self.get_gradients(loss, params)\n        self.updates\
    \ = [K.update_add(self.iterations, 1)]\n\n        t = K.cast(self.iterations,\
    \ K.floatx()) + 1\n\n        # Due to the recommendations in [2], i.e. warming\
    \ momentum schedule\n        momentum_cache_t = self.beta_1 * (1. - 0.5 * (\n\
    \            K.pow(K.cast_to_floatx(0.96), t * self.schedule_decay)))\n      \
    \  momentum_cache_t_1 = self.beta_1 * (1. - 0.5 * (\n            K.pow(K.cast_to_floatx(0.96),\
    \ (t + 1) * self.schedule_decay)))\n        m_schedule_new = self.m_schedule *\
    \ momentum_cache_t\n        m_schedule_next = self.m_schedule * momentum_cache_t\
    \ * momentum_cache_t_1\n        self.updates.append((self.m_schedule, m_schedule_new))\n\
    \n        shapes = [K.int_shape(p) for p in params]\n        ms = [K.zeros(shape)\
    \ for shape in shapes]\n        vs = [K.zeros(shape) for shape in shapes]\n\n\
    \        self.weights = [self.iterations] + ms + vs\n\n        for p, g, m, v\
    \ in zip(params, grads, ms, vs):\n            # the following equations given\
    \ in [1]\n            g_prime = g / (1. - m_schedule_new)\n            m_t = self.beta_1\
    \ * m + (1. - self.beta_1) * g\n            m_t_prime = m_t / (1. - m_schedule_next)\n\
    \            v_t = self.beta_2 * v + (1. - self.beta_2) * K.square(g)\n      \
    \      v_t_prime = v_t / (1. - K.pow(self.beta_2, t))\n            m_t_bar = (1.\
    \ - momentum_cache_t) * g_prime + (\n                momentum_cache_t_1 * m_t_prime)\n\
    \n            self.updates.append(K.update(m, m_t))\n            self.updates.append(K.update(v,\
    \ v_t))\n\n            p_t = p - self.lr * m_t_bar / (K.sqrt(v_t_prime) + self.epsilon)\n\
    \            new_p = p_t\n\n            # Apply constraints.\n            if getattr(p,\
    \ 'constraint', None) is not None:\n                new_p = p.constraint(new_p)\n\
    \n            self.updates.append(K.update(p, new_p))\n        return self.updates\n\
    \n    def get_config(self):\n        config = {'lr': float(K.get_value(self.lr)),\n\
    \                  'beta_1': float(K.get_value(self.beta_1)),\n              \
    \    'beta_2': float(K.get_value(self.beta_2)),\n                  'epsilon':\
    \ self.epsilon,\n                  'schedule_decay': self.schedule_decay}\n  \
    \      base_config = super(Nadam, self).get_config()\n        return dict(list(base_config.items())\
    \ + list(config.items()))\n"
  sourcefile: D:\Python36\lib\site-packages\keras\optimizers.py
- doc: "RMSProp optimizer.\n\nIt is recommended to leave the parameters of this optimizer\n\
    at their default values\n(except the learning rate, which can be freely tuned).\n\
    \nThis optimizer is usually a good choice for recurrent\nneural networks.\n\n\
    # Arguments\n    lr: float >= 0. Learning rate.\n    rho: float >= 0.\n    epsilon:\
    \ float >= 0. Fuzz factor. If `None`, defaults to `K.epsilon()`.\n    decay: float\
    \ >= 0. Learning rate decay over each update.\n\n# References\n    - [rmsprop:\
    \ Divide the gradient by a running average of its recent magnitude]\n      (http://www.cs.toronto.edu/~tijmen/csc321/slides/lecture_slides_lec6.pdf)"
  kind: Optimizer
  name: RMSprop
  parameters:
  - {defaultValue: '0.001', kind: any, name: lr}
  - {defaultValue: '0.9', kind: any, name: rho}
  - {defaultValue: None, kind: any, name: epsilon}
  - {defaultValue: '0.0', kind: any, name: decay}
  source: "class RMSprop(Optimizer):\n    \"\"\"RMSProp optimizer.\n\n    It is recommended\
    \ to leave the parameters of this optimizer\n    at their default values\n   \
    \ (except the learning rate, which can be freely tuned).\n\n    This optimizer\
    \ is usually a good choice for recurrent\n    neural networks.\n\n    # Arguments\n\
    \        lr: float >= 0. Learning rate.\n        rho: float >= 0.\n        epsilon:\
    \ float >= 0. Fuzz factor. If `None`, defaults to `K.epsilon()`.\n        decay:\
    \ float >= 0. Learning rate decay over each update.\n\n    # References\n    \
    \    - [rmsprop: Divide the gradient by a running average of its recent magnitude]\n\
    \          (http://www.cs.toronto.edu/~tijmen/csc321/slides/lecture_slides_lec6.pdf)\n\
    \    \"\"\"\n\n    def __init__(self, lr=0.001, rho=0.9, epsilon=None, decay=0.,\n\
    \                 **kwargs):\n        super(RMSprop, self).__init__(**kwargs)\n\
    \        with K.name_scope(self.__class__.__name__):\n            self.lr = K.variable(lr,\
    \ name='lr')\n            self.rho = K.variable(rho, name='rho')\n           \
    \ self.decay = K.variable(decay, name='decay')\n            self.iterations =\
    \ K.variable(0, dtype='int64', name='iterations')\n        if epsilon is None:\n\
    \            epsilon = K.epsilon()\n        self.epsilon = epsilon\n        self.initial_decay\
    \ = decay\n\n    @interfaces.legacy_get_updates_support\n    def get_updates(self,\
    \ loss, params):\n        grads = self.get_gradients(loss, params)\n        accumulators\
    \ = [K.zeros(K.int_shape(p), dtype=K.dtype(p)) for p in params]\n        self.weights\
    \ = accumulators\n        self.updates = [K.update_add(self.iterations, 1)]\n\n\
    \        lr = self.lr\n        if self.initial_decay > 0:\n            lr = lr\
    \ * (1. / (1. + self.decay * K.cast(self.iterations,\n                       \
    \                               K.dtype(self.decay))))\n\n        for p, g, a\
    \ in zip(params, grads, accumulators):\n            # update accumulator\n   \
    \         new_a = self.rho * a + (1. - self.rho) * K.square(g)\n            self.updates.append(K.update(a,\
    \ new_a))\n            new_p = p - lr * g / (K.sqrt(new_a) + self.epsilon)\n\n\
    \            # Apply constraints.\n            if getattr(p, 'constraint', None)\
    \ is not None:\n                new_p = p.constraint(new_p)\n\n            self.updates.append(K.update(p,\
    \ new_p))\n        return self.updates\n\n    def get_config(self):\n        config\
    \ = {'lr': float(K.get_value(self.lr)),\n                  'rho': float(K.get_value(self.rho)),\n\
    \                  'decay': float(K.get_value(self.decay)),\n                \
    \  'epsilon': self.epsilon}\n        base_config = super(RMSprop, self).get_config()\n\
    \        return dict(list(base_config.items()) + list(config.items()))\n"
  sourcefile: D:\Python36\lib\site-packages\keras\optimizers.py
- doc: "Stochastic gradient descent optimizer.\n\nIncludes support for momentum,\n\
    learning rate decay, and Nesterov momentum.\n\n# Arguments\n    lr: float >= 0.\
    \ Learning rate.\n    momentum: float >= 0. Parameter that accelerates SGD\n \
    \       in the relevant direction and dampens oscillations.\n    decay: float\
    \ >= 0. Learning rate decay over each update.\n    nesterov: boolean. Whether\
    \ to apply Nesterov momentum."
  kind: Optimizer
  name: SGD
  parameters:
  - {defaultValue: '0.01', kind: any, name: lr}
  - {defaultValue: '0.0', kind: any, name: momentum}
  - {defaultValue: '0.0', kind: any, name: decay}
  - {defaultValue: 'False', kind: any, name: nesterov}
  source: "class SGD(Optimizer):\n    \"\"\"Stochastic gradient descent optimizer.\n\
    \n    Includes support for momentum,\n    learning rate decay, and Nesterov momentum.\n\
    \n    # Arguments\n        lr: float >= 0. Learning rate.\n        momentum: float\
    \ >= 0. Parameter that accelerates SGD\n            in the relevant direction\
    \ and dampens oscillations.\n        decay: float >= 0. Learning rate decay over\
    \ each update.\n        nesterov: boolean. Whether to apply Nesterov momentum.\n\
    \    \"\"\"\n\n    def __init__(self, lr=0.01, momentum=0., decay=0.,\n      \
    \           nesterov=False, **kwargs):\n        super(SGD, self).__init__(**kwargs)\n\
    \        with K.name_scope(self.__class__.__name__):\n            self.iterations\
    \ = K.variable(0, dtype='int64', name='iterations')\n            self.lr = K.variable(lr,\
    \ name='lr')\n            self.momentum = K.variable(momentum, name='momentum')\n\
    \            self.decay = K.variable(decay, name='decay')\n        self.initial_decay\
    \ = decay\n        self.nesterov = nesterov\n\n    @interfaces.legacy_get_updates_support\n\
    \    def get_updates(self, loss, params):\n        grads = self.get_gradients(loss,\
    \ params)\n        self.updates = [K.update_add(self.iterations, 1)]\n\n     \
    \   lr = self.lr\n        if self.initial_decay > 0:\n            lr = lr * (1.\
    \ / (1. + self.decay * K.cast(self.iterations,\n                             \
    \                         K.dtype(self.decay))))\n        # momentum\n       \
    \ shapes = [K.int_shape(p) for p in params]\n        moments = [K.zeros(shape)\
    \ for shape in shapes]\n        self.weights = [self.iterations] + moments\n \
    \       for p, g, m in zip(params, grads, moments):\n            v = self.momentum\
    \ * m - lr * g  # velocity\n            self.updates.append(K.update(m, v))\n\n\
    \            if self.nesterov:\n                new_p = p + self.momentum * v\
    \ - lr * g\n            else:\n                new_p = p + v\n\n            #\
    \ Apply constraints.\n            if getattr(p, 'constraint', None) is not None:\n\
    \                new_p = p.constraint(new_p)\n\n            self.updates.append(K.update(p,\
    \ new_p))\n        return self.updates\n\n    def get_config(self):\n        config\
    \ = {'lr': float(K.get_value(self.lr)),\n                  'momentum': float(K.get_value(self.momentum)),\n\
    \                  'decay': float(K.get_value(self.decay)),\n                \
    \  'nesterov': self.nesterov}\n        base_config = super(SGD, self).get_config()\n\
    \        return dict(list(base_config.items()) + list(config.items()))\n"
  sourcefile: D:\Python36\lib\site-packages\keras\optimizers.py
- doc: "Wrapper class for native TensorFlow optimizers.\n    "
  kind: Optimizer
  name: TFOptimizer
  parameters:
  - {kind: any, name: optimizer}
  source: "class TFOptimizer(Optimizer):\n    \"\"\"Wrapper class for native TensorFlow\
    \ optimizers.\n    \"\"\"\n\n    def __init__(self, optimizer):\n        self.optimizer\
    \ = optimizer\n        with K.name_scope(self.__class__.__name__):\n         \
    \   self.iterations = K.variable(0, dtype='int64', name='iterations')\n\n    @interfaces.legacy_get_updates_support\n\
    \    def get_updates(self, loss, params):\n        grads = self.optimizer.compute_gradients(loss,\
    \ params)\n        self.updates = [K.update_add(self.iterations, 1)]\n       \
    \ opt_update = self.optimizer.apply_gradients(\n            grads, global_step=self.iterations)\n\
    \        self.updates.append(opt_update)\n        return self.updates\n\n    @property\n\
    \    def weights(self):\n        raise NotImplementedError\n\n    def get_config(self):\n\
    \        raise NotImplementedError\n\n    def from_config(self, config):\n   \
    \     raise NotImplementedError\n"
  sourcefile: D:\Python36\lib\site-packages\keras\optimizers.py
- doc: "Adadelta optimizer.\n\nAdadelta is a more robust extension of Adagrad\nthat\
    \ adapts learning rates based on a moving window of gradient updates,\ninstead\
    \ of accumulating all past gradients. This way, Adadelta continues\nlearning even\
    \ when many updates have been done. Compared to Adagrad, in the\noriginal version\
    \ of Adadelta you don't have to set an initial learning\nrate. In this version,\
    \ initial learning rate and decay factor can\nbe set, as in most other Keras optimizers.\n\
    \nIt is recommended to leave the parameters of this optimizer\nat their default\
    \ values.\n\n# Arguments\n    lr: float >= 0. Initial learning rate, defaults\
    \ to 1.\n        It is recommended to leave it at the default value.\n    rho:\
    \ float >= 0. Adadelta decay factor, corresponding to fraction of\n        gradient\
    \ to keep at each time step.\n    epsilon: float >= 0. Fuzz factor. If `None`,\
    \ defaults to `K.epsilon()`.\n    decay: float >= 0. Initial learning rate decay.\n\
    \n# References\n    - [Adadelta - an adaptive learning rate method]\n      (https://arxiv.org/abs/1212.5701)"
  kind: Optimizer
  name: Adadelta
  parameters:
  - {defaultValue: '1.0', kind: any, name: lr}
  - {defaultValue: '0.95', kind: any, name: rho}
  - {defaultValue: None, kind: any, name: epsilon}
  - {defaultValue: '0.0', kind: any, name: decay}
  source: "class Adadelta(Optimizer):\n    \"\"\"Adadelta optimizer.\n\n    Adadelta\
    \ is a more robust extension of Adagrad\n    that adapts learning rates based\
    \ on a moving window of gradient updates,\n    instead of accumulating all past\
    \ gradients. This way, Adadelta continues\n    learning even when many updates\
    \ have been done. Compared to Adagrad, in the\n    original version of Adadelta\
    \ you don't have to set an initial learning\n    rate. In this version, initial\
    \ learning rate and decay factor can\n    be set, as in most other Keras optimizers.\n\
    \n    It is recommended to leave the parameters of this optimizer\n    at their\
    \ default values.\n\n    # Arguments\n        lr: float >= 0. Initial learning\
    \ rate, defaults to 1.\n            It is recommended to leave it at the default\
    \ value.\n        rho: float >= 0. Adadelta decay factor, corresponding to fraction\
    \ of\n            gradient to keep at each time step.\n        epsilon: float\
    \ >= 0. Fuzz factor. If `None`, defaults to `K.epsilon()`.\n        decay: float\
    \ >= 0. Initial learning rate decay.\n\n    # References\n        - [Adadelta\
    \ - an adaptive learning rate method]\n          (https://arxiv.org/abs/1212.5701)\n\
    \    \"\"\"\n\n    def __init__(self, lr=1.0, rho=0.95, epsilon=None, decay=0.,\n\
    \                 **kwargs):\n        super(Adadelta, self).__init__(**kwargs)\n\
    \        with K.name_scope(self.__class__.__name__):\n            self.lr = K.variable(lr,\
    \ name='lr')\n            self.decay = K.variable(decay, name='decay')\n     \
    \       self.iterations = K.variable(0, dtype='int64', name='iterations')\n  \
    \      if epsilon is None:\n            epsilon = K.epsilon()\n        self.rho\
    \ = rho\n        self.epsilon = epsilon\n        self.initial_decay = decay\n\n\
    \    @interfaces.legacy_get_updates_support\n    def get_updates(self, loss, params):\n\
    \        grads = self.get_gradients(loss, params)\n        shapes = [K.int_shape(p)\
    \ for p in params]\n        accumulators = [K.zeros(shape) for shape in shapes]\n\
    \        delta_accumulators = [K.zeros(shape) for shape in shapes]\n        self.weights\
    \ = accumulators + delta_accumulators\n        self.updates = [K.update_add(self.iterations,\
    \ 1)]\n\n        lr = self.lr\n        if self.initial_decay > 0:\n          \
    \  lr = lr * (1. / (1. + self.decay * K.cast(self.iterations,\n              \
    \                                        K.dtype(self.decay))))\n\n        for\
    \ p, g, a, d_a in zip(params, grads, accumulators, delta_accumulators):\n    \
    \        # update accumulator\n            new_a = self.rho * a + (1. - self.rho)\
    \ * K.square(g)\n            self.updates.append(K.update(a, new_a))\n\n     \
    \       # use the new accumulator and the *old* delta_accumulator\n          \
    \  update = g * K.sqrt(d_a + self.epsilon) / K.sqrt(new_a + self.epsilon)\n  \
    \          new_p = p - lr * update\n\n            # Apply constraints.\n     \
    \       if getattr(p, 'constraint', None) is not None:\n                new_p\
    \ = p.constraint(new_p)\n\n            self.updates.append(K.update(p, new_p))\n\
    \n            # update delta_accumulator\n            new_d_a = self.rho * d_a\
    \ + (1 - self.rho) * K.square(update)\n            self.updates.append(K.update(d_a,\
    \ new_d_a))\n        return self.updates\n\n    def get_config(self):\n      \
    \  config = {'lr': float(K.get_value(self.lr)),\n                  'rho': self.rho,\n\
    \                  'decay': float(K.get_value(self.decay)),\n                \
    \  'epsilon': self.epsilon}\n        base_config = super(Adadelta, self).get_config()\n\
    \        return dict(list(base_config.items()) + list(config.items()))\n"
  sourcefile: D:\Python36\lib\site-packages\keras\optimizers.py
- doc: "Adagrad optimizer.\n\nAdagrad is an optimizer with parameter-specific learning\
    \ rates,\nwhich are adapted relative to how frequently a parameter gets\nupdated\
    \ during training. The more updates a parameter receives,\nthe smaller the updates.\n\
    \nIt is recommended to leave the parameters of this optimizer\nat their default\
    \ values.\n\n# Arguments\n    lr: float >= 0. Initial learning rate.\n    epsilon:\
    \ float >= 0. If `None`, defaults to `K.epsilon()`.\n    decay: float >= 0. Learning\
    \ rate decay over each update.\n\n# References\n    - [Adaptive Subgradient Methods\
    \ for Online Learning and Stochastic\n       Optimization](http://www.jmlr.org/papers/volume12/duchi11a/duchi11a.pdf)"
  kind: Optimizer
  name: Adagrad
  parameters:
  - {defaultValue: '0.01', kind: any, name: lr}
  - {defaultValue: None, kind: any, name: epsilon}
  - {defaultValue: '0.0', kind: any, name: decay}
  source: "class Adagrad(Optimizer):\n    \"\"\"Adagrad optimizer.\n\n    Adagrad\
    \ is an optimizer with parameter-specific learning rates,\n    which are adapted\
    \ relative to how frequently a parameter gets\n    updated during training. The\
    \ more updates a parameter receives,\n    the smaller the updates.\n\n    It is\
    \ recommended to leave the parameters of this optimizer\n    at their default\
    \ values.\n\n    # Arguments\n        lr: float >= 0. Initial learning rate.\n\
    \        epsilon: float >= 0. If `None`, defaults to `K.epsilon()`.\n        decay:\
    \ float >= 0. Learning rate decay over each update.\n\n    # References\n    \
    \    - [Adaptive Subgradient Methods for Online Learning and Stochastic\n    \
    \       Optimization](http://www.jmlr.org/papers/volume12/duchi11a/duchi11a.pdf)\n\
    \    \"\"\"\n\n    def __init__(self, lr=0.01, epsilon=None, decay=0., **kwargs):\n\
    \        super(Adagrad, self).__init__(**kwargs)\n        with K.name_scope(self.__class__.__name__):\n\
    \            self.lr = K.variable(lr, name='lr')\n            self.decay = K.variable(decay,\
    \ name='decay')\n            self.iterations = K.variable(0, dtype='int64', name='iterations')\n\
    \        if epsilon is None:\n            epsilon = K.epsilon()\n        self.epsilon\
    \ = epsilon\n        self.initial_decay = decay\n\n    @interfaces.legacy_get_updates_support\n\
    \    def get_updates(self, loss, params):\n        grads = self.get_gradients(loss,\
    \ params)\n        shapes = [K.int_shape(p) for p in params]\n        accumulators\
    \ = [K.zeros(shape) for shape in shapes]\n        self.weights = accumulators\n\
    \        self.updates = [K.update_add(self.iterations, 1)]\n\n        lr = self.lr\n\
    \        if self.initial_decay > 0:\n            lr = lr * (1. / (1. + self.decay\
    \ * K.cast(self.iterations,\n                                                \
    \      K.dtype(self.decay))))\n\n        for p, g, a in zip(params, grads, accumulators):\n\
    \            new_a = a + K.square(g)  # update accumulator\n            self.updates.append(K.update(a,\
    \ new_a))\n            new_p = p - lr * g / (K.sqrt(new_a) + self.epsilon)\n\n\
    \            # Apply constraints.\n            if getattr(p, 'constraint', None)\
    \ is not None:\n                new_p = p.constraint(new_p)\n\n            self.updates.append(K.update(p,\
    \ new_p))\n        return self.updates\n\n    def get_config(self):\n        config\
    \ = {'lr': float(K.get_value(self.lr)),\n                  'decay': float(K.get_value(self.decay)),\n\
    \                  'epsilon': self.epsilon}\n        base_config = super(Adagrad,\
    \ self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))\n"
  sourcefile: D:\Python36\lib\site-packages\keras\optimizers.py
- doc: "Adam optimizer.\n\nDefault parameters follow those provided in the original\
    \ paper.\n\n# Arguments\n    lr: float >= 0. Learning rate.\n    beta_1: float,\
    \ 0 < beta < 1. Generally close to 1.\n    beta_2: float, 0 < beta < 1. Generally\
    \ close to 1.\n    epsilon: float >= 0. Fuzz factor. If `None`, defaults to `K.epsilon()`.\n\
    \    decay: float >= 0. Learning rate decay over each update.\n    amsgrad: boolean.\
    \ Whether to apply the AMSGrad variant of this\n        algorithm from the paper\
    \ \"On the Convergence of Adam and\n        Beyond\".\n\n# References\n    - [Adam\
    \ - A Method for Stochastic Optimization]\n      (https://arxiv.org/abs/1412.6980v8)\n\
    \    - [On the Convergence of Adam and Beyond]\n      (https://openreview.net/forum?id=ryQu7f-RZ)"
  kind: Optimizer
  name: Adam
  parameters:
  - {defaultValue: '0.001', kind: any, name: lr}
  - {defaultValue: '0.9', kind: any, name: beta_1}
  - {defaultValue: '0.999', kind: any, name: beta_2}
  - {defaultValue: None, kind: any, name: epsilon}
  - {defaultValue: '0.0', kind: any, name: decay}
  - {defaultValue: 'False', kind: any, name: amsgrad}
  source: "class Adam(Optimizer):\n    \"\"\"Adam optimizer.\n\n    Default parameters\
    \ follow those provided in the original paper.\n\n    # Arguments\n        lr:\
    \ float >= 0. Learning rate.\n        beta_1: float, 0 < beta < 1. Generally close\
    \ to 1.\n        beta_2: float, 0 < beta < 1. Generally close to 1.\n        epsilon:\
    \ float >= 0. Fuzz factor. If `None`, defaults to `K.epsilon()`.\n        decay:\
    \ float >= 0. Learning rate decay over each update.\n        amsgrad: boolean.\
    \ Whether to apply the AMSGrad variant of this\n            algorithm from the\
    \ paper \"On the Convergence of Adam and\n            Beyond\".\n\n    # References\n\
    \        - [Adam - A Method for Stochastic Optimization]\n          (https://arxiv.org/abs/1412.6980v8)\n\
    \        - [On the Convergence of Adam and Beyond]\n          (https://openreview.net/forum?id=ryQu7f-RZ)\n\
    \    \"\"\"\n\n    def __init__(self, lr=0.001, beta_1=0.9, beta_2=0.999,\n  \
    \               epsilon=None, decay=0., amsgrad=False, **kwargs):\n        super(Adam,\
    \ self).__init__(**kwargs)\n        with K.name_scope(self.__class__.__name__):\n\
    \            self.iterations = K.variable(0, dtype='int64', name='iterations')\n\
    \            self.lr = K.variable(lr, name='lr')\n            self.beta_1 = K.variable(beta_1,\
    \ name='beta_1')\n            self.beta_2 = K.variable(beta_2, name='beta_2')\n\
    \            self.decay = K.variable(decay, name='decay')\n        if epsilon\
    \ is None:\n            epsilon = K.epsilon()\n        self.epsilon = epsilon\n\
    \        self.initial_decay = decay\n        self.amsgrad = amsgrad\n\n    @interfaces.legacy_get_updates_support\n\
    \    def get_updates(self, loss, params):\n        grads = self.get_gradients(loss,\
    \ params)\n        self.updates = [K.update_add(self.iterations, 1)]\n\n     \
    \   lr = self.lr\n        if self.initial_decay > 0:\n            lr = lr * (1.\
    \ / (1. + self.decay * K.cast(self.iterations,\n                             \
    \                         K.dtype(self.decay))))\n\n        t = K.cast(self.iterations,\
    \ K.floatx()) + 1\n        lr_t = lr * (K.sqrt(1. - K.pow(self.beta_2, t)) /\n\
    \                     (1. - K.pow(self.beta_1, t)))\n\n        ms = [K.zeros(K.int_shape(p),\
    \ dtype=K.dtype(p)) for p in params]\n        vs = [K.zeros(K.int_shape(p), dtype=K.dtype(p))\
    \ for p in params]\n        if self.amsgrad:\n            vhats = [K.zeros(K.int_shape(p),\
    \ dtype=K.dtype(p)) for p in params]\n        else:\n            vhats = [K.zeros(1)\
    \ for _ in params]\n        self.weights = [self.iterations] + ms + vs + vhats\n\
    \n        for p, g, m, v, vhat in zip(params, grads, ms, vs, vhats):\n       \
    \     m_t = (self.beta_1 * m) + (1. - self.beta_1) * g\n            v_t = (self.beta_2\
    \ * v) + (1. - self.beta_2) * K.square(g)\n            if self.amsgrad:\n    \
    \            vhat_t = K.maximum(vhat, v_t)\n                p_t = p - lr_t * m_t\
    \ / (K.sqrt(vhat_t) + self.epsilon)\n                self.updates.append(K.update(vhat,\
    \ vhat_t))\n            else:\n                p_t = p - lr_t * m_t / (K.sqrt(v_t)\
    \ + self.epsilon)\n\n            self.updates.append(K.update(m, m_t))\n     \
    \       self.updates.append(K.update(v, v_t))\n            new_p = p_t\n\n   \
    \         # Apply constraints.\n            if getattr(p, 'constraint', None)\
    \ is not None:\n                new_p = p.constraint(new_p)\n\n            self.updates.append(K.update(p,\
    \ new_p))\n        return self.updates\n\n    def get_config(self):\n        config\
    \ = {'lr': float(K.get_value(self.lr)),\n                  'beta_1': float(K.get_value(self.beta_1)),\n\
    \                  'beta_2': float(K.get_value(self.beta_2)),\n              \
    \    'decay': float(K.get_value(self.decay)),\n                  'epsilon': self.epsilon,\n\
    \                  'amsgrad': self.amsgrad}\n        base_config = super(Adam,\
    \ self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))\n"
  sourcefile: D:\Python36\lib\site-packages\keras\optimizers.py
- doc: "Adamax optimizer from Adam paper's Section 7.\n\nIt is a variant of Adam based\
    \ on the infinity norm.\nDefault parameters follow those provided in the paper.\n\
    \n# Arguments\n    lr: float >= 0. Learning rate.\n    beta_1/beta_2: floats,\
    \ 0 < beta < 1. Generally close to 1.\n    epsilon: float >= 0. Fuzz factor. If\
    \ `None`, defaults to `K.epsilon()`.\n    decay: float >= 0. Learning rate decay\
    \ over each update.\n\n# References\n    - [Adam - A Method for Stochastic Optimization]\n\
    \      (https://arxiv.org/abs/1412.6980v8)"
  kind: Optimizer
  name: Adamax
  parameters:
  - {defaultValue: '0.002', kind: any, name: lr}
  - {defaultValue: '0.9', kind: any, name: beta_1}
  - {defaultValue: '0.999', kind: any, name: beta_2}
  - {defaultValue: None, kind: any, name: epsilon}
  - {defaultValue: '0.0', kind: any, name: decay}
  source: "class Adamax(Optimizer):\n    \"\"\"Adamax optimizer from Adam paper's\
    \ Section 7.\n\n    It is a variant of Adam based on the infinity norm.\n    Default\
    \ parameters follow those provided in the paper.\n\n    # Arguments\n        lr:\
    \ float >= 0. Learning rate.\n        beta_1/beta_2: floats, 0 < beta < 1. Generally\
    \ close to 1.\n        epsilon: float >= 0. Fuzz factor. If `None`, defaults to\
    \ `K.epsilon()`.\n        decay: float >= 0. Learning rate decay over each update.\n\
    \n    # References\n        - [Adam - A Method for Stochastic Optimization]\n\
    \          (https://arxiv.org/abs/1412.6980v8)\n    \"\"\"\n\n    def __init__(self,\
    \ lr=0.002, beta_1=0.9, beta_2=0.999,\n                 epsilon=None, decay=0.,\
    \ **kwargs):\n        super(Adamax, self).__init__(**kwargs)\n        with K.name_scope(self.__class__.__name__):\n\
    \            self.iterations = K.variable(0, dtype='int64', name='iterations')\n\
    \            self.lr = K.variable(lr, name='lr')\n            self.beta_1 = K.variable(beta_1,\
    \ name='beta_1')\n            self.beta_2 = K.variable(beta_2, name='beta_2')\n\
    \            self.decay = K.variable(decay, name='decay')\n        if epsilon\
    \ is None:\n            epsilon = K.epsilon()\n        self.epsilon = epsilon\n\
    \        self.initial_decay = decay\n\n    @interfaces.legacy_get_updates_support\n\
    \    def get_updates(self, loss, params):\n        grads = self.get_gradients(loss,\
    \ params)\n        self.updates = [K.update_add(self.iterations, 1)]\n\n     \
    \   lr = self.lr\n        if self.initial_decay > 0:\n            lr = lr * (1.\
    \ / (1. + self.decay * K.cast(self.iterations,\n                             \
    \                         K.dtype(self.decay))))\n\n        t = K.cast(self.iterations,\
    \ K.floatx()) + 1\n        lr_t = lr / (1. - K.pow(self.beta_1, t))\n\n      \
    \  shapes = [K.int_shape(p) for p in params]\n        # zero init of 1st moment\n\
    \        ms = [K.zeros(shape) for shape in shapes]\n        # zero init of exponentially\
    \ weighted infinity norm\n        us = [K.zeros(shape) for shape in shapes]\n\
    \        self.weights = [self.iterations] + ms + us\n\n        for p, g, m, u\
    \ in zip(params, grads, ms, us):\n\n            m_t = (self.beta_1 * m) + (1.\
    \ - self.beta_1) * g\n            u_t = K.maximum(self.beta_2 * u, K.abs(g))\n\
    \            p_t = p - lr_t * m_t / (u_t + self.epsilon)\n\n            self.updates.append(K.update(m,\
    \ m_t))\n            self.updates.append(K.update(u, u_t))\n            new_p\
    \ = p_t\n\n            # Apply constraints.\n            if getattr(p, 'constraint',\
    \ None) is not None:\n                new_p = p.constraint(new_p)\n\n        \
    \    self.updates.append(K.update(p, new_p))\n        return self.updates\n\n\
    \    def get_config(self):\n        config = {'lr': float(K.get_value(self.lr)),\n\
    \                  'beta_1': float(K.get_value(self.beta_1)),\n              \
    \    'beta_2': float(K.get_value(self.beta_2)),\n                  'decay': float(K.get_value(self.decay)),\n\
    \                  'epsilon': self.epsilon}\n        base_config = super(Adamax,\
    \ self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))\n"
  sourcefile: D:\Python36\lib\site-packages\keras\optimizers.py
- doc: "Nesterov Adam optimizer.\n\nMuch like Adam is essentially RMSprop with momentum,\n\
    Nadam is Adam RMSprop with Nesterov momentum.\n\nDefault parameters follow those\
    \ provided in the paper.\nIt is recommended to leave the parameters of this optimizer\n\
    at their default values.\n\n# Arguments\n    lr: float >= 0. Learning rate.\n\
    \    beta_1/beta_2: floats, 0 < beta < 1. Generally close to 1.\n    epsilon:\
    \ float >= 0. Fuzz factor. If `None`, defaults to `K.epsilon()`.\n\n# References\n\
    \    - [Nadam report](http://cs229.stanford.edu/proj2015/054_report.pdf)\n   \
    \ - [On the importance of initialization and momentum in deep learning]\n    \
    \  (http://www.cs.toronto.edu/~fritz/absps/momentum.pdf)"
  kind: Optimizer
  name: Nadam
  parameters:
  - {defaultValue: '0.002', kind: any, name: lr}
  - {defaultValue: '0.9', kind: any, name: beta_1}
  - {defaultValue: '0.999', kind: any, name: beta_2}
  - {defaultValue: None, kind: any, name: epsilon}
  - {defaultValue: '0.004', kind: any, name: schedule_decay}
  source: "class Nadam(Optimizer):\n    \"\"\"Nesterov Adam optimizer.\n\n    Much\
    \ like Adam is essentially RMSprop with momentum,\n    Nadam is Adam RMSprop with\
    \ Nesterov momentum.\n\n    Default parameters follow those provided in the paper.\n\
    \    It is recommended to leave the parameters of this optimizer\n    at their\
    \ default values.\n\n    # Arguments\n        lr: float >= 0. Learning rate.\n\
    \        beta_1/beta_2: floats, 0 < beta < 1. Generally close to 1.\n        epsilon:\
    \ float >= 0. Fuzz factor. If `None`, defaults to `K.epsilon()`.\n\n    # References\n\
    \        - [Nadam report](http://cs229.stanford.edu/proj2015/054_report.pdf)\n\
    \        - [On the importance of initialization and momentum in deep learning]\n\
    \          (http://www.cs.toronto.edu/~fritz/absps/momentum.pdf)\n    \"\"\"\n\
    \n    def __init__(self, lr=0.002, beta_1=0.9, beta_2=0.999,\n               \
    \  epsilon=None, schedule_decay=0.004, **kwargs):\n        super(Nadam, self).__init__(**kwargs)\n\
    \        with K.name_scope(self.__class__.__name__):\n            self.iterations\
    \ = K.variable(0, dtype='int64', name='iterations')\n            self.m_schedule\
    \ = K.variable(1., name='m_schedule')\n            self.lr = K.variable(lr, name='lr')\n\
    \            self.beta_1 = K.variable(beta_1, name='beta_1')\n            self.beta_2\
    \ = K.variable(beta_2, name='beta_2')\n        if epsilon is None:\n         \
    \   epsilon = K.epsilon()\n        self.epsilon = epsilon\n        self.schedule_decay\
    \ = schedule_decay\n\n    @interfaces.legacy_get_updates_support\n    def get_updates(self,\
    \ loss, params):\n        grads = self.get_gradients(loss, params)\n        self.updates\
    \ = [K.update_add(self.iterations, 1)]\n\n        t = K.cast(self.iterations,\
    \ K.floatx()) + 1\n\n        # Due to the recommendations in [2], i.e. warming\
    \ momentum schedule\n        momentum_cache_t = self.beta_1 * (1. - 0.5 * (\n\
    \            K.pow(K.cast_to_floatx(0.96), t * self.schedule_decay)))\n      \
    \  momentum_cache_t_1 = self.beta_1 * (1. - 0.5 * (\n            K.pow(K.cast_to_floatx(0.96),\
    \ (t + 1) * self.schedule_decay)))\n        m_schedule_new = self.m_schedule *\
    \ momentum_cache_t\n        m_schedule_next = self.m_schedule * momentum_cache_t\
    \ * momentum_cache_t_1\n        self.updates.append((self.m_schedule, m_schedule_new))\n\
    \n        shapes = [K.int_shape(p) for p in params]\n        ms = [K.zeros(shape)\
    \ for shape in shapes]\n        vs = [K.zeros(shape) for shape in shapes]\n\n\
    \        self.weights = [self.iterations] + ms + vs\n\n        for p, g, m, v\
    \ in zip(params, grads, ms, vs):\n            # the following equations given\
    \ in [1]\n            g_prime = g / (1. - m_schedule_new)\n            m_t = self.beta_1\
    \ * m + (1. - self.beta_1) * g\n            m_t_prime = m_t / (1. - m_schedule_next)\n\
    \            v_t = self.beta_2 * v + (1. - self.beta_2) * K.square(g)\n      \
    \      v_t_prime = v_t / (1. - K.pow(self.beta_2, t))\n            m_t_bar = (1.\
    \ - momentum_cache_t) * g_prime + (\n                momentum_cache_t_1 * m_t_prime)\n\
    \n            self.updates.append(K.update(m, m_t))\n            self.updates.append(K.update(v,\
    \ v_t))\n\n            p_t = p - self.lr * m_t_bar / (K.sqrt(v_t_prime) + self.epsilon)\n\
    \            new_p = p_t\n\n            # Apply constraints.\n            if getattr(p,\
    \ 'constraint', None) is not None:\n                new_p = p.constraint(new_p)\n\
    \n            self.updates.append(K.update(p, new_p))\n        return self.updates\n\
    \n    def get_config(self):\n        config = {'lr': float(K.get_value(self.lr)),\n\
    \                  'beta_1': float(K.get_value(self.beta_1)),\n              \
    \    'beta_2': float(K.get_value(self.beta_2)),\n                  'epsilon':\
    \ self.epsilon,\n                  'schedule_decay': self.schedule_decay}\n  \
    \      base_config = super(Nadam, self).get_config()\n        return dict(list(base_config.items())\
    \ + list(config.items()))\n"
  sourcefile: D:\Python36\lib\site-packages\keras\optimizers.py
- doc: "RMSProp optimizer.\n\nIt is recommended to leave the parameters of this optimizer\n\
    at their default values\n(except the learning rate, which can be freely tuned).\n\
    \nThis optimizer is usually a good choice for recurrent\nneural networks.\n\n\
    # Arguments\n    lr: float >= 0. Learning rate.\n    rho: float >= 0.\n    epsilon:\
    \ float >= 0. Fuzz factor. If `None`, defaults to `K.epsilon()`.\n    decay: float\
    \ >= 0. Learning rate decay over each update.\n\n# References\n    - [rmsprop:\
    \ Divide the gradient by a running average of its recent magnitude]\n      (http://www.cs.toronto.edu/~tijmen/csc321/slides/lecture_slides_lec6.pdf)"
  kind: Optimizer
  name: RMSprop
  parameters:
  - {defaultValue: '0.001', kind: any, name: lr}
  - {defaultValue: '0.9', kind: any, name: rho}
  - {defaultValue: None, kind: any, name: epsilon}
  - {defaultValue: '0.0', kind: any, name: decay}
  source: "class RMSprop(Optimizer):\n    \"\"\"RMSProp optimizer.\n\n    It is recommended\
    \ to leave the parameters of this optimizer\n    at their default values\n   \
    \ (except the learning rate, which can be freely tuned).\n\n    This optimizer\
    \ is usually a good choice for recurrent\n    neural networks.\n\n    # Arguments\n\
    \        lr: float >= 0. Learning rate.\n        rho: float >= 0.\n        epsilon:\
    \ float >= 0. Fuzz factor. If `None`, defaults to `K.epsilon()`.\n        decay:\
    \ float >= 0. Learning rate decay over each update.\n\n    # References\n    \
    \    - [rmsprop: Divide the gradient by a running average of its recent magnitude]\n\
    \          (http://www.cs.toronto.edu/~tijmen/csc321/slides/lecture_slides_lec6.pdf)\n\
    \    \"\"\"\n\n    def __init__(self, lr=0.001, rho=0.9, epsilon=None, decay=0.,\n\
    \                 **kwargs):\n        super(RMSprop, self).__init__(**kwargs)\n\
    \        with K.name_scope(self.__class__.__name__):\n            self.lr = K.variable(lr,\
    \ name='lr')\n            self.rho = K.variable(rho, name='rho')\n           \
    \ self.decay = K.variable(decay, name='decay')\n            self.iterations =\
    \ K.variable(0, dtype='int64', name='iterations')\n        if epsilon is None:\n\
    \            epsilon = K.epsilon()\n        self.epsilon = epsilon\n        self.initial_decay\
    \ = decay\n\n    @interfaces.legacy_get_updates_support\n    def get_updates(self,\
    \ loss, params):\n        grads = self.get_gradients(loss, params)\n        accumulators\
    \ = [K.zeros(K.int_shape(p), dtype=K.dtype(p)) for p in params]\n        self.weights\
    \ = accumulators\n        self.updates = [K.update_add(self.iterations, 1)]\n\n\
    \        lr = self.lr\n        if self.initial_decay > 0:\n            lr = lr\
    \ * (1. / (1. + self.decay * K.cast(self.iterations,\n                       \
    \                               K.dtype(self.decay))))\n\n        for p, g, a\
    \ in zip(params, grads, accumulators):\n            # update accumulator\n   \
    \         new_a = self.rho * a + (1. - self.rho) * K.square(g)\n            self.updates.append(K.update(a,\
    \ new_a))\n            new_p = p - lr * g / (K.sqrt(new_a) + self.epsilon)\n\n\
    \            # Apply constraints.\n            if getattr(p, 'constraint', None)\
    \ is not None:\n                new_p = p.constraint(new_p)\n\n            self.updates.append(K.update(p,\
    \ new_p))\n        return self.updates\n\n    def get_config(self):\n        config\
    \ = {'lr': float(K.get_value(self.lr)),\n                  'rho': float(K.get_value(self.rho)),\n\
    \                  'decay': float(K.get_value(self.decay)),\n                \
    \  'epsilon': self.epsilon}\n        base_config = super(RMSprop, self).get_config()\n\
    \        return dict(list(base_config.items()) + list(config.items()))\n"
  sourcefile: D:\Python36\lib\site-packages\keras\optimizers.py
- doc: "Stochastic gradient descent optimizer.\n\nIncludes support for momentum,\n\
    learning rate decay, and Nesterov momentum.\n\n# Arguments\n    lr: float >= 0.\
    \ Learning rate.\n    momentum: float >= 0. Parameter that accelerates SGD\n \
    \       in the relevant direction and dampens oscillations.\n    decay: float\
    \ >= 0. Learning rate decay over each update.\n    nesterov: boolean. Whether\
    \ to apply Nesterov momentum."
  kind: Optimizer
  name: SGD
  parameters:
  - {defaultValue: '0.01', kind: any, name: lr}
  - {defaultValue: '0.0', kind: any, name: momentum}
  - {defaultValue: '0.0', kind: any, name: decay}
  - {defaultValue: 'False', kind: any, name: nesterov}
  source: "class SGD(Optimizer):\n    \"\"\"Stochastic gradient descent optimizer.\n\
    \n    Includes support for momentum,\n    learning rate decay, and Nesterov momentum.\n\
    \n    # Arguments\n        lr: float >= 0. Learning rate.\n        momentum: float\
    \ >= 0. Parameter that accelerates SGD\n            in the relevant direction\
    \ and dampens oscillations.\n        decay: float >= 0. Learning rate decay over\
    \ each update.\n        nesterov: boolean. Whether to apply Nesterov momentum.\n\
    \    \"\"\"\n\n    def __init__(self, lr=0.01, momentum=0., decay=0.,\n      \
    \           nesterov=False, **kwargs):\n        super(SGD, self).__init__(**kwargs)\n\
    \        with K.name_scope(self.__class__.__name__):\n            self.iterations\
    \ = K.variable(0, dtype='int64', name='iterations')\n            self.lr = K.variable(lr,\
    \ name='lr')\n            self.momentum = K.variable(momentum, name='momentum')\n\
    \            self.decay = K.variable(decay, name='decay')\n        self.initial_decay\
    \ = decay\n        self.nesterov = nesterov\n\n    @interfaces.legacy_get_updates_support\n\
    \    def get_updates(self, loss, params):\n        grads = self.get_gradients(loss,\
    \ params)\n        self.updates = [K.update_add(self.iterations, 1)]\n\n     \
    \   lr = self.lr\n        if self.initial_decay > 0:\n            lr = lr * (1.\
    \ / (1. + self.decay * K.cast(self.iterations,\n                             \
    \                         K.dtype(self.decay))))\n        # momentum\n       \
    \ shapes = [K.int_shape(p) for p in params]\n        moments = [K.zeros(shape)\
    \ for shape in shapes]\n        self.weights = [self.iterations] + moments\n \
    \       for p, g, m in zip(params, grads, moments):\n            v = self.momentum\
    \ * m - lr * g  # velocity\n            self.updates.append(K.update(m, v))\n\n\
    \            if self.nesterov:\n                new_p = p + self.momentum * v\
    \ - lr * g\n            else:\n                new_p = p + v\n\n            #\
    \ Apply constraints.\n            if getattr(p, 'constraint', None) is not None:\n\
    \                new_p = p.constraint(new_p)\n\n            self.updates.append(K.update(p,\
    \ new_p))\n        return self.updates\n\n    def get_config(self):\n        config\
    \ = {'lr': float(K.get_value(self.lr)),\n                  'momentum': float(K.get_value(self.momentum)),\n\
    \                  'decay': float(K.get_value(self.decay)),\n                \
    \  'nesterov': self.nesterov}\n        base_config = super(SGD, self).get_config()\n\
    \        return dict(list(base_config.items()) + list(config.items()))\n"
  sourcefile: D:\Python36\lib\site-packages\keras\optimizers.py
- doc: "Applies an activation function to an output.\n\n# Arguments\n    activation:\
    \ name of activation function to use\n        (see: [activations](../activations.md)),\n\
    \        or alternatively, a Theano or TensorFlow operation.\n\n# Input shape\n\
    \    Arbitrary. Use the keyword argument `input_shape`\n    (tuple of integers,\
    \ does not include the samples axis)\n    when using this layer as the first layer\
    \ in a model.\n\n# Output shape\n    Same shape as input."
  kind: Layer
  name: Activation
  parameters:
  - {kind: any, name: activation}
  - {defaultValue: 'true', name: trainable, type: bool}
  source: "class Activation(Layer):\n    \"\"\"Applies an activation function to an\
    \ output.\n\n    # Arguments\n        activation: name of activation function\
    \ to use\n            (see: [activations](../activations.md)),\n            or\
    \ alternatively, a Theano or TensorFlow operation.\n\n    # Input shape\n    \
    \    Arbitrary. Use the keyword argument `input_shape`\n        (tuple of integers,\
    \ does not include the samples axis)\n        when using this layer as the first\
    \ layer in a model.\n\n    # Output shape\n        Same shape as input.\n    \"\
    \"\"\n\n    def __init__(self, activation, **kwargs):\n        super(Activation,\
    \ self).__init__(**kwargs)\n        self.supports_masking = True\n        self.activation\
    \ = activations.get(activation)\n\n    def call(self, inputs):\n        return\
    \ self.activation(inputs)\n\n    def get_config(self):\n        config = {'activation':\
    \ activations.serialize(self.activation)}\n        base_config = super(Activation,\
    \ self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))\n\
    \n    def compute_output_shape(self, input_shape):\n        return input_shape\n"
  sourcefile: D:\Python36\lib\site-packages\keras\layers\core.py
- doc: "Layer that applies an update to the cost function based input activity.\n\n\
    # Arguments\n    l1: L1 regularization factor (positive float).\n    l2: L2 regularization\
    \ factor (positive float).\n\n# Input shape\n    Arbitrary. Use the keyword argument\
    \ `input_shape`\n    (tuple of integers, does not include the samples axis)\n\
    \    when using this layer as the first layer in a model.\n\n# Output shape\n\
    \    Same shape as input."
  kind: Layer
  name: ActivityRegularization
  parameters:
  - {defaultValue: '0.0', kind: any, name: l1}
  - {defaultValue: '0.0', kind: any, name: l2}
  - {defaultValue: 'true', name: trainable, type: bool}
  source: "class ActivityRegularization(Layer):\n    \"\"\"Layer that applies an update\
    \ to the cost function based input activity.\n\n    # Arguments\n        l1: L1\
    \ regularization factor (positive float).\n        l2: L2 regularization factor\
    \ (positive float).\n\n    # Input shape\n        Arbitrary. Use the keyword argument\
    \ `input_shape`\n        (tuple of integers, does not include the samples axis)\n\
    \        when using this layer as the first layer in a model.\n\n    # Output\
    \ shape\n        Same shape as input.\n    \"\"\"\n\n    def __init__(self, l1=0.,\
    \ l2=0., **kwargs):\n        super(ActivityRegularization, self).__init__(**kwargs)\n\
    \        self.supports_masking = True\n        self.l1 = l1\n        self.l2 =\
    \ l2\n        self.activity_regularizer = regularizers.L1L2(l1=l1, l2=l2)\n\n\
    \    def get_config(self):\n        config = {'l1': self.l1,\n               \
    \   'l2': self.l2}\n        base_config = super(ActivityRegularization, self).get_config()\n\
    \        return dict(list(base_config.items()) + list(config.items()))\n\n   \
    \ def compute_output_shape(self, input_shape):\n        return input_shape\n"
  sourcefile: D:\Python36\lib\site-packages\keras\layers\core.py
- doc: "Layer that adds a list of inputs.\n\nIt takes as input a list of tensors,\n\
    all of the same shape, and returns\na single tensor (also of the same shape).\n\
    \n# Examples\n\n```python\n    import keras\n\n    input1 = keras.layers.Input(shape=(16,))\n\
    \    x1 = keras.layers.Dense(8, activation='relu')(input1)\n    input2 = keras.layers.Input(shape=(32,))\n\
    \    x2 = keras.layers.Dense(8, activation='relu')(input2)\n    # equivalent to\
    \ added = keras.layers.add([x1, x2])\n    added = keras.layers.Add()([x1, x2])\n\
    \n    out = keras.layers.Dense(4)(added)\n    model = keras.models.Model(inputs=[input1,\
    \ input2], outputs=out)\n```"
  kind: Layer
  name: Add
  parameters:
  - {defaultValue: 'true', name: trainable, type: bool}
  source: "class Add(_Merge):\n    \"\"\"Layer that adds a list of inputs.\n\n   \
    \ It takes as input a list of tensors,\n    all of the same shape, and returns\n\
    \    a single tensor (also of the same shape).\n\n    # Examples\n\n    ```python\n\
    \        import keras\n\n        input1 = keras.layers.Input(shape=(16,))\n  \
    \      x1 = keras.layers.Dense(8, activation='relu')(input1)\n        input2 =\
    \ keras.layers.Input(shape=(32,))\n        x2 = keras.layers.Dense(8, activation='relu')(input2)\n\
    \        # equivalent to added = keras.layers.add([x1, x2])\n        added = keras.layers.Add()([x1,\
    \ x2])\n\n        out = keras.layers.Dense(4)(added)\n        model = keras.models.Model(inputs=[input1,\
    \ input2], outputs=out)\n    ```\n    \"\"\"\n\n    def _merge_function(self,\
    \ inputs):\n        output = inputs[0]\n        for i in range(1, len(inputs)):\n\
    \            output += inputs[i]\n        return output\n"
  sourcefile: D:\Python36\lib\site-packages\keras\layers\merge.py
- doc: "Applies Alpha Dropout to the input.\n\nAlpha Dropout is a `Dropout` that keeps\
    \ mean and variance of inputs\nto their original values, in order to ensure the\
    \ self-normalizing property\neven after this dropout.\nAlpha Dropout fits well\
    \ to Scaled Exponential Linear Units\nby randomly setting activations to the negative\
    \ saturation value.\n\n# Arguments\n    rate: float, drop probability (as with\
    \ `Dropout`).\n        The multiplicative noise will have\n        standard deviation\
    \ `sqrt(rate / (1 - rate))`.\n    seed: A Python integer to use as random seed.\n\
    \n# Input shape\n    Arbitrary. Use the keyword argument `input_shape`\n    (tuple\
    \ of integers, does not include the samples axis)\n    when using this layer as\
    \ the first layer in a model.\n\n# Output shape\n    Same shape as input.\n\n\
    # References\n    - [Self-Normalizing Neural Networks](https://arxiv.org/abs/1706.02515)"
  kind: Layer
  name: AlphaDropout
  parameters:
  - {kind: any, name: rate}
  - {defaultValue: None, kind: any, name: noise_shape}
  - {defaultValue: None, kind: any, name: seed}
  - {defaultValue: 'true', name: trainable, type: bool}
  source: "class AlphaDropout(Layer):\n    \"\"\"Applies Alpha Dropout to the input.\n\
    \n    Alpha Dropout is a `Dropout` that keeps mean and variance of inputs\n  \
    \  to their original values, in order to ensure the self-normalizing property\n\
    \    even after this dropout.\n    Alpha Dropout fits well to Scaled Exponential\
    \ Linear Units\n    by randomly setting activations to the negative saturation\
    \ value.\n\n    # Arguments\n        rate: float, drop probability (as with `Dropout`).\n\
    \            The multiplicative noise will have\n            standard deviation\
    \ `sqrt(rate / (1 - rate))`.\n        seed: A Python integer to use as random\
    \ seed.\n\n    # Input shape\n        Arbitrary. Use the keyword argument `input_shape`\n\
    \        (tuple of integers, does not include the samples axis)\n        when\
    \ using this layer as the first layer in a model.\n\n    # Output shape\n    \
    \    Same shape as input.\n\n    # References\n        - [Self-Normalizing Neural\
    \ Networks](https://arxiv.org/abs/1706.02515)\n    \"\"\"\n    def __init__(self,\
    \ rate, noise_shape=None, seed=None, **kwargs):\n        super(AlphaDropout, self).__init__(**kwargs)\n\
    \        self.rate = rate\n        self.noise_shape = noise_shape\n        self.seed\
    \ = seed\n        self.supports_masking = True\n\n    def _get_noise_shape(self,\
    \ inputs):\n        return self.noise_shape if self.noise_shape else K.shape(inputs)\n\
    \n    def call(self, inputs, training=None):\n        if 0. < self.rate < 1.:\n\
    \            noise_shape = self._get_noise_shape(inputs)\n\n            def dropped_inputs(inputs=inputs,\
    \ rate=self.rate, seed=self.seed):\n                alpha = 1.6732632423543772848170429916717\n\
    \                scale = 1.0507009873554804934193349852946\n                alpha_p\
    \ = -alpha * scale\n\n                kept_idx = K.greater_equal(K.random_uniform(noise_shape,\n\
    \                                                            seed=seed), rate)\n\
    \                kept_idx = K.cast(kept_idx, K.floatx())\n\n                #\
    \ Get affine transformation params\n                a = ((1 - rate) * (1 + rate\
    \ * alpha_p ** 2)) ** -0.5\n                b = -a * alpha_p * rate\n\n      \
    \          # Apply mask\n                x = inputs * kept_idx + alpha_p * (1\
    \ - kept_idx)\n\n                # Do affine transformation\n                return\
    \ a * x + b\n\n            return K.in_train_phase(dropped_inputs, inputs, training=training)\n\
    \        return inputs\n\n    def get_config(self):\n        config = {'rate':\
    \ self.rate}\n        base_config = super(AlphaDropout, self).get_config()\n \
    \       return dict(list(base_config.items()) + list(config.items()))\n\n    def\
    \ compute_output_shape(self, input_shape):\n        return input_shape\n"
  sourcefile: D:\Python36\lib\site-packages\keras\layers\noise.py
- doc: 'Layer that averages a list of inputs.


    It takes as input a list of tensors,

    all of the same shape, and returns

    a single tensor (also of the same shape).'
  kind: Layer
  name: Average
  parameters:
  - {defaultValue: 'true', name: trainable, type: bool}
  source: "class Average(_Merge):\n    \"\"\"Layer that averages a list of inputs.\n\
    \n    It takes as input a list of tensors,\n    all of the same shape, and returns\n\
    \    a single tensor (also of the same shape).\n    \"\"\"\n\n    def _merge_function(self,\
    \ inputs):\n        output = inputs[0]\n        for i in range(1, len(inputs)):\n\
    \            output += inputs[i]\n        return output / len(inputs)\n"
  sourcefile: D:\Python36\lib\site-packages\keras\layers\merge.py
- doc: "Average pooling for temporal data.\n\n# Arguments\n    pool_size: Integer,\
    \ size of the average pooling windows.\n    strides: Integer, or None. Factor\
    \ by which to downscale.\n        E.g. 2 will halve the input.\n        If None,\
    \ it will default to `pool_size`.\n    padding: One of `\"valid\"` or `\"same\"\
    ` (case-insensitive).\n    data_format: A string,\n        one of `channels_last`\
    \ (default) or `channels_first`.\n        The ordering of the dimensions in the\
    \ inputs.\n        `channels_last` corresponds to inputs with shape\n        `(batch,\
    \ steps, features)` while `channels_first`\n        corresponds to inputs with\
    \ shape\n        `(batch, features, steps)`.\n\n# Input shape\n    - If `data_format='channels_last'`:\n\
    \        3D tensor with shape:\n        `(batch_size, steps, features)`\n    -\
    \ If `data_format='channels_first'`:\n        3D tensor with shape:\n        `(batch_size,\
    \ features, steps)`\n\n# Output shape\n    - If `data_format='channels_last'`:\n\
    \        3D tensor with shape:\n        `(batch_size, downsampled_steps, features)`\n\
    \    - If `data_format='channels_first'`:\n        3D tensor with shape:\n   \
    \     `(batch_size, features, downsampled_steps)`"
  kind: Layer
  name: AveragePooling1D
  parameters:
  - {defaultValue: '2', kind: any, name: pool_size}
  - {defaultValue: None, kind: any, name: strides}
  - {defaultValue: valid, kind: any, name: padding}
  - {defaultValue: channels_last, kind: any, name: data_format}
  - {defaultValue: 'true', name: trainable, type: bool}
  source: "class AveragePooling1D(_Pooling1D):\n    \"\"\"Average pooling for temporal\
    \ data.\n\n    # Arguments\n        pool_size: Integer, size of the average pooling\
    \ windows.\n        strides: Integer, or None. Factor by which to downscale.\n\
    \            E.g. 2 will halve the input.\n            If None, it will default\
    \ to `pool_size`.\n        padding: One of `\"valid\"` or `\"same\"` (case-insensitive).\n\
    \        data_format: A string,\n            one of `channels_last` (default)\
    \ or `channels_first`.\n            The ordering of the dimensions in the inputs.\n\
    \            `channels_last` corresponds to inputs with shape\n            `(batch,\
    \ steps, features)` while `channels_first`\n            corresponds to inputs\
    \ with shape\n            `(batch, features, steps)`.\n\n    # Input shape\n \
    \       - If `data_format='channels_last'`:\n            3D tensor with shape:\n\
    \            `(batch_size, steps, features)`\n        - If `data_format='channels_first'`:\n\
    \            3D tensor with shape:\n            `(batch_size, features, steps)`\n\
    \n    # Output shape\n        - If `data_format='channels_last'`:\n          \
    \  3D tensor with shape:\n            `(batch_size, downsampled_steps, features)`\n\
    \        - If `data_format='channels_first'`:\n            3D tensor with shape:\n\
    \            `(batch_size, features, downsampled_steps)`\n    \"\"\"\n\n    @interfaces.legacy_pooling1d_support\n\
    \    def __init__(self, pool_size=2, strides=None,\n                 padding='valid',\
    \ data_format='channels_last', **kwargs):\n        super(AveragePooling1D, self).__init__(pool_size,\
    \ strides,\n                                               padding, data_format,\n\
    \                                               **kwargs)\n\n    def _pooling_function(self,\
    \ inputs, pool_size, strides,\n                          padding, data_format):\n\
    \        output = K.pool2d(inputs, pool_size, strides,\n                     \
    \     padding, data_format, pool_mode='avg')\n        return output\n"
  sourcefile: D:\Python36\lib\site-packages\keras\layers\pooling.py
- doc: "Average pooling operation for spatial data.\n\n# Arguments\n    pool_size:\
    \ integer or tuple of 2 integers,\n        factors by which to downscale (vertical,\
    \ horizontal).\n        (2, 2) will halve the input in both spatial dimension.\n\
    \        If only one integer is specified, the same window length\n        will\
    \ be used for both dimensions.\n    strides: Integer, tuple of 2 integers, or\
    \ None.\n        Strides values.\n        If None, it will default to `pool_size`.\n\
    \    padding: One of `\"valid\"` or `\"same\"` (case-insensitive).\n    data_format:\
    \ A string,\n        one of `channels_last` (default) or `channels_first`.\n \
    \       The ordering of the dimensions in the inputs.\n        `channels_last`\
    \ corresponds to inputs with shape\n        `(batch, height, width, channels)`\
    \ while `channels_first`\n        corresponds to inputs with shape\n        `(batch,\
    \ channels, height, width)`.\n        It defaults to the `image_data_format` value\
    \ found in your\n        Keras config file at `~/.keras/keras.json`.\n       \
    \ If you never set it, then it will be \"channels_last\".\n\n# Input shape\n \
    \   - If `data_format='channels_last'`:\n        4D tensor with shape:\n     \
    \   `(batch_size, rows, cols, channels)`\n    - If `data_format='channels_first'`:\n\
    \        4D tensor with shape:\n        `(batch_size, channels, rows, cols)`\n\
    \n# Output shape\n    - If `data_format='channels_last'`:\n        4D tensor with\
    \ shape:\n        `(batch_size, pooled_rows, pooled_cols, channels)`\n    - If\
    \ `data_format='channels_first'`:\n        4D tensor with shape:\n        `(batch_size,\
    \ channels, pooled_rows, pooled_cols)`"
  kind: Layer
  name: AveragePooling2D
  parameters:
  - {defaultValue: '(2, 2)', kind: any, name: pool_size}
  - {defaultValue: None, kind: any, name: strides}
  - {defaultValue: valid, kind: any, name: padding}
  - {defaultValue: None, kind: any, name: data_format}
  - {defaultValue: 'true', name: trainable, type: bool}
  source: "class AveragePooling2D(_Pooling2D):\n    \"\"\"Average pooling operation\
    \ for spatial data.\n\n    # Arguments\n        pool_size: integer or tuple of\
    \ 2 integers,\n            factors by which to downscale (vertical, horizontal).\n\
    \            (2, 2) will halve the input in both spatial dimension.\n        \
    \    If only one integer is specified, the same window length\n            will\
    \ be used for both dimensions.\n        strides: Integer, tuple of 2 integers,\
    \ or None.\n            Strides values.\n            If None, it will default\
    \ to `pool_size`.\n        padding: One of `\"valid\"` or `\"same\"` (case-insensitive).\n\
    \        data_format: A string,\n            one of `channels_last` (default)\
    \ or `channels_first`.\n            The ordering of the dimensions in the inputs.\n\
    \            `channels_last` corresponds to inputs with shape\n            `(batch,\
    \ height, width, channels)` while `channels_first`\n            corresponds to\
    \ inputs with shape\n            `(batch, channels, height, width)`.\n       \
    \     It defaults to the `image_data_format` value found in your\n           \
    \ Keras config file at `~/.keras/keras.json`.\n            If you never set it,\
    \ then it will be \"channels_last\".\n\n    # Input shape\n        - If `data_format='channels_last'`:\n\
    \            4D tensor with shape:\n            `(batch_size, rows, cols, channels)`\n\
    \        - If `data_format='channels_first'`:\n            4D tensor with shape:\n\
    \            `(batch_size, channels, rows, cols)`\n\n    # Output shape\n    \
    \    - If `data_format='channels_last'`:\n            4D tensor with shape:\n\
    \            `(batch_size, pooled_rows, pooled_cols, channels)`\n        - If\
    \ `data_format='channels_first'`:\n            4D tensor with shape:\n       \
    \     `(batch_size, channels, pooled_rows, pooled_cols)`\n    \"\"\"\n\n    @interfaces.legacy_pooling2d_support\n\
    \    def __init__(self, pool_size=(2, 2), strides=None, padding='valid',\n   \
    \              data_format=None, **kwargs):\n        super(AveragePooling2D, self).__init__(pool_size,\
    \ strides, padding,\n                                               data_format,\
    \ **kwargs)\n\n    def _pooling_function(self, inputs, pool_size, strides,\n \
    \                         padding, data_format):\n        output = K.pool2d(inputs,\
    \ pool_size, strides,\n                          padding, data_format, pool_mode='avg')\n\
    \        return output\n"
  sourcefile: D:\Python36\lib\site-packages\keras\layers\pooling.py
- doc: "Average pooling operation for 3D data (spatial or spatio-temporal).\n\n# Arguments\n\
    \    pool_size: tuple of 3 integers,\n        factors by which to downscale (dim1,\
    \ dim2, dim3).\n        (2, 2, 2) will halve the size of the 3D input in each\
    \ dimension.\n    strides: tuple of 3 integers, or None. Strides values.\n   \
    \ padding: One of `\"valid\"` or `\"same\"` (case-insensitive).\n    data_format:\
    \ A string,\n        one of `channels_last` (default) or `channels_first`.\n \
    \       The ordering of the dimensions in the inputs.\n        `channels_last`\
    \ corresponds to inputs with shape\n        `(batch, spatial_dim1, spatial_dim2,\
    \ spatial_dim3, channels)`\n        while `channels_first` corresponds to inputs\
    \ with shape\n        `(batch, channels, spatial_dim1, spatial_dim2, spatial_dim3)`.\n\
    \        It defaults to the `image_data_format` value found in your\n        Keras\
    \ config file at `~/.keras/keras.json`.\n        If you never set it, then it\
    \ will be \"channels_last\".\n\n# Input shape\n    - If `data_format='channels_last'`:\n\
    \        5D tensor with shape:\n        `(batch_size, spatial_dim1, spatial_dim2,\
    \ spatial_dim3, channels)`\n    - If `data_format='channels_first'`:\n       \
    \ 5D tensor with shape:\n        `(batch_size, channels, spatial_dim1, spatial_dim2,\
    \ spatial_dim3)`\n\n# Output shape\n    - If `data_format='channels_last'`:\n\
    \        5D tensor with shape:\n        `(batch_size, pooled_dim1, pooled_dim2,\
    \ pooled_dim3, channels)`\n    - If `data_format='channels_first'`:\n        5D\
    \ tensor with shape:\n        `(batch_size, channels, pooled_dim1, pooled_dim2,\
    \ pooled_dim3)`"
  kind: Layer
  name: AveragePooling3D
  parameters:
  - {defaultValue: '(2, 2, 2)', kind: any, name: pool_size}
  - {defaultValue: None, kind: any, name: strides}
  - {defaultValue: valid, kind: any, name: padding}
  - {defaultValue: None, kind: any, name: data_format}
  - {defaultValue: 'true', name: trainable, type: bool}
  source: "class AveragePooling3D(_Pooling3D):\n    \"\"\"Average pooling operation\
    \ for 3D data (spatial or spatio-temporal).\n\n    # Arguments\n        pool_size:\
    \ tuple of 3 integers,\n            factors by which to downscale (dim1, dim2,\
    \ dim3).\n            (2, 2, 2) will halve the size of the 3D input in each dimension.\n\
    \        strides: tuple of 3 integers, or None. Strides values.\n        padding:\
    \ One of `\"valid\"` or `\"same\"` (case-insensitive).\n        data_format: A\
    \ string,\n            one of `channels_last` (default) or `channels_first`.\n\
    \            The ordering of the dimensions in the inputs.\n            `channels_last`\
    \ corresponds to inputs with shape\n            `(batch, spatial_dim1, spatial_dim2,\
    \ spatial_dim3, channels)`\n            while `channels_first` corresponds to\
    \ inputs with shape\n            `(batch, channels, spatial_dim1, spatial_dim2,\
    \ spatial_dim3)`.\n            It defaults to the `image_data_format` value found\
    \ in your\n            Keras config file at `~/.keras/keras.json`.\n         \
    \   If you never set it, then it will be \"channels_last\".\n\n    # Input shape\n\
    \        - If `data_format='channels_last'`:\n            5D tensor with shape:\n\
    \            `(batch_size, spatial_dim1, spatial_dim2, spatial_dim3, channels)`\n\
    \        - If `data_format='channels_first'`:\n            5D tensor with shape:\n\
    \            `(batch_size, channels, spatial_dim1, spatial_dim2, spatial_dim3)`\n\
    \n    # Output shape\n        - If `data_format='channels_last'`:\n          \
    \  5D tensor with shape:\n            `(batch_size, pooled_dim1, pooled_dim2,\
    \ pooled_dim3, channels)`\n        - If `data_format='channels_first'`:\n    \
    \        5D tensor with shape:\n            `(batch_size, channels, pooled_dim1,\
    \ pooled_dim2, pooled_dim3)`\n    \"\"\"\n\n    @interfaces.legacy_pooling3d_support\n\
    \    def __init__(self, pool_size=(2, 2, 2), strides=None, padding='valid',\n\
    \                 data_format=None, **kwargs):\n        super(AveragePooling3D,\
    \ self).__init__(pool_size, strides, padding,\n                              \
    \                 data_format, **kwargs)\n\n    def _pooling_function(self, inputs,\
    \ pool_size, strides,\n                          padding, data_format):\n    \
    \    output = K.pool3d(inputs, pool_size, strides,\n                         \
    \ padding, data_format,\n                          pool_mode='avg')\n        return\
    \ output\n"
  sourcefile: D:\Python36\lib\site-packages\keras\layers\pooling.py
- doc: "Average pooling for temporal data.\n\n# Arguments\n    pool_size: Integer,\
    \ size of the average pooling windows.\n    strides: Integer, or None. Factor\
    \ by which to downscale.\n        E.g. 2 will halve the input.\n        If None,\
    \ it will default to `pool_size`.\n    padding: One of `\"valid\"` or `\"same\"\
    ` (case-insensitive).\n    data_format: A string,\n        one of `channels_last`\
    \ (default) or `channels_first`.\n        The ordering of the dimensions in the\
    \ inputs.\n        `channels_last` corresponds to inputs with shape\n        `(batch,\
    \ steps, features)` while `channels_first`\n        corresponds to inputs with\
    \ shape\n        `(batch, features, steps)`.\n\n# Input shape\n    - If `data_format='channels_last'`:\n\
    \        3D tensor with shape:\n        `(batch_size, steps, features)`\n    -\
    \ If `data_format='channels_first'`:\n        3D tensor with shape:\n        `(batch_size,\
    \ features, steps)`\n\n# Output shape\n    - If `data_format='channels_last'`:\n\
    \        3D tensor with shape:\n        `(batch_size, downsampled_steps, features)`\n\
    \    - If `data_format='channels_first'`:\n        3D tensor with shape:\n   \
    \     `(batch_size, features, downsampled_steps)`"
  kind: Layer
  name: AveragePooling1D
  parameters:
  - {defaultValue: '2', kind: any, name: pool_size}
  - {defaultValue: None, kind: any, name: strides}
  - {defaultValue: valid, kind: any, name: padding}
  - {defaultValue: channels_last, kind: any, name: data_format}
  - {defaultValue: 'true', name: trainable, type: bool}
  source: "class AveragePooling1D(_Pooling1D):\n    \"\"\"Average pooling for temporal\
    \ data.\n\n    # Arguments\n        pool_size: Integer, size of the average pooling\
    \ windows.\n        strides: Integer, or None. Factor by which to downscale.\n\
    \            E.g. 2 will halve the input.\n            If None, it will default\
    \ to `pool_size`.\n        padding: One of `\"valid\"` or `\"same\"` (case-insensitive).\n\
    \        data_format: A string,\n            one of `channels_last` (default)\
    \ or `channels_first`.\n            The ordering of the dimensions in the inputs.\n\
    \            `channels_last` corresponds to inputs with shape\n            `(batch,\
    \ steps, features)` while `channels_first`\n            corresponds to inputs\
    \ with shape\n            `(batch, features, steps)`.\n\n    # Input shape\n \
    \       - If `data_format='channels_last'`:\n            3D tensor with shape:\n\
    \            `(batch_size, steps, features)`\n        - If `data_format='channels_first'`:\n\
    \            3D tensor with shape:\n            `(batch_size, features, steps)`\n\
    \n    # Output shape\n        - If `data_format='channels_last'`:\n          \
    \  3D tensor with shape:\n            `(batch_size, downsampled_steps, features)`\n\
    \        - If `data_format='channels_first'`:\n            3D tensor with shape:\n\
    \            `(batch_size, features, downsampled_steps)`\n    \"\"\"\n\n    @interfaces.legacy_pooling1d_support\n\
    \    def __init__(self, pool_size=2, strides=None,\n                 padding='valid',\
    \ data_format='channels_last', **kwargs):\n        super(AveragePooling1D, self).__init__(pool_size,\
    \ strides,\n                                               padding, data_format,\n\
    \                                               **kwargs)\n\n    def _pooling_function(self,\
    \ inputs, pool_size, strides,\n                          padding, data_format):\n\
    \        output = K.pool2d(inputs, pool_size, strides,\n                     \
    \     padding, data_format, pool_mode='avg')\n        return output\n"
  sourcefile: D:\Python36\lib\site-packages\keras\layers\pooling.py
- doc: "Average pooling operation for spatial data.\n\n# Arguments\n    pool_size:\
    \ integer or tuple of 2 integers,\n        factors by which to downscale (vertical,\
    \ horizontal).\n        (2, 2) will halve the input in both spatial dimension.\n\
    \        If only one integer is specified, the same window length\n        will\
    \ be used for both dimensions.\n    strides: Integer, tuple of 2 integers, or\
    \ None.\n        Strides values.\n        If None, it will default to `pool_size`.\n\
    \    padding: One of `\"valid\"` or `\"same\"` (case-insensitive).\n    data_format:\
    \ A string,\n        one of `channels_last` (default) or `channels_first`.\n \
    \       The ordering of the dimensions in the inputs.\n        `channels_last`\
    \ corresponds to inputs with shape\n        `(batch, height, width, channels)`\
    \ while `channels_first`\n        corresponds to inputs with shape\n        `(batch,\
    \ channels, height, width)`.\n        It defaults to the `image_data_format` value\
    \ found in your\n        Keras config file at `~/.keras/keras.json`.\n       \
    \ If you never set it, then it will be \"channels_last\".\n\n# Input shape\n \
    \   - If `data_format='channels_last'`:\n        4D tensor with shape:\n     \
    \   `(batch_size, rows, cols, channels)`\n    - If `data_format='channels_first'`:\n\
    \        4D tensor with shape:\n        `(batch_size, channels, rows, cols)`\n\
    \n# Output shape\n    - If `data_format='channels_last'`:\n        4D tensor with\
    \ shape:\n        `(batch_size, pooled_rows, pooled_cols, channels)`\n    - If\
    \ `data_format='channels_first'`:\n        4D tensor with shape:\n        `(batch_size,\
    \ channels, pooled_rows, pooled_cols)`"
  kind: Layer
  name: AveragePooling2D
  parameters:
  - {defaultValue: '(2, 2)', kind: any, name: pool_size}
  - {defaultValue: None, kind: any, name: strides}
  - {defaultValue: valid, kind: any, name: padding}
  - {defaultValue: None, kind: any, name: data_format}
  - {defaultValue: 'true', name: trainable, type: bool}
  source: "class AveragePooling2D(_Pooling2D):\n    \"\"\"Average pooling operation\
    \ for spatial data.\n\n    # Arguments\n        pool_size: integer or tuple of\
    \ 2 integers,\n            factors by which to downscale (vertical, horizontal).\n\
    \            (2, 2) will halve the input in both spatial dimension.\n        \
    \    If only one integer is specified, the same window length\n            will\
    \ be used for both dimensions.\n        strides: Integer, tuple of 2 integers,\
    \ or None.\n            Strides values.\n            If None, it will default\
    \ to `pool_size`.\n        padding: One of `\"valid\"` or `\"same\"` (case-insensitive).\n\
    \        data_format: A string,\n            one of `channels_last` (default)\
    \ or `channels_first`.\n            The ordering of the dimensions in the inputs.\n\
    \            `channels_last` corresponds to inputs with shape\n            `(batch,\
    \ height, width, channels)` while `channels_first`\n            corresponds to\
    \ inputs with shape\n            `(batch, channels, height, width)`.\n       \
    \     It defaults to the `image_data_format` value found in your\n           \
    \ Keras config file at `~/.keras/keras.json`.\n            If you never set it,\
    \ then it will be \"channels_last\".\n\n    # Input shape\n        - If `data_format='channels_last'`:\n\
    \            4D tensor with shape:\n            `(batch_size, rows, cols, channels)`\n\
    \        - If `data_format='channels_first'`:\n            4D tensor with shape:\n\
    \            `(batch_size, channels, rows, cols)`\n\n    # Output shape\n    \
    \    - If `data_format='channels_last'`:\n            4D tensor with shape:\n\
    \            `(batch_size, pooled_rows, pooled_cols, channels)`\n        - If\
    \ `data_format='channels_first'`:\n            4D tensor with shape:\n       \
    \     `(batch_size, channels, pooled_rows, pooled_cols)`\n    \"\"\"\n\n    @interfaces.legacy_pooling2d_support\n\
    \    def __init__(self, pool_size=(2, 2), strides=None, padding='valid',\n   \
    \              data_format=None, **kwargs):\n        super(AveragePooling2D, self).__init__(pool_size,\
    \ strides, padding,\n                                               data_format,\
    \ **kwargs)\n\n    def _pooling_function(self, inputs, pool_size, strides,\n \
    \                         padding, data_format):\n        output = K.pool2d(inputs,\
    \ pool_size, strides,\n                          padding, data_format, pool_mode='avg')\n\
    \        return output\n"
  sourcefile: D:\Python36\lib\site-packages\keras\layers\pooling.py
- doc: "Average pooling operation for 3D data (spatial or spatio-temporal).\n\n# Arguments\n\
    \    pool_size: tuple of 3 integers,\n        factors by which to downscale (dim1,\
    \ dim2, dim3).\n        (2, 2, 2) will halve the size of the 3D input in each\
    \ dimension.\n    strides: tuple of 3 integers, or None. Strides values.\n   \
    \ padding: One of `\"valid\"` or `\"same\"` (case-insensitive).\n    data_format:\
    \ A string,\n        one of `channels_last` (default) or `channels_first`.\n \
    \       The ordering of the dimensions in the inputs.\n        `channels_last`\
    \ corresponds to inputs with shape\n        `(batch, spatial_dim1, spatial_dim2,\
    \ spatial_dim3, channels)`\n        while `channels_first` corresponds to inputs\
    \ with shape\n        `(batch, channels, spatial_dim1, spatial_dim2, spatial_dim3)`.\n\
    \        It defaults to the `image_data_format` value found in your\n        Keras\
    \ config file at `~/.keras/keras.json`.\n        If you never set it, then it\
    \ will be \"channels_last\".\n\n# Input shape\n    - If `data_format='channels_last'`:\n\
    \        5D tensor with shape:\n        `(batch_size, spatial_dim1, spatial_dim2,\
    \ spatial_dim3, channels)`\n    - If `data_format='channels_first'`:\n       \
    \ 5D tensor with shape:\n        `(batch_size, channels, spatial_dim1, spatial_dim2,\
    \ spatial_dim3)`\n\n# Output shape\n    - If `data_format='channels_last'`:\n\
    \        5D tensor with shape:\n        `(batch_size, pooled_dim1, pooled_dim2,\
    \ pooled_dim3, channels)`\n    - If `data_format='channels_first'`:\n        5D\
    \ tensor with shape:\n        `(batch_size, channels, pooled_dim1, pooled_dim2,\
    \ pooled_dim3)`"
  kind: Layer
  name: AveragePooling3D
  parameters:
  - {defaultValue: '(2, 2, 2)', kind: any, name: pool_size}
  - {defaultValue: None, kind: any, name: strides}
  - {defaultValue: valid, kind: any, name: padding}
  - {defaultValue: None, kind: any, name: data_format}
  - {defaultValue: 'true', name: trainable, type: bool}
  source: "class AveragePooling3D(_Pooling3D):\n    \"\"\"Average pooling operation\
    \ for 3D data (spatial or spatio-temporal).\n\n    # Arguments\n        pool_size:\
    \ tuple of 3 integers,\n            factors by which to downscale (dim1, dim2,\
    \ dim3).\n            (2, 2, 2) will halve the size of the 3D input in each dimension.\n\
    \        strides: tuple of 3 integers, or None. Strides values.\n        padding:\
    \ One of `\"valid\"` or `\"same\"` (case-insensitive).\n        data_format: A\
    \ string,\n            one of `channels_last` (default) or `channels_first`.\n\
    \            The ordering of the dimensions in the inputs.\n            `channels_last`\
    \ corresponds to inputs with shape\n            `(batch, spatial_dim1, spatial_dim2,\
    \ spatial_dim3, channels)`\n            while `channels_first` corresponds to\
    \ inputs with shape\n            `(batch, channels, spatial_dim1, spatial_dim2,\
    \ spatial_dim3)`.\n            It defaults to the `image_data_format` value found\
    \ in your\n            Keras config file at `~/.keras/keras.json`.\n         \
    \   If you never set it, then it will be \"channels_last\".\n\n    # Input shape\n\
    \        - If `data_format='channels_last'`:\n            5D tensor with shape:\n\
    \            `(batch_size, spatial_dim1, spatial_dim2, spatial_dim3, channels)`\n\
    \        - If `data_format='channels_first'`:\n            5D tensor with shape:\n\
    \            `(batch_size, channels, spatial_dim1, spatial_dim2, spatial_dim3)`\n\
    \n    # Output shape\n        - If `data_format='channels_last'`:\n          \
    \  5D tensor with shape:\n            `(batch_size, pooled_dim1, pooled_dim2,\
    \ pooled_dim3, channels)`\n        - If `data_format='channels_first'`:\n    \
    \        5D tensor with shape:\n            `(batch_size, channels, pooled_dim1,\
    \ pooled_dim2, pooled_dim3)`\n    \"\"\"\n\n    @interfaces.legacy_pooling3d_support\n\
    \    def __init__(self, pool_size=(2, 2, 2), strides=None, padding='valid',\n\
    \                 data_format=None, **kwargs):\n        super(AveragePooling3D,\
    \ self).__init__(pool_size, strides, padding,\n                              \
    \                 data_format, **kwargs)\n\n    def _pooling_function(self, inputs,\
    \ pool_size, strides,\n                          padding, data_format):\n    \
    \    output = K.pool3d(inputs, pool_size, strides,\n                         \
    \ padding, data_format,\n                          pool_mode='avg')\n        return\
    \ output\n"
  sourcefile: D:\Python36\lib\site-packages\keras\layers\pooling.py
- doc: "Batch normalization layer (Ioffe and Szegedy, 2014).\n\nNormalize the activations\
    \ of the previous layer at each batch,\ni.e. applies a transformation that maintains\
    \ the mean activation\nclose to 0 and the activation standard deviation close\
    \ to 1.\n\n# Arguments\n    axis: Integer, the axis that should be normalized\n\
    \        (typically the features axis).\n        For instance, after a `Conv2D`\
    \ layer with\n        `data_format=\"channels_first\"`,\n        set `axis=1`\
    \ in `BatchNormalization`.\n    momentum: Momentum for the moving mean and the\
    \ moving variance.\n    epsilon: Small float added to variance to avoid dividing\
    \ by zero.\n    center: If True, add offset of `beta` to normalized tensor.\n\
    \        If False, `beta` is ignored.\n    scale: If True, multiply by `gamma`.\n\
    \        If False, `gamma` is not used.\n        When the next layer is linear\
    \ (also e.g. `nn.relu`),\n        this can be disabled since the scaling\n   \
    \     will be done by the next layer.\n    beta_initializer: Initializer for the\
    \ beta weight.\n    gamma_initializer: Initializer for the gamma weight.\n   \
    \ moving_mean_initializer: Initializer for the moving mean.\n    moving_variance_initializer:\
    \ Initializer for the moving variance.\n    beta_regularizer: Optional regularizer\
    \ for the beta weight.\n    gamma_regularizer: Optional regularizer for the gamma\
    \ weight.\n    beta_constraint: Optional constraint for the beta weight.\n   \
    \ gamma_constraint: Optional constraint for the gamma weight.\n\n# Input shape\n\
    \    Arbitrary. Use the keyword argument `input_shape`\n    (tuple of integers,\
    \ does not include the samples axis)\n    when using this layer as the first layer\
    \ in a model.\n\n# Output shape\n    Same shape as input.\n\n# References\n  \
    \  - [Batch Normalization: Accelerating Deep Network Training by\n       Reducing\
    \ Internal Covariate Shift](https://arxiv.org/abs/1502.03167)"
  kind: Layer
  name: BatchNormalization
  parameters:
  - {defaultValue: '-1', kind: any, name: axis}
  - {defaultValue: '0.99', kind: any, name: momentum}
  - {defaultValue: '0.001', kind: any, name: epsilon}
  - {defaultValue: 'True', kind: any, name: center}
  - {defaultValue: 'True', kind: any, name: scale}
  - {defaultValue: zeros, kind: any, name: beta_initializer}
  - {defaultValue: ones, kind: any, name: gamma_initializer}
  - {defaultValue: zeros, kind: any, name: moving_mean_initializer}
  - {defaultValue: ones, kind: any, name: moving_variance_initializer}
  - {defaultValue: None, kind: any, name: beta_regularizer}
  - {defaultValue: None, kind: any, name: gamma_regularizer}
  - {defaultValue: None, kind: any, name: beta_constraint}
  - {defaultValue: None, kind: any, name: gamma_constraint}
  - {defaultValue: 'true', name: trainable, type: bool}
  source: "class BatchNormalization(Layer):\n    \"\"\"Batch normalization layer (Ioffe\
    \ and Szegedy, 2014).\n\n    Normalize the activations of the previous layer at\
    \ each batch,\n    i.e. applies a transformation that maintains the mean activation\n\
    \    close to 0 and the activation standard deviation close to 1.\n\n    # Arguments\n\
    \        axis: Integer, the axis that should be normalized\n            (typically\
    \ the features axis).\n            For instance, after a `Conv2D` layer with\n\
    \            `data_format=\"channels_first\"`,\n            set `axis=1` in `BatchNormalization`.\n\
    \        momentum: Momentum for the moving mean and the moving variance.\n   \
    \     epsilon: Small float added to variance to avoid dividing by zero.\n    \
    \    center: If True, add offset of `beta` to normalized tensor.\n           \
    \ If False, `beta` is ignored.\n        scale: If True, multiply by `gamma`.\n\
    \            If False, `gamma` is not used.\n            When the next layer is\
    \ linear (also e.g. `nn.relu`),\n            this can be disabled since the scaling\n\
    \            will be done by the next layer.\n        beta_initializer: Initializer\
    \ for the beta weight.\n        gamma_initializer: Initializer for the gamma weight.\n\
    \        moving_mean_initializer: Initializer for the moving mean.\n        moving_variance_initializer:\
    \ Initializer for the moving variance.\n        beta_regularizer: Optional regularizer\
    \ for the beta weight.\n        gamma_regularizer: Optional regularizer for the\
    \ gamma weight.\n        beta_constraint: Optional constraint for the beta weight.\n\
    \        gamma_constraint: Optional constraint for the gamma weight.\n\n    #\
    \ Input shape\n        Arbitrary. Use the keyword argument `input_shape`\n   \
    \     (tuple of integers, does not include the samples axis)\n        when using\
    \ this layer as the first layer in a model.\n\n    # Output shape\n        Same\
    \ shape as input.\n\n    # References\n        - [Batch Normalization: Accelerating\
    \ Deep Network Training by\n           Reducing Internal Covariate Shift](https://arxiv.org/abs/1502.03167)\n\
    \    \"\"\"\n\n    @interfaces.legacy_batchnorm_support\n    def __init__(self,\n\
    \                 axis=-1,\n                 momentum=0.99,\n                \
    \ epsilon=1e-3,\n                 center=True,\n                 scale=True,\n\
    \                 beta_initializer='zeros',\n                 gamma_initializer='ones',\n\
    \                 moving_mean_initializer='zeros',\n                 moving_variance_initializer='ones',\n\
    \                 beta_regularizer=None,\n                 gamma_regularizer=None,\n\
    \                 beta_constraint=None,\n                 gamma_constraint=None,\n\
    \                 **kwargs):\n        super(BatchNormalization, self).__init__(**kwargs)\n\
    \        self.supports_masking = True\n        self.axis = axis\n        self.momentum\
    \ = momentum\n        self.epsilon = epsilon\n        self.center = center\n \
    \       self.scale = scale\n        self.beta_initializer = initializers.get(beta_initializer)\n\
    \        self.gamma_initializer = initializers.get(gamma_initializer)\n      \
    \  self.moving_mean_initializer = initializers.get(moving_mean_initializer)\n\
    \        self.moving_variance_initializer = (\n            initializers.get(moving_variance_initializer))\n\
    \        self.beta_regularizer = regularizers.get(beta_regularizer)\n        self.gamma_regularizer\
    \ = regularizers.get(gamma_regularizer)\n        self.beta_constraint = constraints.get(beta_constraint)\n\
    \        self.gamma_constraint = constraints.get(gamma_constraint)\n\n    def\
    \ build(self, input_shape):\n        dim = input_shape[self.axis]\n        if\
    \ dim is None:\n            raise ValueError('Axis ' + str(self.axis) + ' of '\n\
    \                             'input tensor should have a defined dimension '\n\
    \                             'but the layer received an input with shape ' +\n\
    \                             str(input_shape) + '.')\n        self.input_spec\
    \ = InputSpec(ndim=len(input_shape),\n                                    axes={self.axis:\
    \ dim})\n        shape = (dim,)\n\n        if self.scale:\n            self.gamma\
    \ = self.add_weight(shape=shape,\n                                         name='gamma',\n\
    \                                         initializer=self.gamma_initializer,\n\
    \                                         regularizer=self.gamma_regularizer,\n\
    \                                         constraint=self.gamma_constraint)\n\
    \        else:\n            self.gamma = None\n        if self.center:\n     \
    \       self.beta = self.add_weight(shape=shape,\n                           \
    \             name='beta',\n                                        initializer=self.beta_initializer,\n\
    \                                        regularizer=self.beta_regularizer,\n\
    \                                        constraint=self.beta_constraint)\n  \
    \      else:\n            self.beta = None\n        self.moving_mean = self.add_weight(\n\
    \            shape=shape,\n            name='moving_mean',\n            initializer=self.moving_mean_initializer,\n\
    \            trainable=False)\n        self.moving_variance = self.add_weight(\n\
    \            shape=shape,\n            name='moving_variance',\n            initializer=self.moving_variance_initializer,\n\
    \            trainable=False)\n        self.built = True\n\n    def call(self,\
    \ inputs, training=None):\n        input_shape = K.int_shape(inputs)\n       \
    \ # Prepare broadcasting shape.\n        ndim = len(input_shape)\n        reduction_axes\
    \ = list(range(len(input_shape)))\n        del reduction_axes[self.axis]\n   \
    \     broadcast_shape = [1] * len(input_shape)\n        broadcast_shape[self.axis]\
    \ = input_shape[self.axis]\n\n        # Determines whether broadcasting is needed.\n\
    \        needs_broadcasting = (sorted(reduction_axes) != list(range(ndim))[:-1])\n\
    \n        def normalize_inference():\n            if needs_broadcasting:\n   \
    \             # In this case we must explicitly broadcast all parameters.\n  \
    \              broadcast_moving_mean = K.reshape(self.moving_mean,\n         \
    \                                         broadcast_shape)\n                broadcast_moving_variance\
    \ = K.reshape(self.moving_variance,\n                                        \
    \              broadcast_shape)\n                if self.center:\n           \
    \         broadcast_beta = K.reshape(self.beta, broadcast_shape)\n           \
    \     else:\n                    broadcast_beta = None\n                if self.scale:\n\
    \                    broadcast_gamma = K.reshape(self.gamma,\n               \
    \                                 broadcast_shape)\n                else:\n  \
    \                  broadcast_gamma = None\n                return K.batch_normalization(\n\
    \                    inputs,\n                    broadcast_moving_mean,\n   \
    \                 broadcast_moving_variance,\n                    broadcast_beta,\n\
    \                    broadcast_gamma,\n                    axis=self.axis,\n \
    \                   epsilon=self.epsilon)\n            else:\n               \
    \ return K.batch_normalization(\n                    inputs,\n               \
    \     self.moving_mean,\n                    self.moving_variance,\n         \
    \           self.beta,\n                    self.gamma,\n                    axis=self.axis,\n\
    \                    epsilon=self.epsilon)\n\n        # If the learning phase\
    \ is *static* and set to inference:\n        if training in {0, False}:\n    \
    \        return normalize_inference()\n\n        # If the learning is either dynamic,\
    \ or set to training:\n        normed_training, mean, variance = K.normalize_batch_in_training(\n\
    \            inputs, self.gamma, self.beta, reduction_axes,\n            epsilon=self.epsilon)\n\
    \n        if K.backend() != 'cntk':\n            sample_size = K.prod([K.shape(inputs)[axis]\n\
    \                                  for axis in reduction_axes])\n            sample_size\
    \ = K.cast(sample_size, dtype=K.dtype(inputs))\n\n            # sample variance\
    \ - unbiased estimator of population variance\n            variance *= sample_size\
    \ / (sample_size - (1.0 + self.epsilon))\n\n        self.add_update([K.moving_average_update(self.moving_mean,\n\
    \                                                 mean,\n                    \
    \                             self.momentum),\n                         K.moving_average_update(self.moving_variance,\n\
    \                                                 variance,\n                \
    \                                 self.momentum)],\n                        inputs)\n\
    \n        # Pick the normalized form corresponding to the training phase.\n  \
    \      return K.in_train_phase(normed_training,\n                            \
    \    normalize_inference,\n                                training=training)\n\
    \n    def get_config(self):\n        config = {\n            'axis': self.axis,\n\
    \            'momentum': self.momentum,\n            'epsilon': self.epsilon,\n\
    \            'center': self.center,\n            'scale': self.scale,\n      \
    \      'beta_initializer': initializers.serialize(self.beta_initializer),\n  \
    \          'gamma_initializer': initializers.serialize(self.gamma_initializer),\n\
    \            'moving_mean_initializer':\n                initializers.serialize(self.moving_mean_initializer),\n\
    \            'moving_variance_initializer':\n                initializers.serialize(self.moving_variance_initializer),\n\
    \            'beta_regularizer': regularizers.serialize(self.beta_regularizer),\n\
    \            'gamma_regularizer': regularizers.serialize(self.gamma_regularizer),\n\
    \            'beta_constraint': constraints.serialize(self.beta_constraint),\n\
    \            'gamma_constraint': constraints.serialize(self.gamma_constraint)\n\
    \        }\n        base_config = super(BatchNormalization, self).get_config()\n\
    \        return dict(list(base_config.items()) + list(config.items()))\n\n   \
    \ def compute_output_shape(self, input_shape):\n        return input_shape\n"
  sourcefile: D:\Python36\lib\site-packages\keras\layers\normalization.py
- doc: "Bidirectional wrapper for RNNs.\n\n# Arguments\n    layer: `Recurrent` instance.\n\
    \    merge_mode: Mode by which outputs of the\n        forward and backward RNNs\
    \ will be combined.\n        One of {'sum', 'mul', 'concat', 'ave', None}.\n \
    \       If None, the outputs will not be combined,\n        they will be returned\
    \ as a list.\n\n# Raises\n    ValueError: In case of invalid `merge_mode` argument.\n\
    \n# Examples\n\n```python\n    model = Sequential()\n    model.add(Bidirectional(LSTM(10,\
    \ return_sequences=True),\n                            input_shape=(5, 10)))\n\
    \    model.add(Bidirectional(LSTM(10)))\n    model.add(Dense(5))\n    model.add(Activation('softmax'))\n\
    \    model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n```"
  kind: Layer
  name: Bidirectional
  parameters:
  - {kind: any, name: layer}
  - {defaultValue: concat, kind: any, name: merge_mode}
  - {defaultValue: None, kind: any, name: weights}
  - {defaultValue: 'true', name: trainable, type: bool}
  source: "class Bidirectional(Wrapper):\n    \"\"\"Bidirectional wrapper for RNNs.\n\
    \n    # Arguments\n        layer: `Recurrent` instance.\n        merge_mode: Mode\
    \ by which outputs of the\n            forward and backward RNNs will be combined.\n\
    \            One of {'sum', 'mul', 'concat', 'ave', None}.\n            If None,\
    \ the outputs will not be combined,\n            they will be returned as a list.\n\
    \n    # Raises\n        ValueError: In case of invalid `merge_mode` argument.\n\
    \n    # Examples\n\n    ```python\n        model = Sequential()\n        model.add(Bidirectional(LSTM(10,\
    \ return_sequences=True),\n                                input_shape=(5, 10)))\n\
    \        model.add(Bidirectional(LSTM(10)))\n        model.add(Dense(5))\n   \
    \     model.add(Activation('softmax'))\n        model.compile(loss='categorical_crossentropy',\
    \ optimizer='rmsprop')\n    ```\n    \"\"\"\n\n    def __init__(self, layer, merge_mode='concat',\
    \ weights=None, **kwargs):\n        if merge_mode not in ['sum', 'mul', 'ave',\
    \ 'concat', None]:\n            raise ValueError('Invalid merge mode. '\n    \
    \                         'Merge mode should be one of '\n                   \
    \          '{\"sum\", \"mul\", \"ave\", \"concat\", None}')\n        self.forward_layer\
    \ = copy.copy(layer)\n        if isinstance(layer, dict):\n            print(\"\
    AAA\")\n        config = layer.get_config()\n        config['go_backwards'] =\
    \ not config['go_backwards']\n        self.backward_layer = layer.__class__.from_config(config)\n\
    \        self.forward_layer.name = 'forward_' + self.forward_layer.name\n    \
    \    self.backward_layer.name = 'backward_' + self.backward_layer.name\n     \
    \   self.merge_mode = merge_mode\n        if weights:\n            nw = len(weights)\n\
    \            self.forward_layer.initial_weights = weights[:nw // 2]\n        \
    \    self.backward_layer.initial_weights = weights[nw // 2:]\n        self.stateful\
    \ = layer.stateful\n        self.return_sequences = layer.return_sequences\n \
    \       self.return_state = layer.return_state\n        self.supports_masking\
    \ = True\n        self._trainable = True\n        super(Bidirectional, self).__init__(layer,\
    \ **kwargs)\n        self.input_spec = layer.input_spec\n        self._num_constants\
    \ = None\n\n    @property\n    def trainable(self):\n        return self._trainable\n\
    \n    @trainable.setter\n    def trainable(self, value):\n        self._trainable\
    \ = value\n        self.forward_layer.trainable = value\n        self.backward_layer.trainable\
    \ = value\n\n    def get_weights(self):\n        return self.forward_layer.get_weights()\
    \ + self.backward_layer.get_weights()\n\n    def set_weights(self, weights):\n\
    \        nw = len(weights)\n        self.forward_layer.set_weights(weights[:nw\
    \ // 2])\n        self.backward_layer.set_weights(weights[nw // 2:])\n\n    def\
    \ compute_output_shape(self, input_shape):\n        output_shape = self.forward_layer.compute_output_shape(input_shape)\n\
    \        if self.return_state:\n            state_shape = output_shape[1:]\n \
    \           output_shape = output_shape[0]\n\n        if self.merge_mode == 'concat':\n\
    \            output_shape = list(output_shape)\n            output_shape[-1] *=\
    \ 2\n            output_shape = tuple(output_shape)\n        elif self.merge_mode\
    \ is None:\n            output_shape = [output_shape, copy.copy(output_shape)]\n\
    \n        if self.return_state:\n            if self.merge_mode is None:\n   \
    \             return output_shape + state_shape + copy.copy(state_shape)\n   \
    \         return [output_shape] + state_shape + copy.copy(state_shape)\n     \
    \   return output_shape\n\n    def __call__(self, inputs, initial_state=None,\
    \ constants=None, **kwargs):\n        inputs, initial_state, constants = recurrent._standardize_args(\n\
    \            inputs, initial_state, constants, self._num_constants)\n\n      \
    \  if initial_state is None and constants is None:\n            return super(Bidirectional,\
    \ self).__call__(inputs, **kwargs)\n\n        # Applies the same workaround as\
    \ in `RNN.__call__`\n        additional_inputs = []\n        additional_specs\
    \ = []\n        if initial_state is not None:\n            # Check if `initial_state`\
    \ can be splitted into half\n            num_states = len(initial_state)\n   \
    \         if num_states % 2 > 0:\n                raise ValueError(\n        \
    \            'When passing `initial_state` to a Bidirectional RNN, '\n       \
    \             'the state should be a list containing the states of '\n       \
    \             'the underlying RNNs. '\n                    'Found: ' + str(initial_state))\n\
    \n            kwargs['initial_state'] = initial_state\n            additional_inputs\
    \ += initial_state\n            state_specs = [InputSpec(shape=K.int_shape(state))\n\
    \                           for state in initial_state]\n            self.forward_layer.state_spec\
    \ = state_specs[:num_states // 2]\n            self.backward_layer.state_spec\
    \ = state_specs[num_states // 2:]\n            additional_specs += state_specs\n\
    \        if constants is not None:\n            kwargs['constants'] = constants\n\
    \            additional_inputs += constants\n            constants_spec = [InputSpec(shape=K.int_shape(constant))\n\
    \                              for constant in constants]\n            self.forward_layer.constants_spec\
    \ = constants_spec\n            self.backward_layer.constants_spec = constants_spec\n\
    \            additional_specs += constants_spec\n\n            self._num_constants\
    \ = len(constants)\n            self.forward_layer._num_constants = self._num_constants\n\
    \            self.backward_layer._num_constants = self._num_constants\n\n    \
    \    is_keras_tensor = K.is_keras_tensor(additional_inputs[0])\n        for tensor\
    \ in additional_inputs:\n            if K.is_keras_tensor(tensor) != is_keras_tensor:\n\
    \                raise ValueError('The initial state of a Bidirectional'\n   \
    \                              ' layer cannot be specified with a mix of'\n  \
    \                               ' Keras tensors and non-Keras tensors'\n     \
    \                            ' (a \"Keras tensor\" is a tensor that was'\n   \
    \                              ' returned by a Keras layer, or by `Input`)')\n\
    \n        if is_keras_tensor:\n            # Compute the full input spec, including\
    \ state\n            full_input = [inputs] + additional_inputs\n            full_input_spec\
    \ = self.input_spec + additional_specs\n\n            # Perform the call with\
    \ temporarily replaced input_spec\n            original_input_spec = self.input_spec\n\
    \            self.input_spec = full_input_spec\n            output = super(Bidirectional,\
    \ self).__call__(full_input, **kwargs)\n            self.input_spec = original_input_spec\n\
    \            return output\n        else:\n            return super(Bidirectional,\
    \ self).__call__(inputs, **kwargs)\n\n    def call(self,\n             inputs,\n\
    \             mask=None,\n             training=None,\n             initial_state=None,\n\
    \             constants=None):\n        kwargs = {}\n        if has_arg(self.layer.call,\
    \ 'training'):\n            kwargs['training'] = training\n        if has_arg(self.layer.call,\
    \ 'mask'):\n            kwargs['mask'] = mask\n        if has_arg(self.layer.call,\
    \ 'constants'):\n            kwargs['constants'] = constants\n\n        if initial_state\
    \ is not None and has_arg(self.layer.call, 'initial_state'):\n            forward_inputs\
    \ = [inputs[0]]\n            backward_inputs = [inputs[0]]\n            pivot\
    \ = len(initial_state) // 2 + 1\n            # add forward initial state\n   \
    \         forward_state = inputs[1:pivot]\n            forward_inputs += forward_state\n\
    \            if self._num_constants is None:\n                # add backward initial\
    \ state\n                backward_state = inputs[pivot:]\n                backward_inputs\
    \ += backward_state\n            else:\n                # add backward initial\
    \ state\n                backward_state = inputs[pivot:-self._num_constants]\n\
    \                backward_inputs += backward_state\n                # add constants\
    \ for forward and backward layers\n                forward_inputs += inputs[-self._num_constants:]\n\
    \                backward_inputs += inputs[-self._num_constants:]\n          \
    \  y = self.forward_layer.call(forward_inputs,\n                             \
    \           initial_state=forward_state, **kwargs)\n            y_rev = self.backward_layer.call(backward_inputs,\n\
    \                                             initial_state=backward_state, **kwargs)\n\
    \        else:\n            y = self.forward_layer.call(inputs, **kwargs)\n  \
    \          y_rev = self.backward_layer.call(inputs, **kwargs)\n\n        if self.return_state:\n\
    \            states = y[1:] + y_rev[1:]\n            y = y[0]\n            y_rev\
    \ = y_rev[0]\n\n        if self.return_sequences:\n            y_rev = K.reverse(y_rev,\
    \ 1)\n        if self.merge_mode == 'concat':\n            output = K.concatenate([y,\
    \ y_rev])\n        elif self.merge_mode == 'sum':\n            output = y + y_rev\n\
    \        elif self.merge_mode == 'ave':\n            output = (y + y_rev) / 2\n\
    \        elif self.merge_mode == 'mul':\n            output = y * y_rev\n    \
    \    elif self.merge_mode is None:\n            output = [y, y_rev]\n        else:\n\
    \            raise ValueError('Unrecognized value for argument '\n           \
    \                  'merge_mode: %s' % (self.merge_mode))\n\n        # Properly\
    \ set learning phase\n        if (getattr(y, '_uses_learning_phase', False) or\n\
    \           getattr(y_rev, '_uses_learning_phase', False)):\n            if self.merge_mode\
    \ is None:\n                for out in output:\n                    out._uses_learning_phase\
    \ = True\n            else:\n                output._uses_learning_phase = True\n\
    \n        if self.return_state:\n            if self.merge_mode is None:\n   \
    \             return output + states\n            return [output] + states\n \
    \       return output\n\n    def reset_states(self):\n        self.forward_layer.reset_states()\n\
    \        self.backward_layer.reset_states()\n\n    def build(self, input_shape):\n\
    \        with K.name_scope(self.forward_layer.name):\n            self.forward_layer.build(input_shape)\n\
    \        with K.name_scope(self.backward_layer.name):\n            self.backward_layer.build(input_shape)\n\
    \        self.built = True\n\n    def compute_mask(self, inputs, mask):\n    \
    \    if isinstance(mask, list):\n            mask = mask[0]\n        if self.return_sequences:\n\
    \            if not self.merge_mode:\n                output_mask = [mask, mask]\n\
    \            else:\n                output_mask = mask\n        else:\n      \
    \      output_mask = [None, None] if not self.merge_mode else None\n\n       \
    \ if self.return_state:\n            states = self.forward_layer.states\n    \
    \        state_mask = [None for _ in states]\n            if isinstance(output_mask,\
    \ list):\n                return output_mask + state_mask * 2\n            return\
    \ [output_mask] + state_mask * 2\n\n        return output_mask\n\n    @property\n\
    \    def trainable_weights(self):\n        if hasattr(self.forward_layer, 'trainable_weights'):\n\
    \            return (self.forward_layer.trainable_weights +\n                \
    \    self.backward_layer.trainable_weights)\n        return []\n\n    @property\n\
    \    def non_trainable_weights(self):\n        if hasattr(self.forward_layer,\
    \ 'non_trainable_weights'):\n            return (self.forward_layer.non_trainable_weights\
    \ +\n                    self.backward_layer.non_trainable_weights)\n        return\
    \ []\n\n    @property\n    def updates(self):\n        if hasattr(self.forward_layer,\
    \ 'updates'):\n            return self.forward_layer.updates + self.backward_layer.updates\n\
    \        return []\n\n    def get_updates_for(self, inputs=None):\n        forward_updates\
    \ = self.forward_layer.get_updates_for(inputs)\n        backward_updates = self.backward_layer.get_updates_for(inputs)\n\
    \        return (super(Wrapper, self).get_updates_for(inputs) +\n            \
    \    forward_updates + backward_updates)\n\n    @property\n    def losses(self):\n\
    \        if hasattr(self.forward_layer, 'losses'):\n            return self.forward_layer.losses\
    \ + self.backward_layer.losses\n        return []\n\n    def get_losses_for(self,\
    \ inputs=None):\n        forward_losses = self.forward_layer.get_losses_for(inputs)\n\
    \        backward_losses = self.backward_layer.get_losses_for(inputs)\n      \
    \  return (super(Wrapper, self).get_losses_for(inputs) +\n                forward_losses\
    \ + backward_losses)\n\n    @property\n    def constraints(self):\n        constraints\
    \ = {}\n        if hasattr(self.forward_layer, 'constraints'):\n            constraints.update(self.forward_layer.constraints)\n\
    \            constraints.update(self.backward_layer.constraints)\n        return\
    \ constraints\n\n    def get_config(self):\n        config = {'merge_mode': self.merge_mode}\n\
    \        if self._num_constants is not None:\n            config['num_constants']\
    \ = self._num_constants\n\n        base_config = super(Bidirectional, self).get_config()\n\
    \        return dict(list(base_config.items()) + list(config.items()))\n\n   \
    \ @classmethod\n    def from_config(cls, config, custom_objects=None):\n     \
    \   from . import deserialize as deserialize_layer\n        rnn_layer = deserialize_layer(config.pop('layer'),\n\
    \                                      custom_objects=custom_objects)\n      \
    \  num_constants = config.pop('num_constants', None)\n        layer = cls(rnn_layer,\
    \ **config)\n        layer._num_constants = num_constants\n        return layer\n"
  sourcefile: D:\Python36\lib\site-packages\keras\layers\wrappers.py
- doc: "Layer that concatenates a list of inputs.\n\nIt takes as input a list of tensors,\n\
    all of the same shape except for the concatenation axis,\nand returns a single\
    \ tensor, the concatenation of all inputs.\n\n# Arguments\n    axis: Axis along\
    \ which to concatenate.\n    **kwargs: standard layer keyword arguments."
  kind: Layer
  name: Concatenate
  parameters:
  - {defaultValue: '-1', kind: any, name: axis}
  - {defaultValue: 'true', name: trainable, type: bool}
  source: "class Concatenate(_Merge):\n    \"\"\"Layer that concatenates a list of\
    \ inputs.\n\n    It takes as input a list of tensors,\n    all of the same shape\
    \ except for the concatenation axis,\n    and returns a single tensor, the concatenation\
    \ of all inputs.\n\n    # Arguments\n        axis: Axis along which to concatenate.\n\
    \        **kwargs: standard layer keyword arguments.\n    \"\"\"\n\n    def __init__(self,\
    \ axis=-1, **kwargs):\n        super(Concatenate, self).__init__(**kwargs)\n \
    \       self.axis = axis\n        self.supports_masking = True\n        self._reshape_required\
    \ = False\n\n    def build(self, input_shape):\n        # Used purely for shape\
    \ validation.\n        if not isinstance(input_shape, list) or len(input_shape)\
    \ < 2:\n            raise ValueError('A `Concatenate` layer should be called '\n\
    \                             'on a list of at least 2 inputs')\n        if all([shape\
    \ is None for shape in input_shape]):\n            return\n        reduced_inputs_shapes\
    \ = [list(shape) for shape in input_shape]\n        shape_set = set()\n      \
    \  for i in range(len(reduced_inputs_shapes)):\n            del reduced_inputs_shapes[i][self.axis]\n\
    \            shape_set.add(tuple(reduced_inputs_shapes[i]))\n        if len(shape_set)\
    \ > 1:\n            raise ValueError('A `Concatenate` layer requires '\n     \
    \                        'inputs with matching shapes '\n                    \
    \         'except for the concat axis. '\n                             'Got inputs\
    \ shapes: %s' % (input_shape))\n\n    def _merge_function(self, inputs):\n   \
    \     return K.concatenate(inputs, axis=self.axis)\n\n    def compute_output_shape(self,\
    \ input_shape):\n        if not isinstance(input_shape, list):\n            raise\
    \ ValueError('A `Concatenate` layer should be called '\n                     \
    \        'on a list of inputs.')\n        input_shapes = input_shape\n       \
    \ output_shape = list(input_shapes[0])\n        for shape in input_shapes[1:]:\n\
    \            if output_shape[self.axis] is None or shape[self.axis] is None:\n\
    \                output_shape[self.axis] = None\n                break\n     \
    \       output_shape[self.axis] += shape[self.axis]\n        return tuple(output_shape)\n\
    \n    def compute_mask(self, inputs, mask=None):\n        if mask is None:\n \
    \           return None\n        if not isinstance(mask, list):\n            raise\
    \ ValueError('`mask` should be a list.')\n        if not isinstance(inputs, list):\n\
    \            raise ValueError('`inputs` should be a list.')\n        if len(mask)\
    \ != len(inputs):\n            raise ValueError('The lists `inputs` and `mask`\
    \ '\n                             'should have the same length.')\n        if\
    \ all([m is None for m in mask]):\n            return None\n        # Make a list\
    \ of masks while making sure\n        # the dimensionality of each mask\n    \
    \    # is the same as the corresponding input.\n        masks = []\n        for\
    \ input_i, mask_i in zip(inputs, mask):\n            if mask_i is None:\n    \
    \            # Input is unmasked. Append all 1s to masks,\n                masks.append(K.ones_like(input_i,\
    \ dtype='bool'))\n            elif K.ndim(mask_i) < K.ndim(input_i):\n       \
    \         # Mask is smaller than the input, expand it\n                masks.append(K.expand_dims(mask_i))\n\
    \            else:\n                masks.append(mask_i)\n        concatenated\
    \ = K.concatenate(masks, axis=self.axis)\n        return K.all(concatenated, axis=-1,\
    \ keepdims=False)\n\n    def get_config(self):\n        config = {\n         \
    \   'axis': self.axis,\n        }\n        base_config = super(Concatenate, self).get_config()\n\
    \        return dict(list(base_config.items()) + list(config.items()))\n"
  sourcefile: D:\Python36\lib\site-packages\keras\layers\merge.py
- doc: "1D convolution layer (e.g. temporal convolution).\n\nThis layer creates a\
    \ convolution kernel that is convolved\nwith the layer input over a single spatial\
    \ (or temporal) dimension\nto produce a tensor of outputs.\nIf `use_bias` is True,\
    \ a bias vector is created and added to the outputs.\nFinally, if `activation`\
    \ is not `None`,\nit is applied to the outputs as well.\n\nWhen using this layer\
    \ as the first layer in a model,\nprovide an `input_shape` argument\n(tuple of\
    \ integers or `None`, e.g.\n`(10, 128)` for sequences of 10 vectors of 128-dimensional\
    \ vectors,\nor `(None, 128)` for variable-length sequences of 128-dimensional\
    \ vectors.\n\n# Arguments\n    filters: Integer, the dimensionality of the output\
    \ space\n        (i.e. the number of output filters in the convolution).\n   \
    \ kernel_size: An integer or tuple/list of a single integer,\n        specifying\
    \ the length of the 1D convolution window.\n    strides: An integer or tuple/list\
    \ of a single integer,\n        specifying the stride length of the convolution.\n\
    \        Specifying any stride value != 1 is incompatible with specifying\n  \
    \      any `dilation_rate` value != 1.\n    padding: One of `\"valid\"`, `\"causal\"\
    ` or `\"same\"` (case-insensitive).\n        `\"valid\"` means \"no padding\"\
    .\n        `\"same\"` results in padding the input such that\n        the output\
    \ has the same length as the original input.\n        `\"causal\"` results in\
    \ causal (dilated) convolutions,\n        e.g. `output[t]` does not depend on\
    \ `input[t + 1:]`.\n        A zero padding is used such that\n        the output\
    \ has the same length as the original input.\n        Useful when modeling temporal\
    \ data where the model\n        should not violate the temporal order. See\n \
    \       [WaveNet: A Generative Model for Raw Audio, section 2.1]\n        (https://arxiv.org/abs/1609.03499).\n\
    \    data_format: A string,\n        one of `\"channels_last\"` (default) or `\"\
    channels_first\"`.\n        The ordering of the dimensions in the inputs.\n  \
    \      `\"channels_last\"` corresponds to inputs with shape\n        `(batch,\
    \ steps, channels)`\n        (default format for temporal data in Keras)\n   \
    \     while `\"channels_first\"` corresponds to inputs\n        with shape `(batch,\
    \ channels, steps)`.\n    dilation_rate: an integer or tuple/list of a single\
    \ integer, specifying\n        the dilation rate to use for dilated convolution.\n\
    \        Currently, specifying any `dilation_rate` value != 1 is\n        incompatible\
    \ with specifying any `strides` value != 1.\n    activation: Activation function\
    \ to use\n        (see [activations](../activations.md)).\n        If you don't\
    \ specify anything, no activation is applied\n        (ie. \"linear\" activation:\
    \ `a(x) = x`).\n    use_bias: Boolean, whether the layer uses a bias vector.\n\
    \    kernel_initializer: Initializer for the `kernel` weights matrix\n       \
    \ (see [initializers](../initializers.md)).\n    bias_initializer: Initializer\
    \ for the bias vector\n        (see [initializers](../initializers.md)).\n   \
    \ kernel_regularizer: Regularizer function applied to\n        the `kernel` weights\
    \ matrix\n        (see [regularizer](../regularizers.md)).\n    bias_regularizer:\
    \ Regularizer function applied to the bias vector\n        (see [regularizer](../regularizers.md)).\n\
    \    activity_regularizer: Regularizer function applied to\n        the output\
    \ of the layer (its \"activation\").\n        (see [regularizer](../regularizers.md)).\n\
    \    kernel_constraint: Constraint function applied to the kernel matrix\n   \
    \     (see [constraints](../constraints.md)).\n    bias_constraint: Constraint\
    \ function applied to the bias vector\n        (see [constraints](../constraints.md)).\n\
    \n# Input shape\n    3D tensor with shape: `(batch, steps, channels)`\n\n# Output\
    \ shape\n    3D tensor with shape: `(batch, new_steps, filters)`\n    `steps`\
    \ value might have changed due to padding or strides."
  kind: Layer
  name: Conv1D
  parameters:
  - {kind: any, name: filters}
  - {kind: any, name: kernel_size}
  - {defaultValue: '1', kind: any, name: strides}
  - {defaultValue: valid, kind: any, name: padding}
  - {defaultValue: channels_last, kind: any, name: data_format}
  - {defaultValue: '1', kind: any, name: dilation_rate}
  - {defaultValue: None, kind: any, name: activation}
  - {defaultValue: 'True', kind: any, name: use_bias}
  - {defaultValue: glorot_uniform, kind: any, name: kernel_initializer}
  - {defaultValue: zeros, kind: any, name: bias_initializer}
  - {defaultValue: None, kind: any, name: kernel_regularizer}
  - {defaultValue: None, kind: any, name: bias_regularizer}
  - {defaultValue: None, kind: any, name: activity_regularizer}
  - {defaultValue: None, kind: any, name: kernel_constraint}
  - {defaultValue: None, kind: any, name: bias_constraint}
  - {defaultValue: 'true', name: trainable, type: bool}
  source: "class Conv1D(_Conv):\n    \"\"\"1D convolution layer (e.g. temporal convolution).\n\
    \n    This layer creates a convolution kernel that is convolved\n    with the\
    \ layer input over a single spatial (or temporal) dimension\n    to produce a\
    \ tensor of outputs.\n    If `use_bias` is True, a bias vector is created and\
    \ added to the outputs.\n    Finally, if `activation` is not `None`,\n    it is\
    \ applied to the outputs as well.\n\n    When using this layer as the first layer\
    \ in a model,\n    provide an `input_shape` argument\n    (tuple of integers or\
    \ `None`, e.g.\n    `(10, 128)` for sequences of 10 vectors of 128-dimensional\
    \ vectors,\n    or `(None, 128)` for variable-length sequences of 128-dimensional\
    \ vectors.\n\n    # Arguments\n        filters: Integer, the dimensionality of\
    \ the output space\n            (i.e. the number of output filters in the convolution).\n\
    \        kernel_size: An integer or tuple/list of a single integer,\n        \
    \    specifying the length of the 1D convolution window.\n        strides: An\
    \ integer or tuple/list of a single integer,\n            specifying the stride\
    \ length of the convolution.\n            Specifying any stride value != 1 is\
    \ incompatible with specifying\n            any `dilation_rate` value != 1.\n\
    \        padding: One of `\"valid\"`, `\"causal\"` or `\"same\"` (case-insensitive).\n\
    \            `\"valid\"` means \"no padding\".\n            `\"same\"` results\
    \ in padding the input such that\n            the output has the same length as\
    \ the original input.\n            `\"causal\"` results in causal (dilated) convolutions,\n\
    \            e.g. `output[t]` does not depend on `input[t + 1:]`.\n          \
    \  A zero padding is used such that\n            the output has the same length\
    \ as the original input.\n            Useful when modeling temporal data where\
    \ the model\n            should not violate the temporal order. See\n        \
    \    [WaveNet: A Generative Model for Raw Audio, section 2.1]\n            (https://arxiv.org/abs/1609.03499).\n\
    \        data_format: A string,\n            one of `\"channels_last\"` (default)\
    \ or `\"channels_first\"`.\n            The ordering of the dimensions in the\
    \ inputs.\n            `\"channels_last\"` corresponds to inputs with shape\n\
    \            `(batch, steps, channels)`\n            (default format for temporal\
    \ data in Keras)\n            while `\"channels_first\"` corresponds to inputs\n\
    \            with shape `(batch, channels, steps)`.\n        dilation_rate: an\
    \ integer or tuple/list of a single integer, specifying\n            the dilation\
    \ rate to use for dilated convolution.\n            Currently, specifying any\
    \ `dilation_rate` value != 1 is\n            incompatible with specifying any\
    \ `strides` value != 1.\n        activation: Activation function to use\n    \
    \        (see [activations](../activations.md)).\n            If you don't specify\
    \ anything, no activation is applied\n            (ie. \"linear\" activation:\
    \ `a(x) = x`).\n        use_bias: Boolean, whether the layer uses a bias vector.\n\
    \        kernel_initializer: Initializer for the `kernel` weights matrix\n   \
    \         (see [initializers](../initializers.md)).\n        bias_initializer:\
    \ Initializer for the bias vector\n            (see [initializers](../initializers.md)).\n\
    \        kernel_regularizer: Regularizer function applied to\n            the\
    \ `kernel` weights matrix\n            (see [regularizer](../regularizers.md)).\n\
    \        bias_regularizer: Regularizer function applied to the bias vector\n \
    \           (see [regularizer](../regularizers.md)).\n        activity_regularizer:\
    \ Regularizer function applied to\n            the output of the layer (its \"\
    activation\").\n            (see [regularizer](../regularizers.md)).\n       \
    \ kernel_constraint: Constraint function applied to the kernel matrix\n      \
    \      (see [constraints](../constraints.md)).\n        bias_constraint: Constraint\
    \ function applied to the bias vector\n            (see [constraints](../constraints.md)).\n\
    \n    # Input shape\n        3D tensor with shape: `(batch, steps, channels)`\n\
    \n    # Output shape\n        3D tensor with shape: `(batch, new_steps, filters)`\n\
    \        `steps` value might have changed due to padding or strides.\n    \"\"\
    \"\n\n    @interfaces.legacy_conv1d_support\n    def __init__(self, filters,\n\
    \                 kernel_size,\n                 strides=1,\n                \
    \ padding='valid',\n                 data_format='channels_last',\n          \
    \       dilation_rate=1,\n                 activation=None,\n                \
    \ use_bias=True,\n                 kernel_initializer='glorot_uniform',\n    \
    \             bias_initializer='zeros',\n                 kernel_regularizer=None,\n\
    \                 bias_regularizer=None,\n                 activity_regularizer=None,\n\
    \                 kernel_constraint=None,\n                 bias_constraint=None,\n\
    \                 **kwargs):\n        if padding == 'causal':\n            if\
    \ data_format != 'channels_last':\n                raise ValueError('When using\
    \ causal padding in `Conv1D`, '\n                                 '`data_format`\
    \ must be \"channels_last\" '\n                                 '(temporal data).')\n\
    \        super(Conv1D, self).__init__(\n            rank=1,\n            filters=filters,\n\
    \            kernel_size=kernel_size,\n            strides=strides,\n        \
    \    padding=padding,\n            data_format=data_format,\n            dilation_rate=dilation_rate,\n\
    \            activation=activation,\n            use_bias=use_bias,\n        \
    \    kernel_initializer=kernel_initializer,\n            bias_initializer=bias_initializer,\n\
    \            kernel_regularizer=kernel_regularizer,\n            bias_regularizer=bias_regularizer,\n\
    \            activity_regularizer=activity_regularizer,\n            kernel_constraint=kernel_constraint,\n\
    \            bias_constraint=bias_constraint,\n            **kwargs)\n\n    def\
    \ get_config(self):\n        config = super(Conv1D, self).get_config()\n     \
    \   config.pop('rank')\n        return config\n"
  sourcefile: D:\Python36\lib\site-packages\keras\layers\convolutional.py
- doc: "2D convolution layer (e.g. spatial convolution over images).\n\nThis layer\
    \ creates a convolution kernel that is convolved\nwith the layer input to produce\
    \ a tensor of\noutputs. If `use_bias` is True,\na bias vector is created and added\
    \ to the outputs. Finally, if\n`activation` is not `None`, it is applied to the\
    \ outputs as well.\n\nWhen using this layer as the first layer in a model,\nprovide\
    \ the keyword argument `input_shape`\n(tuple of integers, does not include the\
    \ sample axis),\ne.g. `input_shape=(128, 128, 3)` for 128x128 RGB pictures\nin\
    \ `data_format=\"channels_last\"`.\n\n# Arguments\n    filters: Integer, the dimensionality\
    \ of the output space\n        (i.e. the number of output filters in the convolution).\n\
    \    kernel_size: An integer or tuple/list of 2 integers, specifying the\n   \
    \     height and width of the 2D convolution window.\n        Can be a single\
    \ integer to specify the same value for\n        all spatial dimensions.\n   \
    \ strides: An integer or tuple/list of 2 integers,\n        specifying the strides\
    \ of the convolution\n        along the height and width.\n        Can be a single\
    \ integer to specify the same value for\n        all spatial dimensions.\n   \
    \     Specifying any stride value != 1 is incompatible with specifying\n     \
    \   any `dilation_rate` value != 1.\n    padding: one of `\"valid\"` or `\"same\"\
    ` (case-insensitive).\n        Note that `\"same\"` is slightly inconsistent across\
    \ backends with\n        `strides` != 1, as described\n        [here](https://github.com/keras-team/keras/pull/9473#issuecomment-372166860)\n\
    \    data_format: A string,\n        one of `\"channels_last\"` or `\"channels_first\"\
    `.\n        The ordering of the dimensions in the inputs.\n        `\"channels_last\"\
    ` corresponds to inputs with shape\n        `(batch, height, width, channels)`\
    \ while `\"channels_first\"`\n        corresponds to inputs with shape\n     \
    \   `(batch, channels, height, width)`.\n        It defaults to the `image_data_format`\
    \ value found in your\n        Keras config file at `~/.keras/keras.json`.\n \
    \       If you never set it, then it will be \"channels_last\".\n    dilation_rate:\
    \ an integer or tuple/list of 2 integers, specifying\n        the dilation rate\
    \ to use for dilated convolution.\n        Can be a single integer to specify\
    \ the same value for\n        all spatial dimensions.\n        Currently, specifying\
    \ any `dilation_rate` value != 1 is\n        incompatible with specifying any\
    \ stride value != 1.\n    activation: Activation function to use\n        (see\
    \ [activations](../activations.md)).\n        If you don't specify anything, no\
    \ activation is applied\n        (ie. \"linear\" activation: `a(x) = x`).\n  \
    \  use_bias: Boolean, whether the layer uses a bias vector.\n    kernel_initializer:\
    \ Initializer for the `kernel` weights matrix\n        (see [initializers](../initializers.md)).\n\
    \    bias_initializer: Initializer for the bias vector\n        (see [initializers](../initializers.md)).\n\
    \    kernel_regularizer: Regularizer function applied to\n        the `kernel`\
    \ weights matrix\n        (see [regularizer](../regularizers.md)).\n    bias_regularizer:\
    \ Regularizer function applied to the bias vector\n        (see [regularizer](../regularizers.md)).\n\
    \    activity_regularizer: Regularizer function applied to\n        the output\
    \ of the layer (its \"activation\").\n        (see [regularizer](../regularizers.md)).\n\
    \    kernel_constraint: Constraint function applied to the kernel matrix\n   \
    \     (see [constraints](../constraints.md)).\n    bias_constraint: Constraint\
    \ function applied to the bias vector\n        (see [constraints](../constraints.md)).\n\
    \n# Input shape\n    4D tensor with shape:\n    `(batch, channels, rows, cols)`\n\
    \    if `data_format` is `\"channels_first\"`\n    or 4D tensor with shape:\n\
    \    `(batch, rows, cols, channels)`\n    if `data_format` is `\"channels_last\"\
    `.\n\n# Output shape\n    4D tensor with shape:\n    `(batch, filters, new_rows,\
    \ new_cols)`\n    if `data_format` is `\"channels_first\"`\n    or 4D tensor with\
    \ shape:\n    `(batch, new_rows, new_cols, filters)`\n    if `data_format` is\
    \ `\"channels_last\"`.\n    `rows` and `cols` values might have changed due to\
    \ padding."
  kind: Layer
  name: Conv2D
  parameters:
  - {kind: any, name: filters}
  - {kind: any, name: kernel_size}
  - {defaultValue: '(1, 1)', kind: any, name: strides}
  - {defaultValue: valid, kind: any, name: padding}
  - {defaultValue: None, kind: any, name: data_format}
  - {defaultValue: '(1, 1)', kind: any, name: dilation_rate}
  - {defaultValue: None, kind: any, name: activation}
  - {defaultValue: 'True', kind: any, name: use_bias}
  - {defaultValue: glorot_uniform, kind: any, name: kernel_initializer}
  - {defaultValue: zeros, kind: any, name: bias_initializer}
  - {defaultValue: None, kind: any, name: kernel_regularizer}
  - {defaultValue: None, kind: any, name: bias_regularizer}
  - {defaultValue: None, kind: any, name: activity_regularizer}
  - {defaultValue: None, kind: any, name: kernel_constraint}
  - {defaultValue: None, kind: any, name: bias_constraint}
  - {defaultValue: 'true', name: trainable, type: bool}
  source: "class Conv2D(_Conv):\n    \"\"\"2D convolution layer (e.g. spatial convolution\
    \ over images).\n\n    This layer creates a convolution kernel that is convolved\n\
    \    with the layer input to produce a tensor of\n    outputs. If `use_bias` is\
    \ True,\n    a bias vector is created and added to the outputs. Finally, if\n\
    \    `activation` is not `None`, it is applied to the outputs as well.\n\n   \
    \ When using this layer as the first layer in a model,\n    provide the keyword\
    \ argument `input_shape`\n    (tuple of integers, does not include the sample\
    \ axis),\n    e.g. `input_shape=(128, 128, 3)` for 128x128 RGB pictures\n    in\
    \ `data_format=\"channels_last\"`.\n\n    # Arguments\n        filters: Integer,\
    \ the dimensionality of the output space\n            (i.e. the number of output\
    \ filters in the convolution).\n        kernel_size: An integer or tuple/list\
    \ of 2 integers, specifying the\n            height and width of the 2D convolution\
    \ window.\n            Can be a single integer to specify the same value for\n\
    \            all spatial dimensions.\n        strides: An integer or tuple/list\
    \ of 2 integers,\n            specifying the strides of the convolution\n    \
    \        along the height and width.\n            Can be a single integer to specify\
    \ the same value for\n            all spatial dimensions.\n            Specifying\
    \ any stride value != 1 is incompatible with specifying\n            any `dilation_rate`\
    \ value != 1.\n        padding: one of `\"valid\"` or `\"same\"` (case-insensitive).\n\
    \            Note that `\"same\"` is slightly inconsistent across backends with\n\
    \            `strides` != 1, as described\n            [here](https://github.com/keras-team/keras/pull/9473#issuecomment-372166860)\n\
    \        data_format: A string,\n            one of `\"channels_last\"` or `\"\
    channels_first\"`.\n            The ordering of the dimensions in the inputs.\n\
    \            `\"channels_last\"` corresponds to inputs with shape\n          \
    \  `(batch, height, width, channels)` while `\"channels_first\"`\n           \
    \ corresponds to inputs with shape\n            `(batch, channels, height, width)`.\n\
    \            It defaults to the `image_data_format` value found in your\n    \
    \        Keras config file at `~/.keras/keras.json`.\n            If you never\
    \ set it, then it will be \"channels_last\".\n        dilation_rate: an integer\
    \ or tuple/list of 2 integers, specifying\n            the dilation rate to use\
    \ for dilated convolution.\n            Can be a single integer to specify the\
    \ same value for\n            all spatial dimensions.\n            Currently,\
    \ specifying any `dilation_rate` value != 1 is\n            incompatible with\
    \ specifying any stride value != 1.\n        activation: Activation function to\
    \ use\n            (see [activations](../activations.md)).\n            If you\
    \ don't specify anything, no activation is applied\n            (ie. \"linear\"\
    \ activation: `a(x) = x`).\n        use_bias: Boolean, whether the layer uses\
    \ a bias vector.\n        kernel_initializer: Initializer for the `kernel` weights\
    \ matrix\n            (see [initializers](../initializers.md)).\n        bias_initializer:\
    \ Initializer for the bias vector\n            (see [initializers](../initializers.md)).\n\
    \        kernel_regularizer: Regularizer function applied to\n            the\
    \ `kernel` weights matrix\n            (see [regularizer](../regularizers.md)).\n\
    \        bias_regularizer: Regularizer function applied to the bias vector\n \
    \           (see [regularizer](../regularizers.md)).\n        activity_regularizer:\
    \ Regularizer function applied to\n            the output of the layer (its \"\
    activation\").\n            (see [regularizer](../regularizers.md)).\n       \
    \ kernel_constraint: Constraint function applied to the kernel matrix\n      \
    \      (see [constraints](../constraints.md)).\n        bias_constraint: Constraint\
    \ function applied to the bias vector\n            (see [constraints](../constraints.md)).\n\
    \n    # Input shape\n        4D tensor with shape:\n        `(batch, channels,\
    \ rows, cols)`\n        if `data_format` is `\"channels_first\"`\n        or 4D\
    \ tensor with shape:\n        `(batch, rows, cols, channels)`\n        if `data_format`\
    \ is `\"channels_last\"`.\n\n    # Output shape\n        4D tensor with shape:\n\
    \        `(batch, filters, new_rows, new_cols)`\n        if `data_format` is `\"\
    channels_first\"`\n        or 4D tensor with shape:\n        `(batch, new_rows,\
    \ new_cols, filters)`\n        if `data_format` is `\"channels_last\"`.\n    \
    \    `rows` and `cols` values might have changed due to padding.\n    \"\"\"\n\
    \n    @interfaces.legacy_conv2d_support\n    def __init__(self, filters,\n   \
    \              kernel_size,\n                 strides=(1, 1),\n              \
    \   padding='valid',\n                 data_format=None,\n                 dilation_rate=(1,\
    \ 1),\n                 activation=None,\n                 use_bias=True,\n  \
    \               kernel_initializer='glorot_uniform',\n                 bias_initializer='zeros',\n\
    \                 kernel_regularizer=None,\n                 bias_regularizer=None,\n\
    \                 activity_regularizer=None,\n                 kernel_constraint=None,\n\
    \                 bias_constraint=None,\n                 **kwargs):\n       \
    \ super(Conv2D, self).__init__(\n            rank=2,\n            filters=filters,\n\
    \            kernel_size=kernel_size,\n            strides=strides,\n        \
    \    padding=padding,\n            data_format=data_format,\n            dilation_rate=dilation_rate,\n\
    \            activation=activation,\n            use_bias=use_bias,\n        \
    \    kernel_initializer=kernel_initializer,\n            bias_initializer=bias_initializer,\n\
    \            kernel_regularizer=kernel_regularizer,\n            bias_regularizer=bias_regularizer,\n\
    \            activity_regularizer=activity_regularizer,\n            kernel_constraint=kernel_constraint,\n\
    \            bias_constraint=bias_constraint,\n            **kwargs)\n\n    def\
    \ get_config(self):\n        config = super(Conv2D, self).get_config()\n     \
    \   config.pop('rank')\n        return config\n"
  sourcefile: D:\Python36\lib\site-packages\keras\layers\convolutional.py
- doc: "Transposed convolution layer (sometimes called Deconvolution).\n\nThe need\
    \ for transposed convolutions generally arises\nfrom the desire to use a transformation\
    \ going in the opposite direction\nof a normal convolution, i.e., from something\
    \ that has the shape of the\noutput of some convolution to something that has\
    \ the shape of its input\nwhile maintaining a connectivity pattern that is compatible\
    \ with\nsaid convolution.\n\nWhen using this layer as the first layer in a model,\n\
    provide the keyword argument `input_shape`\n(tuple of integers, does not include\
    \ the sample axis),\ne.g. `input_shape=(128, 128, 3)` for 128x128 RGB pictures\n\
    in `data_format=\"channels_last\"`.\n\n# Arguments\n    filters: Integer, the\
    \ dimensionality of the output space\n        (i.e. the number of output filters\
    \ in the convolution).\n    kernel_size: An integer or tuple/list of 2 integers,\
    \ specifying the\n        height and width of the 2D convolution window.\n   \
    \     Can be a single integer to specify the same value for\n        all spatial\
    \ dimensions.\n    strides: An integer or tuple/list of 2 integers,\n        specifying\
    \ the strides of the convolution\n        along the height and width.\n      \
    \  Can be a single integer to specify the same value for\n        all spatial\
    \ dimensions.\n        Specifying any stride value != 1 is incompatible with specifying\n\
    \        any `dilation_rate` value != 1.\n    padding: one of `\"valid\"` or `\"\
    same\"` (case-insensitive).\n    output_padding: An integer or tuple/list of 2\
    \ integers,\n        specifying the amount of padding along the height and width\n\
    \        of the output tensor.\n        Can be a single integer to specify the\
    \ same value for all\n        spatial dimensions.\n        The amount of output\
    \ padding along a given dimension must be\n        lower than the stride along\
    \ that same dimension.\n        If set to `None` (default), the output shape is\
    \ inferred.\n    data_format: A string,\n        one of `\"channels_last\"` or\
    \ `\"channels_first\"`.\n        The ordering of the dimensions in the inputs.\n\
    \        `\"channels_last\"` corresponds to inputs with shape\n        `(batch,\
    \ height, width, channels)` while `\"channels_first\"`\n        corresponds to\
    \ inputs with shape\n        `(batch, channels, height, width)`.\n        It defaults\
    \ to the `image_data_format` value found in your\n        Keras config file at\
    \ `~/.keras/keras.json`.\n        If you never set it, then it will be \"channels_last\"\
    .\n    dilation_rate: an integer or tuple/list of 2 integers, specifying\n   \
    \     the dilation rate to use for dilated convolution.\n        Can be a single\
    \ integer to specify the same value for\n        all spatial dimensions.\n   \
    \     Currently, specifying any `dilation_rate` value != 1 is\n        incompatible\
    \ with specifying any stride value != 1.\n    activation: Activation function\
    \ to use\n        (see [activations](../activations.md)).\n        If you don't\
    \ specify anything, no activation is applied\n        (ie. \"linear\" activation:\
    \ `a(x) = x`).\n    use_bias: Boolean, whether the layer uses a bias vector.\n\
    \    kernel_initializer: Initializer for the `kernel` weights matrix\n       \
    \ (see [initializers](../initializers.md)).\n    bias_initializer: Initializer\
    \ for the bias vector\n        (see [initializers](../initializers.md)).\n   \
    \ kernel_regularizer: Regularizer function applied to\n        the `kernel` weights\
    \ matrix\n        (see [regularizer](../regularizers.md)).\n    bias_regularizer:\
    \ Regularizer function applied to the bias vector\n        (see [regularizer](../regularizers.md)).\n\
    \    activity_regularizer: Regularizer function applied to\n        the output\
    \ of the layer (its \"activation\").\n        (see [regularizer](../regularizers.md)).\n\
    \    kernel_constraint: Constraint function applied to the kernel matrix\n   \
    \     (see [constraints](../constraints.md)).\n    bias_constraint: Constraint\
    \ function applied to the bias vector\n        (see [constraints](../constraints.md)).\n\
    \n# Input shape\n    4D tensor with shape:\n    `(batch, channels, rows, cols)`\n\
    \    if `data_format` is `\"channels_first\"`\n    or 4D tensor with shape:\n\
    \    `(batch, rows, cols, channels)`\n    if `data_format` is `\"channels_last\"\
    `.\n\n# Output shape\n    4D tensor with shape:\n    `(batch, filters, new_rows,\
    \ new_cols)`\n    if `data_format` is `\"channels_first\"`\n    or 4D tensor with\
    \ shape:\n    `(batch, new_rows, new_cols, filters)`\n    if `data_format` is\
    \ `\"channels_last\"`.\n    `rows` and `cols` values might have changed due to\
    \ padding.\n    If `output_padding` is specified:\n\n    ```\n    new_rows = ((rows\
    \ - 1) * strides[0] + kernel_size[0]\n                - 2 * padding[0] + output_padding[0])\n\
    \    new_cols = ((cols - 1) * strides[1] + kernel_size[1]\n                - 2\
    \ * padding[1] + output_padding[1])\n    ```\n\n# References\n    - [A guide to\
    \ convolution arithmetic for deep learning]\n      (https://arxiv.org/abs/1603.07285v1)\n\
    \    - [Deconvolutional Networks]\n      (http://www.matthewzeiler.com/pubs/cvpr2010/cvpr2010.pdf)"
  kind: Layer
  name: Conv2DTranspose
  parameters:
  - {kind: any, name: filters}
  - {kind: any, name: kernel_size}
  - {defaultValue: '(1, 1)', kind: any, name: strides}
  - {defaultValue: valid, kind: any, name: padding}
  - {defaultValue: None, kind: any, name: output_padding}
  - {defaultValue: None, kind: any, name: data_format}
  - {defaultValue: '(1, 1)', kind: any, name: dilation_rate}
  - {defaultValue: None, kind: any, name: activation}
  - {defaultValue: 'True', kind: any, name: use_bias}
  - {defaultValue: glorot_uniform, kind: any, name: kernel_initializer}
  - {defaultValue: zeros, kind: any, name: bias_initializer}
  - {defaultValue: None, kind: any, name: kernel_regularizer}
  - {defaultValue: None, kind: any, name: bias_regularizer}
  - {defaultValue: None, kind: any, name: activity_regularizer}
  - {defaultValue: None, kind: any, name: kernel_constraint}
  - {defaultValue: None, kind: any, name: bias_constraint}
  - {defaultValue: 'true', name: trainable, type: bool}
  source: "class Conv2DTranspose(Conv2D):\n    \"\"\"Transposed convolution layer\
    \ (sometimes called Deconvolution).\n\n    The need for transposed convolutions\
    \ generally arises\n    from the desire to use a transformation going in the opposite\
    \ direction\n    of a normal convolution, i.e., from something that has the shape\
    \ of the\n    output of some convolution to something that has the shape of its\
    \ input\n    while maintaining a connectivity pattern that is compatible with\n\
    \    said convolution.\n\n    When using this layer as the first layer in a model,\n\
    \    provide the keyword argument `input_shape`\n    (tuple of integers, does\
    \ not include the sample axis),\n    e.g. `input_shape=(128, 128, 3)` for 128x128\
    \ RGB pictures\n    in `data_format=\"channels_last\"`.\n\n    # Arguments\n \
    \       filters: Integer, the dimensionality of the output space\n           \
    \ (i.e. the number of output filters in the convolution).\n        kernel_size:\
    \ An integer or tuple/list of 2 integers, specifying the\n            height and\
    \ width of the 2D convolution window.\n            Can be a single integer to\
    \ specify the same value for\n            all spatial dimensions.\n        strides:\
    \ An integer or tuple/list of 2 integers,\n            specifying the strides\
    \ of the convolution\n            along the height and width.\n            Can\
    \ be a single integer to specify the same value for\n            all spatial dimensions.\n\
    \            Specifying any stride value != 1 is incompatible with specifying\n\
    \            any `dilation_rate` value != 1.\n        padding: one of `\"valid\"\
    ` or `\"same\"` (case-insensitive).\n        output_padding: An integer or tuple/list\
    \ of 2 integers,\n            specifying the amount of padding along the height\
    \ and width\n            of the output tensor.\n            Can be a single integer\
    \ to specify the same value for all\n            spatial dimensions.\n       \
    \     The amount of output padding along a given dimension must be\n         \
    \   lower than the stride along that same dimension.\n            If set to `None`\
    \ (default), the output shape is inferred.\n        data_format: A string,\n \
    \           one of `\"channels_last\"` or `\"channels_first\"`.\n            The\
    \ ordering of the dimensions in the inputs.\n            `\"channels_last\"` corresponds\
    \ to inputs with shape\n            `(batch, height, width, channels)` while `\"\
    channels_first\"`\n            corresponds to inputs with shape\n            `(batch,\
    \ channels, height, width)`.\n            It defaults to the `image_data_format`\
    \ value found in your\n            Keras config file at `~/.keras/keras.json`.\n\
    \            If you never set it, then it will be \"channels_last\".\n       \
    \ dilation_rate: an integer or tuple/list of 2 integers, specifying\n        \
    \    the dilation rate to use for dilated convolution.\n            Can be a single\
    \ integer to specify the same value for\n            all spatial dimensions.\n\
    \            Currently, specifying any `dilation_rate` value != 1 is\n       \
    \     incompatible with specifying any stride value != 1.\n        activation:\
    \ Activation function to use\n            (see [activations](../activations.md)).\n\
    \            If you don't specify anything, no activation is applied\n       \
    \     (ie. \"linear\" activation: `a(x) = x`).\n        use_bias: Boolean, whether\
    \ the layer uses a bias vector.\n        kernel_initializer: Initializer for the\
    \ `kernel` weights matrix\n            (see [initializers](../initializers.md)).\n\
    \        bias_initializer: Initializer for the bias vector\n            (see [initializers](../initializers.md)).\n\
    \        kernel_regularizer: Regularizer function applied to\n            the\
    \ `kernel` weights matrix\n            (see [regularizer](../regularizers.md)).\n\
    \        bias_regularizer: Regularizer function applied to the bias vector\n \
    \           (see [regularizer](../regularizers.md)).\n        activity_regularizer:\
    \ Regularizer function applied to\n            the output of the layer (its \"\
    activation\").\n            (see [regularizer](../regularizers.md)).\n       \
    \ kernel_constraint: Constraint function applied to the kernel matrix\n      \
    \      (see [constraints](../constraints.md)).\n        bias_constraint: Constraint\
    \ function applied to the bias vector\n            (see [constraints](../constraints.md)).\n\
    \n    # Input shape\n        4D tensor with shape:\n        `(batch, channels,\
    \ rows, cols)`\n        if `data_format` is `\"channels_first\"`\n        or 4D\
    \ tensor with shape:\n        `(batch, rows, cols, channels)`\n        if `data_format`\
    \ is `\"channels_last\"`.\n\n    # Output shape\n        4D tensor with shape:\n\
    \        `(batch, filters, new_rows, new_cols)`\n        if `data_format` is `\"\
    channels_first\"`\n        or 4D tensor with shape:\n        `(batch, new_rows,\
    \ new_cols, filters)`\n        if `data_format` is `\"channels_last\"`.\n    \
    \    `rows` and `cols` values might have changed due to padding.\n        If `output_padding`\
    \ is specified:\n\n        ```\n        new_rows = ((rows - 1) * strides[0] +\
    \ kernel_size[0]\n                    - 2 * padding[0] + output_padding[0])\n\
    \        new_cols = ((cols - 1) * strides[1] + kernel_size[1]\n              \
    \      - 2 * padding[1] + output_padding[1])\n        ```\n\n    # References\n\
    \        - [A guide to convolution arithmetic for deep learning]\n          (https://arxiv.org/abs/1603.07285v1)\n\
    \        - [Deconvolutional Networks]\n          (http://www.matthewzeiler.com/pubs/cvpr2010/cvpr2010.pdf)\n\
    \    \"\"\"\n\n    @interfaces.legacy_deconv2d_support\n    def __init__(self,\
    \ filters,\n                 kernel_size,\n                 strides=(1, 1),\n\
    \                 padding='valid',\n                 output_padding=None,\n  \
    \               data_format=None,\n                 dilation_rate=(1, 1),\n  \
    \               activation=None,\n                 use_bias=True,\n          \
    \       kernel_initializer='glorot_uniform',\n                 bias_initializer='zeros',\n\
    \                 kernel_regularizer=None,\n                 bias_regularizer=None,\n\
    \                 activity_regularizer=None,\n                 kernel_constraint=None,\n\
    \                 bias_constraint=None,\n                 **kwargs):\n       \
    \ super(Conv2DTranspose, self).__init__(\n            filters,\n            kernel_size,\n\
    \            strides=strides,\n            padding=padding,\n            data_format=data_format,\n\
    \            dilation_rate=dilation_rate,\n            activation=activation,\n\
    \            use_bias=use_bias,\n            kernel_initializer=kernel_initializer,\n\
    \            bias_initializer=bias_initializer,\n            kernel_regularizer=kernel_regularizer,\n\
    \            bias_regularizer=bias_regularizer,\n            activity_regularizer=activity_regularizer,\n\
    \            kernel_constraint=kernel_constraint,\n            bias_constraint=bias_constraint,\n\
    \            **kwargs)\n\n        self.output_padding = output_padding\n     \
    \   if self.output_padding is not None:\n            self.output_padding = conv_utils.normalize_tuple(\n\
    \                self.output_padding, 2, 'output_padding')\n            for stride,\
    \ out_pad in zip(self.strides, self.output_padding):\n                if out_pad\
    \ >= stride:\n                    raise ValueError('Stride ' + str(self.strides)\
    \ + ' must be '\n                                     'greater than output padding\
    \ ' +\n                                     str(self.output_padding))\n\n    def\
    \ build(self, input_shape):\n        if len(input_shape) != 4:\n            raise\
    \ ValueError('Inputs should have rank ' +\n                             str(4)\
    \ +\n                             '; Received input shape:', str(input_shape))\n\
    \        if self.data_format == 'channels_first':\n            channel_axis =\
    \ 1\n        else:\n            channel_axis = -1\n        if input_shape[channel_axis]\
    \ is None:\n            raise ValueError('The channel dimension of the inputs\
    \ '\n                             'should be defined. Found `None`.')\n      \
    \  input_dim = input_shape[channel_axis]\n        kernel_shape = self.kernel_size\
    \ + (self.filters, input_dim)\n\n        self.kernel = self.add_weight(shape=kernel_shape,\n\
    \                                      initializer=self.kernel_initializer,\n\
    \                                      name='kernel',\n                      \
    \                regularizer=self.kernel_regularizer,\n                      \
    \                constraint=self.kernel_constraint)\n        if self.use_bias:\n\
    \            self.bias = self.add_weight(shape=(self.filters,),\n            \
    \                            initializer=self.bias_initializer,\n            \
    \                            name='bias',\n                                  \
    \      regularizer=self.bias_regularizer,\n                                  \
    \      constraint=self.bias_constraint)\n        else:\n            self.bias\
    \ = None\n        # Set input spec.\n        self.input_spec = InputSpec(ndim=4,\
    \ axes={channel_axis: input_dim})\n        self.built = True\n\n    def call(self,\
    \ inputs):\n        input_shape = K.shape(inputs)\n        batch_size = input_shape[0]\n\
    \        if self.data_format == 'channels_first':\n            h_axis, w_axis\
    \ = 2, 3\n        else:\n            h_axis, w_axis = 1, 2\n\n        height,\
    \ width = input_shape[h_axis], input_shape[w_axis]\n        kernel_h, kernel_w\
    \ = self.kernel_size\n        stride_h, stride_w = self.strides\n        if self.output_padding\
    \ is None:\n            out_pad_h = out_pad_w = None\n        else:\n        \
    \    out_pad_h, out_pad_w = self.output_padding\n\n        # Infer the dynamic\
    \ output shape:\n        out_height = conv_utils.deconv_length(height,\n     \
    \                                         stride_h, kernel_h,\n              \
    \                                self.padding,\n                             \
    \                 out_pad_h,\n                                              self.dilation_rate[0])\n\
    \        out_width = conv_utils.deconv_length(width,\n                       \
    \                      stride_w, kernel_w,\n                                 \
    \            self.padding,\n                                             out_pad_w,\n\
    \                                             self.dilation_rate[1])\n       \
    \ if self.data_format == 'channels_first':\n            output_shape = (batch_size,\
    \ self.filters, out_height, out_width)\n        else:\n            output_shape\
    \ = (batch_size, out_height, out_width, self.filters)\n\n        outputs = K.conv2d_transpose(\n\
    \            inputs,\n            self.kernel,\n            output_shape,\n  \
    \          self.strides,\n            padding=self.padding,\n            data_format=self.data_format,\n\
    \            dilation_rate=self.dilation_rate)\n\n        if self.use_bias:\n\
    \            outputs = K.bias_add(\n                outputs,\n               \
    \ self.bias,\n                data_format=self.data_format)\n\n        if self.activation\
    \ is not None:\n            return self.activation(outputs)\n        return outputs\n\
    \n    def compute_output_shape(self, input_shape):\n        output_shape = list(input_shape)\n\
    \        if self.data_format == 'channels_first':\n            c_axis, h_axis,\
    \ w_axis = 1, 2, 3\n        else:\n            c_axis, h_axis, w_axis = 3, 1,\
    \ 2\n\n        kernel_h, kernel_w = self.kernel_size\n        stride_h, stride_w\
    \ = self.strides\n        if self.output_padding is None:\n            out_pad_h\
    \ = out_pad_w = None\n        else:\n            out_pad_h, out_pad_w = self.output_padding\n\
    \n        output_shape[c_axis] = self.filters\n        output_shape[h_axis] =\
    \ conv_utils.deconv_length(output_shape[h_axis],\n                           \
    \                             stride_h,\n                                    \
    \                    kernel_h,\n                                             \
    \           self.padding,\n                                                  \
    \      out_pad_h,\n                                                        self.dilation_rate[0])\n\
    \        output_shape[w_axis] = conv_utils.deconv_length(output_shape[w_axis],\n\
    \                                                        stride_w,\n         \
    \                                               kernel_w,\n                  \
    \                                      self.padding,\n                       \
    \                                 out_pad_w,\n                               \
    \                         self.dilation_rate[1])\n        return tuple(output_shape)\n\
    \n    def get_config(self):\n        config = super(Conv2DTranspose, self).get_config()\n\
    \        config['output_padding'] = self.output_padding\n        return config\n"
  sourcefile: D:\Python36\lib\site-packages\keras\layers\convolutional.py
- doc: "3D convolution layer (e.g. spatial convolution over volumes).\n\nThis layer\
    \ creates a convolution kernel that is convolved\nwith the layer input to produce\
    \ a tensor of\noutputs. If `use_bias` is True,\na bias vector is created and added\
    \ to the outputs. Finally, if\n`activation` is not `None`, it is applied to the\
    \ outputs as well.\n\nWhen using this layer as the first layer in a model,\nprovide\
    \ the keyword argument `input_shape`\n(tuple of integers, does not include the\
    \ sample axis),\ne.g. `input_shape=(128, 128, 128, 1)` for 128x128x128 volumes\n\
    with a single channel,\nin `data_format=\"channels_last\"`.\n\n# Arguments\n \
    \   filters: Integer, the dimensionality of the output space\n        (i.e. the\
    \ number of output filters in the convolution).\n    kernel_size: An integer or\
    \ tuple/list of 3 integers, specifying the\n        depth, height and width of\
    \ the 3D convolution window.\n        Can be a single integer to specify the same\
    \ value for\n        all spatial dimensions.\n    strides: An integer or tuple/list\
    \ of 3 integers,\n        specifying the strides of the convolution along each\
    \ spatial dimension.\n        Can be a single integer to specify the same value\
    \ for\n        all spatial dimensions.\n        Specifying any stride value !=\
    \ 1 is incompatible with specifying\n        any `dilation_rate` value != 1.\n\
    \    padding: one of `\"valid\"` or `\"same\"` (case-insensitive).\n    data_format:\
    \ A string,\n        one of `\"channels_last\"` or `\"channels_first\"`.\n   \
    \     The ordering of the dimensions in the inputs.\n        `\"channels_last\"\
    ` corresponds to inputs with shape\n        `(batch, spatial_dim1, spatial_dim2,\
    \ spatial_dim3, channels)`\n        while `\"channels_first\"` corresponds to\
    \ inputs with shape\n        `(batch, channels, spatial_dim1, spatial_dim2, spatial_dim3)`.\n\
    \        It defaults to the `image_data_format` value found in your\n        Keras\
    \ config file at `~/.keras/keras.json`.\n        If you never set it, then it\
    \ will be \"channels_last\".\n    dilation_rate: an integer or tuple/list of 3\
    \ integers, specifying\n        the dilation rate to use for dilated convolution.\n\
    \        Can be a single integer to specify the same value for\n        all spatial\
    \ dimensions.\n        Currently, specifying any `dilation_rate` value != 1 is\n\
    \        incompatible with specifying any stride value != 1.\n    activation:\
    \ Activation function to use\n        (see [activations](../activations.md)).\n\
    \        If you don't specify anything, no activation is applied\n        (ie.\
    \ \"linear\" activation: `a(x) = x`).\n    use_bias: Boolean, whether the layer\
    \ uses a bias vector.\n    kernel_initializer: Initializer for the `kernel` weights\
    \ matrix\n        (see [initializers](../initializers.md)).\n    bias_initializer:\
    \ Initializer for the bias vector\n        (see [initializers](../initializers.md)).\n\
    \    kernel_regularizer: Regularizer function applied to\n        the `kernel`\
    \ weights matrix\n        (see [regularizer](../regularizers.md)).\n    bias_regularizer:\
    \ Regularizer function applied to the bias vector\n        (see [regularizer](../regularizers.md)).\n\
    \    activity_regularizer: Regularizer function applied to\n        the output\
    \ of the layer (its \"activation\").\n        (see [regularizer](../regularizers.md)).\n\
    \    kernel_constraint: Constraint function applied to the kernel matrix\n   \
    \     (see [constraints](../constraints.md)).\n    bias_constraint: Constraint\
    \ function applied to the bias vector\n        (see [constraints](../constraints.md)).\n\
    \n# Input shape\n    5D tensor with shape:\n    `(batch, channels, conv_dim1,\
    \ conv_dim2, conv_dim3)`\n    if `data_format` is `\"channels_first\"`\n    or\
    \ 5D tensor with shape:\n    `(batch, conv_dim1, conv_dim2, conv_dim3, channels)`\n\
    \    if `data_format` is `\"channels_last\"`.\n\n# Output shape\n    5D tensor\
    \ with shape:\n    `(batch, filters, new_conv_dim1, new_conv_dim2, new_conv_dim3)`\n\
    \    if `data_format` is `\"channels_first\"`\n    or 5D tensor with shape:\n\
    \    `(batch, new_conv_dim1, new_conv_dim2, new_conv_dim3, filters)`\n    if `data_format`\
    \ is `\"channels_last\"`.\n    `new_conv_dim1`, `new_conv_dim2` and `new_conv_dim3`\
    \ values might have\n    changed due to padding."
  kind: Layer
  name: Conv3D
  parameters:
  - {kind: any, name: filters}
  - {kind: any, name: kernel_size}
  - {defaultValue: '(1, 1, 1)', kind: any, name: strides}
  - {defaultValue: valid, kind: any, name: padding}
  - {defaultValue: None, kind: any, name: data_format}
  - {defaultValue: '(1, 1, 1)', kind: any, name: dilation_rate}
  - {defaultValue: None, kind: any, name: activation}
  - {defaultValue: 'True', kind: any, name: use_bias}
  - {defaultValue: glorot_uniform, kind: any, name: kernel_initializer}
  - {defaultValue: zeros, kind: any, name: bias_initializer}
  - {defaultValue: None, kind: any, name: kernel_regularizer}
  - {defaultValue: None, kind: any, name: bias_regularizer}
  - {defaultValue: None, kind: any, name: activity_regularizer}
  - {defaultValue: None, kind: any, name: kernel_constraint}
  - {defaultValue: None, kind: any, name: bias_constraint}
  - {defaultValue: 'true', name: trainable, type: bool}
  source: "class Conv3D(_Conv):\n    \"\"\"3D convolution layer (e.g. spatial convolution\
    \ over volumes).\n\n    This layer creates a convolution kernel that is convolved\n\
    \    with the layer input to produce a tensor of\n    outputs. If `use_bias` is\
    \ True,\n    a bias vector is created and added to the outputs. Finally, if\n\
    \    `activation` is not `None`, it is applied to the outputs as well.\n\n   \
    \ When using this layer as the first layer in a model,\n    provide the keyword\
    \ argument `input_shape`\n    (tuple of integers, does not include the sample\
    \ axis),\n    e.g. `input_shape=(128, 128, 128, 1)` for 128x128x128 volumes\n\
    \    with a single channel,\n    in `data_format=\"channels_last\"`.\n\n    #\
    \ Arguments\n        filters: Integer, the dimensionality of the output space\n\
    \            (i.e. the number of output filters in the convolution).\n       \
    \ kernel_size: An integer or tuple/list of 3 integers, specifying the\n      \
    \      depth, height and width of the 3D convolution window.\n            Can\
    \ be a single integer to specify the same value for\n            all spatial dimensions.\n\
    \        strides: An integer or tuple/list of 3 integers,\n            specifying\
    \ the strides of the convolution along each spatial dimension.\n            Can\
    \ be a single integer to specify the same value for\n            all spatial dimensions.\n\
    \            Specifying any stride value != 1 is incompatible with specifying\n\
    \            any `dilation_rate` value != 1.\n        padding: one of `\"valid\"\
    ` or `\"same\"` (case-insensitive).\n        data_format: A string,\n        \
    \    one of `\"channels_last\"` or `\"channels_first\"`.\n            The ordering\
    \ of the dimensions in the inputs.\n            `\"channels_last\"` corresponds\
    \ to inputs with shape\n            `(batch, spatial_dim1, spatial_dim2, spatial_dim3,\
    \ channels)`\n            while `\"channels_first\"` corresponds to inputs with\
    \ shape\n            `(batch, channels, spatial_dim1, spatial_dim2, spatial_dim3)`.\n\
    \            It defaults to the `image_data_format` value found in your\n    \
    \        Keras config file at `~/.keras/keras.json`.\n            If you never\
    \ set it, then it will be \"channels_last\".\n        dilation_rate: an integer\
    \ or tuple/list of 3 integers, specifying\n            the dilation rate to use\
    \ for dilated convolution.\n            Can be a single integer to specify the\
    \ same value for\n            all spatial dimensions.\n            Currently,\
    \ specifying any `dilation_rate` value != 1 is\n            incompatible with\
    \ specifying any stride value != 1.\n        activation: Activation function to\
    \ use\n            (see [activations](../activations.md)).\n            If you\
    \ don't specify anything, no activation is applied\n            (ie. \"linear\"\
    \ activation: `a(x) = x`).\n        use_bias: Boolean, whether the layer uses\
    \ a bias vector.\n        kernel_initializer: Initializer for the `kernel` weights\
    \ matrix\n            (see [initializers](../initializers.md)).\n        bias_initializer:\
    \ Initializer for the bias vector\n            (see [initializers](../initializers.md)).\n\
    \        kernel_regularizer: Regularizer function applied to\n            the\
    \ `kernel` weights matrix\n            (see [regularizer](../regularizers.md)).\n\
    \        bias_regularizer: Regularizer function applied to the bias vector\n \
    \           (see [regularizer](../regularizers.md)).\n        activity_regularizer:\
    \ Regularizer function applied to\n            the output of the layer (its \"\
    activation\").\n            (see [regularizer](../regularizers.md)).\n       \
    \ kernel_constraint: Constraint function applied to the kernel matrix\n      \
    \      (see [constraints](../constraints.md)).\n        bias_constraint: Constraint\
    \ function applied to the bias vector\n            (see [constraints](../constraints.md)).\n\
    \n    # Input shape\n        5D tensor with shape:\n        `(batch, channels,\
    \ conv_dim1, conv_dim2, conv_dim3)`\n        if `data_format` is `\"channels_first\"\
    `\n        or 5D tensor with shape:\n        `(batch, conv_dim1, conv_dim2, conv_dim3,\
    \ channels)`\n        if `data_format` is `\"channels_last\"`.\n\n    # Output\
    \ shape\n        5D tensor with shape:\n        `(batch, filters, new_conv_dim1,\
    \ new_conv_dim2, new_conv_dim3)`\n        if `data_format` is `\"channels_first\"\
    `\n        or 5D tensor with shape:\n        `(batch, new_conv_dim1, new_conv_dim2,\
    \ new_conv_dim3, filters)`\n        if `data_format` is `\"channels_last\"`.\n\
    \        `new_conv_dim1`, `new_conv_dim2` and `new_conv_dim3` values might have\n\
    \        changed due to padding.\n    \"\"\"\n\n    @interfaces.legacy_conv3d_support\n\
    \    def __init__(self, filters,\n                 kernel_size,\n            \
    \     strides=(1, 1, 1),\n                 padding='valid',\n                \
    \ data_format=None,\n                 dilation_rate=(1, 1, 1),\n             \
    \    activation=None,\n                 use_bias=True,\n                 kernel_initializer='glorot_uniform',\n\
    \                 bias_initializer='zeros',\n                 kernel_regularizer=None,\n\
    \                 bias_regularizer=None,\n                 activity_regularizer=None,\n\
    \                 kernel_constraint=None,\n                 bias_constraint=None,\n\
    \                 **kwargs):\n        super(Conv3D, self).__init__(\n        \
    \    rank=3,\n            filters=filters,\n            kernel_size=kernel_size,\n\
    \            strides=strides,\n            padding=padding,\n            data_format=data_format,\n\
    \            dilation_rate=dilation_rate,\n            activation=activation,\n\
    \            use_bias=use_bias,\n            kernel_initializer=kernel_initializer,\n\
    \            bias_initializer=bias_initializer,\n            kernel_regularizer=kernel_regularizer,\n\
    \            bias_regularizer=bias_regularizer,\n            activity_regularizer=activity_regularizer,\n\
    \            kernel_constraint=kernel_constraint,\n            bias_constraint=bias_constraint,\n\
    \            **kwargs)\n\n    def get_config(self):\n        config = super(Conv3D,\
    \ self).get_config()\n        config.pop('rank')\n        return config\n"
  sourcefile: D:\Python36\lib\site-packages\keras\layers\convolutional.py
- doc: "Transposed convolution layer (sometimes called Deconvolution).\n\nThe need\
    \ for transposed convolutions generally arises\nfrom the desire to use a transformation\
    \ going in the opposite direction\nof a normal convolution, i.e., from something\
    \ that has the shape of the\noutput of some convolution to something that has\
    \ the shape of its input\nwhile maintaining a connectivity pattern that is compatible\
    \ with\nsaid convolution.\n\nWhen using this layer as the first layer in a model,\n\
    provide the keyword argument `input_shape`\n(tuple of integers, does not include\
    \ the sample axis),\ne.g. `input_shape=(128, 128, 128, 3)` for a 128x128x128 volume\
    \ with 3 channels\nif `data_format=\"channels_last\"`.\n\n# Arguments\n    filters:\
    \ Integer, the dimensionality of the output space\n        (i.e. the number of\
    \ output filters in the convolution).\n    kernel_size: An integer or tuple/list\
    \ of 3 integers, specifying the\n        depth, height and width of the 3D convolution\
    \ window.\n        Can be a single integer to specify the same value for\n   \
    \     all spatial dimensions.\n    strides: An integer or tuple/list of 3 integers,\n\
    \        specifying the strides of the convolution\n        along the depth, height\
    \ and width.\n        Can be a single integer to specify the same value for\n\
    \        all spatial dimensions.\n        Specifying any stride value != 1 is\
    \ incompatible with specifying\n        any `dilation_rate` value != 1.\n    padding:\
    \ one of `\"valid\"` or `\"same\"` (case-insensitive).\n    output_padding: An\
    \ integer or tuple/list of 3 integers,\n        specifying the amount of padding\
    \ along the depth, height, and\n        width.\n        Can be a single integer\
    \ to specify the same value for all\n        spatial dimensions.\n        The\
    \ amount of output padding along a given dimension must be\n        lower than\
    \ the stride along that same dimension.\n        If set to `None` (default), the\
    \ output shape is inferred.\n    data_format: A string,\n        one of `\"channels_last\"\
    ` or `\"channels_first\"`.\n        The ordering of the dimensions in the inputs.\n\
    \        `\"channels_last\"` corresponds to inputs with shape\n        `(batch,\
    \ depth, height, width, channels)` while `\"channels_first\"`\n        corresponds\
    \ to inputs with shape\n        `(batch, channels, depth, height, width)`.\n \
    \       It defaults to the `image_data_format` value found in your\n        Keras\
    \ config file at `~/.keras/keras.json`.\n        If you never set it, then it\
    \ will be \"channels_last\".\n    dilation_rate: an integer or tuple/list of 3\
    \ integers, specifying\n        the dilation rate to use for dilated convolution.\n\
    \        Can be a single integer to specify the same value for\n        all spatial\
    \ dimensions.\n        Currently, specifying any `dilation_rate` value != 1 is\n\
    \        incompatible with specifying any stride value != 1.\n    activation:\
    \ Activation function to use\n        (see [activations](../activations.md)).\n\
    \        If you don't specify anything, no activation is applied\n        (ie.\
    \ \"linear\" activation: `a(x) = x`).\n    use_bias: Boolean, whether the layer\
    \ uses a bias vector.\n    kernel_initializer: Initializer for the `kernel` weights\
    \ matrix\n        (see [initializers](../initializers.md)).\n    bias_initializer:\
    \ Initializer for the bias vector\n        (see [initializers](../initializers.md)).\n\
    \    kernel_regularizer: Regularizer function applied to\n        the `kernel`\
    \ weights matrix\n        (see [regularizer](../regularizers.md)).\n    bias_regularizer:\
    \ Regularizer function applied to the bias vector\n        (see [regularizer](../regularizers.md)).\n\
    \    activity_regularizer: Regularizer function applied to\n        the output\
    \ of the layer (its \"activation\").\n        (see [regularizer](../regularizers.md)).\n\
    \    kernel_constraint: Constraint function applied to the kernel matrix\n   \
    \     (see [constraints](../constraints.md)).\n    bias_constraint: Constraint\
    \ function applied to the bias vector\n        (see [constraints](../constraints.md)).\n\
    \n# Input shape\n    5D tensor with shape:\n    `(batch, channels, depth, rows,\
    \ cols)`\n    if `data_format` is `\"channels_first\"`\n    or 5D tensor with\
    \ shape:\n    `(batch, depth, rows, cols, channels)`\n    if `data_format` is\
    \ `\"channels_last\"`.\n\n# Output shape\n    5D tensor with shape:\n    `(batch,\
    \ filters, new_depth, new_rows, new_cols)`\n    if `data_format` is `\"channels_first\"\
    `\n    or 5D tensor with shape:\n    `(batch, new_depth, new_rows, new_cols, filters)`\n\
    \    if `data_format` is `\"channels_last\"`.\n    `depth` and `rows` and `cols`\
    \ values might have changed due to padding.\n    If `output_padding` is specified::\n\
    \n    ```\n    new_depth = ((depth - 1) * strides[0] + kernel_size[0]\n      \
    \           - 2 * padding[0] + output_padding[0])\n    new_rows = ((rows - 1)\
    \ * strides[1] + kernel_size[1]\n                - 2 * padding[1] + output_padding[1])\n\
    \    new_cols = ((cols - 1) * strides[2] + kernel_size[2]\n                - 2\
    \ * padding[2] + output_padding[2])\n    ```\n\n# References\n    - [A guide to\
    \ convolution arithmetic for deep learning]\n      (https://arxiv.org/abs/1603.07285v1)\n\
    \    - [Deconvolutional Networks]\n      (http://www.matthewzeiler.com/pubs/cvpr2010/cvpr2010.pdf)"
  kind: Layer
  name: Conv3DTranspose
  parameters:
  - {kind: any, name: filters}
  - {kind: any, name: kernel_size}
  - {defaultValue: '(1, 1, 1)', kind: any, name: strides}
  - {defaultValue: valid, kind: any, name: padding}
  - {defaultValue: None, kind: any, name: output_padding}
  - {defaultValue: None, kind: any, name: data_format}
  - {defaultValue: None, kind: any, name: activation}
  - {defaultValue: 'True', kind: any, name: use_bias}
  - {defaultValue: glorot_uniform, kind: any, name: kernel_initializer}
  - {defaultValue: zeros, kind: any, name: bias_initializer}
  - {defaultValue: None, kind: any, name: kernel_regularizer}
  - {defaultValue: None, kind: any, name: bias_regularizer}
  - {defaultValue: None, kind: any, name: activity_regularizer}
  - {defaultValue: None, kind: any, name: kernel_constraint}
  - {defaultValue: None, kind: any, name: bias_constraint}
  - {defaultValue: 'true', name: trainable, type: bool}
  source: "class Conv3DTranspose(Conv3D):\n    \"\"\"Transposed convolution layer\
    \ (sometimes called Deconvolution).\n\n    The need for transposed convolutions\
    \ generally arises\n    from the desire to use a transformation going in the opposite\
    \ direction\n    of a normal convolution, i.e., from something that has the shape\
    \ of the\n    output of some convolution to something that has the shape of its\
    \ input\n    while maintaining a connectivity pattern that is compatible with\n\
    \    said convolution.\n\n    When using this layer as the first layer in a model,\n\
    \    provide the keyword argument `input_shape`\n    (tuple of integers, does\
    \ not include the sample axis),\n    e.g. `input_shape=(128, 128, 128, 3)` for\
    \ a 128x128x128 volume with 3 channels\n    if `data_format=\"channels_last\"\
    `.\n\n    # Arguments\n        filters: Integer, the dimensionality of the output\
    \ space\n            (i.e. the number of output filters in the convolution).\n\
    \        kernel_size: An integer or tuple/list of 3 integers, specifying the\n\
    \            depth, height and width of the 3D convolution window.\n         \
    \   Can be a single integer to specify the same value for\n            all spatial\
    \ dimensions.\n        strides: An integer or tuple/list of 3 integers,\n    \
    \        specifying the strides of the convolution\n            along the depth,\
    \ height and width.\n            Can be a single integer to specify the same value\
    \ for\n            all spatial dimensions.\n            Specifying any stride\
    \ value != 1 is incompatible with specifying\n            any `dilation_rate`\
    \ value != 1.\n        padding: one of `\"valid\"` or `\"same\"` (case-insensitive).\n\
    \        output_padding: An integer or tuple/list of 3 integers,\n           \
    \ specifying the amount of padding along the depth, height, and\n            width.\n\
    \            Can be a single integer to specify the same value for all\n     \
    \       spatial dimensions.\n            The amount of output padding along a\
    \ given dimension must be\n            lower than the stride along that same dimension.\n\
    \            If set to `None` (default), the output shape is inferred.\n     \
    \   data_format: A string,\n            one of `\"channels_last\"` or `\"channels_first\"\
    `.\n            The ordering of the dimensions in the inputs.\n            `\"\
    channels_last\"` corresponds to inputs with shape\n            `(batch, depth,\
    \ height, width, channels)` while `\"channels_first\"`\n            corresponds\
    \ to inputs with shape\n            `(batch, channels, depth, height, width)`.\n\
    \            It defaults to the `image_data_format` value found in your\n    \
    \        Keras config file at `~/.keras/keras.json`.\n            If you never\
    \ set it, then it will be \"channels_last\".\n        dilation_rate: an integer\
    \ or tuple/list of 3 integers, specifying\n            the dilation rate to use\
    \ for dilated convolution.\n            Can be a single integer to specify the\
    \ same value for\n            all spatial dimensions.\n            Currently,\
    \ specifying any `dilation_rate` value != 1 is\n            incompatible with\
    \ specifying any stride value != 1.\n        activation: Activation function to\
    \ use\n            (see [activations](../activations.md)).\n            If you\
    \ don't specify anything, no activation is applied\n            (ie. \"linear\"\
    \ activation: `a(x) = x`).\n        use_bias: Boolean, whether the layer uses\
    \ a bias vector.\n        kernel_initializer: Initializer for the `kernel` weights\
    \ matrix\n            (see [initializers](../initializers.md)).\n        bias_initializer:\
    \ Initializer for the bias vector\n            (see [initializers](../initializers.md)).\n\
    \        kernel_regularizer: Regularizer function applied to\n            the\
    \ `kernel` weights matrix\n            (see [regularizer](../regularizers.md)).\n\
    \        bias_regularizer: Regularizer function applied to the bias vector\n \
    \           (see [regularizer](../regularizers.md)).\n        activity_regularizer:\
    \ Regularizer function applied to\n            the output of the layer (its \"\
    activation\").\n            (see [regularizer](../regularizers.md)).\n       \
    \ kernel_constraint: Constraint function applied to the kernel matrix\n      \
    \      (see [constraints](../constraints.md)).\n        bias_constraint: Constraint\
    \ function applied to the bias vector\n            (see [constraints](../constraints.md)).\n\
    \n    # Input shape\n        5D tensor with shape:\n        `(batch, channels,\
    \ depth, rows, cols)`\n        if `data_format` is `\"channels_first\"`\n    \
    \    or 5D tensor with shape:\n        `(batch, depth, rows, cols, channels)`\n\
    \        if `data_format` is `\"channels_last\"`.\n\n    # Output shape\n    \
    \    5D tensor with shape:\n        `(batch, filters, new_depth, new_rows, new_cols)`\n\
    \        if `data_format` is `\"channels_first\"`\n        or 5D tensor with shape:\n\
    \        `(batch, new_depth, new_rows, new_cols, filters)`\n        if `data_format`\
    \ is `\"channels_last\"`.\n        `depth` and `rows` and `cols` values might\
    \ have changed due to padding.\n        If `output_padding` is specified::\n\n\
    \        ```\n        new_depth = ((depth - 1) * strides[0] + kernel_size[0]\n\
    \                     - 2 * padding[0] + output_padding[0])\n        new_rows\
    \ = ((rows - 1) * strides[1] + kernel_size[1]\n                    - 2 * padding[1]\
    \ + output_padding[1])\n        new_cols = ((cols - 1) * strides[2] + kernel_size[2]\n\
    \                    - 2 * padding[2] + output_padding[2])\n        ```\n\n  \
    \  # References\n        - [A guide to convolution arithmetic for deep learning]\n\
    \          (https://arxiv.org/abs/1603.07285v1)\n        - [Deconvolutional Networks]\n\
    \          (http://www.matthewzeiler.com/pubs/cvpr2010/cvpr2010.pdf)\n    \"\"\
    \"\n\n    def __init__(self, filters,\n                 kernel_size,\n       \
    \          strides=(1, 1, 1),\n                 padding='valid',\n           \
    \      output_padding=None,\n                 data_format=None,\n            \
    \     activation=None,\n                 use_bias=True,\n                 kernel_initializer='glorot_uniform',\n\
    \                 bias_initializer='zeros',\n                 kernel_regularizer=None,\n\
    \                 bias_regularizer=None,\n                 activity_regularizer=None,\n\
    \                 kernel_constraint=None,\n                 bias_constraint=None,\n\
    \                 **kwargs):\n        super(Conv3DTranspose, self).__init__(\n\
    \            filters,\n            kernel_size,\n            strides=strides,\n\
    \            padding=padding,\n            data_format=data_format,\n        \
    \    activation=activation,\n            use_bias=use_bias,\n            kernel_initializer=kernel_initializer,\n\
    \            bias_initializer=bias_initializer,\n            kernel_regularizer=kernel_regularizer,\n\
    \            bias_regularizer=bias_regularizer,\n            activity_regularizer=activity_regularizer,\n\
    \            kernel_constraint=kernel_constraint,\n            bias_constraint=bias_constraint,\n\
    \            **kwargs)\n\n        self.output_padding = output_padding\n     \
    \   if self.output_padding is not None:\n            self.output_padding = conv_utils.normalize_tuple(\n\
    \                self.output_padding, 3, 'output_padding')\n            for stride,\
    \ out_pad in zip(self.strides, self.output_padding):\n                if out_pad\
    \ >= stride:\n                    raise ValueError('Stride ' + str(self.strides)\
    \ + ' must be '\n                                     'greater than output padding\
    \ ' +\n                                     str(self.output_padding))\n\n    def\
    \ build(self, input_shape):\n        if len(input_shape) != 5:\n            raise\
    \ ValueError('Inputs should have rank ' +\n                             str(5)\
    \ +\n                             '; Received input shape:', str(input_shape))\n\
    \        if self.data_format == 'channels_first':\n            channel_axis =\
    \ 1\n        else:\n            channel_axis = -1\n        if input_shape[channel_axis]\
    \ is None:\n            raise ValueError('The channel dimension of the inputs\
    \ '\n                             'should be defined. Found `None`.')\n      \
    \  input_dim = input_shape[channel_axis]\n        kernel_shape = self.kernel_size\
    \ + (self.filters, input_dim)\n\n        self.kernel = self.add_weight(shape=kernel_shape,\n\
    \                                      initializer=self.kernel_initializer,\n\
    \                                      name='kernel',\n                      \
    \                regularizer=self.kernel_regularizer,\n                      \
    \                constraint=self.kernel_constraint)\n        if self.use_bias:\n\
    \            self.bias = self.add_weight(shape=(self.filters,),\n            \
    \                            initializer=self.bias_initializer,\n            \
    \                            name='bias',\n                                  \
    \      regularizer=self.bias_regularizer,\n                                  \
    \      constraint=self.bias_constraint)\n        else:\n            self.bias\
    \ = None\n        # Set input spec.\n        self.input_spec = InputSpec(ndim=5,\
    \ axes={channel_axis: input_dim})\n        self.built = True\n\n    def call(self,\
    \ inputs):\n        input_shape = K.shape(inputs)\n        batch_size = input_shape[0]\n\
    \        if self.data_format == 'channels_first':\n            d_axis, h_axis,\
    \ w_axis = 2, 3, 4\n        else:\n            d_axis, h_axis, w_axis = 1, 2,\
    \ 3\n\n        depth = input_shape[d_axis]\n        height = input_shape[h_axis]\n\
    \        width = input_shape[w_axis]\n\n        kernel_d, kernel_h, kernel_w =\
    \ self.kernel_size\n        stride_d, stride_h, stride_w = self.strides\n    \
    \    if self.output_padding is None:\n            out_pad_d = out_pad_h = out_pad_w\
    \ = None\n        else:\n            out_pad_d, out_pad_h, out_pad_w = self.output_padding\n\
    \n        # Infer the dynamic output shape:\n        out_depth = conv_utils.deconv_length(depth,\n\
    \                                             stride_d, kernel_d,\n          \
    \                                   self.padding,\n                          \
    \                   out_pad_d)\n        out_height = conv_utils.deconv_length(height,\n\
    \                                              stride_h, kernel_h,\n         \
    \                                     self.padding,\n                        \
    \                      out_pad_h)\n        out_width = conv_utils.deconv_length(width,\n\
    \                                             stride_w, kernel_w,\n          \
    \                                   self.padding,\n                          \
    \                   out_pad_w)\n\n        if self.data_format == 'channels_first':\n\
    \            output_shape = (batch_size, self.filters,\n                     \
    \       out_depth, out_height, out_width)\n        else:\n            output_shape\
    \ = (batch_size, out_depth,\n                            out_height, out_width,\
    \ self.filters)\n\n        outputs = K.conv3d_transpose(inputs,\n            \
    \                         self.kernel,\n                                     output_shape,\n\
    \                                     self.strides,\n                        \
    \             padding=self.padding,\n                                     data_format=self.data_format)\n\
    \n        if self.use_bias:\n            outputs = K.bias_add(\n             \
    \   outputs,\n                self.bias,\n                data_format=self.data_format)\n\
    \n        if self.activation is not None:\n            return self.activation(outputs)\n\
    \        return outputs\n\n    def compute_output_shape(self, input_shape):\n\
    \        output_shape = list(input_shape)\n        if self.data_format == 'channels_first':\n\
    \            c_axis, d_axis, h_axis, w_axis = 1, 2, 3, 4\n        else:\n    \
    \        c_axis, d_axis, h_axis, w_axis = 4, 1, 2, 3\n\n        kernel_d, kernel_h,\
    \ kernel_w = self.kernel_size\n        stride_d, stride_h, stride_w = self.strides\n\
    \        if self.output_padding is None:\n            out_pad_d = out_pad_h =\
    \ out_pad_w = None\n        else:\n            out_pad_d, out_pad_h, out_pad_w\
    \ = self.output_padding\n\n        output_shape[c_axis] = self.filters\n     \
    \   output_shape[d_axis] = conv_utils.deconv_length(output_shape[d_axis],\n  \
    \                                                      stride_d,\n           \
    \                                             kernel_d,\n                    \
    \                                    self.padding,\n                         \
    \                               out_pad_d)\n        output_shape[h_axis] = conv_utils.deconv_length(output_shape[h_axis],\n\
    \                                                        stride_h,\n         \
    \                                               kernel_h,\n                  \
    \                                      self.padding,\n                       \
    \                                 out_pad_h)\n        output_shape[w_axis] = conv_utils.deconv_length(output_shape[w_axis],\n\
    \                                                        stride_w,\n         \
    \                                               kernel_w,\n                  \
    \                                      self.padding,\n                       \
    \                                 out_pad_w)\n\n        return tuple(output_shape)\n\
    \n    def get_config(self):\n        config = super(Conv3DTranspose, self).get_config()\n\
    \        config.pop('dilation_rate')\n        config['output_padding'] = self.output_padding\n\
    \        return config\n"
  sourcefile: D:\Python36\lib\site-packages\keras\layers\convolutional.py
- doc: "Convolutional LSTM.\n\nIt is similar to an LSTM layer, but the input transformations\n\
    and recurrent transformations are both convolutional.\n\n# Arguments\n    filters:\
    \ Integer, the dimensionality of the output space\n        (i.e. the number output\
    \ of filters in the convolution).\n    kernel_size: An integer or tuple/list of\
    \ n integers, specifying the\n        dimensions of the convolution window.\n\
    \    strides: An integer or tuple/list of n integers,\n        specifying the\
    \ strides of the convolution.\n        Specifying any stride value != 1 is incompatible\
    \ with specifying\n        any `dilation_rate` value != 1.\n    padding: One of\
    \ `\"valid\"` or `\"same\"` (case-insensitive).\n    data_format: A string,\n\
    \        one of `\"channels_last\"` (default) or `\"channels_first\"`.\n     \
    \   The ordering of the dimensions in the inputs.\n        `\"channels_last\"\
    ` corresponds to inputs with shape\n        `(batch, time, ..., channels)`\n \
    \       while `\"channels_first\"` corresponds to\n        inputs with shape `(batch,\
    \ time, channels, ...)`.\n        It defaults to the `image_data_format` value\
    \ found in your\n        Keras config file at `~/.keras/keras.json`.\n       \
    \ If you never set it, then it will be `\"channels_last\"`.\n    dilation_rate:\
    \ An integer or tuple/list of n integers, specifying\n        the dilation rate\
    \ to use for dilated convolution.\n        Currently, specifying any `dilation_rate`\
    \ value != 1 is\n        incompatible with specifying any `strides` value != 1.\n\
    \    activation: Activation function to use\n        (see [activations](../activations.md)).\n\
    \        If you don't specify anything, no activation is applied\n        (ie.\
    \ \"linear\" activation: `a(x) = x`).\n    recurrent_activation: Activation function\
    \ to use\n        for the recurrent step\n        (see [activations](../activations.md)).\n\
    \    use_bias: Boolean, whether the layer uses a bias vector.\n    kernel_initializer:\
    \ Initializer for the `kernel` weights matrix,\n        used for the linear transformation\
    \ of the inputs.\n        (see [initializers](../initializers.md)).\n    recurrent_initializer:\
    \ Initializer for the `recurrent_kernel`\n        weights matrix,\n        used\
    \ for the linear transformation of the recurrent state.\n        (see [initializers](../initializers.md)).\n\
    \    bias_initializer: Initializer for the bias vector\n        (see [initializers](../initializers.md)).\n\
    \    unit_forget_bias: Boolean.\n        If True, add 1 to the bias of the forget\
    \ gate at initialization.\n        Use in combination with `bias_initializer=\"\
    zeros\"`.\n        This is recommended in [Jozefowicz et al.]\n        (http://www.jmlr.org/proceedings/papers/v37/jozefowicz15.pdf).\n\
    \    kernel_regularizer: Regularizer function applied to\n        the `kernel`\
    \ weights matrix\n        (see [regularizer](../regularizers.md)).\n    recurrent_regularizer:\
    \ Regularizer function applied to\n        the `recurrent_kernel` weights matrix\n\
    \        (see [regularizer](../regularizers.md)).\n    bias_regularizer: Regularizer\
    \ function applied to the bias vector\n        (see [regularizer](../regularizers.md)).\n\
    \    activity_regularizer: Regularizer function applied to\n        the output\
    \ of the layer (its \"activation\").\n        (see [regularizer](../regularizers.md)).\n\
    \    kernel_constraint: Constraint function applied to\n        the `kernel` weights\
    \ matrix\n        (see [constraints](../constraints.md)).\n    recurrent_constraint:\
    \ Constraint function applied to\n        the `recurrent_kernel` weights matrix\n\
    \        (see [constraints](../constraints.md)).\n    bias_constraint: Constraint\
    \ function applied to the bias vector\n        (see [constraints](../constraints.md)).\n\
    \    return_sequences: Boolean. Whether to return the last output\n        in\
    \ the output sequence, or the full sequence.\n    go_backwards: Boolean (default\
    \ False).\n        If True, process the input sequence backwards.\n    stateful:\
    \ Boolean (default False). If True, the last state\n        for each sample at\
    \ index i in a batch will be used as initial\n        state for the sample of\
    \ index i in the following batch.\n    dropout: Float between 0 and 1.\n     \
    \   Fraction of the units to drop for\n        the linear transformation of the\
    \ inputs.\n    recurrent_dropout: Float between 0 and 1.\n        Fraction of\
    \ the units to drop for\n        the linear transformation of the recurrent state.\n\
    \n# Input shape\n    - if data_format='channels_first'\n        5D tensor with\
    \ shape:\n        `(samples, time, channels, rows, cols)`\n    - if data_format='channels_last'\n\
    \        5D tensor with shape:\n        `(samples, time, rows, cols, channels)`\n\
    \n# Output shape\n    - if `return_sequences`\n         - if data_format='channels_first'\n\
    \            5D tensor with shape:\n            `(samples, time, filters, output_row,\
    \ output_col)`\n         - if data_format='channels_last'\n            5D tensor\
    \ with shape:\n            `(samples, time, output_row, output_col, filters)`\n\
    \    - else\n        - if data_format='channels_first'\n            4D tensor\
    \ with shape:\n            `(samples, filters, output_row, output_col)`\n    \
    \    - if data_format='channels_last'\n            4D tensor with shape:\n   \
    \         `(samples, output_row, output_col, filters)`\n        where o_row and\
    \ o_col depend on the shape of the filter and\n        the padding\n\n# Raises\n\
    \    ValueError: in case of invalid constructor arguments.\n\n# References\n \
    \   - [Convolutional LSTM Network: A Machine Learning Approach for\n    Precipitation\
    \ Nowcasting](http://arxiv.org/abs/1506.04214v1)\n    The current implementation\
    \ does not include the feedback loop on the\n    cells output"
  kind: Layer
  name: ConvLSTM2D
  parameters:
  - {kind: any, name: filters}
  - {kind: any, name: kernel_size}
  - {defaultValue: '(1, 1)', kind: any, name: strides}
  - {defaultValue: valid, kind: any, name: padding}
  - {defaultValue: None, kind: any, name: data_format}
  - {defaultValue: '(1, 1)', kind: any, name: dilation_rate}
  - {defaultValue: tanh, kind: any, name: activation}
  - {defaultValue: hard_sigmoid, kind: any, name: recurrent_activation}
  - {defaultValue: 'True', kind: any, name: use_bias}
  - {defaultValue: glorot_uniform, kind: any, name: kernel_initializer}
  - {defaultValue: orthogonal, kind: any, name: recurrent_initializer}
  - {defaultValue: zeros, kind: any, name: bias_initializer}
  - {defaultValue: 'True', kind: any, name: unit_forget_bias}
  - {defaultValue: None, kind: any, name: kernel_regularizer}
  - {defaultValue: None, kind: any, name: recurrent_regularizer}
  - {defaultValue: None, kind: any, name: bias_regularizer}
  - {defaultValue: None, kind: any, name: activity_regularizer}
  - {defaultValue: None, kind: any, name: kernel_constraint}
  - {defaultValue: None, kind: any, name: recurrent_constraint}
  - {defaultValue: None, kind: any, name: bias_constraint}
  - {defaultValue: 'False', kind: any, name: return_sequences}
  - {defaultValue: 'False', kind: any, name: go_backwards}
  - {defaultValue: 'False', kind: any, name: stateful}
  - {defaultValue: '0.0', kind: any, name: dropout}
  - {defaultValue: '0.0', kind: any, name: recurrent_dropout}
  - {defaultValue: 'true', name: trainable, type: bool}
  source: "class ConvLSTM2D(ConvRNN2D):\n    \"\"\"Convolutional LSTM.\n\n    It is\
    \ similar to an LSTM layer, but the input transformations\n    and recurrent transformations\
    \ are both convolutional.\n\n    # Arguments\n        filters: Integer, the dimensionality\
    \ of the output space\n            (i.e. the number output of filters in the convolution).\n\
    \        kernel_size: An integer or tuple/list of n integers, specifying the\n\
    \            dimensions of the convolution window.\n        strides: An integer\
    \ or tuple/list of n integers,\n            specifying the strides of the convolution.\n\
    \            Specifying any stride value != 1 is incompatible with specifying\n\
    \            any `dilation_rate` value != 1.\n        padding: One of `\"valid\"\
    ` or `\"same\"` (case-insensitive).\n        data_format: A string,\n        \
    \    one of `\"channels_last\"` (default) or `\"channels_first\"`.\n         \
    \   The ordering of the dimensions in the inputs.\n            `\"channels_last\"\
    ` corresponds to inputs with shape\n            `(batch, time, ..., channels)`\n\
    \            while `\"channels_first\"` corresponds to\n            inputs with\
    \ shape `(batch, time, channels, ...)`.\n            It defaults to the `image_data_format`\
    \ value found in your\n            Keras config file at `~/.keras/keras.json`.\n\
    \            If you never set it, then it will be `\"channels_last\"`.\n     \
    \   dilation_rate: An integer or tuple/list of n integers, specifying\n      \
    \      the dilation rate to use for dilated convolution.\n            Currently,\
    \ specifying any `dilation_rate` value != 1 is\n            incompatible with\
    \ specifying any `strides` value != 1.\n        activation: Activation function\
    \ to use\n            (see [activations](../activations.md)).\n            If\
    \ you don't specify anything, no activation is applied\n            (ie. \"linear\"\
    \ activation: `a(x) = x`).\n        recurrent_activation: Activation function\
    \ to use\n            for the recurrent step\n            (see [activations](../activations.md)).\n\
    \        use_bias: Boolean, whether the layer uses a bias vector.\n        kernel_initializer:\
    \ Initializer for the `kernel` weights matrix,\n            used for the linear\
    \ transformation of the inputs.\n            (see [initializers](../initializers.md)).\n\
    \        recurrent_initializer: Initializer for the `recurrent_kernel`\n     \
    \       weights matrix,\n            used for the linear transformation of the\
    \ recurrent state.\n            (see [initializers](../initializers.md)).\n  \
    \      bias_initializer: Initializer for the bias vector\n            (see [initializers](../initializers.md)).\n\
    \        unit_forget_bias: Boolean.\n            If True, add 1 to the bias of\
    \ the forget gate at initialization.\n            Use in combination with `bias_initializer=\"\
    zeros\"`.\n            This is recommended in [Jozefowicz et al.]\n          \
    \  (http://www.jmlr.org/proceedings/papers/v37/jozefowicz15.pdf).\n        kernel_regularizer:\
    \ Regularizer function applied to\n            the `kernel` weights matrix\n \
    \           (see [regularizer](../regularizers.md)).\n        recurrent_regularizer:\
    \ Regularizer function applied to\n            the `recurrent_kernel` weights\
    \ matrix\n            (see [regularizer](../regularizers.md)).\n        bias_regularizer:\
    \ Regularizer function applied to the bias vector\n            (see [regularizer](../regularizers.md)).\n\
    \        activity_regularizer: Regularizer function applied to\n            the\
    \ output of the layer (its \"activation\").\n            (see [regularizer](../regularizers.md)).\n\
    \        kernel_constraint: Constraint function applied to\n            the `kernel`\
    \ weights matrix\n            (see [constraints](../constraints.md)).\n      \
    \  recurrent_constraint: Constraint function applied to\n            the `recurrent_kernel`\
    \ weights matrix\n            (see [constraints](../constraints.md)).\n      \
    \  bias_constraint: Constraint function applied to the bias vector\n         \
    \   (see [constraints](../constraints.md)).\n        return_sequences: Boolean.\
    \ Whether to return the last output\n            in the output sequence, or the\
    \ full sequence.\n        go_backwards: Boolean (default False).\n           \
    \ If True, process the input sequence backwards.\n        stateful: Boolean (default\
    \ False). If True, the last state\n            for each sample at index i in a\
    \ batch will be used as initial\n            state for the sample of index i in\
    \ the following batch.\n        dropout: Float between 0 and 1.\n            Fraction\
    \ of the units to drop for\n            the linear transformation of the inputs.\n\
    \        recurrent_dropout: Float between 0 and 1.\n            Fraction of the\
    \ units to drop for\n            the linear transformation of the recurrent state.\n\
    \n    # Input shape\n        - if data_format='channels_first'\n            5D\
    \ tensor with shape:\n            `(samples, time, channels, rows, cols)`\n  \
    \      - if data_format='channels_last'\n            5D tensor with shape:\n \
    \           `(samples, time, rows, cols, channels)`\n\n    # Output shape\n  \
    \      - if `return_sequences`\n             - if data_format='channels_first'\n\
    \                5D tensor with shape:\n                `(samples, time, filters,\
    \ output_row, output_col)`\n             - if data_format='channels_last'\n  \
    \              5D tensor with shape:\n                `(samples, time, output_row,\
    \ output_col, filters)`\n        - else\n            - if data_format='channels_first'\n\
    \                4D tensor with shape:\n                `(samples, filters, output_row,\
    \ output_col)`\n            - if data_format='channels_last'\n               \
    \ 4D tensor with shape:\n                `(samples, output_row, output_col, filters)`\n\
    \            where o_row and o_col depend on the shape of the filter and\n   \
    \         the padding\n\n    # Raises\n        ValueError: in case of invalid\
    \ constructor arguments.\n\n    # References\n        - [Convolutional LSTM Network:\
    \ A Machine Learning Approach for\n        Precipitation Nowcasting](http://arxiv.org/abs/1506.04214v1)\n\
    \        The current implementation does not include the feedback loop on the\n\
    \        cells output\n    \"\"\"\n\n    @interfaces.legacy_convlstm2d_support\n\
    \    def __init__(self, filters,\n                 kernel_size,\n            \
    \     strides=(1, 1),\n                 padding='valid',\n                 data_format=None,\n\
    \                 dilation_rate=(1, 1),\n                 activation='tanh',\n\
    \                 recurrent_activation='hard_sigmoid',\n                 use_bias=True,\n\
    \                 kernel_initializer='glorot_uniform',\n                 recurrent_initializer='orthogonal',\n\
    \                 bias_initializer='zeros',\n                 unit_forget_bias=True,\n\
    \                 kernel_regularizer=None,\n                 recurrent_regularizer=None,\n\
    \                 bias_regularizer=None,\n                 activity_regularizer=None,\n\
    \                 kernel_constraint=None,\n                 recurrent_constraint=None,\n\
    \                 bias_constraint=None,\n                 return_sequences=False,\n\
    \                 go_backwards=False,\n                 stateful=False,\n    \
    \             dropout=0.,\n                 recurrent_dropout=0.,\n          \
    \       **kwargs):\n        cell = ConvLSTM2DCell(filters=filters,\n         \
    \                     kernel_size=kernel_size,\n                             \
    \ strides=strides,\n                              padding=padding,\n         \
    \                     data_format=data_format,\n                             \
    \ dilation_rate=dilation_rate,\n                              activation=activation,\n\
    \                              recurrent_activation=recurrent_activation,\n  \
    \                            use_bias=use_bias,\n                            \
    \  kernel_initializer=kernel_initializer,\n                              recurrent_initializer=recurrent_initializer,\n\
    \                              bias_initializer=bias_initializer,\n          \
    \                    unit_forget_bias=unit_forget_bias,\n                    \
    \          kernel_regularizer=kernel_regularizer,\n                          \
    \    recurrent_regularizer=recurrent_regularizer,\n                          \
    \    bias_regularizer=bias_regularizer,\n                              kernel_constraint=kernel_constraint,\n\
    \                              recurrent_constraint=recurrent_constraint,\n  \
    \                            bias_constraint=bias_constraint,\n              \
    \                dropout=dropout,\n                              recurrent_dropout=recurrent_dropout)\n\
    \        super(ConvLSTM2D, self).__init__(cell,\n                            \
    \             return_sequences=return_sequences,\n                           \
    \              go_backwards=go_backwards,\n                                  \
    \       stateful=stateful,\n                                         **kwargs)\n\
    \        self.activity_regularizer = regularizers.get(activity_regularizer)\n\n\
    \    def call(self, inputs, mask=None, training=None, initial_state=None):\n \
    \       return super(ConvLSTM2D, self).call(inputs,\n                        \
    \                    mask=mask,\n                                            training=training,\n\
    \                                            initial_state=initial_state)\n\n\
    \    @property\n    def filters(self):\n        return self.cell.filters\n\n \
    \   @property\n    def kernel_size(self):\n        return self.cell.kernel_size\n\
    \n    @property\n    def strides(self):\n        return self.cell.strides\n\n\
    \    @property\n    def padding(self):\n        return self.cell.padding\n\n \
    \   @property\n    def data_format(self):\n        return self.cell.data_format\n\
    \n    @property\n    def dilation_rate(self):\n        return self.cell.dilation_rate\n\
    \n    @property\n    def activation(self):\n        return self.cell.activation\n\
    \n    @property\n    def recurrent_activation(self):\n        return self.cell.recurrent_activation\n\
    \n    @property\n    def use_bias(self):\n        return self.cell.use_bias\n\n\
    \    @property\n    def kernel_initializer(self):\n        return self.cell.kernel_initializer\n\
    \n    @property\n    def recurrent_initializer(self):\n        return self.cell.recurrent_initializer\n\
    \n    @property\n    def bias_initializer(self):\n        return self.cell.bias_initializer\n\
    \n    @property\n    def unit_forget_bias(self):\n        return self.cell.unit_forget_bias\n\
    \n    @property\n    def kernel_regularizer(self):\n        return self.cell.kernel_regularizer\n\
    \n    @property\n    def recurrent_regularizer(self):\n        return self.cell.recurrent_regularizer\n\
    \n    @property\n    def bias_regularizer(self):\n        return self.cell.bias_regularizer\n\
    \n    @property\n    def kernel_constraint(self):\n        return self.cell.kernel_constraint\n\
    \n    @property\n    def recurrent_constraint(self):\n        return self.cell.recurrent_constraint\n\
    \n    @property\n    def bias_constraint(self):\n        return self.cell.bias_constraint\n\
    \n    @property\n    def dropout(self):\n        return self.cell.dropout\n\n\
    \    @property\n    def recurrent_dropout(self):\n        return self.cell.recurrent_dropout\n\
    \n    def get_config(self):\n        config = {'filters': self.filters,\n    \
    \              'kernel_size': self.kernel_size,\n                  'strides':\
    \ self.strides,\n                  'padding': self.padding,\n                \
    \  'data_format': self.data_format,\n                  'dilation_rate': self.dilation_rate,\n\
    \                  'activation': activations.serialize(self.activation),\n   \
    \               'recurrent_activation':\n                      activations.serialize(self.recurrent_activation),\n\
    \                  'use_bias': self.use_bias,\n                  'kernel_initializer':\n\
    \                      initializers.serialize(self.kernel_initializer),\n    \
    \              'recurrent_initializer':\n                      initializers.serialize(self.recurrent_initializer),\n\
    \                  'bias_initializer': initializers.serialize(self.bias_initializer),\n\
    \                  'unit_forget_bias': self.unit_forget_bias,\n              \
    \    'kernel_regularizer':\n                      regularizers.serialize(self.kernel_regularizer),\n\
    \                  'recurrent_regularizer':\n                      regularizers.serialize(self.recurrent_regularizer),\n\
    \                  'bias_regularizer': regularizers.serialize(self.bias_regularizer),\n\
    \                  'activity_regularizer':\n                      regularizers.serialize(self.activity_regularizer),\n\
    \                  'kernel_constraint':\n                      constraints.serialize(self.kernel_constraint),\n\
    \                  'recurrent_constraint':\n                      constraints.serialize(self.recurrent_constraint),\n\
    \                  'bias_constraint': constraints.serialize(self.bias_constraint),\n\
    \                  'dropout': self.dropout,\n                  'recurrent_dropout':\
    \ self.recurrent_dropout}\n        base_config = super(ConvLSTM2D, self).get_config()\n\
    \        del base_config['cell']\n        return dict(list(base_config.items())\
    \ + list(config.items()))\n\n    @classmethod\n    def from_config(cls, config):\n\
    \        return cls(**config)\n"
  sourcefile: D:\Python36\lib\site-packages\keras\layers\convolutional_recurrent.py
- doc: "Cell class for the ConvLSTM2D layer.\n\n# Arguments\n    filters: Integer,\
    \ the dimensionality of the output space\n        (i.e. the number of output filters\
    \ in the convolution).\n    kernel_size: An integer or tuple/list of n integers,\
    \ specifying the\n        dimensions of the convolution window.\n    strides:\
    \ An integer or tuple/list of n integers,\n        specifying the strides of the\
    \ convolution.\n        Specifying any stride value != 1 is incompatible with\
    \ specifying\n        any `dilation_rate` value != 1.\n    padding: One of `\"\
    valid\"` or `\"same\"` (case-insensitive).\n    data_format: A string,\n     \
    \   one of `\"channels_last\"` (default) or `\"channels_first\"`.\n        It\
    \ defaults to the `image_data_format` value found in your\n        Keras config\
    \ file at `~/.keras/keras.json`.\n        If you never set it, then it will be\
    \ `\"channels_last\"`.\n    dilation_rate: An integer or tuple/list of n integers,\
    \ specifying\n        the dilation rate to use for dilated convolution.\n    \
    \    Currently, specifying any `dilation_rate` value != 1 is\n        incompatible\
    \ with specifying any `strides` value != 1.\n    activation: Activation function\
    \ to use\n        (see [activations](../activations.md)).\n        If you don't\
    \ specify anything, no activation is applied\n        (ie. \"linear\" activation:\
    \ `a(x) = x`).\n    recurrent_activation: Activation function to use\n       \
    \ for the recurrent step\n        (see [activations](../activations.md)).\n  \
    \  use_bias: Boolean, whether the layer uses a bias vector.\n    kernel_initializer:\
    \ Initializer for the `kernel` weights matrix,\n        used for the linear transformation\
    \ of the inputs.\n        (see [initializers](../initializers.md)).\n    recurrent_initializer:\
    \ Initializer for the `recurrent_kernel`\n        weights matrix,\n        used\
    \ for the linear transformation of the recurrent state.\n        (see [initializers](../initializers.md)).\n\
    \    bias_initializer: Initializer for the bias vector\n        (see [initializers](../initializers.md)).\n\
    \    unit_forget_bias: Boolean.\n        If True, add 1 to the bias of the forget\
    \ gate at initialization.\n        Use in combination with `bias_initializer=\"\
    zeros\"`.\n        This is recommended in [Jozefowicz et al.]\n        (http://www.jmlr.org/proceedings/papers/v37/jozefowicz15.pdf).\n\
    \    kernel_regularizer: Regularizer function applied to\n        the `kernel`\
    \ weights matrix\n        (see [regularizer](../regularizers.md)).\n    recurrent_regularizer:\
    \ Regularizer function applied to\n        the `recurrent_kernel` weights matrix\n\
    \        (see [regularizer](../regularizers.md)).\n    bias_regularizer: Regularizer\
    \ function applied to the bias vector\n        (see [regularizer](../regularizers.md)).\n\
    \    kernel_constraint: Constraint function applied to\n        the `kernel` weights\
    \ matrix\n        (see [constraints](../constraints.md)).\n    recurrent_constraint:\
    \ Constraint function applied to\n        the `recurrent_kernel` weights matrix\n\
    \        (see [constraints](../constraints.md)).\n    bias_constraint: Constraint\
    \ function applied to the bias vector\n        (see [constraints](../constraints.md)).\n\
    \    dropout: Float between 0 and 1.\n        Fraction of the units to drop for\n\
    \        the linear transformation of the inputs.\n    recurrent_dropout: Float\
    \ between 0 and 1.\n        Fraction of the units to drop for\n        the linear\
    \ transformation of the recurrent state."
  kind: Layer
  name: ConvLSTM2DCell
  parameters:
  - {kind: any, name: filters}
  - {kind: any, name: kernel_size}
  - {defaultValue: '(1, 1)', kind: any, name: strides}
  - {defaultValue: valid, kind: any, name: padding}
  - {defaultValue: None, kind: any, name: data_format}
  - {defaultValue: '(1, 1)', kind: any, name: dilation_rate}
  - {defaultValue: tanh, kind: any, name: activation}
  - {defaultValue: hard_sigmoid, kind: any, name: recurrent_activation}
  - {defaultValue: 'True', kind: any, name: use_bias}
  - {defaultValue: glorot_uniform, kind: any, name: kernel_initializer}
  - {defaultValue: orthogonal, kind: any, name: recurrent_initializer}
  - {defaultValue: zeros, kind: any, name: bias_initializer}
  - {defaultValue: 'True', kind: any, name: unit_forget_bias}
  - {defaultValue: None, kind: any, name: kernel_regularizer}
  - {defaultValue: None, kind: any, name: recurrent_regularizer}
  - {defaultValue: None, kind: any, name: bias_regularizer}
  - {defaultValue: None, kind: any, name: kernel_constraint}
  - {defaultValue: None, kind: any, name: recurrent_constraint}
  - {defaultValue: None, kind: any, name: bias_constraint}
  - {defaultValue: '0.0', kind: any, name: dropout}
  - {defaultValue: '0.0', kind: any, name: recurrent_dropout}
  - {defaultValue: 'true', name: trainable, type: bool}
  source: "class ConvLSTM2DCell(Layer):\n    \"\"\"Cell class for the ConvLSTM2D layer.\n\
    \n    # Arguments\n        filters: Integer, the dimensionality of the output\
    \ space\n            (i.e. the number of output filters in the convolution).\n\
    \        kernel_size: An integer or tuple/list of n integers, specifying the\n\
    \            dimensions of the convolution window.\n        strides: An integer\
    \ or tuple/list of n integers,\n            specifying the strides of the convolution.\n\
    \            Specifying any stride value != 1 is incompatible with specifying\n\
    \            any `dilation_rate` value != 1.\n        padding: One of `\"valid\"\
    ` or `\"same\"` (case-insensitive).\n        data_format: A string,\n        \
    \    one of `\"channels_last\"` (default) or `\"channels_first\"`.\n         \
    \   It defaults to the `image_data_format` value found in your\n            Keras\
    \ config file at `~/.keras/keras.json`.\n            If you never set it, then\
    \ it will be `\"channels_last\"`.\n        dilation_rate: An integer or tuple/list\
    \ of n integers, specifying\n            the dilation rate to use for dilated\
    \ convolution.\n            Currently, specifying any `dilation_rate` value !=\
    \ 1 is\n            incompatible with specifying any `strides` value != 1.\n \
    \       activation: Activation function to use\n            (see [activations](../activations.md)).\n\
    \            If you don't specify anything, no activation is applied\n       \
    \     (ie. \"linear\" activation: `a(x) = x`).\n        recurrent_activation:\
    \ Activation function to use\n            for the recurrent step\n           \
    \ (see [activations](../activations.md)).\n        use_bias: Boolean, whether\
    \ the layer uses a bias vector.\n        kernel_initializer: Initializer for the\
    \ `kernel` weights matrix,\n            used for the linear transformation of\
    \ the inputs.\n            (see [initializers](../initializers.md)).\n       \
    \ recurrent_initializer: Initializer for the `recurrent_kernel`\n            weights\
    \ matrix,\n            used for the linear transformation of the recurrent state.\n\
    \            (see [initializers](../initializers.md)).\n        bias_initializer:\
    \ Initializer for the bias vector\n            (see [initializers](../initializers.md)).\n\
    \        unit_forget_bias: Boolean.\n            If True, add 1 to the bias of\
    \ the forget gate at initialization.\n            Use in combination with `bias_initializer=\"\
    zeros\"`.\n            This is recommended in [Jozefowicz et al.]\n          \
    \  (http://www.jmlr.org/proceedings/papers/v37/jozefowicz15.pdf).\n        kernel_regularizer:\
    \ Regularizer function applied to\n            the `kernel` weights matrix\n \
    \           (see [regularizer](../regularizers.md)).\n        recurrent_regularizer:\
    \ Regularizer function applied to\n            the `recurrent_kernel` weights\
    \ matrix\n            (see [regularizer](../regularizers.md)).\n        bias_regularizer:\
    \ Regularizer function applied to the bias vector\n            (see [regularizer](../regularizers.md)).\n\
    \        kernel_constraint: Constraint function applied to\n            the `kernel`\
    \ weights matrix\n            (see [constraints](../constraints.md)).\n      \
    \  recurrent_constraint: Constraint function applied to\n            the `recurrent_kernel`\
    \ weights matrix\n            (see [constraints](../constraints.md)).\n      \
    \  bias_constraint: Constraint function applied to the bias vector\n         \
    \   (see [constraints](../constraints.md)).\n        dropout: Float between 0\
    \ and 1.\n            Fraction of the units to drop for\n            the linear\
    \ transformation of the inputs.\n        recurrent_dropout: Float between 0 and\
    \ 1.\n            Fraction of the units to drop for\n            the linear transformation\
    \ of the recurrent state.\n    \"\"\"\n\n    def __init__(self, filters,\n   \
    \              kernel_size,\n                 strides=(1, 1),\n              \
    \   padding='valid',\n                 data_format=None,\n                 dilation_rate=(1,\
    \ 1),\n                 activation='tanh',\n                 recurrent_activation='hard_sigmoid',\n\
    \                 use_bias=True,\n                 kernel_initializer='glorot_uniform',\n\
    \                 recurrent_initializer='orthogonal',\n                 bias_initializer='zeros',\n\
    \                 unit_forget_bias=True,\n                 kernel_regularizer=None,\n\
    \                 recurrent_regularizer=None,\n                 bias_regularizer=None,\n\
    \                 kernel_constraint=None,\n                 recurrent_constraint=None,\n\
    \                 bias_constraint=None,\n                 dropout=0.,\n      \
    \           recurrent_dropout=0.,\n                 **kwargs):\n        super(ConvLSTM2DCell,\
    \ self).__init__(**kwargs)\n        self.filters = filters\n        self.kernel_size\
    \ = conv_utils.normalize_tuple(kernel_size, 2, 'kernel_size')\n        self.strides\
    \ = conv_utils.normalize_tuple(strides, 2, 'strides')\n        self.padding =\
    \ conv_utils.normalize_padding(padding)\n        self.data_format = K.normalize_data_format(data_format)\n\
    \        self.dilation_rate = conv_utils.normalize_tuple(dilation_rate, 2,\n \
    \                                                       'dilation_rate')\n   \
    \     self.activation = activations.get(activation)\n        self.recurrent_activation\
    \ = activations.get(recurrent_activation)\n        self.use_bias = use_bias\n\n\
    \        self.kernel_initializer = initializers.get(kernel_initializer)\n    \
    \    self.recurrent_initializer = initializers.get(recurrent_initializer)\n  \
    \      self.bias_initializer = initializers.get(bias_initializer)\n        self.unit_forget_bias\
    \ = unit_forget_bias\n\n        self.kernel_regularizer = regularizers.get(kernel_regularizer)\n\
    \        self.recurrent_regularizer = regularizers.get(recurrent_regularizer)\n\
    \        self.bias_regularizer = regularizers.get(bias_regularizer)\n\n      \
    \  self.kernel_constraint = constraints.get(kernel_constraint)\n        self.recurrent_constraint\
    \ = constraints.get(recurrent_constraint)\n        self.bias_constraint = constraints.get(bias_constraint)\n\
    \n        if K.backend() == 'theano' and (dropout or recurrent_dropout):\n   \
    \         warnings.warn(\n                'RNN dropout is no longer supported\
    \ with the Theano backend '\n                'due to technical limitations. '\n\
    \                'You can either set `dropout` and `recurrent_dropout` to 0, '\n\
    \                'or use the TensorFlow backend.')\n            dropout = 0.\n\
    \            recurrent_dropout = 0.\n        self.dropout = min(1., max(0., dropout))\n\
    \        self.recurrent_dropout = min(1., max(0., recurrent_dropout))\n      \
    \  self.state_size = (self.filters, self.filters)\n        self._dropout_mask\
    \ = None\n        self._recurrent_dropout_mask = None\n\n    def build(self, input_shape):\n\
    \n        if self.data_format == 'channels_first':\n            channel_axis =\
    \ 1\n        else:\n            channel_axis = -1\n        if input_shape[channel_axis]\
    \ is None:\n            raise ValueError('The channel dimension of the inputs\
    \ '\n                             'should be defined. Found `None`.')\n      \
    \  input_dim = input_shape[channel_axis]\n        kernel_shape = self.kernel_size\
    \ + (input_dim, self.filters * 4)\n        self.kernel_shape = kernel_shape\n\
    \        recurrent_kernel_shape = self.kernel_size + (self.filters, self.filters\
    \ * 4)\n\n        self.kernel = self.add_weight(shape=kernel_shape,\n        \
    \                              initializer=self.kernel_initializer,\n        \
    \                              name='kernel',\n                              \
    \        regularizer=self.kernel_regularizer,\n                              \
    \        constraint=self.kernel_constraint)\n        self.recurrent_kernel = self.add_weight(\n\
    \            shape=recurrent_kernel_shape,\n            initializer=self.recurrent_initializer,\n\
    \            name='recurrent_kernel',\n            regularizer=self.recurrent_regularizer,\n\
    \            constraint=self.recurrent_constraint)\n        if self.use_bias:\n\
    \            if self.unit_forget_bias:\n                def bias_initializer(_,\
    \ *args, **kwargs):\n                    return K.concatenate([\n            \
    \            self.bias_initializer((self.filters,), *args, **kwargs),\n      \
    \                  initializers.Ones()((self.filters,), *args, **kwargs),\n  \
    \                      self.bias_initializer((self.filters * 2,), *args, **kwargs),\n\
    \                    ])\n            else:\n                bias_initializer =\
    \ self.bias_initializer\n            self.bias = self.add_weight(shape=(self.filters\
    \ * 4,),\n                                        name='bias',\n             \
    \                           initializer=bias_initializer,\n                  \
    \                      regularizer=self.bias_regularizer,\n                  \
    \                      constraint=self.bias_constraint)\n        else:\n     \
    \       self.bias = None\n\n        self.kernel_i = self.kernel[:, :, :, :self.filters]\n\
    \        self.recurrent_kernel_i = self.recurrent_kernel[:, :, :, :self.filters]\n\
    \        self.kernel_f = self.kernel[:, :, :, self.filters: self.filters * 2]\n\
    \        self.recurrent_kernel_f = (\n            self.recurrent_kernel[:, :,\
    \ :, self.filters: self.filters * 2])\n        self.kernel_c = self.kernel[:,\
    \ :, :, self.filters * 2: self.filters * 3]\n        self.recurrent_kernel_c =\
    \ (\n            self.recurrent_kernel[:, :, :, self.filters * 2: self.filters\
    \ * 3])\n        self.kernel_o = self.kernel[:, :, :, self.filters * 3:]\n   \
    \     self.recurrent_kernel_o = self.recurrent_kernel[:, :, :, self.filters *\
    \ 3:]\n\n        if self.use_bias:\n            self.bias_i = self.bias[:self.filters]\n\
    \            self.bias_f = self.bias[self.filters: self.filters * 2]\n       \
    \     self.bias_c = self.bias[self.filters * 2: self.filters * 3]\n          \
    \  self.bias_o = self.bias[self.filters * 3:]\n        else:\n            self.bias_i\
    \ = None\n            self.bias_f = None\n            self.bias_c = None\n   \
    \         self.bias_o = None\n        self.built = True\n\n    def call(self,\
    \ inputs, states, training=None):\n        if 0 < self.dropout < 1 and self._dropout_mask\
    \ is None:\n            self._dropout_mask = _generate_dropout_mask(\n       \
    \         K.ones_like(inputs),\n                self.dropout,\n              \
    \  training=training,\n                count=4)\n        if (0 < self.recurrent_dropout\
    \ < 1 and\n                self._recurrent_dropout_mask is None):\n          \
    \  self._recurrent_dropout_mask = _generate_dropout_mask(\n                K.ones_like(states[1]),\n\
    \                self.recurrent_dropout,\n                training=training,\n\
    \                count=4)\n\n        # dropout matrices for input units\n    \
    \    dp_mask = self._dropout_mask\n        # dropout matrices for recurrent units\n\
    \        rec_dp_mask = self._recurrent_dropout_mask\n\n        h_tm1 = states[0]\
    \  # previous memory state\n        c_tm1 = states[1]  # previous carry state\n\
    \n        if 0 < self.dropout < 1.:\n            inputs_i = inputs * dp_mask[0]\n\
    \            inputs_f = inputs * dp_mask[1]\n            inputs_c = inputs * dp_mask[2]\n\
    \            inputs_o = inputs * dp_mask[3]\n        else:\n            inputs_i\
    \ = inputs\n            inputs_f = inputs\n            inputs_c = inputs\n   \
    \         inputs_o = inputs\n\n        if 0 < self.recurrent_dropout < 1.:\n \
    \           h_tm1_i = h_tm1 * rec_dp_mask[0]\n            h_tm1_f = h_tm1 * rec_dp_mask[1]\n\
    \            h_tm1_c = h_tm1 * rec_dp_mask[2]\n            h_tm1_o = h_tm1 * rec_dp_mask[3]\n\
    \        else:\n            h_tm1_i = h_tm1\n            h_tm1_f = h_tm1\n   \
    \         h_tm1_c = h_tm1\n            h_tm1_o = h_tm1\n\n        x_i = self.input_conv(inputs_i,\
    \ self.kernel_i, self.bias_i,\n                              padding=self.padding)\n\
    \        x_f = self.input_conv(inputs_f, self.kernel_f, self.bias_f,\n       \
    \                       padding=self.padding)\n        x_c = self.input_conv(inputs_c,\
    \ self.kernel_c, self.bias_c,\n                              padding=self.padding)\n\
    \        x_o = self.input_conv(inputs_o, self.kernel_o, self.bias_o,\n       \
    \                       padding=self.padding)\n        h_i = self.recurrent_conv(h_tm1_i,\n\
    \                                  self.recurrent_kernel_i)\n        h_f = self.recurrent_conv(h_tm1_f,\n\
    \                                  self.recurrent_kernel_f)\n        h_c = self.recurrent_conv(h_tm1_c,\n\
    \                                  self.recurrent_kernel_c)\n        h_o = self.recurrent_conv(h_tm1_o,\n\
    \                                  self.recurrent_kernel_o)\n\n        i = self.recurrent_activation(x_i\
    \ + h_i)\n        f = self.recurrent_activation(x_f + h_f)\n        c = f * c_tm1\
    \ + i * self.activation(x_c + h_c)\n        o = self.recurrent_activation(x_o\
    \ + h_o)\n        h = o * self.activation(c)\n\n        if 0 < self.dropout +\
    \ self.recurrent_dropout:\n            if training is None:\n                h._uses_learning_phase\
    \ = True\n\n        return h, [h, c]\n\n    def input_conv(self, x, w, b=None,\
    \ padding='valid'):\n        conv_out = K.conv2d(x, w, strides=self.strides,\n\
    \                            padding=padding,\n                            data_format=self.data_format,\n\
    \                            dilation_rate=self.dilation_rate)\n        if b is\
    \ not None:\n            conv_out = K.bias_add(conv_out, b,\n                \
    \                  data_format=self.data_format)\n        return conv_out\n\n\
    \    def recurrent_conv(self, x, w):\n        conv_out = K.conv2d(x, w, strides=(1,\
    \ 1),\n                            padding='same',\n                         \
    \   data_format=self.data_format)\n        return conv_out\n\n    def get_config(self):\n\
    \        config = {'filters': self.filters,\n                  'kernel_size':\
    \ self.kernel_size,\n                  'strides': self.strides,\n            \
    \      'padding': self.padding,\n                  'data_format': self.data_format,\n\
    \                  'dilation_rate': self.dilation_rate,\n                  'activation':\
    \ activations.serialize(self.activation),\n                  'recurrent_activation':\n\
    \                      activations.serialize(self.recurrent_activation),\n   \
    \               'use_bias': self.use_bias,\n                  'kernel_initializer':\n\
    \                      initializers.serialize(self.kernel_initializer),\n    \
    \              'recurrent_initializer':\n                      initializers.serialize(self.recurrent_initializer),\n\
    \                  'bias_initializer': initializers.serialize(self.bias_initializer),\n\
    \                  'unit_forget_bias': self.unit_forget_bias,\n              \
    \    'kernel_regularizer':\n                      regularizers.serialize(self.kernel_regularizer),\n\
    \                  'recurrent_regularizer':\n                      regularizers.serialize(self.recurrent_regularizer),\n\
    \                  'bias_regularizer': regularizers.serialize(self.bias_regularizer),\n\
    \                  'kernel_constraint':\n                      constraints.serialize(self.kernel_constraint),\n\
    \                  'recurrent_constraint':\n                      constraints.serialize(self.recurrent_constraint),\n\
    \                  'bias_constraint': constraints.serialize(self.bias_constraint),\n\
    \                  'dropout': self.dropout,\n                  'recurrent_dropout':\
    \ self.recurrent_dropout}\n        base_config = super(ConvLSTM2DCell, self).get_config()\n\
    \        return dict(list(base_config.items()) + list(config.items()))\n"
  sourcefile: D:\Python36\lib\site-packages\keras\layers\convolutional_recurrent.py
- doc: "Base class for convolutional-recurrent layers.\n\n# Arguments\n    cell: A\
    \ RNN cell instance. A RNN cell is a class that has:\n        - a `call(input_at_t,\
    \ states_at_t)` method, returning\n          `(output_at_t, states_at_t_plus_1)`.\
    \ The call method of the\n          cell can also take the optional argument `constants`,\
    \ see\n          section \"Note on passing external constants\" below.\n     \
    \   - a `state_size` attribute. This can be a single integer (single state)\n\
    \          in which case it is the number of channels of the recurrent state\n\
    \          (which should be the same as the number of channels of the cell\n \
    \         output). This can also be a list/tuple of integers\n          (one size\
    \ per state). In this case, the first entry (`state_size[0]`)\n          should\
    \ be the same as the size of the cell output.\n    return_sequences: Boolean.\
    \ Whether to return the last output.\n        in the output sequence, or the full\
    \ sequence.\n    return_state: Boolean. Whether to return the last state\n   \
    \     in addition to the output.\n    go_backwards: Boolean (default False).\n\
    \        If True, process the input sequence backwards and return the\n      \
    \  reversed sequence.\n    stateful: Boolean (default False). If True, the last\
    \ state\n        for each sample at index i in a batch will be used as initial\n\
    \        state for the sample of index i in the following batch.\n    input_shape:\
    \ Use this argument to specify the shape of the\n        input when this layer\
    \ is the first one in a model.\n\n# Input shape\n    5D tensor with shape:\n \
    \   `(samples, timesteps, channels, rows, cols)` if data_format='channels_first'\n\
    \    or 5D tensor with shape:\n    `(samples, timesteps, rows, cols, channels)`\
    \ if data_format='channels_last'.\n\n# Output shape\n    - if `return_state`:\
    \ a list of tensors. The first tensor is\n        the output. The remaining tensors\
    \ are the last states,\n        each 5D tensor with shape:\n        `(samples,\
    \ timesteps,\n          filters, new_rows, new_cols)` if data_format='channels_first'\n\
    \        or 5D tensor with shape:\n        `(samples, timesteps,\n          new_rows,\
    \ new_cols, filters)` if data_format='channels_last'.\n        `rows` and `cols`\
    \ values might have changed due to padding.\n    - if `return_sequences`: 5D tensor\
    \ with shape:\n        `(samples, timesteps,\n          filters, new_rows, new_cols)`\
    \ if data_format='channels_first'\n        or 5D tensor with shape:\n        `(samples,\
    \ timesteps,\n          new_rows, new_cols, filters)` if data_format='channels_last'.\n\
    \    - else, 4D tensor with shape:\n        `(samples, filters, new_rows, new_cols)`\
    \ if data_format='channels_first'\n        or 4D tensor with shape:\n        `(samples,\
    \ new_rows, new_cols, filters)` if data_format='channels_last'.\n\n# Masking\n\
    \    This layer supports masking for input data with a variable number\n    of\
    \ timesteps. To introduce masks to your data,\n    use an [Embedding](embeddings.md)\
    \ layer with the `mask_zero` parameter\n    set to `True`.\n\n# Note on using\
    \ statefulness in RNNs\n    You can set RNN layers to be 'stateful', which means\
    \ that the states\n    computed for the samples in one batch will be reused as\
    \ initial states\n    for the samples in the next batch. This assumes a one-to-one\
    \ mapping\n    between samples in different successive batches.\n\n    To enable\
    \ statefulness:\n        - specify `stateful=True` in the layer constructor.\n\
    \        - specify a fixed batch size for your model, by passing\n           \
    \  - if sequential model:\n                `batch_input_shape=(...)` to the first\
    \ layer in your model.\n             - if functional model with 1 or more Input\
    \ layers:\n                `batch_shape=(...)` to all the first layers in your\
    \ model.\n                This is the expected shape of your inputs\n        \
    \        *including the batch size*.\n                It should be a tuple of\
    \ integers, e.g. `(32, 10, 100, 100, 32)`.\n                Note that the number\
    \ of rows and columns should be specified too.\n        - specify `shuffle=False`\
    \ when calling fit().\n\n    To reset the states of your model, call `.reset_states()`\
    \ on either\n    a specific layer, or on your entire model.\n\n# Note on specifying\
    \ the initial state of RNNs\n    You can specify the initial state of RNN layers\
    \ symbolically by\n    calling them with the keyword argument `initial_state`.\
    \ The value of\n    `initial_state` should be a tensor or list of tensors representing\n\
    \    the initial state of the RNN layer.\n\n    You can specify the initial state\
    \ of RNN layers numerically by\n    calling `reset_states` with the keyword argument\
    \ `states`. The value of\n    `states` should be a numpy array or list of numpy\
    \ arrays representing\n    the initial state of the RNN layer.\n\n# Note on passing\
    \ external constants to RNNs\n    You can pass \"external\" constants to the cell\
    \ using the `constants`\n    keyword argument of `RNN.__call__` (as well as `RNN.call`)\
    \ method. This\n    requires that the `cell.call` method accepts the same keyword\
    \ argument\n    `constants`. Such constants can be used to condition the cell\n\
    \    transformation on additional static inputs (not changing over time),\n  \
    \  a.k.a. an attention mechanism."
  kind: Layer
  name: ConvRNN2D
  parameters:
  - {kind: any, name: cell}
  - {defaultValue: 'False', kind: any, name: return_sequences}
  - {defaultValue: 'False', kind: any, name: return_state}
  - {defaultValue: 'False', kind: any, name: go_backwards}
  - {defaultValue: 'False', kind: any, name: stateful}
  - {defaultValue: 'False', kind: any, name: unroll}
  - {defaultValue: 'true', name: trainable, type: bool}
  source: "class ConvRNN2D(RNN):\n    \"\"\"Base class for convolutional-recurrent\
    \ layers.\n\n    # Arguments\n        cell: A RNN cell instance. A RNN cell is\
    \ a class that has:\n            - a `call(input_at_t, states_at_t)` method, returning\n\
    \              `(output_at_t, states_at_t_plus_1)`. The call method of the\n \
    \             cell can also take the optional argument `constants`, see\n    \
    \          section \"Note on passing external constants\" below.\n           \
    \ - a `state_size` attribute. This can be a single integer (single state)\n  \
    \            in which case it is the number of channels of the recurrent state\n\
    \              (which should be the same as the number of channels of the cell\n\
    \              output). This can also be a list/tuple of integers\n          \
    \    (one size per state). In this case, the first entry (`state_size[0]`)\n \
    \             should be the same as the size of the cell output.\n        return_sequences:\
    \ Boolean. Whether to return the last output.\n            in the output sequence,\
    \ or the full sequence.\n        return_state: Boolean. Whether to return the\
    \ last state\n            in addition to the output.\n        go_backwards: Boolean\
    \ (default False).\n            If True, process the input sequence backwards\
    \ and return the\n            reversed sequence.\n        stateful: Boolean (default\
    \ False). If True, the last state\n            for each sample at index i in a\
    \ batch will be used as initial\n            state for the sample of index i in\
    \ the following batch.\n        input_shape: Use this argument to specify the\
    \ shape of the\n            input when this layer is the first one in a model.\n\
    \n    # Input shape\n        5D tensor with shape:\n        `(samples, timesteps,\
    \ channels, rows, cols)` if data_format='channels_first'\n        or 5D tensor\
    \ with shape:\n        `(samples, timesteps, rows, cols, channels)` if data_format='channels_last'.\n\
    \n    # Output shape\n        - if `return_state`: a list of tensors. The first\
    \ tensor is\n            the output. The remaining tensors are the last states,\n\
    \            each 5D tensor with shape:\n            `(samples, timesteps,\n \
    \             filters, new_rows, new_cols)` if data_format='channels_first'\n\
    \            or 5D tensor with shape:\n            `(samples, timesteps,\n   \
    \           new_rows, new_cols, filters)` if data_format='channels_last'.\n  \
    \          `rows` and `cols` values might have changed due to padding.\n     \
    \   - if `return_sequences`: 5D tensor with shape:\n            `(samples, timesteps,\n\
    \              filters, new_rows, new_cols)` if data_format='channels_first'\n\
    \            or 5D tensor with shape:\n            `(samples, timesteps,\n   \
    \           new_rows, new_cols, filters)` if data_format='channels_last'.\n  \
    \      - else, 4D tensor with shape:\n            `(samples, filters, new_rows,\
    \ new_cols)` if data_format='channels_first'\n            or 4D tensor with shape:\n\
    \            `(samples, new_rows, new_cols, filters)` if data_format='channels_last'.\n\
    \n    # Masking\n        This layer supports masking for input data with a variable\
    \ number\n        of timesteps. To introduce masks to your data,\n        use\
    \ an [Embedding](embeddings.md) layer with the `mask_zero` parameter\n       \
    \ set to `True`.\n\n    # Note on using statefulness in RNNs\n        You can\
    \ set RNN layers to be 'stateful', which means that the states\n        computed\
    \ for the samples in one batch will be reused as initial states\n        for the\
    \ samples in the next batch. This assumes a one-to-one mapping\n        between\
    \ samples in different successive batches.\n\n        To enable statefulness:\n\
    \            - specify `stateful=True` in the layer constructor.\n           \
    \ - specify a fixed batch size for your model, by passing\n                 -\
    \ if sequential model:\n                    `batch_input_shape=(...)` to the first\
    \ layer in your model.\n                 - if functional model with 1 or more\
    \ Input layers:\n                    `batch_shape=(...)` to all the first layers\
    \ in your model.\n                    This is the expected shape of your inputs\n\
    \                    *including the batch size*.\n                    It should\
    \ be a tuple of integers, e.g. `(32, 10, 100, 100, 32)`.\n                   \
    \ Note that the number of rows and columns should be specified too.\n        \
    \    - specify `shuffle=False` when calling fit().\n\n        To reset the states\
    \ of your model, call `.reset_states()` on either\n        a specific layer, or\
    \ on your entire model.\n\n    # Note on specifying the initial state of RNNs\n\
    \        You can specify the initial state of RNN layers symbolically by\n   \
    \     calling them with the keyword argument `initial_state`. The value of\n \
    \       `initial_state` should be a tensor or list of tensors representing\n \
    \       the initial state of the RNN layer.\n\n        You can specify the initial\
    \ state of RNN layers numerically by\n        calling `reset_states` with the\
    \ keyword argument `states`. The value of\n        `states` should be a numpy\
    \ array or list of numpy arrays representing\n        the initial state of the\
    \ RNN layer.\n\n    # Note on passing external constants to RNNs\n        You\
    \ can pass \"external\" constants to the cell using the `constants`\n        keyword\
    \ argument of `RNN.__call__` (as well as `RNN.call`) method. This\n        requires\
    \ that the `cell.call` method accepts the same keyword argument\n        `constants`.\
    \ Such constants can be used to condition the cell\n        transformation on\
    \ additional static inputs (not changing over time),\n        a.k.a. an attention\
    \ mechanism.\n    \"\"\"\n\n    def __init__(self, cell,\n                 return_sequences=False,\n\
    \                 return_state=False,\n                 go_backwards=False,\n\
    \                 stateful=False,\n                 unroll=False,\n          \
    \       **kwargs):\n        if unroll:\n            raise TypeError('Unrolling\
    \ isn\\'t possible with '\n                            'convolutional RNNs.')\n\
    \        if isinstance(cell, (list, tuple)):\n            # The StackedConvRNN2DCells\
    \ isn't implemented yet.\n            raise TypeError('It is not possible at the\
    \ moment to'\n                            'stack convolutional cells.')\n    \
    \    super(ConvRNN2D, self).__init__(cell,\n                                 \
    \       return_sequences,\n                                        return_state,\n\
    \                                        go_backwards,\n                     \
    \                   stateful,\n                                        unroll,\n\
    \                                        **kwargs)\n        self.input_spec =\
    \ [InputSpec(ndim=5)]\n\n    def compute_output_shape(self, input_shape):\n  \
    \      if isinstance(input_shape, list):\n            input_shape = input_shape[0]\n\
    \n        cell = self.cell\n        if cell.data_format == 'channels_first':\n\
    \            rows = input_shape[3]\n            cols = input_shape[4]\n      \
    \  elif cell.data_format == 'channels_last':\n            rows = input_shape[2]\n\
    \            cols = input_shape[3]\n        rows = conv_utils.conv_output_length(rows,\n\
    \                                             cell.kernel_size[0],\n         \
    \                                    padding=cell.padding,\n                 \
    \                            stride=cell.strides[0],\n                       \
    \                      dilation=cell.dilation_rate[0])\n        cols = conv_utils.conv_output_length(cols,\n\
    \                                             cell.kernel_size[1],\n         \
    \                                    padding=cell.padding,\n                 \
    \                            stride=cell.strides[1],\n                       \
    \                      dilation=cell.dilation_rate[1])\n\n        output_shape\
    \ = input_shape[:2] + (rows, cols, cell.filters)\n        output_shape = transpose_shape(output_shape,\
    \ cell.data_format,\n                                       spatial_axes=(2, 3))\n\
    \n        if not self.return_sequences:\n            output_shape = output_shape[:1]\
    \ + output_shape[2:]\n\n        if self.return_state:\n            output_shape\
    \ = [output_shape]\n            base = (input_shape[0], rows, cols, cell.filters)\n\
    \            base = transpose_shape(base, cell.data_format, spatial_axes=(1, 2))\n\
    \            output_shape += [base[:] for _ in range(2)]\n        return output_shape\n\
    \n    def build(self, input_shape):\n        # Note input_shape will be list of\
    \ shapes of initial states and\n        # constants if these are passed in __call__.\n\
    \        if self._num_constants is not None:\n            constants_shape = input_shape[-self._num_constants:]\n\
    \        else:\n            constants_shape = None\n\n        if isinstance(input_shape,\
    \ list):\n            input_shape = input_shape[0]\n\n        batch_size = input_shape[0]\
    \ if self.stateful else None\n        self.input_spec[0] = InputSpec(shape=(batch_size,\
    \ None) + input_shape[2:5])\n\n        # allow cell (if layer) to build before\
    \ we set or validate state_spec\n        if isinstance(self.cell, Layer):\n  \
    \          step_input_shape = (input_shape[0],) + input_shape[2:]\n          \
    \  if constants_shape is not None:\n                self.cell.build([step_input_shape]\
    \ + constants_shape)\n            else:\n                self.cell.build(step_input_shape)\n\
    \n        # set or validate state_spec\n        if hasattr(self.cell.state_size,\
    \ '__len__'):\n            state_size = list(self.cell.state_size)\n        else:\n\
    \            state_size = [self.cell.state_size]\n\n        if self.state_spec\
    \ is not None:\n            # initial_state was passed in call, check compatibility\n\
    \            if self.cell.data_format == 'channels_first':\n                ch_dim\
    \ = 1\n            elif self.cell.data_format == 'channels_last':\n          \
    \      ch_dim = 3\n            if not [spec.shape[ch_dim] for spec in self.state_spec]\
    \ == state_size:\n                raise ValueError(\n                    'An initial_state\
    \ was passed that is not compatible with '\n                    '`cell.state_size`.\
    \ Received `state_spec`={}; '\n                    'However `cell.state_size`\
    \ is '\n                    '{}'.format([spec.shape for spec in self.state_spec],\n\
    \                                self.cell.state_size))\n        else:\n     \
    \       if self.cell.data_format == 'channels_first':\n                self.state_spec\
    \ = [InputSpec(shape=(None, dim, None, None))\n                              \
    \     for dim in state_size]\n            elif self.cell.data_format == 'channels_last':\n\
    \                self.state_spec = [InputSpec(shape=(None, None, None, dim))\n\
    \                                   for dim in state_size]\n        if self.stateful:\n\
    \            self.reset_states()\n        self.built = True\n\n    def get_initial_state(self,\
    \ inputs):\n        # (samples, timesteps, rows, cols, filters)\n        initial_state\
    \ = K.zeros_like(inputs)\n        # (samples, rows, cols, filters)\n        initial_state\
    \ = K.sum(initial_state, axis=1)\n        shape = list(self.cell.kernel_shape)\n\
    \        shape[-1] = self.cell.filters\n        initial_state = self.cell.input_conv(initial_state,\n\
    \                                             K.zeros(tuple(shape)),\n       \
    \                                      padding=self.cell.padding)\n        # Fix\
    \ for Theano because it needs\n        # K.int_shape to work in call() with initial_state.\n\
    \        keras_shape = list(K.int_shape(inputs))\n        keras_shape.pop(1)\n\
    \        if K.image_data_format() == 'channels_first':\n            indices =\
    \ 2, 3\n        else:\n            indices = 1, 2\n        for i, j in enumerate(indices):\n\
    \            keras_shape[j] = conv_utils.conv_output_length(\n               \
    \ keras_shape[j],\n                shape[i],\n                padding=self.cell.padding,\n\
    \                stride=self.cell.strides[i],\n                dilation=self.cell.dilation_rate[i])\n\
    \        initial_state._keras_shape = keras_shape\n\n        if hasattr(self.cell.state_size,\
    \ '__len__'):\n            return [initial_state for _ in self.cell.state_size]\n\
    \        else:\n            return [initial_state]\n\n    def __call__(self, inputs,\
    \ initial_state=None, constants=None, **kwargs):\n        inputs, initial_state,\
    \ constants = _standardize_args(\n            inputs, initial_state, constants,\
    \ self._num_constants)\n\n        if initial_state is None and constants is None:\n\
    \            return super(ConvRNN2D, self).__call__(inputs, **kwargs)\n\n    \
    \    # If any of `initial_state` or `constants` are specified and are Keras\n\
    \        # tensors, then add them to the inputs and temporarily modify the\n \
    \       # input_spec to include them.\n\n        additional_inputs = []\n    \
    \    additional_specs = []\n        if initial_state is not None:\n          \
    \  kwargs['initial_state'] = initial_state\n            additional_inputs += initial_state\n\
    \            self.state_spec = []\n            for state in initial_state:\n \
    \               try:\n                    shape = K.int_shape(state)\n       \
    \         # Fix for Theano\n                except TypeError:\n              \
    \      shape = tuple(None for _ in range(K.ndim(state)))\n                self.state_spec.append(InputSpec(shape=shape))\n\
    \n            additional_specs += self.state_spec\n        if constants is not\
    \ None:\n            kwargs['constants'] = constants\n            additional_inputs\
    \ += constants\n            self.constants_spec = [InputSpec(shape=K.int_shape(constant))\n\
    \                                   for constant in constants]\n            self._num_constants\
    \ = len(constants)\n            additional_specs += self.constants_spec\n    \
    \    # at this point additional_inputs cannot be empty\n        for tensor in\
    \ additional_inputs:\n            if K.is_keras_tensor(tensor) != K.is_keras_tensor(additional_inputs[0]):\n\
    \                raise ValueError('The initial state or constants of an RNN'\n\
    \                                 ' layer cannot be specified with a mix of'\n\
    \                                 ' Keras tensors and non-Keras tensors')\n\n\
    \        if K.is_keras_tensor(additional_inputs[0]):\n            # Compute the\
    \ full input spec, including state and constants\n            full_input = [inputs]\
    \ + additional_inputs\n            full_input_spec = self.input_spec + additional_specs\n\
    \            # Perform the call with temporarily replaced input_spec\n       \
    \     original_input_spec = self.input_spec\n            self.input_spec = full_input_spec\n\
    \            output = super(ConvRNN2D, self).__call__(full_input, **kwargs)\n\
    \            self.input_spec = original_input_spec\n            return output\n\
    \        else:\n            return super(ConvRNN2D, self).__call__(inputs, **kwargs)\n\
    \n    def call(self,\n             inputs,\n             mask=None,\n        \
    \     training=None,\n             initial_state=None,\n             constants=None):\n\
    \        # note that the .build() method of subclasses MUST define\n        #\
    \ self.input_spec and self.state_spec with complete input shapes.\n        if\
    \ isinstance(inputs, list):\n            inputs = inputs[0]\n        if initial_state\
    \ is not None:\n            pass\n        elif self.stateful:\n            initial_state\
    \ = self.states\n        else:\n            initial_state = self.get_initial_state(inputs)\n\
    \n        if isinstance(mask, list):\n            mask = mask[0]\n\n        if\
    \ len(initial_state) != len(self.states):\n            raise ValueError('Layer\
    \ has ' + str(len(self.states)) +\n                             ' states but was\
    \ passed ' +\n                             str(len(initial_state)) +\n       \
    \                      ' initial states.')\n        timesteps = K.int_shape(inputs)[1]\n\
    \n        kwargs = {}\n        if has_arg(self.cell.call, 'training'):\n     \
    \       kwargs['training'] = training\n\n        if constants:\n            if\
    \ not has_arg(self.cell.call, 'constants'):\n                raise ValueError('RNN\
    \ cell does not support constants')\n\n            def step(inputs, states):\n\
    \                constants = states[-self._num_constants:]\n                states\
    \ = states[:-self._num_constants]\n                return self.cell.call(inputs,\
    \ states, constants=constants,\n                                      **kwargs)\n\
    \        else:\n            def step(inputs, states):\n                return\
    \ self.cell.call(inputs, states, **kwargs)\n\n        last_output, outputs, states\
    \ = K.rnn(step,\n                                             inputs,\n      \
    \                                       initial_state,\n                     \
    \                        constants=constants,\n                              \
    \               go_backwards=self.go_backwards,\n                            \
    \                 mask=mask,\n                                             input_length=timesteps)\n\
    \        if self.stateful:\n            updates = []\n            for i in range(len(states)):\n\
    \                updates.append((self.states[i], states[i]))\n            self.add_update(updates,\
    \ inputs)\n\n        if self.return_sequences:\n            output = outputs\n\
    \        else:\n            output = last_output\n\n        # Properly set learning\
    \ phase\n        if getattr(last_output, '_uses_learning_phase', False):\n   \
    \         output._uses_learning_phase = True\n\n        if self.return_state:\n\
    \            states = to_list(states, allow_tuple=True)\n            return [output]\
    \ + states\n        else:\n            return output\n\n    def reset_states(self,\
    \ states=None):\n        if not self.stateful:\n            raise AttributeError('Layer\
    \ must be stateful.')\n        input_shape = self.input_spec[0].shape\n      \
    \  state_shape = self.compute_output_shape(input_shape)\n        if self.return_state:\n\
    \            state_shape = state_shape[0]\n        if self.return_sequences:\n\
    \            state_shape = state_shape[:1] + state_shape[2:]\n        if None\
    \ in state_shape:\n            raise ValueError('If a RNN is stateful, it needs\
    \ to know '\n                             'its batch size. Specify the batch size\
    \ '\n                             'of your input tensors: \\n'\n             \
    \                '- If using a Sequential model, '\n                         \
    \    'specify the batch size by passing '\n                             'a `batch_input_shape`\
    \ '\n                             'argument to your first layer.\\n'\n       \
    \                      '- If using the functional API, specify '\n           \
    \                  'the time dimension by passing a '\n                      \
    \       '`batch_shape` argument to your Input layer.\\n'\n                   \
    \          'The same thing goes for the number of rows '\n                   \
    \          'and columns.')\n\n        # helper function\n        def get_tuple_shape(nb_channels):\n\
    \            result = list(state_shape)\n            if self.cell.data_format\
    \ == 'channels_first':\n                result[1] = nb_channels\n            elif\
    \ self.cell.data_format == 'channels_last':\n                result[3] = nb_channels\n\
    \            else:\n                raise KeyError\n            return tuple(result)\n\
    \n        # initialize state if None\n        if self.states[0] is None:\n   \
    \         if hasattr(self.cell.state_size, '__len__'):\n                self.states\
    \ = [K.zeros(get_tuple_shape(dim))\n                               for dim in\
    \ self.cell.state_size]\n            else:\n                self.states = [K.zeros(get_tuple_shape(self.cell.state_size))]\n\
    \        elif states is None:\n            if hasattr(self.cell.state_size, '__len__'):\n\
    \                for state, dim in zip(self.states, self.cell.state_size):\n \
    \                   K.set_value(state, np.zeros(get_tuple_shape(dim)))\n     \
    \       else:\n                K.set_value(self.states[0],\n                 \
    \           np.zeros(get_tuple_shape(self.cell.state_size)))\n        else:\n\
    \            states = to_list(states, allow_tuple=True)\n            if len(states)\
    \ != len(self.states):\n                raise ValueError('Layer ' + self.name\
    \ + ' expects ' +\n                                 str(len(self.states)) + '\
    \ states, '\n                                 'but it received ' + str(len(states))\
    \ +\n                                 ' state values. Input received: ' +\n  \
    \                               str(states))\n            for index, (value, state)\
    \ in enumerate(zip(states, self.states)):\n                if hasattr(self.cell.state_size,\
    \ '__len__'):\n                    dim = self.cell.state_size[index]\n       \
    \         else:\n                    dim = self.cell.state_size\n            \
    \    if value.shape != get_tuple_shape(dim):\n                    raise ValueError('State\
    \ ' + str(index) +\n                                     ' is incompatible with\
    \ layer ' +\n                                     self.name + ': expected shape='\
    \ +\n                                     str(get_tuple_shape(dim)) +\n      \
    \                               ', found shape=' + str(value.shape))\n       \
    \         # TODO: consider batch calls to `set_value`.\n                K.set_value(state,\
    \ value)\n"
  sourcefile: D:\Python36\lib\site-packages\keras\layers\convolutional_recurrent.py
- doc: "Abstract base class for convolutional recurrent layers.\n\nDo not use in a\
    \ model -- it's not a functional layer!\n\n# Arguments\n    filters: Integer,\
    \ the dimensionality of the output space\n        (i.e. the number output of filters\
    \ in the convolution).\n    kernel_size: An integer or tuple/list of n integers,\
    \ specifying the\n        dimensions of the convolution window.\n    strides:\
    \ An integer or tuple/list of n integers,\n        specifying the strides of the\
    \ convolution.\n        Specifying any stride value != 1 is incompatible with\
    \ specifying\n        any `dilation_rate` value != 1.\n    padding: One of `\"\
    valid\"` or `\"same\"` (case-insensitive).\n    data_format: A string,\n     \
    \   one of `channels_last` (default) or `channels_first`.\n        The ordering\
    \ of the dimensions in the inputs.\n        `channels_last` corresponds to inputs\
    \ with shape\n        `(batch, time, ..., channels)`\n        while `channels_first`\
    \ corresponds to\n        inputs with shape `(batch, time, channels, ...)`.\n\
    \        It defaults to the `image_data_format` value found in your\n        Keras\
    \ config file at `~/.keras/keras.json`.\n        If you never set it, then it\
    \ will be \"channels_last\".\n    dilation_rate: An integer or tuple/list of n\
    \ integers, specifying\n        the dilation rate to use for dilated convolution.\n\
    \        Currently, specifying any `dilation_rate` value != 1 is\n        incompatible\
    \ with specifying any `strides` value != 1.\n    return_sequences: Boolean. Whether\
    \ to return the last output\n        in the output sequence, or the full sequence.\n\
    \    go_backwards: Boolean (default False).\n        If True, process the input\
    \ sequence backwards.\n    stateful: Boolean (default False). If True, the last\
    \ state\n        for each sample at index i in a batch will be used as initial\n\
    \        state for the sample of index i in the following batch.\n\n# Input shape\n\
    \    5D tensor with shape `(num_samples, timesteps, channels, rows, cols)`.\n\n\
    # Output shape\n    - if `return_sequences`: 5D tensor with shape\n        `(num_samples,\
    \ timesteps, channels, rows, cols)`.\n    - else, 4D tensor with shape `(num_samples,\
    \ channels, rows, cols)`.\n\n# Masking\n    This layer supports masking for input\
    \ data with a variable number\n    of timesteps. To introduce masks to your data,\n\
    \    use an [Embedding](embeddings.md) layer with the `mask_zero` parameter\n\
    \    set to `True`.\n    **Note:** for the time being, masking is only supported\
    \ with Theano.\n\n# Note on using statefulness in RNNs\n    You can set RNN layers\
    \ to be 'stateful', which means that the states\n    computed for the samples\
    \ in one batch will be reused as initial states\n    for the samples in the next\
    \ batch.\n    This assumes a one-to-one mapping between\n    samples in different\
    \ successive batches.\n\n    To enable statefulness:\n        - specify `stateful=True`\
    \ in the layer constructor.\n        - specify a fixed batch size for your model,\
    \ by passing\n            a `batch_input_size=(...)` to the first layer in your\
    \ model.\n            This is the expected shape of your inputs *including the\
    \ batch\n            size*.\n            It should be a tuple of integers, e.g.\
    \ `(32, 10, 100)`.\n\n    To reset the states of your model, call `.reset_states()`\
    \ on either\n    a specific layer, or on your entire model."
  kind: Layer
  name: ConvRecurrent2D
  parameters:
  - {kind: any, name: filters}
  - {kind: any, name: kernel_size}
  - {defaultValue: '(1, 1)', kind: any, name: strides}
  - {defaultValue: valid, kind: any, name: padding}
  - {defaultValue: None, kind: any, name: data_format}
  - {defaultValue: '(1, 1)', kind: any, name: dilation_rate}
  - {defaultValue: 'False', kind: any, name: return_sequences}
  - {defaultValue: 'False', kind: any, name: go_backwards}
  - {defaultValue: 'False', kind: any, name: stateful}
  - {defaultValue: 'true', name: trainable, type: bool}
  source: "class ConvRecurrent2D(Recurrent):\n    \"\"\"Abstract base class for convolutional\
    \ recurrent layers.\n\n    Do not use in a model -- it's not a functional layer!\n\
    \n    # Arguments\n        filters: Integer, the dimensionality of the output\
    \ space\n            (i.e. the number output of filters in the convolution).\n\
    \        kernel_size: An integer or tuple/list of n integers, specifying the\n\
    \            dimensions of the convolution window.\n        strides: An integer\
    \ or tuple/list of n integers,\n            specifying the strides of the convolution.\n\
    \            Specifying any stride value != 1 is incompatible with specifying\n\
    \            any `dilation_rate` value != 1.\n        padding: One of `\"valid\"\
    ` or `\"same\"` (case-insensitive).\n        data_format: A string,\n        \
    \    one of `channels_last` (default) or `channels_first`.\n            The ordering\
    \ of the dimensions in the inputs.\n            `channels_last` corresponds to\
    \ inputs with shape\n            `(batch, time, ..., channels)`\n            while\
    \ `channels_first` corresponds to\n            inputs with shape `(batch, time,\
    \ channels, ...)`.\n            It defaults to the `image_data_format` value found\
    \ in your\n            Keras config file at `~/.keras/keras.json`.\n         \
    \   If you never set it, then it will be \"channels_last\".\n        dilation_rate:\
    \ An integer or tuple/list of n integers, specifying\n            the dilation\
    \ rate to use for dilated convolution.\n            Currently, specifying any\
    \ `dilation_rate` value != 1 is\n            incompatible with specifying any\
    \ `strides` value != 1.\n        return_sequences: Boolean. Whether to return\
    \ the last output\n            in the output sequence, or the full sequence.\n\
    \        go_backwards: Boolean (default False).\n            If True, process\
    \ the input sequence backwards.\n        stateful: Boolean (default False). If\
    \ True, the last state\n            for each sample at index i in a batch will\
    \ be used as initial\n            state for the sample of index i in the following\
    \ batch.\n\n    # Input shape\n        5D tensor with shape `(num_samples, timesteps,\
    \ channels, rows, cols)`.\n\n    # Output shape\n        - if `return_sequences`:\
    \ 5D tensor with shape\n            `(num_samples, timesteps, channels, rows,\
    \ cols)`.\n        - else, 4D tensor with shape `(num_samples, channels, rows,\
    \ cols)`.\n\n    # Masking\n        This layer supports masking for input data\
    \ with a variable number\n        of timesteps. To introduce masks to your data,\n\
    \        use an [Embedding](embeddings.md) layer with the `mask_zero` parameter\n\
    \        set to `True`.\n        **Note:** for the time being, masking is only\
    \ supported with Theano.\n\n    # Note on using statefulness in RNNs\n       \
    \ You can set RNN layers to be 'stateful', which means that the states\n     \
    \   computed for the samples in one batch will be reused as initial states\n \
    \       for the samples in the next batch.\n        This assumes a one-to-one\
    \ mapping between\n        samples in different successive batches.\n\n      \
    \  To enable statefulness:\n            - specify `stateful=True` in the layer\
    \ constructor.\n            - specify a fixed batch size for your model, by passing\n\
    \                a `batch_input_size=(...)` to the first layer in your model.\n\
    \                This is the expected shape of your inputs *including the batch\n\
    \                size*.\n                It should be a tuple of integers, e.g.\
    \ `(32, 10, 100)`.\n\n        To reset the states of your model, call `.reset_states()`\
    \ on either\n        a specific layer, or on your entire model.\n    \"\"\"\n\n\
    \    def __init__(self, filters,\n                 kernel_size,\n            \
    \     strides=(1, 1),\n                 padding='valid',\n                 data_format=None,\n\
    \                 dilation_rate=(1, 1),\n                 return_sequences=False,\n\
    \                 go_backwards=False,\n                 stateful=False,\n    \
    \             **kwargs):\n        super(ConvRecurrent2D, self).__init__(**kwargs)\n\
    \        self.filters = filters\n        self.kernel_size = conv_utils.normalize_tuple(kernel_size,\
    \ 2, 'kernel_size')\n        self.strides = conv_utils.normalize_tuple(strides,\
    \ 2, 'strides')\n        self.padding = conv_utils.normalize_padding(padding)\n\
    \        self.data_format = K.normalize_data_format(data_format)\n        self.dilation_rate\
    \ = conv_utils.normalize_tuple(dilation_rate, 2,\n                           \
    \                             'dilation_rate')\n        self.return_sequences\
    \ = return_sequences\n        self.go_backwards = go_backwards\n        self.stateful\
    \ = stateful\n        self.input_spec = [InputSpec(ndim=5)]\n        self.state_spec\
    \ = None\n\n    def compute_output_shape(self, input_shape):\n        if isinstance(input_shape,\
    \ list):\n            input_shape = input_shape[0]\n        if self.data_format\
    \ == 'channels_first':\n            rows = input_shape[3]\n            cols =\
    \ input_shape[4]\n        elif self.data_format == 'channels_last':\n        \
    \    rows = input_shape[2]\n            cols = input_shape[3]\n        rows =\
    \ conv_utils.conv_output_length(rows,\n                                      \
    \       self.kernel_size[0],\n                                             padding=self.padding,\n\
    \                                             stride=self.strides[0],\n      \
    \                                       dilation=self.dilation_rate[0])\n    \
    \    cols = conv_utils.conv_output_length(cols,\n                            \
    \                 self.kernel_size[1],\n                                     \
    \        padding=self.padding,\n                                             stride=self.strides[1],\n\
    \                                             dilation=self.dilation_rate[1])\n\
    \        if self.return_sequences:\n            if self.data_format == 'channels_first':\n\
    \                output_shape = (input_shape[0], input_shape[1],\n           \
    \                     self.filters, rows, cols)\n            elif self.data_format\
    \ == 'channels_last':\n                output_shape = (input_shape[0], input_shape[1],\n\
    \                                rows, cols, self.filters)\n        else:\n  \
    \          if self.data_format == 'channels_first':\n                output_shape\
    \ = (input_shape[0], self.filters, rows, cols)\n            elif self.data_format\
    \ == 'channels_last':\n                output_shape = (input_shape[0], rows, cols,\
    \ self.filters)\n\n        if self.return_state:\n            if self.data_format\
    \ == 'channels_first':\n                state_shape = (input_shape[0], self.filters,\
    \ rows, cols)\n            elif self.data_format == 'channels_last':\n       \
    \         state_shape = (input_shape[0], rows, cols, self.filters)\n         \
    \   output_shape = [output_shape, state_shape, state_shape]\n\n        return\
    \ output_shape\n\n    def get_config(self):\n        config = {'filters': self.filters,\n\
    \                  'kernel_size': self.kernel_size,\n                  'strides':\
    \ self.strides,\n                  'padding': self.padding,\n                \
    \  'data_format': self.data_format,\n                  'dilation_rate': self.dilation_rate,\n\
    \                  'return_sequences': self.return_sequences,\n              \
    \    'go_backwards': self.go_backwards,\n                  'stateful': self.stateful}\n\
    \        base_config = super(ConvRecurrent2D, self).get_config()\n        return\
    \ dict(list(base_config.items()) + list(config.items()))\n"
  sourcefile: D:\Python36\lib\site-packages\keras\legacy\layers.py
- doc: "1D convolution layer (e.g. temporal convolution).\n\nThis layer creates a\
    \ convolution kernel that is convolved\nwith the layer input over a single spatial\
    \ (or temporal) dimension\nto produce a tensor of outputs.\nIf `use_bias` is True,\
    \ a bias vector is created and added to the outputs.\nFinally, if `activation`\
    \ is not `None`,\nit is applied to the outputs as well.\n\nWhen using this layer\
    \ as the first layer in a model,\nprovide an `input_shape` argument\n(tuple of\
    \ integers or `None`, e.g.\n`(10, 128)` for sequences of 10 vectors of 128-dimensional\
    \ vectors,\nor `(None, 128)` for variable-length sequences of 128-dimensional\
    \ vectors.\n\n# Arguments\n    filters: Integer, the dimensionality of the output\
    \ space\n        (i.e. the number of output filters in the convolution).\n   \
    \ kernel_size: An integer or tuple/list of a single integer,\n        specifying\
    \ the length of the 1D convolution window.\n    strides: An integer or tuple/list\
    \ of a single integer,\n        specifying the stride length of the convolution.\n\
    \        Specifying any stride value != 1 is incompatible with specifying\n  \
    \      any `dilation_rate` value != 1.\n    padding: One of `\"valid\"`, `\"causal\"\
    ` or `\"same\"` (case-insensitive).\n        `\"valid\"` means \"no padding\"\
    .\n        `\"same\"` results in padding the input such that\n        the output\
    \ has the same length as the original input.\n        `\"causal\"` results in\
    \ causal (dilated) convolutions,\n        e.g. `output[t]` does not depend on\
    \ `input[t + 1:]`.\n        A zero padding is used such that\n        the output\
    \ has the same length as the original input.\n        Useful when modeling temporal\
    \ data where the model\n        should not violate the temporal order. See\n \
    \       [WaveNet: A Generative Model for Raw Audio, section 2.1]\n        (https://arxiv.org/abs/1609.03499).\n\
    \    data_format: A string,\n        one of `\"channels_last\"` (default) or `\"\
    channels_first\"`.\n        The ordering of the dimensions in the inputs.\n  \
    \      `\"channels_last\"` corresponds to inputs with shape\n        `(batch,\
    \ steps, channels)`\n        (default format for temporal data in Keras)\n   \
    \     while `\"channels_first\"` corresponds to inputs\n        with shape `(batch,\
    \ channels, steps)`.\n    dilation_rate: an integer or tuple/list of a single\
    \ integer, specifying\n        the dilation rate to use for dilated convolution.\n\
    \        Currently, specifying any `dilation_rate` value != 1 is\n        incompatible\
    \ with specifying any `strides` value != 1.\n    activation: Activation function\
    \ to use\n        (see [activations](../activations.md)).\n        If you don't\
    \ specify anything, no activation is applied\n        (ie. \"linear\" activation:\
    \ `a(x) = x`).\n    use_bias: Boolean, whether the layer uses a bias vector.\n\
    \    kernel_initializer: Initializer for the `kernel` weights matrix\n       \
    \ (see [initializers](../initializers.md)).\n    bias_initializer: Initializer\
    \ for the bias vector\n        (see [initializers](../initializers.md)).\n   \
    \ kernel_regularizer: Regularizer function applied to\n        the `kernel` weights\
    \ matrix\n        (see [regularizer](../regularizers.md)).\n    bias_regularizer:\
    \ Regularizer function applied to the bias vector\n        (see [regularizer](../regularizers.md)).\n\
    \    activity_regularizer: Regularizer function applied to\n        the output\
    \ of the layer (its \"activation\").\n        (see [regularizer](../regularizers.md)).\n\
    \    kernel_constraint: Constraint function applied to the kernel matrix\n   \
    \     (see [constraints](../constraints.md)).\n    bias_constraint: Constraint\
    \ function applied to the bias vector\n        (see [constraints](../constraints.md)).\n\
    \n# Input shape\n    3D tensor with shape: `(batch, steps, channels)`\n\n# Output\
    \ shape\n    3D tensor with shape: `(batch, new_steps, filters)`\n    `steps`\
    \ value might have changed due to padding or strides."
  kind: Layer
  name: Conv1D
  parameters:
  - {kind: any, name: filters}
  - {kind: any, name: kernel_size}
  - {defaultValue: '1', kind: any, name: strides}
  - {defaultValue: valid, kind: any, name: padding}
  - {defaultValue: channels_last, kind: any, name: data_format}
  - {defaultValue: '1', kind: any, name: dilation_rate}
  - {defaultValue: None, kind: any, name: activation}
  - {defaultValue: 'True', kind: any, name: use_bias}
  - {defaultValue: glorot_uniform, kind: any, name: kernel_initializer}
  - {defaultValue: zeros, kind: any, name: bias_initializer}
  - {defaultValue: None, kind: any, name: kernel_regularizer}
  - {defaultValue: None, kind: any, name: bias_regularizer}
  - {defaultValue: None, kind: any, name: activity_regularizer}
  - {defaultValue: None, kind: any, name: kernel_constraint}
  - {defaultValue: None, kind: any, name: bias_constraint}
  - {defaultValue: 'true', name: trainable, type: bool}
  source: "class Conv1D(_Conv):\n    \"\"\"1D convolution layer (e.g. temporal convolution).\n\
    \n    This layer creates a convolution kernel that is convolved\n    with the\
    \ layer input over a single spatial (or temporal) dimension\n    to produce a\
    \ tensor of outputs.\n    If `use_bias` is True, a bias vector is created and\
    \ added to the outputs.\n    Finally, if `activation` is not `None`,\n    it is\
    \ applied to the outputs as well.\n\n    When using this layer as the first layer\
    \ in a model,\n    provide an `input_shape` argument\n    (tuple of integers or\
    \ `None`, e.g.\n    `(10, 128)` for sequences of 10 vectors of 128-dimensional\
    \ vectors,\n    or `(None, 128)` for variable-length sequences of 128-dimensional\
    \ vectors.\n\n    # Arguments\n        filters: Integer, the dimensionality of\
    \ the output space\n            (i.e. the number of output filters in the convolution).\n\
    \        kernel_size: An integer or tuple/list of a single integer,\n        \
    \    specifying the length of the 1D convolution window.\n        strides: An\
    \ integer or tuple/list of a single integer,\n            specifying the stride\
    \ length of the convolution.\n            Specifying any stride value != 1 is\
    \ incompatible with specifying\n            any `dilation_rate` value != 1.\n\
    \        padding: One of `\"valid\"`, `\"causal\"` or `\"same\"` (case-insensitive).\n\
    \            `\"valid\"` means \"no padding\".\n            `\"same\"` results\
    \ in padding the input such that\n            the output has the same length as\
    \ the original input.\n            `\"causal\"` results in causal (dilated) convolutions,\n\
    \            e.g. `output[t]` does not depend on `input[t + 1:]`.\n          \
    \  A zero padding is used such that\n            the output has the same length\
    \ as the original input.\n            Useful when modeling temporal data where\
    \ the model\n            should not violate the temporal order. See\n        \
    \    [WaveNet: A Generative Model for Raw Audio, section 2.1]\n            (https://arxiv.org/abs/1609.03499).\n\
    \        data_format: A string,\n            one of `\"channels_last\"` (default)\
    \ or `\"channels_first\"`.\n            The ordering of the dimensions in the\
    \ inputs.\n            `\"channels_last\"` corresponds to inputs with shape\n\
    \            `(batch, steps, channels)`\n            (default format for temporal\
    \ data in Keras)\n            while `\"channels_first\"` corresponds to inputs\n\
    \            with shape `(batch, channels, steps)`.\n        dilation_rate: an\
    \ integer or tuple/list of a single integer, specifying\n            the dilation\
    \ rate to use for dilated convolution.\n            Currently, specifying any\
    \ `dilation_rate` value != 1 is\n            incompatible with specifying any\
    \ `strides` value != 1.\n        activation: Activation function to use\n    \
    \        (see [activations](../activations.md)).\n            If you don't specify\
    \ anything, no activation is applied\n            (ie. \"linear\" activation:\
    \ `a(x) = x`).\n        use_bias: Boolean, whether the layer uses a bias vector.\n\
    \        kernel_initializer: Initializer for the `kernel` weights matrix\n   \
    \         (see [initializers](../initializers.md)).\n        bias_initializer:\
    \ Initializer for the bias vector\n            (see [initializers](../initializers.md)).\n\
    \        kernel_regularizer: Regularizer function applied to\n            the\
    \ `kernel` weights matrix\n            (see [regularizer](../regularizers.md)).\n\
    \        bias_regularizer: Regularizer function applied to the bias vector\n \
    \           (see [regularizer](../regularizers.md)).\n        activity_regularizer:\
    \ Regularizer function applied to\n            the output of the layer (its \"\
    activation\").\n            (see [regularizer](../regularizers.md)).\n       \
    \ kernel_constraint: Constraint function applied to the kernel matrix\n      \
    \      (see [constraints](../constraints.md)).\n        bias_constraint: Constraint\
    \ function applied to the bias vector\n            (see [constraints](../constraints.md)).\n\
    \n    # Input shape\n        3D tensor with shape: `(batch, steps, channels)`\n\
    \n    # Output shape\n        3D tensor with shape: `(batch, new_steps, filters)`\n\
    \        `steps` value might have changed due to padding or strides.\n    \"\"\
    \"\n\n    @interfaces.legacy_conv1d_support\n    def __init__(self, filters,\n\
    \                 kernel_size,\n                 strides=1,\n                \
    \ padding='valid',\n                 data_format='channels_last',\n          \
    \       dilation_rate=1,\n                 activation=None,\n                \
    \ use_bias=True,\n                 kernel_initializer='glorot_uniform',\n    \
    \             bias_initializer='zeros',\n                 kernel_regularizer=None,\n\
    \                 bias_regularizer=None,\n                 activity_regularizer=None,\n\
    \                 kernel_constraint=None,\n                 bias_constraint=None,\n\
    \                 **kwargs):\n        if padding == 'causal':\n            if\
    \ data_format != 'channels_last':\n                raise ValueError('When using\
    \ causal padding in `Conv1D`, '\n                                 '`data_format`\
    \ must be \"channels_last\" '\n                                 '(temporal data).')\n\
    \        super(Conv1D, self).__init__(\n            rank=1,\n            filters=filters,\n\
    \            kernel_size=kernel_size,\n            strides=strides,\n        \
    \    padding=padding,\n            data_format=data_format,\n            dilation_rate=dilation_rate,\n\
    \            activation=activation,\n            use_bias=use_bias,\n        \
    \    kernel_initializer=kernel_initializer,\n            bias_initializer=bias_initializer,\n\
    \            kernel_regularizer=kernel_regularizer,\n            bias_regularizer=bias_regularizer,\n\
    \            activity_regularizer=activity_regularizer,\n            kernel_constraint=kernel_constraint,\n\
    \            bias_constraint=bias_constraint,\n            **kwargs)\n\n    def\
    \ get_config(self):\n        config = super(Conv1D, self).get_config()\n     \
    \   config.pop('rank')\n        return config\n"
  sourcefile: D:\Python36\lib\site-packages\keras\layers\convolutional.py
- doc: "2D convolution layer (e.g. spatial convolution over images).\n\nThis layer\
    \ creates a convolution kernel that is convolved\nwith the layer input to produce\
    \ a tensor of\noutputs. If `use_bias` is True,\na bias vector is created and added\
    \ to the outputs. Finally, if\n`activation` is not `None`, it is applied to the\
    \ outputs as well.\n\nWhen using this layer as the first layer in a model,\nprovide\
    \ the keyword argument `input_shape`\n(tuple of integers, does not include the\
    \ sample axis),\ne.g. `input_shape=(128, 128, 3)` for 128x128 RGB pictures\nin\
    \ `data_format=\"channels_last\"`.\n\n# Arguments\n    filters: Integer, the dimensionality\
    \ of the output space\n        (i.e. the number of output filters in the convolution).\n\
    \    kernel_size: An integer or tuple/list of 2 integers, specifying the\n   \
    \     height and width of the 2D convolution window.\n        Can be a single\
    \ integer to specify the same value for\n        all spatial dimensions.\n   \
    \ strides: An integer or tuple/list of 2 integers,\n        specifying the strides\
    \ of the convolution\n        along the height and width.\n        Can be a single\
    \ integer to specify the same value for\n        all spatial dimensions.\n   \
    \     Specifying any stride value != 1 is incompatible with specifying\n     \
    \   any `dilation_rate` value != 1.\n    padding: one of `\"valid\"` or `\"same\"\
    ` (case-insensitive).\n        Note that `\"same\"` is slightly inconsistent across\
    \ backends with\n        `strides` != 1, as described\n        [here](https://github.com/keras-team/keras/pull/9473#issuecomment-372166860)\n\
    \    data_format: A string,\n        one of `\"channels_last\"` or `\"channels_first\"\
    `.\n        The ordering of the dimensions in the inputs.\n        `\"channels_last\"\
    ` corresponds to inputs with shape\n        `(batch, height, width, channels)`\
    \ while `\"channels_first\"`\n        corresponds to inputs with shape\n     \
    \   `(batch, channels, height, width)`.\n        It defaults to the `image_data_format`\
    \ value found in your\n        Keras config file at `~/.keras/keras.json`.\n \
    \       If you never set it, then it will be \"channels_last\".\n    dilation_rate:\
    \ an integer or tuple/list of 2 integers, specifying\n        the dilation rate\
    \ to use for dilated convolution.\n        Can be a single integer to specify\
    \ the same value for\n        all spatial dimensions.\n        Currently, specifying\
    \ any `dilation_rate` value != 1 is\n        incompatible with specifying any\
    \ stride value != 1.\n    activation: Activation function to use\n        (see\
    \ [activations](../activations.md)).\n        If you don't specify anything, no\
    \ activation is applied\n        (ie. \"linear\" activation: `a(x) = x`).\n  \
    \  use_bias: Boolean, whether the layer uses a bias vector.\n    kernel_initializer:\
    \ Initializer for the `kernel` weights matrix\n        (see [initializers](../initializers.md)).\n\
    \    bias_initializer: Initializer for the bias vector\n        (see [initializers](../initializers.md)).\n\
    \    kernel_regularizer: Regularizer function applied to\n        the `kernel`\
    \ weights matrix\n        (see [regularizer](../regularizers.md)).\n    bias_regularizer:\
    \ Regularizer function applied to the bias vector\n        (see [regularizer](../regularizers.md)).\n\
    \    activity_regularizer: Regularizer function applied to\n        the output\
    \ of the layer (its \"activation\").\n        (see [regularizer](../regularizers.md)).\n\
    \    kernel_constraint: Constraint function applied to the kernel matrix\n   \
    \     (see [constraints](../constraints.md)).\n    bias_constraint: Constraint\
    \ function applied to the bias vector\n        (see [constraints](../constraints.md)).\n\
    \n# Input shape\n    4D tensor with shape:\n    `(batch, channels, rows, cols)`\n\
    \    if `data_format` is `\"channels_first\"`\n    or 4D tensor with shape:\n\
    \    `(batch, rows, cols, channels)`\n    if `data_format` is `\"channels_last\"\
    `.\n\n# Output shape\n    4D tensor with shape:\n    `(batch, filters, new_rows,\
    \ new_cols)`\n    if `data_format` is `\"channels_first\"`\n    or 4D tensor with\
    \ shape:\n    `(batch, new_rows, new_cols, filters)`\n    if `data_format` is\
    \ `\"channels_last\"`.\n    `rows` and `cols` values might have changed due to\
    \ padding."
  kind: Layer
  name: Conv2D
  parameters:
  - {kind: any, name: filters}
  - {kind: any, name: kernel_size}
  - {defaultValue: '(1, 1)', kind: any, name: strides}
  - {defaultValue: valid, kind: any, name: padding}
  - {defaultValue: None, kind: any, name: data_format}
  - {defaultValue: '(1, 1)', kind: any, name: dilation_rate}
  - {defaultValue: None, kind: any, name: activation}
  - {defaultValue: 'True', kind: any, name: use_bias}
  - {defaultValue: glorot_uniform, kind: any, name: kernel_initializer}
  - {defaultValue: zeros, kind: any, name: bias_initializer}
  - {defaultValue: None, kind: any, name: kernel_regularizer}
  - {defaultValue: None, kind: any, name: bias_regularizer}
  - {defaultValue: None, kind: any, name: activity_regularizer}
  - {defaultValue: None, kind: any, name: kernel_constraint}
  - {defaultValue: None, kind: any, name: bias_constraint}
  - {defaultValue: 'true', name: trainable, type: bool}
  source: "class Conv2D(_Conv):\n    \"\"\"2D convolution layer (e.g. spatial convolution\
    \ over images).\n\n    This layer creates a convolution kernel that is convolved\n\
    \    with the layer input to produce a tensor of\n    outputs. If `use_bias` is\
    \ True,\n    a bias vector is created and added to the outputs. Finally, if\n\
    \    `activation` is not `None`, it is applied to the outputs as well.\n\n   \
    \ When using this layer as the first layer in a model,\n    provide the keyword\
    \ argument `input_shape`\n    (tuple of integers, does not include the sample\
    \ axis),\n    e.g. `input_shape=(128, 128, 3)` for 128x128 RGB pictures\n    in\
    \ `data_format=\"channels_last\"`.\n\n    # Arguments\n        filters: Integer,\
    \ the dimensionality of the output space\n            (i.e. the number of output\
    \ filters in the convolution).\n        kernel_size: An integer or tuple/list\
    \ of 2 integers, specifying the\n            height and width of the 2D convolution\
    \ window.\n            Can be a single integer to specify the same value for\n\
    \            all spatial dimensions.\n        strides: An integer or tuple/list\
    \ of 2 integers,\n            specifying the strides of the convolution\n    \
    \        along the height and width.\n            Can be a single integer to specify\
    \ the same value for\n            all spatial dimensions.\n            Specifying\
    \ any stride value != 1 is incompatible with specifying\n            any `dilation_rate`\
    \ value != 1.\n        padding: one of `\"valid\"` or `\"same\"` (case-insensitive).\n\
    \            Note that `\"same\"` is slightly inconsistent across backends with\n\
    \            `strides` != 1, as described\n            [here](https://github.com/keras-team/keras/pull/9473#issuecomment-372166860)\n\
    \        data_format: A string,\n            one of `\"channels_last\"` or `\"\
    channels_first\"`.\n            The ordering of the dimensions in the inputs.\n\
    \            `\"channels_last\"` corresponds to inputs with shape\n          \
    \  `(batch, height, width, channels)` while `\"channels_first\"`\n           \
    \ corresponds to inputs with shape\n            `(batch, channels, height, width)`.\n\
    \            It defaults to the `image_data_format` value found in your\n    \
    \        Keras config file at `~/.keras/keras.json`.\n            If you never\
    \ set it, then it will be \"channels_last\".\n        dilation_rate: an integer\
    \ or tuple/list of 2 integers, specifying\n            the dilation rate to use\
    \ for dilated convolution.\n            Can be a single integer to specify the\
    \ same value for\n            all spatial dimensions.\n            Currently,\
    \ specifying any `dilation_rate` value != 1 is\n            incompatible with\
    \ specifying any stride value != 1.\n        activation: Activation function to\
    \ use\n            (see [activations](../activations.md)).\n            If you\
    \ don't specify anything, no activation is applied\n            (ie. \"linear\"\
    \ activation: `a(x) = x`).\n        use_bias: Boolean, whether the layer uses\
    \ a bias vector.\n        kernel_initializer: Initializer for the `kernel` weights\
    \ matrix\n            (see [initializers](../initializers.md)).\n        bias_initializer:\
    \ Initializer for the bias vector\n            (see [initializers](../initializers.md)).\n\
    \        kernel_regularizer: Regularizer function applied to\n            the\
    \ `kernel` weights matrix\n            (see [regularizer](../regularizers.md)).\n\
    \        bias_regularizer: Regularizer function applied to the bias vector\n \
    \           (see [regularizer](../regularizers.md)).\n        activity_regularizer:\
    \ Regularizer function applied to\n            the output of the layer (its \"\
    activation\").\n            (see [regularizer](../regularizers.md)).\n       \
    \ kernel_constraint: Constraint function applied to the kernel matrix\n      \
    \      (see [constraints](../constraints.md)).\n        bias_constraint: Constraint\
    \ function applied to the bias vector\n            (see [constraints](../constraints.md)).\n\
    \n    # Input shape\n        4D tensor with shape:\n        `(batch, channels,\
    \ rows, cols)`\n        if `data_format` is `\"channels_first\"`\n        or 4D\
    \ tensor with shape:\n        `(batch, rows, cols, channels)`\n        if `data_format`\
    \ is `\"channels_last\"`.\n\n    # Output shape\n        4D tensor with shape:\n\
    \        `(batch, filters, new_rows, new_cols)`\n        if `data_format` is `\"\
    channels_first\"`\n        or 4D tensor with shape:\n        `(batch, new_rows,\
    \ new_cols, filters)`\n        if `data_format` is `\"channels_last\"`.\n    \
    \    `rows` and `cols` values might have changed due to padding.\n    \"\"\"\n\
    \n    @interfaces.legacy_conv2d_support\n    def __init__(self, filters,\n   \
    \              kernel_size,\n                 strides=(1, 1),\n              \
    \   padding='valid',\n                 data_format=None,\n                 dilation_rate=(1,\
    \ 1),\n                 activation=None,\n                 use_bias=True,\n  \
    \               kernel_initializer='glorot_uniform',\n                 bias_initializer='zeros',\n\
    \                 kernel_regularizer=None,\n                 bias_regularizer=None,\n\
    \                 activity_regularizer=None,\n                 kernel_constraint=None,\n\
    \                 bias_constraint=None,\n                 **kwargs):\n       \
    \ super(Conv2D, self).__init__(\n            rank=2,\n            filters=filters,\n\
    \            kernel_size=kernel_size,\n            strides=strides,\n        \
    \    padding=padding,\n            data_format=data_format,\n            dilation_rate=dilation_rate,\n\
    \            activation=activation,\n            use_bias=use_bias,\n        \
    \    kernel_initializer=kernel_initializer,\n            bias_initializer=bias_initializer,\n\
    \            kernel_regularizer=kernel_regularizer,\n            bias_regularizer=bias_regularizer,\n\
    \            activity_regularizer=activity_regularizer,\n            kernel_constraint=kernel_constraint,\n\
    \            bias_constraint=bias_constraint,\n            **kwargs)\n\n    def\
    \ get_config(self):\n        config = super(Conv2D, self).get_config()\n     \
    \   config.pop('rank')\n        return config\n"
  sourcefile: D:\Python36\lib\site-packages\keras\layers\convolutional.py
- doc: "Transposed convolution layer (sometimes called Deconvolution).\n\nThe need\
    \ for transposed convolutions generally arises\nfrom the desire to use a transformation\
    \ going in the opposite direction\nof a normal convolution, i.e., from something\
    \ that has the shape of the\noutput of some convolution to something that has\
    \ the shape of its input\nwhile maintaining a connectivity pattern that is compatible\
    \ with\nsaid convolution.\n\nWhen using this layer as the first layer in a model,\n\
    provide the keyword argument `input_shape`\n(tuple of integers, does not include\
    \ the sample axis),\ne.g. `input_shape=(128, 128, 3)` for 128x128 RGB pictures\n\
    in `data_format=\"channels_last\"`.\n\n# Arguments\n    filters: Integer, the\
    \ dimensionality of the output space\n        (i.e. the number of output filters\
    \ in the convolution).\n    kernel_size: An integer or tuple/list of 2 integers,\
    \ specifying the\n        height and width of the 2D convolution window.\n   \
    \     Can be a single integer to specify the same value for\n        all spatial\
    \ dimensions.\n    strides: An integer or tuple/list of 2 integers,\n        specifying\
    \ the strides of the convolution\n        along the height and width.\n      \
    \  Can be a single integer to specify the same value for\n        all spatial\
    \ dimensions.\n        Specifying any stride value != 1 is incompatible with specifying\n\
    \        any `dilation_rate` value != 1.\n    padding: one of `\"valid\"` or `\"\
    same\"` (case-insensitive).\n    output_padding: An integer or tuple/list of 2\
    \ integers,\n        specifying the amount of padding along the height and width\n\
    \        of the output tensor.\n        Can be a single integer to specify the\
    \ same value for all\n        spatial dimensions.\n        The amount of output\
    \ padding along a given dimension must be\n        lower than the stride along\
    \ that same dimension.\n        If set to `None` (default), the output shape is\
    \ inferred.\n    data_format: A string,\n        one of `\"channels_last\"` or\
    \ `\"channels_first\"`.\n        The ordering of the dimensions in the inputs.\n\
    \        `\"channels_last\"` corresponds to inputs with shape\n        `(batch,\
    \ height, width, channels)` while `\"channels_first\"`\n        corresponds to\
    \ inputs with shape\n        `(batch, channels, height, width)`.\n        It defaults\
    \ to the `image_data_format` value found in your\n        Keras config file at\
    \ `~/.keras/keras.json`.\n        If you never set it, then it will be \"channels_last\"\
    .\n    dilation_rate: an integer or tuple/list of 2 integers, specifying\n   \
    \     the dilation rate to use for dilated convolution.\n        Can be a single\
    \ integer to specify the same value for\n        all spatial dimensions.\n   \
    \     Currently, specifying any `dilation_rate` value != 1 is\n        incompatible\
    \ with specifying any stride value != 1.\n    activation: Activation function\
    \ to use\n        (see [activations](../activations.md)).\n        If you don't\
    \ specify anything, no activation is applied\n        (ie. \"linear\" activation:\
    \ `a(x) = x`).\n    use_bias: Boolean, whether the layer uses a bias vector.\n\
    \    kernel_initializer: Initializer for the `kernel` weights matrix\n       \
    \ (see [initializers](../initializers.md)).\n    bias_initializer: Initializer\
    \ for the bias vector\n        (see [initializers](../initializers.md)).\n   \
    \ kernel_regularizer: Regularizer function applied to\n        the `kernel` weights\
    \ matrix\n        (see [regularizer](../regularizers.md)).\n    bias_regularizer:\
    \ Regularizer function applied to the bias vector\n        (see [regularizer](../regularizers.md)).\n\
    \    activity_regularizer: Regularizer function applied to\n        the output\
    \ of the layer (its \"activation\").\n        (see [regularizer](../regularizers.md)).\n\
    \    kernel_constraint: Constraint function applied to the kernel matrix\n   \
    \     (see [constraints](../constraints.md)).\n    bias_constraint: Constraint\
    \ function applied to the bias vector\n        (see [constraints](../constraints.md)).\n\
    \n# Input shape\n    4D tensor with shape:\n    `(batch, channels, rows, cols)`\n\
    \    if `data_format` is `\"channels_first\"`\n    or 4D tensor with shape:\n\
    \    `(batch, rows, cols, channels)`\n    if `data_format` is `\"channels_last\"\
    `.\n\n# Output shape\n    4D tensor with shape:\n    `(batch, filters, new_rows,\
    \ new_cols)`\n    if `data_format` is `\"channels_first\"`\n    or 4D tensor with\
    \ shape:\n    `(batch, new_rows, new_cols, filters)`\n    if `data_format` is\
    \ `\"channels_last\"`.\n    `rows` and `cols` values might have changed due to\
    \ padding.\n    If `output_padding` is specified:\n\n    ```\n    new_rows = ((rows\
    \ - 1) * strides[0] + kernel_size[0]\n                - 2 * padding[0] + output_padding[0])\n\
    \    new_cols = ((cols - 1) * strides[1] + kernel_size[1]\n                - 2\
    \ * padding[1] + output_padding[1])\n    ```\n\n# References\n    - [A guide to\
    \ convolution arithmetic for deep learning]\n      (https://arxiv.org/abs/1603.07285v1)\n\
    \    - [Deconvolutional Networks]\n      (http://www.matthewzeiler.com/pubs/cvpr2010/cvpr2010.pdf)"
  kind: Layer
  name: Conv2DTranspose
  parameters:
  - {kind: any, name: filters}
  - {kind: any, name: kernel_size}
  - {defaultValue: '(1, 1)', kind: any, name: strides}
  - {defaultValue: valid, kind: any, name: padding}
  - {defaultValue: None, kind: any, name: output_padding}
  - {defaultValue: None, kind: any, name: data_format}
  - {defaultValue: '(1, 1)', kind: any, name: dilation_rate}
  - {defaultValue: None, kind: any, name: activation}
  - {defaultValue: 'True', kind: any, name: use_bias}
  - {defaultValue: glorot_uniform, kind: any, name: kernel_initializer}
  - {defaultValue: zeros, kind: any, name: bias_initializer}
  - {defaultValue: None, kind: any, name: kernel_regularizer}
  - {defaultValue: None, kind: any, name: bias_regularizer}
  - {defaultValue: None, kind: any, name: activity_regularizer}
  - {defaultValue: None, kind: any, name: kernel_constraint}
  - {defaultValue: None, kind: any, name: bias_constraint}
  - {defaultValue: 'true', name: trainable, type: bool}
  source: "class Conv2DTranspose(Conv2D):\n    \"\"\"Transposed convolution layer\
    \ (sometimes called Deconvolution).\n\n    The need for transposed convolutions\
    \ generally arises\n    from the desire to use a transformation going in the opposite\
    \ direction\n    of a normal convolution, i.e., from something that has the shape\
    \ of the\n    output of some convolution to something that has the shape of its\
    \ input\n    while maintaining a connectivity pattern that is compatible with\n\
    \    said convolution.\n\n    When using this layer as the first layer in a model,\n\
    \    provide the keyword argument `input_shape`\n    (tuple of integers, does\
    \ not include the sample axis),\n    e.g. `input_shape=(128, 128, 3)` for 128x128\
    \ RGB pictures\n    in `data_format=\"channels_last\"`.\n\n    # Arguments\n \
    \       filters: Integer, the dimensionality of the output space\n           \
    \ (i.e. the number of output filters in the convolution).\n        kernel_size:\
    \ An integer or tuple/list of 2 integers, specifying the\n            height and\
    \ width of the 2D convolution window.\n            Can be a single integer to\
    \ specify the same value for\n            all spatial dimensions.\n        strides:\
    \ An integer or tuple/list of 2 integers,\n            specifying the strides\
    \ of the convolution\n            along the height and width.\n            Can\
    \ be a single integer to specify the same value for\n            all spatial dimensions.\n\
    \            Specifying any stride value != 1 is incompatible with specifying\n\
    \            any `dilation_rate` value != 1.\n        padding: one of `\"valid\"\
    ` or `\"same\"` (case-insensitive).\n        output_padding: An integer or tuple/list\
    \ of 2 integers,\n            specifying the amount of padding along the height\
    \ and width\n            of the output tensor.\n            Can be a single integer\
    \ to specify the same value for all\n            spatial dimensions.\n       \
    \     The amount of output padding along a given dimension must be\n         \
    \   lower than the stride along that same dimension.\n            If set to `None`\
    \ (default), the output shape is inferred.\n        data_format: A string,\n \
    \           one of `\"channels_last\"` or `\"channels_first\"`.\n            The\
    \ ordering of the dimensions in the inputs.\n            `\"channels_last\"` corresponds\
    \ to inputs with shape\n            `(batch, height, width, channels)` while `\"\
    channels_first\"`\n            corresponds to inputs with shape\n            `(batch,\
    \ channels, height, width)`.\n            It defaults to the `image_data_format`\
    \ value found in your\n            Keras config file at `~/.keras/keras.json`.\n\
    \            If you never set it, then it will be \"channels_last\".\n       \
    \ dilation_rate: an integer or tuple/list of 2 integers, specifying\n        \
    \    the dilation rate to use for dilated convolution.\n            Can be a single\
    \ integer to specify the same value for\n            all spatial dimensions.\n\
    \            Currently, specifying any `dilation_rate` value != 1 is\n       \
    \     incompatible with specifying any stride value != 1.\n        activation:\
    \ Activation function to use\n            (see [activations](../activations.md)).\n\
    \            If you don't specify anything, no activation is applied\n       \
    \     (ie. \"linear\" activation: `a(x) = x`).\n        use_bias: Boolean, whether\
    \ the layer uses a bias vector.\n        kernel_initializer: Initializer for the\
    \ `kernel` weights matrix\n            (see [initializers](../initializers.md)).\n\
    \        bias_initializer: Initializer for the bias vector\n            (see [initializers](../initializers.md)).\n\
    \        kernel_regularizer: Regularizer function applied to\n            the\
    \ `kernel` weights matrix\n            (see [regularizer](../regularizers.md)).\n\
    \        bias_regularizer: Regularizer function applied to the bias vector\n \
    \           (see [regularizer](../regularizers.md)).\n        activity_regularizer:\
    \ Regularizer function applied to\n            the output of the layer (its \"\
    activation\").\n            (see [regularizer](../regularizers.md)).\n       \
    \ kernel_constraint: Constraint function applied to the kernel matrix\n      \
    \      (see [constraints](../constraints.md)).\n        bias_constraint: Constraint\
    \ function applied to the bias vector\n            (see [constraints](../constraints.md)).\n\
    \n    # Input shape\n        4D tensor with shape:\n        `(batch, channels,\
    \ rows, cols)`\n        if `data_format` is `\"channels_first\"`\n        or 4D\
    \ tensor with shape:\n        `(batch, rows, cols, channels)`\n        if `data_format`\
    \ is `\"channels_last\"`.\n\n    # Output shape\n        4D tensor with shape:\n\
    \        `(batch, filters, new_rows, new_cols)`\n        if `data_format` is `\"\
    channels_first\"`\n        or 4D tensor with shape:\n        `(batch, new_rows,\
    \ new_cols, filters)`\n        if `data_format` is `\"channels_last\"`.\n    \
    \    `rows` and `cols` values might have changed due to padding.\n        If `output_padding`\
    \ is specified:\n\n        ```\n        new_rows = ((rows - 1) * strides[0] +\
    \ kernel_size[0]\n                    - 2 * padding[0] + output_padding[0])\n\
    \        new_cols = ((cols - 1) * strides[1] + kernel_size[1]\n              \
    \      - 2 * padding[1] + output_padding[1])\n        ```\n\n    # References\n\
    \        - [A guide to convolution arithmetic for deep learning]\n          (https://arxiv.org/abs/1603.07285v1)\n\
    \        - [Deconvolutional Networks]\n          (http://www.matthewzeiler.com/pubs/cvpr2010/cvpr2010.pdf)\n\
    \    \"\"\"\n\n    @interfaces.legacy_deconv2d_support\n    def __init__(self,\
    \ filters,\n                 kernel_size,\n                 strides=(1, 1),\n\
    \                 padding='valid',\n                 output_padding=None,\n  \
    \               data_format=None,\n                 dilation_rate=(1, 1),\n  \
    \               activation=None,\n                 use_bias=True,\n          \
    \       kernel_initializer='glorot_uniform',\n                 bias_initializer='zeros',\n\
    \                 kernel_regularizer=None,\n                 bias_regularizer=None,\n\
    \                 activity_regularizer=None,\n                 kernel_constraint=None,\n\
    \                 bias_constraint=None,\n                 **kwargs):\n       \
    \ super(Conv2DTranspose, self).__init__(\n            filters,\n            kernel_size,\n\
    \            strides=strides,\n            padding=padding,\n            data_format=data_format,\n\
    \            dilation_rate=dilation_rate,\n            activation=activation,\n\
    \            use_bias=use_bias,\n            kernel_initializer=kernel_initializer,\n\
    \            bias_initializer=bias_initializer,\n            kernel_regularizer=kernel_regularizer,\n\
    \            bias_regularizer=bias_regularizer,\n            activity_regularizer=activity_regularizer,\n\
    \            kernel_constraint=kernel_constraint,\n            bias_constraint=bias_constraint,\n\
    \            **kwargs)\n\n        self.output_padding = output_padding\n     \
    \   if self.output_padding is not None:\n            self.output_padding = conv_utils.normalize_tuple(\n\
    \                self.output_padding, 2, 'output_padding')\n            for stride,\
    \ out_pad in zip(self.strides, self.output_padding):\n                if out_pad\
    \ >= stride:\n                    raise ValueError('Stride ' + str(self.strides)\
    \ + ' must be '\n                                     'greater than output padding\
    \ ' +\n                                     str(self.output_padding))\n\n    def\
    \ build(self, input_shape):\n        if len(input_shape) != 4:\n            raise\
    \ ValueError('Inputs should have rank ' +\n                             str(4)\
    \ +\n                             '; Received input shape:', str(input_shape))\n\
    \        if self.data_format == 'channels_first':\n            channel_axis =\
    \ 1\n        else:\n            channel_axis = -1\n        if input_shape[channel_axis]\
    \ is None:\n            raise ValueError('The channel dimension of the inputs\
    \ '\n                             'should be defined. Found `None`.')\n      \
    \  input_dim = input_shape[channel_axis]\n        kernel_shape = self.kernel_size\
    \ + (self.filters, input_dim)\n\n        self.kernel = self.add_weight(shape=kernel_shape,\n\
    \                                      initializer=self.kernel_initializer,\n\
    \                                      name='kernel',\n                      \
    \                regularizer=self.kernel_regularizer,\n                      \
    \                constraint=self.kernel_constraint)\n        if self.use_bias:\n\
    \            self.bias = self.add_weight(shape=(self.filters,),\n            \
    \                            initializer=self.bias_initializer,\n            \
    \                            name='bias',\n                                  \
    \      regularizer=self.bias_regularizer,\n                                  \
    \      constraint=self.bias_constraint)\n        else:\n            self.bias\
    \ = None\n        # Set input spec.\n        self.input_spec = InputSpec(ndim=4,\
    \ axes={channel_axis: input_dim})\n        self.built = True\n\n    def call(self,\
    \ inputs):\n        input_shape = K.shape(inputs)\n        batch_size = input_shape[0]\n\
    \        if self.data_format == 'channels_first':\n            h_axis, w_axis\
    \ = 2, 3\n        else:\n            h_axis, w_axis = 1, 2\n\n        height,\
    \ width = input_shape[h_axis], input_shape[w_axis]\n        kernel_h, kernel_w\
    \ = self.kernel_size\n        stride_h, stride_w = self.strides\n        if self.output_padding\
    \ is None:\n            out_pad_h = out_pad_w = None\n        else:\n        \
    \    out_pad_h, out_pad_w = self.output_padding\n\n        # Infer the dynamic\
    \ output shape:\n        out_height = conv_utils.deconv_length(height,\n     \
    \                                         stride_h, kernel_h,\n              \
    \                                self.padding,\n                             \
    \                 out_pad_h,\n                                              self.dilation_rate[0])\n\
    \        out_width = conv_utils.deconv_length(width,\n                       \
    \                      stride_w, kernel_w,\n                                 \
    \            self.padding,\n                                             out_pad_w,\n\
    \                                             self.dilation_rate[1])\n       \
    \ if self.data_format == 'channels_first':\n            output_shape = (batch_size,\
    \ self.filters, out_height, out_width)\n        else:\n            output_shape\
    \ = (batch_size, out_height, out_width, self.filters)\n\n        outputs = K.conv2d_transpose(\n\
    \            inputs,\n            self.kernel,\n            output_shape,\n  \
    \          self.strides,\n            padding=self.padding,\n            data_format=self.data_format,\n\
    \            dilation_rate=self.dilation_rate)\n\n        if self.use_bias:\n\
    \            outputs = K.bias_add(\n                outputs,\n               \
    \ self.bias,\n                data_format=self.data_format)\n\n        if self.activation\
    \ is not None:\n            return self.activation(outputs)\n        return outputs\n\
    \n    def compute_output_shape(self, input_shape):\n        output_shape = list(input_shape)\n\
    \        if self.data_format == 'channels_first':\n            c_axis, h_axis,\
    \ w_axis = 1, 2, 3\n        else:\n            c_axis, h_axis, w_axis = 3, 1,\
    \ 2\n\n        kernel_h, kernel_w = self.kernel_size\n        stride_h, stride_w\
    \ = self.strides\n        if self.output_padding is None:\n            out_pad_h\
    \ = out_pad_w = None\n        else:\n            out_pad_h, out_pad_w = self.output_padding\n\
    \n        output_shape[c_axis] = self.filters\n        output_shape[h_axis] =\
    \ conv_utils.deconv_length(output_shape[h_axis],\n                           \
    \                             stride_h,\n                                    \
    \                    kernel_h,\n                                             \
    \           self.padding,\n                                                  \
    \      out_pad_h,\n                                                        self.dilation_rate[0])\n\
    \        output_shape[w_axis] = conv_utils.deconv_length(output_shape[w_axis],\n\
    \                                                        stride_w,\n         \
    \                                               kernel_w,\n                  \
    \                                      self.padding,\n                       \
    \                                 out_pad_w,\n                               \
    \                         self.dilation_rate[1])\n        return tuple(output_shape)\n\
    \n    def get_config(self):\n        config = super(Conv2DTranspose, self).get_config()\n\
    \        config['output_padding'] = self.output_padding\n        return config\n"
  sourcefile: D:\Python36\lib\site-packages\keras\layers\convolutional.py
- doc: "3D convolution layer (e.g. spatial convolution over volumes).\n\nThis layer\
    \ creates a convolution kernel that is convolved\nwith the layer input to produce\
    \ a tensor of\noutputs. If `use_bias` is True,\na bias vector is created and added\
    \ to the outputs. Finally, if\n`activation` is not `None`, it is applied to the\
    \ outputs as well.\n\nWhen using this layer as the first layer in a model,\nprovide\
    \ the keyword argument `input_shape`\n(tuple of integers, does not include the\
    \ sample axis),\ne.g. `input_shape=(128, 128, 128, 1)` for 128x128x128 volumes\n\
    with a single channel,\nin `data_format=\"channels_last\"`.\n\n# Arguments\n \
    \   filters: Integer, the dimensionality of the output space\n        (i.e. the\
    \ number of output filters in the convolution).\n    kernel_size: An integer or\
    \ tuple/list of 3 integers, specifying the\n        depth, height and width of\
    \ the 3D convolution window.\n        Can be a single integer to specify the same\
    \ value for\n        all spatial dimensions.\n    strides: An integer or tuple/list\
    \ of 3 integers,\n        specifying the strides of the convolution along each\
    \ spatial dimension.\n        Can be a single integer to specify the same value\
    \ for\n        all spatial dimensions.\n        Specifying any stride value !=\
    \ 1 is incompatible with specifying\n        any `dilation_rate` value != 1.\n\
    \    padding: one of `\"valid\"` or `\"same\"` (case-insensitive).\n    data_format:\
    \ A string,\n        one of `\"channels_last\"` or `\"channels_first\"`.\n   \
    \     The ordering of the dimensions in the inputs.\n        `\"channels_last\"\
    ` corresponds to inputs with shape\n        `(batch, spatial_dim1, spatial_dim2,\
    \ spatial_dim3, channels)`\n        while `\"channels_first\"` corresponds to\
    \ inputs with shape\n        `(batch, channels, spatial_dim1, spatial_dim2, spatial_dim3)`.\n\
    \        It defaults to the `image_data_format` value found in your\n        Keras\
    \ config file at `~/.keras/keras.json`.\n        If you never set it, then it\
    \ will be \"channels_last\".\n    dilation_rate: an integer or tuple/list of 3\
    \ integers, specifying\n        the dilation rate to use for dilated convolution.\n\
    \        Can be a single integer to specify the same value for\n        all spatial\
    \ dimensions.\n        Currently, specifying any `dilation_rate` value != 1 is\n\
    \        incompatible with specifying any stride value != 1.\n    activation:\
    \ Activation function to use\n        (see [activations](../activations.md)).\n\
    \        If you don't specify anything, no activation is applied\n        (ie.\
    \ \"linear\" activation: `a(x) = x`).\n    use_bias: Boolean, whether the layer\
    \ uses a bias vector.\n    kernel_initializer: Initializer for the `kernel` weights\
    \ matrix\n        (see [initializers](../initializers.md)).\n    bias_initializer:\
    \ Initializer for the bias vector\n        (see [initializers](../initializers.md)).\n\
    \    kernel_regularizer: Regularizer function applied to\n        the `kernel`\
    \ weights matrix\n        (see [regularizer](../regularizers.md)).\n    bias_regularizer:\
    \ Regularizer function applied to the bias vector\n        (see [regularizer](../regularizers.md)).\n\
    \    activity_regularizer: Regularizer function applied to\n        the output\
    \ of the layer (its \"activation\").\n        (see [regularizer](../regularizers.md)).\n\
    \    kernel_constraint: Constraint function applied to the kernel matrix\n   \
    \     (see [constraints](../constraints.md)).\n    bias_constraint: Constraint\
    \ function applied to the bias vector\n        (see [constraints](../constraints.md)).\n\
    \n# Input shape\n    5D tensor with shape:\n    `(batch, channels, conv_dim1,\
    \ conv_dim2, conv_dim3)`\n    if `data_format` is `\"channels_first\"`\n    or\
    \ 5D tensor with shape:\n    `(batch, conv_dim1, conv_dim2, conv_dim3, channels)`\n\
    \    if `data_format` is `\"channels_last\"`.\n\n# Output shape\n    5D tensor\
    \ with shape:\n    `(batch, filters, new_conv_dim1, new_conv_dim2, new_conv_dim3)`\n\
    \    if `data_format` is `\"channels_first\"`\n    or 5D tensor with shape:\n\
    \    `(batch, new_conv_dim1, new_conv_dim2, new_conv_dim3, filters)`\n    if `data_format`\
    \ is `\"channels_last\"`.\n    `new_conv_dim1`, `new_conv_dim2` and `new_conv_dim3`\
    \ values might have\n    changed due to padding."
  kind: Layer
  name: Conv3D
  parameters:
  - {kind: any, name: filters}
  - {kind: any, name: kernel_size}
  - {defaultValue: '(1, 1, 1)', kind: any, name: strides}
  - {defaultValue: valid, kind: any, name: padding}
  - {defaultValue: None, kind: any, name: data_format}
  - {defaultValue: '(1, 1, 1)', kind: any, name: dilation_rate}
  - {defaultValue: None, kind: any, name: activation}
  - {defaultValue: 'True', kind: any, name: use_bias}
  - {defaultValue: glorot_uniform, kind: any, name: kernel_initializer}
  - {defaultValue: zeros, kind: any, name: bias_initializer}
  - {defaultValue: None, kind: any, name: kernel_regularizer}
  - {defaultValue: None, kind: any, name: bias_regularizer}
  - {defaultValue: None, kind: any, name: activity_regularizer}
  - {defaultValue: None, kind: any, name: kernel_constraint}
  - {defaultValue: None, kind: any, name: bias_constraint}
  - {defaultValue: 'true', name: trainable, type: bool}
  source: "class Conv3D(_Conv):\n    \"\"\"3D convolution layer (e.g. spatial convolution\
    \ over volumes).\n\n    This layer creates a convolution kernel that is convolved\n\
    \    with the layer input to produce a tensor of\n    outputs. If `use_bias` is\
    \ True,\n    a bias vector is created and added to the outputs. Finally, if\n\
    \    `activation` is not `None`, it is applied to the outputs as well.\n\n   \
    \ When using this layer as the first layer in a model,\n    provide the keyword\
    \ argument `input_shape`\n    (tuple of integers, does not include the sample\
    \ axis),\n    e.g. `input_shape=(128, 128, 128, 1)` for 128x128x128 volumes\n\
    \    with a single channel,\n    in `data_format=\"channels_last\"`.\n\n    #\
    \ Arguments\n        filters: Integer, the dimensionality of the output space\n\
    \            (i.e. the number of output filters in the convolution).\n       \
    \ kernel_size: An integer or tuple/list of 3 integers, specifying the\n      \
    \      depth, height and width of the 3D convolution window.\n            Can\
    \ be a single integer to specify the same value for\n            all spatial dimensions.\n\
    \        strides: An integer or tuple/list of 3 integers,\n            specifying\
    \ the strides of the convolution along each spatial dimension.\n            Can\
    \ be a single integer to specify the same value for\n            all spatial dimensions.\n\
    \            Specifying any stride value != 1 is incompatible with specifying\n\
    \            any `dilation_rate` value != 1.\n        padding: one of `\"valid\"\
    ` or `\"same\"` (case-insensitive).\n        data_format: A string,\n        \
    \    one of `\"channels_last\"` or `\"channels_first\"`.\n            The ordering\
    \ of the dimensions in the inputs.\n            `\"channels_last\"` corresponds\
    \ to inputs with shape\n            `(batch, spatial_dim1, spatial_dim2, spatial_dim3,\
    \ channels)`\n            while `\"channels_first\"` corresponds to inputs with\
    \ shape\n            `(batch, channels, spatial_dim1, spatial_dim2, spatial_dim3)`.\n\
    \            It defaults to the `image_data_format` value found in your\n    \
    \        Keras config file at `~/.keras/keras.json`.\n            If you never\
    \ set it, then it will be \"channels_last\".\n        dilation_rate: an integer\
    \ or tuple/list of 3 integers, specifying\n            the dilation rate to use\
    \ for dilated convolution.\n            Can be a single integer to specify the\
    \ same value for\n            all spatial dimensions.\n            Currently,\
    \ specifying any `dilation_rate` value != 1 is\n            incompatible with\
    \ specifying any stride value != 1.\n        activation: Activation function to\
    \ use\n            (see [activations](../activations.md)).\n            If you\
    \ don't specify anything, no activation is applied\n            (ie. \"linear\"\
    \ activation: `a(x) = x`).\n        use_bias: Boolean, whether the layer uses\
    \ a bias vector.\n        kernel_initializer: Initializer for the `kernel` weights\
    \ matrix\n            (see [initializers](../initializers.md)).\n        bias_initializer:\
    \ Initializer for the bias vector\n            (see [initializers](../initializers.md)).\n\
    \        kernel_regularizer: Regularizer function applied to\n            the\
    \ `kernel` weights matrix\n            (see [regularizer](../regularizers.md)).\n\
    \        bias_regularizer: Regularizer function applied to the bias vector\n \
    \           (see [regularizer](../regularizers.md)).\n        activity_regularizer:\
    \ Regularizer function applied to\n            the output of the layer (its \"\
    activation\").\n            (see [regularizer](../regularizers.md)).\n       \
    \ kernel_constraint: Constraint function applied to the kernel matrix\n      \
    \      (see [constraints](../constraints.md)).\n        bias_constraint: Constraint\
    \ function applied to the bias vector\n            (see [constraints](../constraints.md)).\n\
    \n    # Input shape\n        5D tensor with shape:\n        `(batch, channels,\
    \ conv_dim1, conv_dim2, conv_dim3)`\n        if `data_format` is `\"channels_first\"\
    `\n        or 5D tensor with shape:\n        `(batch, conv_dim1, conv_dim2, conv_dim3,\
    \ channels)`\n        if `data_format` is `\"channels_last\"`.\n\n    # Output\
    \ shape\n        5D tensor with shape:\n        `(batch, filters, new_conv_dim1,\
    \ new_conv_dim2, new_conv_dim3)`\n        if `data_format` is `\"channels_first\"\
    `\n        or 5D tensor with shape:\n        `(batch, new_conv_dim1, new_conv_dim2,\
    \ new_conv_dim3, filters)`\n        if `data_format` is `\"channels_last\"`.\n\
    \        `new_conv_dim1`, `new_conv_dim2` and `new_conv_dim3` values might have\n\
    \        changed due to padding.\n    \"\"\"\n\n    @interfaces.legacy_conv3d_support\n\
    \    def __init__(self, filters,\n                 kernel_size,\n            \
    \     strides=(1, 1, 1),\n                 padding='valid',\n                \
    \ data_format=None,\n                 dilation_rate=(1, 1, 1),\n             \
    \    activation=None,\n                 use_bias=True,\n                 kernel_initializer='glorot_uniform',\n\
    \                 bias_initializer='zeros',\n                 kernel_regularizer=None,\n\
    \                 bias_regularizer=None,\n                 activity_regularizer=None,\n\
    \                 kernel_constraint=None,\n                 bias_constraint=None,\n\
    \                 **kwargs):\n        super(Conv3D, self).__init__(\n        \
    \    rank=3,\n            filters=filters,\n            kernel_size=kernel_size,\n\
    \            strides=strides,\n            padding=padding,\n            data_format=data_format,\n\
    \            dilation_rate=dilation_rate,\n            activation=activation,\n\
    \            use_bias=use_bias,\n            kernel_initializer=kernel_initializer,\n\
    \            bias_initializer=bias_initializer,\n            kernel_regularizer=kernel_regularizer,\n\
    \            bias_regularizer=bias_regularizer,\n            activity_regularizer=activity_regularizer,\n\
    \            kernel_constraint=kernel_constraint,\n            bias_constraint=bias_constraint,\n\
    \            **kwargs)\n\n    def get_config(self):\n        config = super(Conv3D,\
    \ self).get_config()\n        config.pop('rank')\n        return config\n"
  sourcefile: D:\Python36\lib\site-packages\keras\layers\convolutional.py
- doc: "Cropping layer for 1D input (e.g. temporal sequence).\n\nIt crops along the\
    \ time dimension (axis 1).\n\n# Arguments\n    cropping: int or tuple of int (length\
    \ 2)\n        How many units should be trimmed off at the beginning and end of\n\
    \        the cropping dimension (axis 1).\n        If a single int is provided,\n\
    \        the same value will be used for both.\n\n# Input shape\n    3D tensor\
    \ with shape `(batch, axis_to_crop, features)`\n\n# Output shape\n    3D tensor\
    \ with shape `(batch, cropped_axis, features)`"
  kind: Layer
  name: Cropping1D
  parameters:
  - {defaultValue: '(1, 1)', kind: any, name: cropping}
  - {defaultValue: 'true', name: trainable, type: bool}
  source: "class Cropping1D(_Cropping):\n    \"\"\"Cropping layer for 1D input (e.g.\
    \ temporal sequence).\n\n    It crops along the time dimension (axis 1).\n\n \
    \   # Arguments\n        cropping: int or tuple of int (length 2)\n          \
    \  How many units should be trimmed off at the beginning and end of\n        \
    \    the cropping dimension (axis 1).\n            If a single int is provided,\n\
    \            the same value will be used for both.\n\n    # Input shape\n    \
    \    3D tensor with shape `(batch, axis_to_crop, features)`\n\n    # Output shape\n\
    \        3D tensor with shape `(batch, cropped_axis, features)`\n    \"\"\"\n\n\
    \    def __init__(self, cropping=(1, 1), **kwargs):\n        normalized_cropping\
    \ = (conv_utils.normalize_tuple(cropping, 2, 'cropping'),)\n        super(Cropping1D,\
    \ self).__init__(normalized_cropping,\n                                      \
    \   'channels_last',\n                                         **kwargs)\n\n \
    \   def get_config(self):\n        base_config = super(Cropping1D, self).get_config()\n\
    \        base_config.pop('data_format')\n        base_config['cropping'] = base_config['cropping'][0]\n\
    \        return base_config\n"
  sourcefile: D:\Python36\lib\site-packages\keras\layers\convolutional.py
- doc: "Cropping layer for 2D input (e.g. picture).\n\nIt crops along spatial dimensions,\
    \ i.e. height and width.\n\n# Arguments\n    cropping: int, or tuple of 2 ints,\
    \ or tuple of 2 tuples of 2 ints.\n        - If int: the same symmetric cropping\n\
    \            is applied to height and width.\n        - If tuple of 2 ints:\n\
    \            interpreted as two different\n            symmetric cropping values\
    \ for height and width:\n            `(symmetric_height_crop, symmetric_width_crop)`.\n\
    \        - If tuple of 2 tuples of 2 ints:\n            interpreted as\n     \
    \       `((top_crop, bottom_crop), (left_crop, right_crop))`\n    data_format:\
    \ A string,\n        one of `\"channels_last\"` or `\"channels_first\"`.\n   \
    \     The ordering of the dimensions in the inputs.\n        `\"channels_last\"\
    ` corresponds to inputs with shape\n        `(batch, height, width, channels)`\
    \ while `\"channels_first\"`\n        corresponds to inputs with shape\n     \
    \   `(batch, channels, height, width)`.\n        It defaults to the `image_data_format`\
    \ value found in your\n        Keras config file at `~/.keras/keras.json`.\n \
    \       If you never set it, then it will be \"channels_last\".\n\n# Input shape\n\
    \    4D tensor with shape:\n    - If `data_format` is `\"channels_last\"`:\n \
    \       `(batch, rows, cols, channels)`\n    - If `data_format` is `\"channels_first\"\
    `:\n        `(batch, channels, rows, cols)`\n\n# Output shape\n    4D tensor with\
    \ shape:\n    - If `data_format` is `\"channels_last\"`:\n        `(batch, cropped_rows,\
    \ cropped_cols, channels)`\n    - If `data_format` is `\"channels_first\"`:\n\
    \        `(batch, channels, cropped_rows, cropped_cols)`\n\n# Examples\n\n```python\n\
    \    # Crop the input 2D images or feature maps\n    model = Sequential()\n  \
    \  model.add(Cropping2D(cropping=((2, 2), (4, 4)),\n                         input_shape=(28,\
    \ 28, 3)))\n    # now model.output_shape == (None, 24, 20, 3)\n    model.add(Conv2D(64,\
    \ (3, 3), padding='same'))\n    model.add(Cropping2D(cropping=((2, 2), (2, 2))))\n\
    \    # now model.output_shape == (None, 20, 16, 64)\n```"
  kind: Layer
  name: Cropping2D
  parameters:
  - {defaultValue: '((0, 0), (0, 0))', kind: any, name: cropping}
  - {defaultValue: None, kind: any, name: data_format}
  - {defaultValue: 'true', name: trainable, type: bool}
  source: "class Cropping2D(_Cropping):\n    \"\"\"Cropping layer for 2D input (e.g.\
    \ picture).\n\n    It crops along spatial dimensions, i.e. height and width.\n\
    \n    # Arguments\n        cropping: int, or tuple of 2 ints, or tuple of 2 tuples\
    \ of 2 ints.\n            - If int: the same symmetric cropping\n            \
    \    is applied to height and width.\n            - If tuple of 2 ints:\n    \
    \            interpreted as two different\n                symmetric cropping\
    \ values for height and width:\n                `(symmetric_height_crop, symmetric_width_crop)`.\n\
    \            - If tuple of 2 tuples of 2 ints:\n                interpreted as\n\
    \                `((top_crop, bottom_crop), (left_crop, right_crop))`\n      \
    \  data_format: A string,\n            one of `\"channels_last\"` or `\"channels_first\"\
    `.\n            The ordering of the dimensions in the inputs.\n            `\"\
    channels_last\"` corresponds to inputs with shape\n            `(batch, height,\
    \ width, channels)` while `\"channels_first\"`\n            corresponds to inputs\
    \ with shape\n            `(batch, channels, height, width)`.\n            It\
    \ defaults to the `image_data_format` value found in your\n            Keras config\
    \ file at `~/.keras/keras.json`.\n            If you never set it, then it will\
    \ be \"channels_last\".\n\n    # Input shape\n        4D tensor with shape:\n\
    \        - If `data_format` is `\"channels_last\"`:\n            `(batch, rows,\
    \ cols, channels)`\n        - If `data_format` is `\"channels_first\"`:\n    \
    \        `(batch, channels, rows, cols)`\n\n    # Output shape\n        4D tensor\
    \ with shape:\n        - If `data_format` is `\"channels_last\"`:\n          \
    \  `(batch, cropped_rows, cropped_cols, channels)`\n        - If `data_format`\
    \ is `\"channels_first\"`:\n            `(batch, channels, cropped_rows, cropped_cols)`\n\
    \n    # Examples\n\n    ```python\n        # Crop the input 2D images or feature\
    \ maps\n        model = Sequential()\n        model.add(Cropping2D(cropping=((2,\
    \ 2), (4, 4)),\n                             input_shape=(28, 28, 3)))\n     \
    \   # now model.output_shape == (None, 24, 20, 3)\n        model.add(Conv2D(64,\
    \ (3, 3), padding='same'))\n        model.add(Cropping2D(cropping=((2, 2), (2,\
    \ 2))))\n        # now model.output_shape == (None, 20, 16, 64)\n    ```\n   \
    \ \"\"\"\n\n    @interfaces.legacy_cropping2d_support\n    def __init__(self,\
    \ cropping=((0, 0), (0, 0)),\n                 data_format=None, **kwargs):\n\
    \        if isinstance(cropping, int):\n            normalized_cropping = ((cropping,\
    \ cropping), (cropping, cropping))\n        elif hasattr(cropping, '__len__'):\n\
    \            if len(cropping) != 2:\n                raise ValueError('`cropping`\
    \ should have two elements. '\n                                 'Found: ' + str(cropping))\n\
    \            height_cropping = conv_utils.normalize_tuple(\n                cropping[0],\
    \ 2,\n                '1st entry of cropping')\n            width_cropping = conv_utils.normalize_tuple(\n\
    \                cropping[1], 2,\n                '2nd entry of cropping')\n \
    \           normalized_cropping = (height_cropping, width_cropping)\n        else:\n\
    \            raise ValueError('`cropping` should be either an int, '\n       \
    \                      'a tuple of 2 ints '\n                             '(symmetric_height_crop,\
    \ symmetric_width_crop), '\n                             'or a tuple of 2 tuples\
    \ of 2 ints '\n                             '((top_crop, bottom_crop), (left_crop,\
    \ right_crop)). '\n                             'Found: ' + str(cropping))\n \
    \       super(Cropping2D, self).__init__(normalized_cropping,\n              \
    \                           data_format,\n                                   \
    \      **kwargs)\n"
  sourcefile: D:\Python36\lib\site-packages\keras\layers\convolutional.py
- doc: "Cropping layer for 3D data (e.g. spatial or spatio-temporal).\n\n# Arguments\n\
    \    cropping: int, or tuple of 3 ints, or tuple of 3 tuples of 2 ints.\n    \
    \    - If int: the same symmetric cropping\n            is applied to depth, height,\
    \ and width.\n        - If tuple of 3 ints:\n            interpreted as two different\n\
    \            symmetric cropping values for depth, height, and width:\n       \
    \     `(symmetric_dim1_crop, symmetric_dim2_crop, symmetric_dim3_crop)`.\n   \
    \     - If tuple of 3 tuples of 2 ints:\n            interpreted as\n        \
    \    `((left_dim1_crop, right_dim1_crop),\n              (left_dim2_crop, right_dim2_crop),\n\
    \              (left_dim3_crop, right_dim3_crop))`\n    data_format: A string,\n\
    \        one of `\"channels_last\"` or `\"channels_first\"`.\n        The ordering\
    \ of the dimensions in the inputs.\n        `\"channels_last\"` corresponds to\
    \ inputs with shape\n        `(batch, spatial_dim1, spatial_dim2, spatial_dim3,\
    \ channels)`\n        while `\"channels_first\"` corresponds to inputs with shape\n\
    \        `(batch, channels, spatial_dim1, spatial_dim2, spatial_dim3)`.\n    \
    \    It defaults to the `image_data_format` value found in your\n        Keras\
    \ config file at `~/.keras/keras.json`.\n        If you never set it, then it\
    \ will be \"channels_last\".\n\n# Input shape\n    5D tensor with shape:\n   \
    \ - If `data_format` is `\"channels_last\"`:\n        `(batch, first_axis_to_crop,\
    \ second_axis_to_crop, third_axis_to_crop,\n          depth)`\n    - If `data_format`\
    \ is `\"channels_first\"`:\n        `(batch, depth,\n          first_axis_to_crop,\
    \ second_axis_to_crop, third_axis_to_crop)`\n\n# Output shape\n    5D tensor with\
    \ shape:\n    - If `data_format` is `\"channels_last\"`:\n        `(batch, first_cropped_axis,\
    \ second_cropped_axis, third_cropped_axis,\n          depth)`\n    - If `data_format`\
    \ is `\"channels_first\"`:\n        `(batch, depth,\n          first_cropped_axis,\
    \ second_cropped_axis, third_cropped_axis)`"
  kind: Layer
  name: Cropping3D
  parameters:
  - {defaultValue: '((1, 1), (1, 1), (1, 1))', kind: any, name: cropping}
  - {defaultValue: None, kind: any, name: data_format}
  - {defaultValue: 'true', name: trainable, type: bool}
  source: "class Cropping3D(_Cropping):\n    \"\"\"Cropping layer for 3D data (e.g.\
    \ spatial or spatio-temporal).\n\n    # Arguments\n        cropping: int, or tuple\
    \ of 3 ints, or tuple of 3 tuples of 2 ints.\n            - If int: the same symmetric\
    \ cropping\n                is applied to depth, height, and width.\n        \
    \    - If tuple of 3 ints:\n                interpreted as two different\n   \
    \             symmetric cropping values for depth, height, and width:\n      \
    \          `(symmetric_dim1_crop, symmetric_dim2_crop, symmetric_dim3_crop)`.\n\
    \            - If tuple of 3 tuples of 2 ints:\n                interpreted as\n\
    \                `((left_dim1_crop, right_dim1_crop),\n                  (left_dim2_crop,\
    \ right_dim2_crop),\n                  (left_dim3_crop, right_dim3_crop))`\n \
    \       data_format: A string,\n            one of `\"channels_last\"` or `\"\
    channels_first\"`.\n            The ordering of the dimensions in the inputs.\n\
    \            `\"channels_last\"` corresponds to inputs with shape\n          \
    \  `(batch, spatial_dim1, spatial_dim2, spatial_dim3, channels)`\n           \
    \ while `\"channels_first\"` corresponds to inputs with shape\n            `(batch,\
    \ channels, spatial_dim1, spatial_dim2, spatial_dim3)`.\n            It defaults\
    \ to the `image_data_format` value found in your\n            Keras config file\
    \ at `~/.keras/keras.json`.\n            If you never set it, then it will be\
    \ \"channels_last\".\n\n    # Input shape\n        5D tensor with shape:\n   \
    \     - If `data_format` is `\"channels_last\"`:\n            `(batch, first_axis_to_crop,\
    \ second_axis_to_crop, third_axis_to_crop,\n              depth)`\n        - If\
    \ `data_format` is `\"channels_first\"`:\n            `(batch, depth,\n      \
    \        first_axis_to_crop, second_axis_to_crop, third_axis_to_crop)`\n\n   \
    \ # Output shape\n        5D tensor with shape:\n        - If `data_format` is\
    \ `\"channels_last\"`:\n            `(batch, first_cropped_axis, second_cropped_axis,\
    \ third_cropped_axis,\n              depth)`\n        - If `data_format` is `\"\
    channels_first\"`:\n            `(batch, depth,\n              first_cropped_axis,\
    \ second_cropped_axis, third_cropped_axis)`\n    \"\"\"\n\n    @interfaces.legacy_cropping3d_support\n\
    \    def __init__(self, cropping=((1, 1), (1, 1), (1, 1)),\n                 data_format=None,\
    \ **kwargs):\n        self.data_format = K.normalize_data_format(data_format)\n\
    \        if isinstance(cropping, int):\n            normalized_cropping = ((cropping,\
    \ cropping),\n                                   (cropping, cropping),\n     \
    \                              (cropping, cropping))\n        elif hasattr(cropping,\
    \ '__len__'):\n            if len(cropping) != 3:\n                raise ValueError('`cropping`\
    \ should have 3 elements. '\n                                 'Found: ' + str(cropping))\n\
    \            dim1_cropping = conv_utils.normalize_tuple(cropping[0], 2,\n    \
    \                                                   '1st entry of cropping')\n\
    \            dim2_cropping = conv_utils.normalize_tuple(cropping[1], 2,\n    \
    \                                                   '2nd entry of cropping')\n\
    \            dim3_cropping = conv_utils.normalize_tuple(cropping[2], 2,\n    \
    \                                                   '3rd entry of cropping')\n\
    \            normalized_cropping = (dim1_cropping, dim2_cropping, dim3_cropping)\n\
    \        else:\n            raise ValueError(\n                '`cropping` should\
    \ be either an int, a tuple of 3 ints '\n                '(symmetric_dim1_crop,\
    \ symmetric_dim2_crop, symmetric_dim3_crop), '\n                'or a tuple of\
    \ 3 tuples of 2 ints '\n                '((left_dim1_crop, right_dim1_crop),'\n\
    \                ' (left_dim2_crop, right_dim2_crop),'\n                ' (left_dim3_crop,\
    \ right_dim2_crop)). '\n                'Found: ' + str(cropping))\n        super(Cropping3D,\
    \ self).__init__(normalized_cropping,\n                                      \
    \   data_format,\n                                         **kwargs)\n"
  sourcefile: D:\Python36\lib\site-packages\keras\layers\convolutional.py
- doc: "Fast GRU implementation backed by [CuDNN](https://developer.nvidia.com/cudnn).\n\
    \nCan only be run on GPU, with the TensorFlow backend.\n\n# Arguments\n    units:\
    \ Positive integer, dimensionality of the output space.\n    kernel_initializer:\
    \ Initializer for the `kernel` weights matrix,\n        used for the linear transformation\
    \ of the inputs.\n        (see [initializers](../initializers.md)).\n    recurrent_initializer:\
    \ Initializer for the `recurrent_kernel`\n        weights matrix,\n        used\
    \ for the linear transformation of the recurrent state.\n        (see [initializers](../initializers.md)).\n\
    \    bias_initializer: Initializer for the bias vector\n        (see [initializers](../initializers.md)).\n\
    \    kernel_regularizer: Regularizer function applied to\n        the `kernel`\
    \ weights matrix\n        (see [regularizer](../regularizers.md)).\n    recurrent_regularizer:\
    \ Regularizer function applied to\n        the `recurrent_kernel` weights matrix\n\
    \        (see [regularizer](../regularizers.md)).\n    bias_regularizer: Regularizer\
    \ function applied to the bias vector\n        (see [regularizer](../regularizers.md)).\n\
    \    activity_regularizer: Regularizer function applied to\n        the output\
    \ of the layer (its \"activation\").\n        (see [regularizer](../regularizers.md)).\n\
    \    kernel_constraint: Constraint function applied to\n        the `kernel` weights\
    \ matrix\n        (see [constraints](../constraints.md)).\n    recurrent_constraint:\
    \ Constraint function applied to\n        the `recurrent_kernel` weights matrix\n\
    \        (see [constraints](../constraints.md)).\n    bias_constraint: Constraint\
    \ function applied to the bias vector\n        (see [constraints](../constraints.md)).\n\
    \    return_sequences: Boolean. Whether to return the last output.\n        in\
    \ the output sequence, or the full sequence.\n    return_state: Boolean. Whether\
    \ to return the last state\n        in addition to the output.\n    stateful:\
    \ Boolean (default False). If True, the last state\n        for each sample at\
    \ index i in a batch will be used as initial\n        state for the sample of\
    \ index i in the following batch."
  kind: Layer
  name: CuDNNGRU
  parameters:
  - {kind: any, name: units}
  - {defaultValue: glorot_uniform, kind: any, name: kernel_initializer}
  - {defaultValue: orthogonal, kind: any, name: recurrent_initializer}
  - {defaultValue: zeros, kind: any, name: bias_initializer}
  - {defaultValue: None, kind: any, name: kernel_regularizer}
  - {defaultValue: None, kind: any, name: recurrent_regularizer}
  - {defaultValue: None, kind: any, name: bias_regularizer}
  - {defaultValue: None, kind: any, name: activity_regularizer}
  - {defaultValue: None, kind: any, name: kernel_constraint}
  - {defaultValue: None, kind: any, name: recurrent_constraint}
  - {defaultValue: None, kind: any, name: bias_constraint}
  - {defaultValue: 'False', kind: any, name: return_sequences}
  - {defaultValue: 'False', kind: any, name: return_state}
  - {defaultValue: 'False', kind: any, name: stateful}
  - {defaultValue: 'true', name: trainable, type: bool}
  source: "class CuDNNGRU(_CuDNNRNN):\n    \"\"\"Fast GRU implementation backed by\
    \ [CuDNN](https://developer.nvidia.com/cudnn).\n\n    Can only be run on GPU,\
    \ with the TensorFlow backend.\n\n    # Arguments\n        units: Positive integer,\
    \ dimensionality of the output space.\n        kernel_initializer: Initializer\
    \ for the `kernel` weights matrix,\n            used for the linear transformation\
    \ of the inputs.\n            (see [initializers](../initializers.md)).\n    \
    \    recurrent_initializer: Initializer for the `recurrent_kernel`\n         \
    \   weights matrix,\n            used for the linear transformation of the recurrent\
    \ state.\n            (see [initializers](../initializers.md)).\n        bias_initializer:\
    \ Initializer for the bias vector\n            (see [initializers](../initializers.md)).\n\
    \        kernel_regularizer: Regularizer function applied to\n            the\
    \ `kernel` weights matrix\n            (see [regularizer](../regularizers.md)).\n\
    \        recurrent_regularizer: Regularizer function applied to\n            the\
    \ `recurrent_kernel` weights matrix\n            (see [regularizer](../regularizers.md)).\n\
    \        bias_regularizer: Regularizer function applied to the bias vector\n \
    \           (see [regularizer](../regularizers.md)).\n        activity_regularizer:\
    \ Regularizer function applied to\n            the output of the layer (its \"\
    activation\").\n            (see [regularizer](../regularizers.md)).\n       \
    \ kernel_constraint: Constraint function applied to\n            the `kernel`\
    \ weights matrix\n            (see [constraints](../constraints.md)).\n      \
    \  recurrent_constraint: Constraint function applied to\n            the `recurrent_kernel`\
    \ weights matrix\n            (see [constraints](../constraints.md)).\n      \
    \  bias_constraint: Constraint function applied to the bias vector\n         \
    \   (see [constraints](../constraints.md)).\n        return_sequences: Boolean.\
    \ Whether to return the last output.\n            in the output sequence, or the\
    \ full sequence.\n        return_state: Boolean. Whether to return the last state\n\
    \            in addition to the output.\n        stateful: Boolean (default False).\
    \ If True, the last state\n            for each sample at index i in a batch will\
    \ be used as initial\n            state for the sample of index i in the following\
    \ batch.\n    \"\"\"\n\n    def __init__(self, units,\n                 kernel_initializer='glorot_uniform',\n\
    \                 recurrent_initializer='orthogonal',\n                 bias_initializer='zeros',\n\
    \                 kernel_regularizer=None,\n                 recurrent_regularizer=None,\n\
    \                 bias_regularizer=None,\n                 activity_regularizer=None,\n\
    \                 kernel_constraint=None,\n                 recurrent_constraint=None,\n\
    \                 bias_constraint=None,\n                 return_sequences=False,\n\
    \                 return_state=False,\n                 stateful=False,\n    \
    \             **kwargs):\n        self.units = units\n        super(CuDNNGRU,\
    \ self).__init__(\n            return_sequences=return_sequences,\n          \
    \  return_state=return_state,\n            stateful=stateful,\n            **kwargs)\n\
    \n        self.kernel_initializer = initializers.get(kernel_initializer)\n   \
    \     self.recurrent_initializer = initializers.get(recurrent_initializer)\n \
    \       self.bias_initializer = initializers.get(bias_initializer)\n\n       \
    \ self.kernel_regularizer = regularizers.get(kernel_regularizer)\n        self.recurrent_regularizer\
    \ = regularizers.get(recurrent_regularizer)\n        self.bias_regularizer = regularizers.get(bias_regularizer)\n\
    \        self.activity_regularizer = regularizers.get(activity_regularizer)\n\n\
    \        self.kernel_constraint = constraints.get(kernel_constraint)\n       \
    \ self.recurrent_constraint = constraints.get(recurrent_constraint)\n        self.bias_constraint\
    \ = constraints.get(bias_constraint)\n\n    @property\n    def cell(self):\n \
    \       Cell = namedtuple('cell', 'state_size')\n        cell = Cell(state_size=self.units)\n\
    \        return cell\n\n    def build(self, input_shape):\n        super(CuDNNGRU,\
    \ self).build(input_shape)\n        if isinstance(input_shape, list):\n      \
    \      input_shape = input_shape[0]\n        input_dim = input_shape[-1]\n\n \
    \       from tensorflow.contrib.cudnn_rnn.python.ops import cudnn_rnn_ops\n  \
    \      self._cudnn_gru = cudnn_rnn_ops.CudnnGRU(\n            num_layers=1,\n\
    \            num_units=self.units,\n            input_size=input_dim,\n      \
    \      input_mode='linear_input')\n\n        self.kernel = self.add_weight(shape=(input_dim,\
    \ self.units * 3),\n                                      name='kernel',\n   \
    \                                   initializer=self.kernel_initializer,\n   \
    \                                   regularizer=self.kernel_regularizer,\n   \
    \                                   constraint=self.kernel_constraint)\n     \
    \   self.recurrent_kernel = self.add_weight(\n            shape=(self.units, self.units\
    \ * 3),\n            name='recurrent_kernel',\n            initializer=self.recurrent_initializer,\n\
    \            regularizer=self.recurrent_regularizer,\n            constraint=self.recurrent_constraint)\n\
    \n        self.bias = self.add_weight(shape=(self.units * 6,),\n             \
    \                       name='bias',\n                                    initializer=self.bias_initializer,\n\
    \                                    regularizer=self.bias_regularizer,\n    \
    \                                constraint=self.bias_constraint)\n\n        self.kernel_z\
    \ = self.kernel[:, :self.units]\n        self.recurrent_kernel_z = self.recurrent_kernel[:,\
    \ :self.units]\n        self.kernel_r = self.kernel[:, self.units: self.units\
    \ * 2]\n        self.recurrent_kernel_r = self.recurrent_kernel[:,\n         \
    \                                               self.units:\n                \
    \                                        self.units * 2]\n        self.kernel_h\
    \ = self.kernel[:, self.units * 2:]\n        self.recurrent_kernel_h = self.recurrent_kernel[:,\
    \ self.units * 2:]\n\n        self.bias_z_i = self.bias[:self.units]\n       \
    \ self.bias_r_i = self.bias[self.units: self.units * 2]\n        self.bias_h_i\
    \ = self.bias[self.units * 2: self.units * 3]\n        self.bias_z = self.bias[self.units\
    \ * 3: self.units * 4]\n        self.bias_r = self.bias[self.units * 4: self.units\
    \ * 5]\n        self.bias_h = self.bias[self.units * 5:]\n\n        self.built\
    \ = True\n\n    def _process_batch(self, inputs, initial_state):\n        import\
    \ tensorflow as tf\n        inputs = tf.transpose(inputs, (1, 0, 2))\n       \
    \ input_h = initial_state[0]\n        input_h = tf.expand_dims(input_h, axis=0)\n\
    \n        params = self._canonical_to_params(\n            weights=[\n       \
    \         self.kernel_r,\n                self.kernel_z,\n                self.kernel_h,\n\
    \                self.recurrent_kernel_r,\n                self.recurrent_kernel_z,\n\
    \                self.recurrent_kernel_h,\n            ],\n            biases=[\n\
    \                self.bias_r_i,\n                self.bias_z_i,\n            \
    \    self.bias_h_i,\n                self.bias_r,\n                self.bias_z,\n\
    \                self.bias_h,\n            ],\n        )\n        outputs, h =\
    \ self._cudnn_gru(\n            inputs,\n            input_h=input_h,\n      \
    \      params=params,\n            is_training=True)\n\n        if self.stateful\
    \ or self.return_state:\n            h = h[0]\n        if self.return_sequences:\n\
    \            output = tf.transpose(outputs, (1, 0, 2))\n        else:\n      \
    \      output = outputs[-1]\n        return output, [h]\n\n    def get_config(self):\n\
    \        config = {\n            'units': self.units,\n            'kernel_initializer':\
    \ initializers.serialize(self.kernel_initializer),\n            'recurrent_initializer':\n\
    \                initializers.serialize(self.recurrent_initializer),\n       \
    \     'bias_initializer': initializers.serialize(self.bias_initializer),\n   \
    \         'kernel_regularizer': regularizers.serialize(self.kernel_regularizer),\n\
    \            'recurrent_regularizer':\n                regularizers.serialize(self.recurrent_regularizer),\n\
    \            'bias_regularizer': regularizers.serialize(self.bias_regularizer),\n\
    \            'activity_regularizer':\n                regularizers.serialize(self.activity_regularizer),\n\
    \            'kernel_constraint': constraints.serialize(self.kernel_constraint),\n\
    \            'recurrent_constraint':\n                constraints.serialize(self.recurrent_constraint),\n\
    \            'bias_constraint': constraints.serialize(self.bias_constraint)}\n\
    \        base_config = super(CuDNNGRU, self).get_config()\n        return dict(list(base_config.items())\
    \ + list(config.items()))\n"
  sourcefile: D:\Python36\lib\site-packages\keras\layers\cudnn_recurrent.py
- doc: "Fast LSTM implementation with [CuDNN](https://developer.nvidia.com/cudnn).\n\
    \nCan only be run on GPU, with the TensorFlow backend.\n\n# Arguments\n    units:\
    \ Positive integer, dimensionality of the output space.\n    kernel_initializer:\
    \ Initializer for the `kernel` weights matrix,\n        used for the linear transformation\
    \ of the inputs.\n        (see [initializers](../initializers.md)).\n    unit_forget_bias:\
    \ Boolean.\n        If True, add 1 to the bias of the forget gate at initialization.\n\
    \        Setting it to true will also force `bias_initializer=\"zeros\"`.\n  \
    \      This is recommended in [Jozefowicz et al.]\n        (http://www.jmlr.org/proceedings/papers/v37/jozefowicz15.pdf).\n\
    \    recurrent_initializer: Initializer for the `recurrent_kernel`\n        weights\
    \ matrix,\n        used for the linear transformation of the recurrent state.\n\
    \        (see [initializers](../initializers.md)).\n    bias_initializer: Initializer\
    \ for the bias vector\n        (see [initializers](../initializers.md)).\n   \
    \ kernel_regularizer: Regularizer function applied to\n        the `kernel` weights\
    \ matrix\n        (see [regularizer](../regularizers.md)).\n    recurrent_regularizer:\
    \ Regularizer function applied to\n        the `recurrent_kernel` weights matrix\n\
    \        (see [regularizer](../regularizers.md)).\n    bias_regularizer: Regularizer\
    \ function applied to the bias vector\n        (see [regularizer](../regularizers.md)).\n\
    \    activity_regularizer: Regularizer function applied to\n        the output\
    \ of the layer (its \"activation\").\n        (see [regularizer](../regularizers.md)).\n\
    \    kernel_constraint: Constraint function applied to\n        the `kernel` weights\
    \ matrix\n        (see [constraints](../constraints.md)).\n    recurrent_constraint:\
    \ Constraint function applied to\n        the `recurrent_kernel` weights matrix\n\
    \        (see [constraints](../constraints.md)).\n    bias_constraint: Constraint\
    \ function applied to the bias vector\n        (see [constraints](../constraints.md)).\n\
    \    return_sequences: Boolean. Whether to return the last output.\n        in\
    \ the output sequence, or the full sequence.\n    return_state: Boolean. Whether\
    \ to return the last state\n        in addition to the output.\n    stateful:\
    \ Boolean (default False). If True, the last state\n        for each sample at\
    \ index i in a batch will be used as initial\n        state for the sample of\
    \ index i in the following batch."
  kind: Layer
  name: CuDNNLSTM
  parameters:
  - {kind: any, name: units}
  - {defaultValue: glorot_uniform, kind: any, name: kernel_initializer}
  - {defaultValue: orthogonal, kind: any, name: recurrent_initializer}
  - {defaultValue: zeros, kind: any, name: bias_initializer}
  - {defaultValue: 'True', kind: any, name: unit_forget_bias}
  - {defaultValue: None, kind: any, name: kernel_regularizer}
  - {defaultValue: None, kind: any, name: recurrent_regularizer}
  - {defaultValue: None, kind: any, name: bias_regularizer}
  - {defaultValue: None, kind: any, name: activity_regularizer}
  - {defaultValue: None, kind: any, name: kernel_constraint}
  - {defaultValue: None, kind: any, name: recurrent_constraint}
  - {defaultValue: None, kind: any, name: bias_constraint}
  - {defaultValue: 'False', kind: any, name: return_sequences}
  - {defaultValue: 'False', kind: any, name: return_state}
  - {defaultValue: 'False', kind: any, name: stateful}
  - {defaultValue: 'true', name: trainable, type: bool}
  source: "class CuDNNLSTM(_CuDNNRNN):\n    \"\"\"Fast LSTM implementation with [CuDNN](https://developer.nvidia.com/cudnn).\n\
    \n    Can only be run on GPU, with the TensorFlow backend.\n\n    # Arguments\n\
    \        units: Positive integer, dimensionality of the output space.\n      \
    \  kernel_initializer: Initializer for the `kernel` weights matrix,\n        \
    \    used for the linear transformation of the inputs.\n            (see [initializers](../initializers.md)).\n\
    \        unit_forget_bias: Boolean.\n            If True, add 1 to the bias of\
    \ the forget gate at initialization.\n            Setting it to true will also\
    \ force `bias_initializer=\"zeros\"`.\n            This is recommended in [Jozefowicz\
    \ et al.]\n            (http://www.jmlr.org/proceedings/papers/v37/jozefowicz15.pdf).\n\
    \        recurrent_initializer: Initializer for the `recurrent_kernel`\n     \
    \       weights matrix,\n            used for the linear transformation of the\
    \ recurrent state.\n            (see [initializers](../initializers.md)).\n  \
    \      bias_initializer: Initializer for the bias vector\n            (see [initializers](../initializers.md)).\n\
    \        kernel_regularizer: Regularizer function applied to\n            the\
    \ `kernel` weights matrix\n            (see [regularizer](../regularizers.md)).\n\
    \        recurrent_regularizer: Regularizer function applied to\n            the\
    \ `recurrent_kernel` weights matrix\n            (see [regularizer](../regularizers.md)).\n\
    \        bias_regularizer: Regularizer function applied to the bias vector\n \
    \           (see [regularizer](../regularizers.md)).\n        activity_regularizer:\
    \ Regularizer function applied to\n            the output of the layer (its \"\
    activation\").\n            (see [regularizer](../regularizers.md)).\n       \
    \ kernel_constraint: Constraint function applied to\n            the `kernel`\
    \ weights matrix\n            (see [constraints](../constraints.md)).\n      \
    \  recurrent_constraint: Constraint function applied to\n            the `recurrent_kernel`\
    \ weights matrix\n            (see [constraints](../constraints.md)).\n      \
    \  bias_constraint: Constraint function applied to the bias vector\n         \
    \   (see [constraints](../constraints.md)).\n        return_sequences: Boolean.\
    \ Whether to return the last output.\n            in the output sequence, or the\
    \ full sequence.\n        return_state: Boolean. Whether to return the last state\n\
    \            in addition to the output.\n        stateful: Boolean (default False).\
    \ If True, the last state\n            for each sample at index i in a batch will\
    \ be used as initial\n            state for the sample of index i in the following\
    \ batch.\n    \"\"\"\n    def __init__(self, units,\n                 kernel_initializer='glorot_uniform',\n\
    \                 recurrent_initializer='orthogonal',\n                 bias_initializer='zeros',\n\
    \                 unit_forget_bias=True,\n                 kernel_regularizer=None,\n\
    \                 recurrent_regularizer=None,\n                 bias_regularizer=None,\n\
    \                 activity_regularizer=None,\n                 kernel_constraint=None,\n\
    \                 recurrent_constraint=None,\n                 bias_constraint=None,\n\
    \                 return_sequences=False,\n                 return_state=False,\n\
    \                 stateful=False,\n                 **kwargs):\n        self.units\
    \ = units\n        super(CuDNNLSTM, self).__init__(\n            return_sequences=return_sequences,\n\
    \            return_state=return_state,\n            stateful=stateful,\n    \
    \        **kwargs)\n\n        self.kernel_initializer = initializers.get(kernel_initializer)\n\
    \        self.recurrent_initializer = initializers.get(recurrent_initializer)\n\
    \        self.bias_initializer = initializers.get(bias_initializer)\n        self.unit_forget_bias\
    \ = unit_forget_bias\n\n        self.kernel_regularizer = regularizers.get(kernel_regularizer)\n\
    \        self.recurrent_regularizer = regularizers.get(recurrent_regularizer)\n\
    \        self.bias_regularizer = regularizers.get(bias_regularizer)\n        self.activity_regularizer\
    \ = regularizers.get(activity_regularizer)\n\n        self.kernel_constraint =\
    \ constraints.get(kernel_constraint)\n        self.recurrent_constraint = constraints.get(recurrent_constraint)\n\
    \        self.bias_constraint = constraints.get(bias_constraint)\n\n    @property\n\
    \    def cell(self):\n        Cell = namedtuple('cell', 'state_size')\n      \
    \  cell = Cell(state_size=(self.units, self.units))\n        return cell\n\n \
    \   def build(self, input_shape):\n        super(CuDNNLSTM, self).build(input_shape)\n\
    \        if isinstance(input_shape, list):\n            input_shape = input_shape[0]\n\
    \        input_dim = input_shape[-1]\n\n        from tensorflow.contrib.cudnn_rnn.python.ops\
    \ import cudnn_rnn_ops\n        self._cudnn_lstm = cudnn_rnn_ops.CudnnLSTM(\n\
    \            num_layers=1,\n            num_units=self.units,\n            input_size=input_dim,\n\
    \            input_mode='linear_input')\n\n        self.kernel = self.add_weight(shape=(input_dim,\
    \ self.units * 4),\n                                      name='kernel',\n   \
    \                                   initializer=self.kernel_initializer,\n   \
    \                                   regularizer=self.kernel_regularizer,\n   \
    \                                   constraint=self.kernel_constraint)\n     \
    \   self.recurrent_kernel = self.add_weight(\n            shape=(self.units, self.units\
    \ * 4),\n            name='recurrent_kernel',\n            initializer=self.recurrent_initializer,\n\
    \            regularizer=self.recurrent_regularizer,\n            constraint=self.recurrent_constraint)\n\
    \n        if self.unit_forget_bias:\n            def bias_initializer(shape, *args,\
    \ **kwargs):\n                return K.concatenate([\n                    self.bias_initializer((self.units\
    \ * 5,), *args, **kwargs),\n                    initializers.Ones()((self.units,),\
    \ *args, **kwargs),\n                    self.bias_initializer((self.units * 2,),\
    \ *args, **kwargs),\n                ])\n        else:\n            bias_initializer\
    \ = self.bias_initializer\n        self.bias = self.add_weight(shape=(self.units\
    \ * 8,),\n                                    name='bias',\n                 \
    \                   initializer=bias_initializer,\n                          \
    \          regularizer=self.bias_regularizer,\n                              \
    \      constraint=self.bias_constraint)\n\n        self.kernel_i = self.kernel[:,\
    \ :self.units]\n        self.kernel_f = self.kernel[:, self.units: self.units\
    \ * 2]\n        self.kernel_c = self.kernel[:, self.units * 2: self.units * 3]\n\
    \        self.kernel_o = self.kernel[:, self.units * 3:]\n\n        self.recurrent_kernel_i\
    \ = self.recurrent_kernel[:, :self.units]\n        self.recurrent_kernel_f = (\n\
    \            self.recurrent_kernel[:, self.units: self.units * 2])\n        self.recurrent_kernel_c\
    \ = (\n            self.recurrent_kernel[:, self.units * 2: self.units * 3])\n\
    \        self.recurrent_kernel_o = self.recurrent_kernel[:, self.units * 3:]\n\
    \n        self.bias_i_i = self.bias[:self.units]\n        self.bias_f_i = self.bias[self.units:\
    \ self.units * 2]\n        self.bias_c_i = self.bias[self.units * 2: self.units\
    \ * 3]\n        self.bias_o_i = self.bias[self.units * 3: self.units * 4]\n  \
    \      self.bias_i = self.bias[self.units * 4: self.units * 5]\n        self.bias_f\
    \ = self.bias[self.units * 5: self.units * 6]\n        self.bias_c = self.bias[self.units\
    \ * 6: self.units * 7]\n        self.bias_o = self.bias[self.units * 7:]\n\n \
    \       self.built = True\n\n    def _process_batch(self, inputs, initial_state):\n\
    \        import tensorflow as tf\n        inputs = tf.transpose(inputs, (1, 0,\
    \ 2))\n        input_h = initial_state[0]\n        input_c = initial_state[1]\n\
    \        input_h = tf.expand_dims(input_h, axis=0)\n        input_c = tf.expand_dims(input_c,\
    \ axis=0)\n\n        params = self._canonical_to_params(\n            weights=[\n\
    \                self.kernel_i,\n                self.kernel_f,\n            \
    \    self.kernel_c,\n                self.kernel_o,\n                self.recurrent_kernel_i,\n\
    \                self.recurrent_kernel_f,\n                self.recurrent_kernel_c,\n\
    \                self.recurrent_kernel_o,\n            ],\n            biases=[\n\
    \                self.bias_i_i,\n                self.bias_f_i,\n            \
    \    self.bias_c_i,\n                self.bias_o_i,\n                self.bias_i,\n\
    \                self.bias_f,\n                self.bias_c,\n                self.bias_o,\n\
    \            ],\n        )\n        outputs, h, c = self._cudnn_lstm(\n      \
    \      inputs,\n            input_h=input_h,\n            input_c=input_c,\n \
    \           params=params,\n            is_training=True)\n\n        if self.stateful\
    \ or self.return_state:\n            h = h[0]\n            c = c[0]\n        if\
    \ self.return_sequences:\n            output = tf.transpose(outputs, (1, 0, 2))\n\
    \        else:\n            output = outputs[-1]\n        return output, [h, c]\n\
    \n    def get_config(self):\n        config = {\n            'units': self.units,\n\
    \            'kernel_initializer': initializers.serialize(self.kernel_initializer),\n\
    \            'recurrent_initializer':\n                initializers.serialize(self.recurrent_initializer),\n\
    \            'bias_initializer': initializers.serialize(self.bias_initializer),\n\
    \            'unit_forget_bias': self.unit_forget_bias,\n            'kernel_regularizer':\
    \ regularizers.serialize(self.kernel_regularizer),\n            'recurrent_regularizer':\n\
    \                regularizers.serialize(self.recurrent_regularizer),\n       \
    \     'bias_regularizer': regularizers.serialize(self.bias_regularizer),\n   \
    \         'activity_regularizer':\n                regularizers.serialize(self.activity_regularizer),\n\
    \            'kernel_constraint': constraints.serialize(self.kernel_constraint),\n\
    \            'recurrent_constraint': constraints.serialize(self.recurrent_constraint),\n\
    \            'bias_constraint': constraints.serialize(self.bias_constraint)}\n\
    \        base_config = super(CuDNNLSTM, self).get_config()\n        return dict(list(base_config.items())\
    \ + list(config.items()))\n"
  sourcefile: D:\Python36\lib\site-packages\keras\layers\cudnn_recurrent.py
- doc: "Transposed convolution layer (sometimes called Deconvolution).\n\nThe need\
    \ for transposed convolutions generally arises\nfrom the desire to use a transformation\
    \ going in the opposite direction\nof a normal convolution, i.e., from something\
    \ that has the shape of the\noutput of some convolution to something that has\
    \ the shape of its input\nwhile maintaining a connectivity pattern that is compatible\
    \ with\nsaid convolution.\n\nWhen using this layer as the first layer in a model,\n\
    provide the keyword argument `input_shape`\n(tuple of integers, does not include\
    \ the sample axis),\ne.g. `input_shape=(128, 128, 3)` for 128x128 RGB pictures\n\
    in `data_format=\"channels_last\"`.\n\n# Arguments\n    filters: Integer, the\
    \ dimensionality of the output space\n        (i.e. the number of output filters\
    \ in the convolution).\n    kernel_size: An integer or tuple/list of 2 integers,\
    \ specifying the\n        height and width of the 2D convolution window.\n   \
    \     Can be a single integer to specify the same value for\n        all spatial\
    \ dimensions.\n    strides: An integer or tuple/list of 2 integers,\n        specifying\
    \ the strides of the convolution\n        along the height and width.\n      \
    \  Can be a single integer to specify the same value for\n        all spatial\
    \ dimensions.\n        Specifying any stride value != 1 is incompatible with specifying\n\
    \        any `dilation_rate` value != 1.\n    padding: one of `\"valid\"` or `\"\
    same\"` (case-insensitive).\n    output_padding: An integer or tuple/list of 2\
    \ integers,\n        specifying the amount of padding along the height and width\n\
    \        of the output tensor.\n        Can be a single integer to specify the\
    \ same value for all\n        spatial dimensions.\n        The amount of output\
    \ padding along a given dimension must be\n        lower than the stride along\
    \ that same dimension.\n        If set to `None` (default), the output shape is\
    \ inferred.\n    data_format: A string,\n        one of `\"channels_last\"` or\
    \ `\"channels_first\"`.\n        The ordering of the dimensions in the inputs.\n\
    \        `\"channels_last\"` corresponds to inputs with shape\n        `(batch,\
    \ height, width, channels)` while `\"channels_first\"`\n        corresponds to\
    \ inputs with shape\n        `(batch, channels, height, width)`.\n        It defaults\
    \ to the `image_data_format` value found in your\n        Keras config file at\
    \ `~/.keras/keras.json`.\n        If you never set it, then it will be \"channels_last\"\
    .\n    dilation_rate: an integer or tuple/list of 2 integers, specifying\n   \
    \     the dilation rate to use for dilated convolution.\n        Can be a single\
    \ integer to specify the same value for\n        all spatial dimensions.\n   \
    \     Currently, specifying any `dilation_rate` value != 1 is\n        incompatible\
    \ with specifying any stride value != 1.\n    activation: Activation function\
    \ to use\n        (see [activations](../activations.md)).\n        If you don't\
    \ specify anything, no activation is applied\n        (ie. \"linear\" activation:\
    \ `a(x) = x`).\n    use_bias: Boolean, whether the layer uses a bias vector.\n\
    \    kernel_initializer: Initializer for the `kernel` weights matrix\n       \
    \ (see [initializers](../initializers.md)).\n    bias_initializer: Initializer\
    \ for the bias vector\n        (see [initializers](../initializers.md)).\n   \
    \ kernel_regularizer: Regularizer function applied to\n        the `kernel` weights\
    \ matrix\n        (see [regularizer](../regularizers.md)).\n    bias_regularizer:\
    \ Regularizer function applied to the bias vector\n        (see [regularizer](../regularizers.md)).\n\
    \    activity_regularizer: Regularizer function applied to\n        the output\
    \ of the layer (its \"activation\").\n        (see [regularizer](../regularizers.md)).\n\
    \    kernel_constraint: Constraint function applied to the kernel matrix\n   \
    \     (see [constraints](../constraints.md)).\n    bias_constraint: Constraint\
    \ function applied to the bias vector\n        (see [constraints](../constraints.md)).\n\
    \n# Input shape\n    4D tensor with shape:\n    `(batch, channels, rows, cols)`\n\
    \    if `data_format` is `\"channels_first\"`\n    or 4D tensor with shape:\n\
    \    `(batch, rows, cols, channels)`\n    if `data_format` is `\"channels_last\"\
    `.\n\n# Output shape\n    4D tensor with shape:\n    `(batch, filters, new_rows,\
    \ new_cols)`\n    if `data_format` is `\"channels_first\"`\n    or 4D tensor with\
    \ shape:\n    `(batch, new_rows, new_cols, filters)`\n    if `data_format` is\
    \ `\"channels_last\"`.\n    `rows` and `cols` values might have changed due to\
    \ padding.\n    If `output_padding` is specified:\n\n    ```\n    new_rows = ((rows\
    \ - 1) * strides[0] + kernel_size[0]\n                - 2 * padding[0] + output_padding[0])\n\
    \    new_cols = ((cols - 1) * strides[1] + kernel_size[1]\n                - 2\
    \ * padding[1] + output_padding[1])\n    ```\n\n# References\n    - [A guide to\
    \ convolution arithmetic for deep learning]\n      (https://arxiv.org/abs/1603.07285v1)\n\
    \    - [Deconvolutional Networks]\n      (http://www.matthewzeiler.com/pubs/cvpr2010/cvpr2010.pdf)"
  kind: Layer
  name: Conv2DTranspose
  parameters:
  - {kind: any, name: filters}
  - {kind: any, name: kernel_size}
  - {defaultValue: '(1, 1)', kind: any, name: strides}
  - {defaultValue: valid, kind: any, name: padding}
  - {defaultValue: None, kind: any, name: output_padding}
  - {defaultValue: None, kind: any, name: data_format}
  - {defaultValue: '(1, 1)', kind: any, name: dilation_rate}
  - {defaultValue: None, kind: any, name: activation}
  - {defaultValue: 'True', kind: any, name: use_bias}
  - {defaultValue: glorot_uniform, kind: any, name: kernel_initializer}
  - {defaultValue: zeros, kind: any, name: bias_initializer}
  - {defaultValue: None, kind: any, name: kernel_regularizer}
  - {defaultValue: None, kind: any, name: bias_regularizer}
  - {defaultValue: None, kind: any, name: activity_regularizer}
  - {defaultValue: None, kind: any, name: kernel_constraint}
  - {defaultValue: None, kind: any, name: bias_constraint}
  - {defaultValue: 'true', name: trainable, type: bool}
  source: "class Conv2DTranspose(Conv2D):\n    \"\"\"Transposed convolution layer\
    \ (sometimes called Deconvolution).\n\n    The need for transposed convolutions\
    \ generally arises\n    from the desire to use a transformation going in the opposite\
    \ direction\n    of a normal convolution, i.e., from something that has the shape\
    \ of the\n    output of some convolution to something that has the shape of its\
    \ input\n    while maintaining a connectivity pattern that is compatible with\n\
    \    said convolution.\n\n    When using this layer as the first layer in a model,\n\
    \    provide the keyword argument `input_shape`\n    (tuple of integers, does\
    \ not include the sample axis),\n    e.g. `input_shape=(128, 128, 3)` for 128x128\
    \ RGB pictures\n    in `data_format=\"channels_last\"`.\n\n    # Arguments\n \
    \       filters: Integer, the dimensionality of the output space\n           \
    \ (i.e. the number of output filters in the convolution).\n        kernel_size:\
    \ An integer or tuple/list of 2 integers, specifying the\n            height and\
    \ width of the 2D convolution window.\n            Can be a single integer to\
    \ specify the same value for\n            all spatial dimensions.\n        strides:\
    \ An integer or tuple/list of 2 integers,\n            specifying the strides\
    \ of the convolution\n            along the height and width.\n            Can\
    \ be a single integer to specify the same value for\n            all spatial dimensions.\n\
    \            Specifying any stride value != 1 is incompatible with specifying\n\
    \            any `dilation_rate` value != 1.\n        padding: one of `\"valid\"\
    ` or `\"same\"` (case-insensitive).\n        output_padding: An integer or tuple/list\
    \ of 2 integers,\n            specifying the amount of padding along the height\
    \ and width\n            of the output tensor.\n            Can be a single integer\
    \ to specify the same value for all\n            spatial dimensions.\n       \
    \     The amount of output padding along a given dimension must be\n         \
    \   lower than the stride along that same dimension.\n            If set to `None`\
    \ (default), the output shape is inferred.\n        data_format: A string,\n \
    \           one of `\"channels_last\"` or `\"channels_first\"`.\n            The\
    \ ordering of the dimensions in the inputs.\n            `\"channels_last\"` corresponds\
    \ to inputs with shape\n            `(batch, height, width, channels)` while `\"\
    channels_first\"`\n            corresponds to inputs with shape\n            `(batch,\
    \ channels, height, width)`.\n            It defaults to the `image_data_format`\
    \ value found in your\n            Keras config file at `~/.keras/keras.json`.\n\
    \            If you never set it, then it will be \"channels_last\".\n       \
    \ dilation_rate: an integer or tuple/list of 2 integers, specifying\n        \
    \    the dilation rate to use for dilated convolution.\n            Can be a single\
    \ integer to specify the same value for\n            all spatial dimensions.\n\
    \            Currently, specifying any `dilation_rate` value != 1 is\n       \
    \     incompatible with specifying any stride value != 1.\n        activation:\
    \ Activation function to use\n            (see [activations](../activations.md)).\n\
    \            If you don't specify anything, no activation is applied\n       \
    \     (ie. \"linear\" activation: `a(x) = x`).\n        use_bias: Boolean, whether\
    \ the layer uses a bias vector.\n        kernel_initializer: Initializer for the\
    \ `kernel` weights matrix\n            (see [initializers](../initializers.md)).\n\
    \        bias_initializer: Initializer for the bias vector\n            (see [initializers](../initializers.md)).\n\
    \        kernel_regularizer: Regularizer function applied to\n            the\
    \ `kernel` weights matrix\n            (see [regularizer](../regularizers.md)).\n\
    \        bias_regularizer: Regularizer function applied to the bias vector\n \
    \           (see [regularizer](../regularizers.md)).\n        activity_regularizer:\
    \ Regularizer function applied to\n            the output of the layer (its \"\
    activation\").\n            (see [regularizer](../regularizers.md)).\n       \
    \ kernel_constraint: Constraint function applied to the kernel matrix\n      \
    \      (see [constraints](../constraints.md)).\n        bias_constraint: Constraint\
    \ function applied to the bias vector\n            (see [constraints](../constraints.md)).\n\
    \n    # Input shape\n        4D tensor with shape:\n        `(batch, channels,\
    \ rows, cols)`\n        if `data_format` is `\"channels_first\"`\n        or 4D\
    \ tensor with shape:\n        `(batch, rows, cols, channels)`\n        if `data_format`\
    \ is `\"channels_last\"`.\n\n    # Output shape\n        4D tensor with shape:\n\
    \        `(batch, filters, new_rows, new_cols)`\n        if `data_format` is `\"\
    channels_first\"`\n        or 4D tensor with shape:\n        `(batch, new_rows,\
    \ new_cols, filters)`\n        if `data_format` is `\"channels_last\"`.\n    \
    \    `rows` and `cols` values might have changed due to padding.\n        If `output_padding`\
    \ is specified:\n\n        ```\n        new_rows = ((rows - 1) * strides[0] +\
    \ kernel_size[0]\n                    - 2 * padding[0] + output_padding[0])\n\
    \        new_cols = ((cols - 1) * strides[1] + kernel_size[1]\n              \
    \      - 2 * padding[1] + output_padding[1])\n        ```\n\n    # References\n\
    \        - [A guide to convolution arithmetic for deep learning]\n          (https://arxiv.org/abs/1603.07285v1)\n\
    \        - [Deconvolutional Networks]\n          (http://www.matthewzeiler.com/pubs/cvpr2010/cvpr2010.pdf)\n\
    \    \"\"\"\n\n    @interfaces.legacy_deconv2d_support\n    def __init__(self,\
    \ filters,\n                 kernel_size,\n                 strides=(1, 1),\n\
    \                 padding='valid',\n                 output_padding=None,\n  \
    \               data_format=None,\n                 dilation_rate=(1, 1),\n  \
    \               activation=None,\n                 use_bias=True,\n          \
    \       kernel_initializer='glorot_uniform',\n                 bias_initializer='zeros',\n\
    \                 kernel_regularizer=None,\n                 bias_regularizer=None,\n\
    \                 activity_regularizer=None,\n                 kernel_constraint=None,\n\
    \                 bias_constraint=None,\n                 **kwargs):\n       \
    \ super(Conv2DTranspose, self).__init__(\n            filters,\n            kernel_size,\n\
    \            strides=strides,\n            padding=padding,\n            data_format=data_format,\n\
    \            dilation_rate=dilation_rate,\n            activation=activation,\n\
    \            use_bias=use_bias,\n            kernel_initializer=kernel_initializer,\n\
    \            bias_initializer=bias_initializer,\n            kernel_regularizer=kernel_regularizer,\n\
    \            bias_regularizer=bias_regularizer,\n            activity_regularizer=activity_regularizer,\n\
    \            kernel_constraint=kernel_constraint,\n            bias_constraint=bias_constraint,\n\
    \            **kwargs)\n\n        self.output_padding = output_padding\n     \
    \   if self.output_padding is not None:\n            self.output_padding = conv_utils.normalize_tuple(\n\
    \                self.output_padding, 2, 'output_padding')\n            for stride,\
    \ out_pad in zip(self.strides, self.output_padding):\n                if out_pad\
    \ >= stride:\n                    raise ValueError('Stride ' + str(self.strides)\
    \ + ' must be '\n                                     'greater than output padding\
    \ ' +\n                                     str(self.output_padding))\n\n    def\
    \ build(self, input_shape):\n        if len(input_shape) != 4:\n            raise\
    \ ValueError('Inputs should have rank ' +\n                             str(4)\
    \ +\n                             '; Received input shape:', str(input_shape))\n\
    \        if self.data_format == 'channels_first':\n            channel_axis =\
    \ 1\n        else:\n            channel_axis = -1\n        if input_shape[channel_axis]\
    \ is None:\n            raise ValueError('The channel dimension of the inputs\
    \ '\n                             'should be defined. Found `None`.')\n      \
    \  input_dim = input_shape[channel_axis]\n        kernel_shape = self.kernel_size\
    \ + (self.filters, input_dim)\n\n        self.kernel = self.add_weight(shape=kernel_shape,\n\
    \                                      initializer=self.kernel_initializer,\n\
    \                                      name='kernel',\n                      \
    \                regularizer=self.kernel_regularizer,\n                      \
    \                constraint=self.kernel_constraint)\n        if self.use_bias:\n\
    \            self.bias = self.add_weight(shape=(self.filters,),\n            \
    \                            initializer=self.bias_initializer,\n            \
    \                            name='bias',\n                                  \
    \      regularizer=self.bias_regularizer,\n                                  \
    \      constraint=self.bias_constraint)\n        else:\n            self.bias\
    \ = None\n        # Set input spec.\n        self.input_spec = InputSpec(ndim=4,\
    \ axes={channel_axis: input_dim})\n        self.built = True\n\n    def call(self,\
    \ inputs):\n        input_shape = K.shape(inputs)\n        batch_size = input_shape[0]\n\
    \        if self.data_format == 'channels_first':\n            h_axis, w_axis\
    \ = 2, 3\n        else:\n            h_axis, w_axis = 1, 2\n\n        height,\
    \ width = input_shape[h_axis], input_shape[w_axis]\n        kernel_h, kernel_w\
    \ = self.kernel_size\n        stride_h, stride_w = self.strides\n        if self.output_padding\
    \ is None:\n            out_pad_h = out_pad_w = None\n        else:\n        \
    \    out_pad_h, out_pad_w = self.output_padding\n\n        # Infer the dynamic\
    \ output shape:\n        out_height = conv_utils.deconv_length(height,\n     \
    \                                         stride_h, kernel_h,\n              \
    \                                self.padding,\n                             \
    \                 out_pad_h,\n                                              self.dilation_rate[0])\n\
    \        out_width = conv_utils.deconv_length(width,\n                       \
    \                      stride_w, kernel_w,\n                                 \
    \            self.padding,\n                                             out_pad_w,\n\
    \                                             self.dilation_rate[1])\n       \
    \ if self.data_format == 'channels_first':\n            output_shape = (batch_size,\
    \ self.filters, out_height, out_width)\n        else:\n            output_shape\
    \ = (batch_size, out_height, out_width, self.filters)\n\n        outputs = K.conv2d_transpose(\n\
    \            inputs,\n            self.kernel,\n            output_shape,\n  \
    \          self.strides,\n            padding=self.padding,\n            data_format=self.data_format,\n\
    \            dilation_rate=self.dilation_rate)\n\n        if self.use_bias:\n\
    \            outputs = K.bias_add(\n                outputs,\n               \
    \ self.bias,\n                data_format=self.data_format)\n\n        if self.activation\
    \ is not None:\n            return self.activation(outputs)\n        return outputs\n\
    \n    def compute_output_shape(self, input_shape):\n        output_shape = list(input_shape)\n\
    \        if self.data_format == 'channels_first':\n            c_axis, h_axis,\
    \ w_axis = 1, 2, 3\n        else:\n            c_axis, h_axis, w_axis = 3, 1,\
    \ 2\n\n        kernel_h, kernel_w = self.kernel_size\n        stride_h, stride_w\
    \ = self.strides\n        if self.output_padding is None:\n            out_pad_h\
    \ = out_pad_w = None\n        else:\n            out_pad_h, out_pad_w = self.output_padding\n\
    \n        output_shape[c_axis] = self.filters\n        output_shape[h_axis] =\
    \ conv_utils.deconv_length(output_shape[h_axis],\n                           \
    \                             stride_h,\n                                    \
    \                    kernel_h,\n                                             \
    \           self.padding,\n                                                  \
    \      out_pad_h,\n                                                        self.dilation_rate[0])\n\
    \        output_shape[w_axis] = conv_utils.deconv_length(output_shape[w_axis],\n\
    \                                                        stride_w,\n         \
    \                                               kernel_w,\n                  \
    \                                      self.padding,\n                       \
    \                                 out_pad_w,\n                               \
    \                         self.dilation_rate[1])\n        return tuple(output_shape)\n\
    \n    def get_config(self):\n        config = super(Conv2DTranspose, self).get_config()\n\
    \        config['output_padding'] = self.output_padding\n        return config\n"
  sourcefile: D:\Python36\lib\site-packages\keras\layers\convolutional.py
- doc: "Transposed convolution layer (sometimes called Deconvolution).\n\nThe need\
    \ for transposed convolutions generally arises\nfrom the desire to use a transformation\
    \ going in the opposite direction\nof a normal convolution, i.e., from something\
    \ that has the shape of the\noutput of some convolution to something that has\
    \ the shape of its input\nwhile maintaining a connectivity pattern that is compatible\
    \ with\nsaid convolution.\n\nWhen using this layer as the first layer in a model,\n\
    provide the keyword argument `input_shape`\n(tuple of integers, does not include\
    \ the sample axis),\ne.g. `input_shape=(128, 128, 128, 3)` for a 128x128x128 volume\
    \ with 3 channels\nif `data_format=\"channels_last\"`.\n\n# Arguments\n    filters:\
    \ Integer, the dimensionality of the output space\n        (i.e. the number of\
    \ output filters in the convolution).\n    kernel_size: An integer or tuple/list\
    \ of 3 integers, specifying the\n        depth, height and width of the 3D convolution\
    \ window.\n        Can be a single integer to specify the same value for\n   \
    \     all spatial dimensions.\n    strides: An integer or tuple/list of 3 integers,\n\
    \        specifying the strides of the convolution\n        along the depth, height\
    \ and width.\n        Can be a single integer to specify the same value for\n\
    \        all spatial dimensions.\n        Specifying any stride value != 1 is\
    \ incompatible with specifying\n        any `dilation_rate` value != 1.\n    padding:\
    \ one of `\"valid\"` or `\"same\"` (case-insensitive).\n    output_padding: An\
    \ integer or tuple/list of 3 integers,\n        specifying the amount of padding\
    \ along the depth, height, and\n        width.\n        Can be a single integer\
    \ to specify the same value for all\n        spatial dimensions.\n        The\
    \ amount of output padding along a given dimension must be\n        lower than\
    \ the stride along that same dimension.\n        If set to `None` (default), the\
    \ output shape is inferred.\n    data_format: A string,\n        one of `\"channels_last\"\
    ` or `\"channels_first\"`.\n        The ordering of the dimensions in the inputs.\n\
    \        `\"channels_last\"` corresponds to inputs with shape\n        `(batch,\
    \ depth, height, width, channels)` while `\"channels_first\"`\n        corresponds\
    \ to inputs with shape\n        `(batch, channels, depth, height, width)`.\n \
    \       It defaults to the `image_data_format` value found in your\n        Keras\
    \ config file at `~/.keras/keras.json`.\n        If you never set it, then it\
    \ will be \"channels_last\".\n    dilation_rate: an integer or tuple/list of 3\
    \ integers, specifying\n        the dilation rate to use for dilated convolution.\n\
    \        Can be a single integer to specify the same value for\n        all spatial\
    \ dimensions.\n        Currently, specifying any `dilation_rate` value != 1 is\n\
    \        incompatible with specifying any stride value != 1.\n    activation:\
    \ Activation function to use\n        (see [activations](../activations.md)).\n\
    \        If you don't specify anything, no activation is applied\n        (ie.\
    \ \"linear\" activation: `a(x) = x`).\n    use_bias: Boolean, whether the layer\
    \ uses a bias vector.\n    kernel_initializer: Initializer for the `kernel` weights\
    \ matrix\n        (see [initializers](../initializers.md)).\n    bias_initializer:\
    \ Initializer for the bias vector\n        (see [initializers](../initializers.md)).\n\
    \    kernel_regularizer: Regularizer function applied to\n        the `kernel`\
    \ weights matrix\n        (see [regularizer](../regularizers.md)).\n    bias_regularizer:\
    \ Regularizer function applied to the bias vector\n        (see [regularizer](../regularizers.md)).\n\
    \    activity_regularizer: Regularizer function applied to\n        the output\
    \ of the layer (its \"activation\").\n        (see [regularizer](../regularizers.md)).\n\
    \    kernel_constraint: Constraint function applied to the kernel matrix\n   \
    \     (see [constraints](../constraints.md)).\n    bias_constraint: Constraint\
    \ function applied to the bias vector\n        (see [constraints](../constraints.md)).\n\
    \n# Input shape\n    5D tensor with shape:\n    `(batch, channels, depth, rows,\
    \ cols)`\n    if `data_format` is `\"channels_first\"`\n    or 5D tensor with\
    \ shape:\n    `(batch, depth, rows, cols, channels)`\n    if `data_format` is\
    \ `\"channels_last\"`.\n\n# Output shape\n    5D tensor with shape:\n    `(batch,\
    \ filters, new_depth, new_rows, new_cols)`\n    if `data_format` is `\"channels_first\"\
    `\n    or 5D tensor with shape:\n    `(batch, new_depth, new_rows, new_cols, filters)`\n\
    \    if `data_format` is `\"channels_last\"`.\n    `depth` and `rows` and `cols`\
    \ values might have changed due to padding.\n    If `output_padding` is specified::\n\
    \n    ```\n    new_depth = ((depth - 1) * strides[0] + kernel_size[0]\n      \
    \           - 2 * padding[0] + output_padding[0])\n    new_rows = ((rows - 1)\
    \ * strides[1] + kernel_size[1]\n                - 2 * padding[1] + output_padding[1])\n\
    \    new_cols = ((cols - 1) * strides[2] + kernel_size[2]\n                - 2\
    \ * padding[2] + output_padding[2])\n    ```\n\n# References\n    - [A guide to\
    \ convolution arithmetic for deep learning]\n      (https://arxiv.org/abs/1603.07285v1)\n\
    \    - [Deconvolutional Networks]\n      (http://www.matthewzeiler.com/pubs/cvpr2010/cvpr2010.pdf)"
  kind: Layer
  name: Conv3DTranspose
  parameters:
  - {kind: any, name: filters}
  - {kind: any, name: kernel_size}
  - {defaultValue: '(1, 1, 1)', kind: any, name: strides}
  - {defaultValue: valid, kind: any, name: padding}
  - {defaultValue: None, kind: any, name: output_padding}
  - {defaultValue: None, kind: any, name: data_format}
  - {defaultValue: None, kind: any, name: activation}
  - {defaultValue: 'True', kind: any, name: use_bias}
  - {defaultValue: glorot_uniform, kind: any, name: kernel_initializer}
  - {defaultValue: zeros, kind: any, name: bias_initializer}
  - {defaultValue: None, kind: any, name: kernel_regularizer}
  - {defaultValue: None, kind: any, name: bias_regularizer}
  - {defaultValue: None, kind: any, name: activity_regularizer}
  - {defaultValue: None, kind: any, name: kernel_constraint}
  - {defaultValue: None, kind: any, name: bias_constraint}
  - {defaultValue: 'true', name: trainable, type: bool}
  source: "class Conv3DTranspose(Conv3D):\n    \"\"\"Transposed convolution layer\
    \ (sometimes called Deconvolution).\n\n    The need for transposed convolutions\
    \ generally arises\n    from the desire to use a transformation going in the opposite\
    \ direction\n    of a normal convolution, i.e., from something that has the shape\
    \ of the\n    output of some convolution to something that has the shape of its\
    \ input\n    while maintaining a connectivity pattern that is compatible with\n\
    \    said convolution.\n\n    When using this layer as the first layer in a model,\n\
    \    provide the keyword argument `input_shape`\n    (tuple of integers, does\
    \ not include the sample axis),\n    e.g. `input_shape=(128, 128, 128, 3)` for\
    \ a 128x128x128 volume with 3 channels\n    if `data_format=\"channels_last\"\
    `.\n\n    # Arguments\n        filters: Integer, the dimensionality of the output\
    \ space\n            (i.e. the number of output filters in the convolution).\n\
    \        kernel_size: An integer or tuple/list of 3 integers, specifying the\n\
    \            depth, height and width of the 3D convolution window.\n         \
    \   Can be a single integer to specify the same value for\n            all spatial\
    \ dimensions.\n        strides: An integer or tuple/list of 3 integers,\n    \
    \        specifying the strides of the convolution\n            along the depth,\
    \ height and width.\n            Can be a single integer to specify the same value\
    \ for\n            all spatial dimensions.\n            Specifying any stride\
    \ value != 1 is incompatible with specifying\n            any `dilation_rate`\
    \ value != 1.\n        padding: one of `\"valid\"` or `\"same\"` (case-insensitive).\n\
    \        output_padding: An integer or tuple/list of 3 integers,\n           \
    \ specifying the amount of padding along the depth, height, and\n            width.\n\
    \            Can be a single integer to specify the same value for all\n     \
    \       spatial dimensions.\n            The amount of output padding along a\
    \ given dimension must be\n            lower than the stride along that same dimension.\n\
    \            If set to `None` (default), the output shape is inferred.\n     \
    \   data_format: A string,\n            one of `\"channels_last\"` or `\"channels_first\"\
    `.\n            The ordering of the dimensions in the inputs.\n            `\"\
    channels_last\"` corresponds to inputs with shape\n            `(batch, depth,\
    \ height, width, channels)` while `\"channels_first\"`\n            corresponds\
    \ to inputs with shape\n            `(batch, channels, depth, height, width)`.\n\
    \            It defaults to the `image_data_format` value found in your\n    \
    \        Keras config file at `~/.keras/keras.json`.\n            If you never\
    \ set it, then it will be \"channels_last\".\n        dilation_rate: an integer\
    \ or tuple/list of 3 integers, specifying\n            the dilation rate to use\
    \ for dilated convolution.\n            Can be a single integer to specify the\
    \ same value for\n            all spatial dimensions.\n            Currently,\
    \ specifying any `dilation_rate` value != 1 is\n            incompatible with\
    \ specifying any stride value != 1.\n        activation: Activation function to\
    \ use\n            (see [activations](../activations.md)).\n            If you\
    \ don't specify anything, no activation is applied\n            (ie. \"linear\"\
    \ activation: `a(x) = x`).\n        use_bias: Boolean, whether the layer uses\
    \ a bias vector.\n        kernel_initializer: Initializer for the `kernel` weights\
    \ matrix\n            (see [initializers](../initializers.md)).\n        bias_initializer:\
    \ Initializer for the bias vector\n            (see [initializers](../initializers.md)).\n\
    \        kernel_regularizer: Regularizer function applied to\n            the\
    \ `kernel` weights matrix\n            (see [regularizer](../regularizers.md)).\n\
    \        bias_regularizer: Regularizer function applied to the bias vector\n \
    \           (see [regularizer](../regularizers.md)).\n        activity_regularizer:\
    \ Regularizer function applied to\n            the output of the layer (its \"\
    activation\").\n            (see [regularizer](../regularizers.md)).\n       \
    \ kernel_constraint: Constraint function applied to the kernel matrix\n      \
    \      (see [constraints](../constraints.md)).\n        bias_constraint: Constraint\
    \ function applied to the bias vector\n            (see [constraints](../constraints.md)).\n\
    \n    # Input shape\n        5D tensor with shape:\n        `(batch, channels,\
    \ depth, rows, cols)`\n        if `data_format` is `\"channels_first\"`\n    \
    \    or 5D tensor with shape:\n        `(batch, depth, rows, cols, channels)`\n\
    \        if `data_format` is `\"channels_last\"`.\n\n    # Output shape\n    \
    \    5D tensor with shape:\n        `(batch, filters, new_depth, new_rows, new_cols)`\n\
    \        if `data_format` is `\"channels_first\"`\n        or 5D tensor with shape:\n\
    \        `(batch, new_depth, new_rows, new_cols, filters)`\n        if `data_format`\
    \ is `\"channels_last\"`.\n        `depth` and `rows` and `cols` values might\
    \ have changed due to padding.\n        If `output_padding` is specified::\n\n\
    \        ```\n        new_depth = ((depth - 1) * strides[0] + kernel_size[0]\n\
    \                     - 2 * padding[0] + output_padding[0])\n        new_rows\
    \ = ((rows - 1) * strides[1] + kernel_size[1]\n                    - 2 * padding[1]\
    \ + output_padding[1])\n        new_cols = ((cols - 1) * strides[2] + kernel_size[2]\n\
    \                    - 2 * padding[2] + output_padding[2])\n        ```\n\n  \
    \  # References\n        - [A guide to convolution arithmetic for deep learning]\n\
    \          (https://arxiv.org/abs/1603.07285v1)\n        - [Deconvolutional Networks]\n\
    \          (http://www.matthewzeiler.com/pubs/cvpr2010/cvpr2010.pdf)\n    \"\"\
    \"\n\n    def __init__(self, filters,\n                 kernel_size,\n       \
    \          strides=(1, 1, 1),\n                 padding='valid',\n           \
    \      output_padding=None,\n                 data_format=None,\n            \
    \     activation=None,\n                 use_bias=True,\n                 kernel_initializer='glorot_uniform',\n\
    \                 bias_initializer='zeros',\n                 kernel_regularizer=None,\n\
    \                 bias_regularizer=None,\n                 activity_regularizer=None,\n\
    \                 kernel_constraint=None,\n                 bias_constraint=None,\n\
    \                 **kwargs):\n        super(Conv3DTranspose, self).__init__(\n\
    \            filters,\n            kernel_size,\n            strides=strides,\n\
    \            padding=padding,\n            data_format=data_format,\n        \
    \    activation=activation,\n            use_bias=use_bias,\n            kernel_initializer=kernel_initializer,\n\
    \            bias_initializer=bias_initializer,\n            kernel_regularizer=kernel_regularizer,\n\
    \            bias_regularizer=bias_regularizer,\n            activity_regularizer=activity_regularizer,\n\
    \            kernel_constraint=kernel_constraint,\n            bias_constraint=bias_constraint,\n\
    \            **kwargs)\n\n        self.output_padding = output_padding\n     \
    \   if self.output_padding is not None:\n            self.output_padding = conv_utils.normalize_tuple(\n\
    \                self.output_padding, 3, 'output_padding')\n            for stride,\
    \ out_pad in zip(self.strides, self.output_padding):\n                if out_pad\
    \ >= stride:\n                    raise ValueError('Stride ' + str(self.strides)\
    \ + ' must be '\n                                     'greater than output padding\
    \ ' +\n                                     str(self.output_padding))\n\n    def\
    \ build(self, input_shape):\n        if len(input_shape) != 5:\n            raise\
    \ ValueError('Inputs should have rank ' +\n                             str(5)\
    \ +\n                             '; Received input shape:', str(input_shape))\n\
    \        if self.data_format == 'channels_first':\n            channel_axis =\
    \ 1\n        else:\n            channel_axis = -1\n        if input_shape[channel_axis]\
    \ is None:\n            raise ValueError('The channel dimension of the inputs\
    \ '\n                             'should be defined. Found `None`.')\n      \
    \  input_dim = input_shape[channel_axis]\n        kernel_shape = self.kernel_size\
    \ + (self.filters, input_dim)\n\n        self.kernel = self.add_weight(shape=kernel_shape,\n\
    \                                      initializer=self.kernel_initializer,\n\
    \                                      name='kernel',\n                      \
    \                regularizer=self.kernel_regularizer,\n                      \
    \                constraint=self.kernel_constraint)\n        if self.use_bias:\n\
    \            self.bias = self.add_weight(shape=(self.filters,),\n            \
    \                            initializer=self.bias_initializer,\n            \
    \                            name='bias',\n                                  \
    \      regularizer=self.bias_regularizer,\n                                  \
    \      constraint=self.bias_constraint)\n        else:\n            self.bias\
    \ = None\n        # Set input spec.\n        self.input_spec = InputSpec(ndim=5,\
    \ axes={channel_axis: input_dim})\n        self.built = True\n\n    def call(self,\
    \ inputs):\n        input_shape = K.shape(inputs)\n        batch_size = input_shape[0]\n\
    \        if self.data_format == 'channels_first':\n            d_axis, h_axis,\
    \ w_axis = 2, 3, 4\n        else:\n            d_axis, h_axis, w_axis = 1, 2,\
    \ 3\n\n        depth = input_shape[d_axis]\n        height = input_shape[h_axis]\n\
    \        width = input_shape[w_axis]\n\n        kernel_d, kernel_h, kernel_w =\
    \ self.kernel_size\n        stride_d, stride_h, stride_w = self.strides\n    \
    \    if self.output_padding is None:\n            out_pad_d = out_pad_h = out_pad_w\
    \ = None\n        else:\n            out_pad_d, out_pad_h, out_pad_w = self.output_padding\n\
    \n        # Infer the dynamic output shape:\n        out_depth = conv_utils.deconv_length(depth,\n\
    \                                             stride_d, kernel_d,\n          \
    \                                   self.padding,\n                          \
    \                   out_pad_d)\n        out_height = conv_utils.deconv_length(height,\n\
    \                                              stride_h, kernel_h,\n         \
    \                                     self.padding,\n                        \
    \                      out_pad_h)\n        out_width = conv_utils.deconv_length(width,\n\
    \                                             stride_w, kernel_w,\n          \
    \                                   self.padding,\n                          \
    \                   out_pad_w)\n\n        if self.data_format == 'channels_first':\n\
    \            output_shape = (batch_size, self.filters,\n                     \
    \       out_depth, out_height, out_width)\n        else:\n            output_shape\
    \ = (batch_size, out_depth,\n                            out_height, out_width,\
    \ self.filters)\n\n        outputs = K.conv3d_transpose(inputs,\n            \
    \                         self.kernel,\n                                     output_shape,\n\
    \                                     self.strides,\n                        \
    \             padding=self.padding,\n                                     data_format=self.data_format)\n\
    \n        if self.use_bias:\n            outputs = K.bias_add(\n             \
    \   outputs,\n                self.bias,\n                data_format=self.data_format)\n\
    \n        if self.activation is not None:\n            return self.activation(outputs)\n\
    \        return outputs\n\n    def compute_output_shape(self, input_shape):\n\
    \        output_shape = list(input_shape)\n        if self.data_format == 'channels_first':\n\
    \            c_axis, d_axis, h_axis, w_axis = 1, 2, 3, 4\n        else:\n    \
    \        c_axis, d_axis, h_axis, w_axis = 4, 1, 2, 3\n\n        kernel_d, kernel_h,\
    \ kernel_w = self.kernel_size\n        stride_d, stride_h, stride_w = self.strides\n\
    \        if self.output_padding is None:\n            out_pad_d = out_pad_h =\
    \ out_pad_w = None\n        else:\n            out_pad_d, out_pad_h, out_pad_w\
    \ = self.output_padding\n\n        output_shape[c_axis] = self.filters\n     \
    \   output_shape[d_axis] = conv_utils.deconv_length(output_shape[d_axis],\n  \
    \                                                      stride_d,\n           \
    \                                             kernel_d,\n                    \
    \                                    self.padding,\n                         \
    \                               out_pad_d)\n        output_shape[h_axis] = conv_utils.deconv_length(output_shape[h_axis],\n\
    \                                                        stride_h,\n         \
    \                                               kernel_h,\n                  \
    \                                      self.padding,\n                       \
    \                                 out_pad_h)\n        output_shape[w_axis] = conv_utils.deconv_length(output_shape[w_axis],\n\
    \                                                        stride_w,\n         \
    \                                               kernel_w,\n                  \
    \                                      self.padding,\n                       \
    \                                 out_pad_w)\n\n        return tuple(output_shape)\n\
    \n    def get_config(self):\n        config = super(Conv3DTranspose, self).get_config()\n\
    \        config.pop('dilation_rate')\n        config['output_padding'] = self.output_padding\n\
    \        return config\n"
  sourcefile: D:\Python36\lib\site-packages\keras\layers\convolutional.py
- doc: "Transposed convolution layer (sometimes called Deconvolution).\n\nThe need\
    \ for transposed convolutions generally arises\nfrom the desire to use a transformation\
    \ going in the opposite direction\nof a normal convolution, i.e., from something\
    \ that has the shape of the\noutput of some convolution to something that has\
    \ the shape of its input\nwhile maintaining a connectivity pattern that is compatible\
    \ with\nsaid convolution.\n\nWhen using this layer as the first layer in a model,\n\
    provide the keyword argument `input_shape`\n(tuple of integers, does not include\
    \ the sample axis),\ne.g. `input_shape=(128, 128, 3)` for 128x128 RGB pictures\n\
    in `data_format=\"channels_last\"`.\n\n# Arguments\n    filters: Integer, the\
    \ dimensionality of the output space\n        (i.e. the number of output filters\
    \ in the convolution).\n    kernel_size: An integer or tuple/list of 2 integers,\
    \ specifying the\n        height and width of the 2D convolution window.\n   \
    \     Can be a single integer to specify the same value for\n        all spatial\
    \ dimensions.\n    strides: An integer or tuple/list of 2 integers,\n        specifying\
    \ the strides of the convolution\n        along the height and width.\n      \
    \  Can be a single integer to specify the same value for\n        all spatial\
    \ dimensions.\n        Specifying any stride value != 1 is incompatible with specifying\n\
    \        any `dilation_rate` value != 1.\n    padding: one of `\"valid\"` or `\"\
    same\"` (case-insensitive).\n    output_padding: An integer or tuple/list of 2\
    \ integers,\n        specifying the amount of padding along the height and width\n\
    \        of the output tensor.\n        Can be a single integer to specify the\
    \ same value for all\n        spatial dimensions.\n        The amount of output\
    \ padding along a given dimension must be\n        lower than the stride along\
    \ that same dimension.\n        If set to `None` (default), the output shape is\
    \ inferred.\n    data_format: A string,\n        one of `\"channels_last\"` or\
    \ `\"channels_first\"`.\n        The ordering of the dimensions in the inputs.\n\
    \        `\"channels_last\"` corresponds to inputs with shape\n        `(batch,\
    \ height, width, channels)` while `\"channels_first\"`\n        corresponds to\
    \ inputs with shape\n        `(batch, channels, height, width)`.\n        It defaults\
    \ to the `image_data_format` value found in your\n        Keras config file at\
    \ `~/.keras/keras.json`.\n        If you never set it, then it will be \"channels_last\"\
    .\n    dilation_rate: an integer or tuple/list of 2 integers, specifying\n   \
    \     the dilation rate to use for dilated convolution.\n        Can be a single\
    \ integer to specify the same value for\n        all spatial dimensions.\n   \
    \     Currently, specifying any `dilation_rate` value != 1 is\n        incompatible\
    \ with specifying any stride value != 1.\n    activation: Activation function\
    \ to use\n        (see [activations](../activations.md)).\n        If you don't\
    \ specify anything, no activation is applied\n        (ie. \"linear\" activation:\
    \ `a(x) = x`).\n    use_bias: Boolean, whether the layer uses a bias vector.\n\
    \    kernel_initializer: Initializer for the `kernel` weights matrix\n       \
    \ (see [initializers](../initializers.md)).\n    bias_initializer: Initializer\
    \ for the bias vector\n        (see [initializers](../initializers.md)).\n   \
    \ kernel_regularizer: Regularizer function applied to\n        the `kernel` weights\
    \ matrix\n        (see [regularizer](../regularizers.md)).\n    bias_regularizer:\
    \ Regularizer function applied to the bias vector\n        (see [regularizer](../regularizers.md)).\n\
    \    activity_regularizer: Regularizer function applied to\n        the output\
    \ of the layer (its \"activation\").\n        (see [regularizer](../regularizers.md)).\n\
    \    kernel_constraint: Constraint function applied to the kernel matrix\n   \
    \     (see [constraints](../constraints.md)).\n    bias_constraint: Constraint\
    \ function applied to the bias vector\n        (see [constraints](../constraints.md)).\n\
    \n# Input shape\n    4D tensor with shape:\n    `(batch, channels, rows, cols)`\n\
    \    if `data_format` is `\"channels_first\"`\n    or 4D tensor with shape:\n\
    \    `(batch, rows, cols, channels)`\n    if `data_format` is `\"channels_last\"\
    `.\n\n# Output shape\n    4D tensor with shape:\n    `(batch, filters, new_rows,\
    \ new_cols)`\n    if `data_format` is `\"channels_first\"`\n    or 4D tensor with\
    \ shape:\n    `(batch, new_rows, new_cols, filters)`\n    if `data_format` is\
    \ `\"channels_last\"`.\n    `rows` and `cols` values might have changed due to\
    \ padding.\n    If `output_padding` is specified:\n\n    ```\n    new_rows = ((rows\
    \ - 1) * strides[0] + kernel_size[0]\n                - 2 * padding[0] + output_padding[0])\n\
    \    new_cols = ((cols - 1) * strides[1] + kernel_size[1]\n                - 2\
    \ * padding[1] + output_padding[1])\n    ```\n\n# References\n    - [A guide to\
    \ convolution arithmetic for deep learning]\n      (https://arxiv.org/abs/1603.07285v1)\n\
    \    - [Deconvolutional Networks]\n      (http://www.matthewzeiler.com/pubs/cvpr2010/cvpr2010.pdf)"
  kind: Layer
  name: Conv2DTranspose
  parameters:
  - {kind: any, name: filters}
  - {kind: any, name: kernel_size}
  - {defaultValue: '(1, 1)', kind: any, name: strides}
  - {defaultValue: valid, kind: any, name: padding}
  - {defaultValue: None, kind: any, name: output_padding}
  - {defaultValue: None, kind: any, name: data_format}
  - {defaultValue: '(1, 1)', kind: any, name: dilation_rate}
  - {defaultValue: None, kind: any, name: activation}
  - {defaultValue: 'True', kind: any, name: use_bias}
  - {defaultValue: glorot_uniform, kind: any, name: kernel_initializer}
  - {defaultValue: zeros, kind: any, name: bias_initializer}
  - {defaultValue: None, kind: any, name: kernel_regularizer}
  - {defaultValue: None, kind: any, name: bias_regularizer}
  - {defaultValue: None, kind: any, name: activity_regularizer}
  - {defaultValue: None, kind: any, name: kernel_constraint}
  - {defaultValue: None, kind: any, name: bias_constraint}
  - {defaultValue: 'true', name: trainable, type: bool}
  source: "class Conv2DTranspose(Conv2D):\n    \"\"\"Transposed convolution layer\
    \ (sometimes called Deconvolution).\n\n    The need for transposed convolutions\
    \ generally arises\n    from the desire to use a transformation going in the opposite\
    \ direction\n    of a normal convolution, i.e., from something that has the shape\
    \ of the\n    output of some convolution to something that has the shape of its\
    \ input\n    while maintaining a connectivity pattern that is compatible with\n\
    \    said convolution.\n\n    When using this layer as the first layer in a model,\n\
    \    provide the keyword argument `input_shape`\n    (tuple of integers, does\
    \ not include the sample axis),\n    e.g. `input_shape=(128, 128, 3)` for 128x128\
    \ RGB pictures\n    in `data_format=\"channels_last\"`.\n\n    # Arguments\n \
    \       filters: Integer, the dimensionality of the output space\n           \
    \ (i.e. the number of output filters in the convolution).\n        kernel_size:\
    \ An integer or tuple/list of 2 integers, specifying the\n            height and\
    \ width of the 2D convolution window.\n            Can be a single integer to\
    \ specify the same value for\n            all spatial dimensions.\n        strides:\
    \ An integer or tuple/list of 2 integers,\n            specifying the strides\
    \ of the convolution\n            along the height and width.\n            Can\
    \ be a single integer to specify the same value for\n            all spatial dimensions.\n\
    \            Specifying any stride value != 1 is incompatible with specifying\n\
    \            any `dilation_rate` value != 1.\n        padding: one of `\"valid\"\
    ` or `\"same\"` (case-insensitive).\n        output_padding: An integer or tuple/list\
    \ of 2 integers,\n            specifying the amount of padding along the height\
    \ and width\n            of the output tensor.\n            Can be a single integer\
    \ to specify the same value for all\n            spatial dimensions.\n       \
    \     The amount of output padding along a given dimension must be\n         \
    \   lower than the stride along that same dimension.\n            If set to `None`\
    \ (default), the output shape is inferred.\n        data_format: A string,\n \
    \           one of `\"channels_last\"` or `\"channels_first\"`.\n            The\
    \ ordering of the dimensions in the inputs.\n            `\"channels_last\"` corresponds\
    \ to inputs with shape\n            `(batch, height, width, channels)` while `\"\
    channels_first\"`\n            corresponds to inputs with shape\n            `(batch,\
    \ channels, height, width)`.\n            It defaults to the `image_data_format`\
    \ value found in your\n            Keras config file at `~/.keras/keras.json`.\n\
    \            If you never set it, then it will be \"channels_last\".\n       \
    \ dilation_rate: an integer or tuple/list of 2 integers, specifying\n        \
    \    the dilation rate to use for dilated convolution.\n            Can be a single\
    \ integer to specify the same value for\n            all spatial dimensions.\n\
    \            Currently, specifying any `dilation_rate` value != 1 is\n       \
    \     incompatible with specifying any stride value != 1.\n        activation:\
    \ Activation function to use\n            (see [activations](../activations.md)).\n\
    \            If you don't specify anything, no activation is applied\n       \
    \     (ie. \"linear\" activation: `a(x) = x`).\n        use_bias: Boolean, whether\
    \ the layer uses a bias vector.\n        kernel_initializer: Initializer for the\
    \ `kernel` weights matrix\n            (see [initializers](../initializers.md)).\n\
    \        bias_initializer: Initializer for the bias vector\n            (see [initializers](../initializers.md)).\n\
    \        kernel_regularizer: Regularizer function applied to\n            the\
    \ `kernel` weights matrix\n            (see [regularizer](../regularizers.md)).\n\
    \        bias_regularizer: Regularizer function applied to the bias vector\n \
    \           (see [regularizer](../regularizers.md)).\n        activity_regularizer:\
    \ Regularizer function applied to\n            the output of the layer (its \"\
    activation\").\n            (see [regularizer](../regularizers.md)).\n       \
    \ kernel_constraint: Constraint function applied to the kernel matrix\n      \
    \      (see [constraints](../constraints.md)).\n        bias_constraint: Constraint\
    \ function applied to the bias vector\n            (see [constraints](../constraints.md)).\n\
    \n    # Input shape\n        4D tensor with shape:\n        `(batch, channels,\
    \ rows, cols)`\n        if `data_format` is `\"channels_first\"`\n        or 4D\
    \ tensor with shape:\n        `(batch, rows, cols, channels)`\n        if `data_format`\
    \ is `\"channels_last\"`.\n\n    # Output shape\n        4D tensor with shape:\n\
    \        `(batch, filters, new_rows, new_cols)`\n        if `data_format` is `\"\
    channels_first\"`\n        or 4D tensor with shape:\n        `(batch, new_rows,\
    \ new_cols, filters)`\n        if `data_format` is `\"channels_last\"`.\n    \
    \    `rows` and `cols` values might have changed due to padding.\n        If `output_padding`\
    \ is specified:\n\n        ```\n        new_rows = ((rows - 1) * strides[0] +\
    \ kernel_size[0]\n                    - 2 * padding[0] + output_padding[0])\n\
    \        new_cols = ((cols - 1) * strides[1] + kernel_size[1]\n              \
    \      - 2 * padding[1] + output_padding[1])\n        ```\n\n    # References\n\
    \        - [A guide to convolution arithmetic for deep learning]\n          (https://arxiv.org/abs/1603.07285v1)\n\
    \        - [Deconvolutional Networks]\n          (http://www.matthewzeiler.com/pubs/cvpr2010/cvpr2010.pdf)\n\
    \    \"\"\"\n\n    @interfaces.legacy_deconv2d_support\n    def __init__(self,\
    \ filters,\n                 kernel_size,\n                 strides=(1, 1),\n\
    \                 padding='valid',\n                 output_padding=None,\n  \
    \               data_format=None,\n                 dilation_rate=(1, 1),\n  \
    \               activation=None,\n                 use_bias=True,\n          \
    \       kernel_initializer='glorot_uniform',\n                 bias_initializer='zeros',\n\
    \                 kernel_regularizer=None,\n                 bias_regularizer=None,\n\
    \                 activity_regularizer=None,\n                 kernel_constraint=None,\n\
    \                 bias_constraint=None,\n                 **kwargs):\n       \
    \ super(Conv2DTranspose, self).__init__(\n            filters,\n            kernel_size,\n\
    \            strides=strides,\n            padding=padding,\n            data_format=data_format,\n\
    \            dilation_rate=dilation_rate,\n            activation=activation,\n\
    \            use_bias=use_bias,\n            kernel_initializer=kernel_initializer,\n\
    \            bias_initializer=bias_initializer,\n            kernel_regularizer=kernel_regularizer,\n\
    \            bias_regularizer=bias_regularizer,\n            activity_regularizer=activity_regularizer,\n\
    \            kernel_constraint=kernel_constraint,\n            bias_constraint=bias_constraint,\n\
    \            **kwargs)\n\n        self.output_padding = output_padding\n     \
    \   if self.output_padding is not None:\n            self.output_padding = conv_utils.normalize_tuple(\n\
    \                self.output_padding, 2, 'output_padding')\n            for stride,\
    \ out_pad in zip(self.strides, self.output_padding):\n                if out_pad\
    \ >= stride:\n                    raise ValueError('Stride ' + str(self.strides)\
    \ + ' must be '\n                                     'greater than output padding\
    \ ' +\n                                     str(self.output_padding))\n\n    def\
    \ build(self, input_shape):\n        if len(input_shape) != 4:\n            raise\
    \ ValueError('Inputs should have rank ' +\n                             str(4)\
    \ +\n                             '; Received input shape:', str(input_shape))\n\
    \        if self.data_format == 'channels_first':\n            channel_axis =\
    \ 1\n        else:\n            channel_axis = -1\n        if input_shape[channel_axis]\
    \ is None:\n            raise ValueError('The channel dimension of the inputs\
    \ '\n                             'should be defined. Found `None`.')\n      \
    \  input_dim = input_shape[channel_axis]\n        kernel_shape = self.kernel_size\
    \ + (self.filters, input_dim)\n\n        self.kernel = self.add_weight(shape=kernel_shape,\n\
    \                                      initializer=self.kernel_initializer,\n\
    \                                      name='kernel',\n                      \
    \                regularizer=self.kernel_regularizer,\n                      \
    \                constraint=self.kernel_constraint)\n        if self.use_bias:\n\
    \            self.bias = self.add_weight(shape=(self.filters,),\n            \
    \                            initializer=self.bias_initializer,\n            \
    \                            name='bias',\n                                  \
    \      regularizer=self.bias_regularizer,\n                                  \
    \      constraint=self.bias_constraint)\n        else:\n            self.bias\
    \ = None\n        # Set input spec.\n        self.input_spec = InputSpec(ndim=4,\
    \ axes={channel_axis: input_dim})\n        self.built = True\n\n    def call(self,\
    \ inputs):\n        input_shape = K.shape(inputs)\n        batch_size = input_shape[0]\n\
    \        if self.data_format == 'channels_first':\n            h_axis, w_axis\
    \ = 2, 3\n        else:\n            h_axis, w_axis = 1, 2\n\n        height,\
    \ width = input_shape[h_axis], input_shape[w_axis]\n        kernel_h, kernel_w\
    \ = self.kernel_size\n        stride_h, stride_w = self.strides\n        if self.output_padding\
    \ is None:\n            out_pad_h = out_pad_w = None\n        else:\n        \
    \    out_pad_h, out_pad_w = self.output_padding\n\n        # Infer the dynamic\
    \ output shape:\n        out_height = conv_utils.deconv_length(height,\n     \
    \                                         stride_h, kernel_h,\n              \
    \                                self.padding,\n                             \
    \                 out_pad_h,\n                                              self.dilation_rate[0])\n\
    \        out_width = conv_utils.deconv_length(width,\n                       \
    \                      stride_w, kernel_w,\n                                 \
    \            self.padding,\n                                             out_pad_w,\n\
    \                                             self.dilation_rate[1])\n       \
    \ if self.data_format == 'channels_first':\n            output_shape = (batch_size,\
    \ self.filters, out_height, out_width)\n        else:\n            output_shape\
    \ = (batch_size, out_height, out_width, self.filters)\n\n        outputs = K.conv2d_transpose(\n\
    \            inputs,\n            self.kernel,\n            output_shape,\n  \
    \          self.strides,\n            padding=self.padding,\n            data_format=self.data_format,\n\
    \            dilation_rate=self.dilation_rate)\n\n        if self.use_bias:\n\
    \            outputs = K.bias_add(\n                outputs,\n               \
    \ self.bias,\n                data_format=self.data_format)\n\n        if self.activation\
    \ is not None:\n            return self.activation(outputs)\n        return outputs\n\
    \n    def compute_output_shape(self, input_shape):\n        output_shape = list(input_shape)\n\
    \        if self.data_format == 'channels_first':\n            c_axis, h_axis,\
    \ w_axis = 1, 2, 3\n        else:\n            c_axis, h_axis, w_axis = 3, 1,\
    \ 2\n\n        kernel_h, kernel_w = self.kernel_size\n        stride_h, stride_w\
    \ = self.strides\n        if self.output_padding is None:\n            out_pad_h\
    \ = out_pad_w = None\n        else:\n            out_pad_h, out_pad_w = self.output_padding\n\
    \n        output_shape[c_axis] = self.filters\n        output_shape[h_axis] =\
    \ conv_utils.deconv_length(output_shape[h_axis],\n                           \
    \                             stride_h,\n                                    \
    \                    kernel_h,\n                                             \
    \           self.padding,\n                                                  \
    \      out_pad_h,\n                                                        self.dilation_rate[0])\n\
    \        output_shape[w_axis] = conv_utils.deconv_length(output_shape[w_axis],\n\
    \                                                        stride_w,\n         \
    \                                               kernel_w,\n                  \
    \                                      self.padding,\n                       \
    \                                 out_pad_w,\n                               \
    \                         self.dilation_rate[1])\n        return tuple(output_shape)\n\
    \n    def get_config(self):\n        config = super(Conv2DTranspose, self).get_config()\n\
    \        config['output_padding'] = self.output_padding\n        return config\n"
  sourcefile: D:\Python36\lib\site-packages\keras\layers\convolutional.py
- doc: "Transposed convolution layer (sometimes called Deconvolution).\n\nThe need\
    \ for transposed convolutions generally arises\nfrom the desire to use a transformation\
    \ going in the opposite direction\nof a normal convolution, i.e., from something\
    \ that has the shape of the\noutput of some convolution to something that has\
    \ the shape of its input\nwhile maintaining a connectivity pattern that is compatible\
    \ with\nsaid convolution.\n\nWhen using this layer as the first layer in a model,\n\
    provide the keyword argument `input_shape`\n(tuple of integers, does not include\
    \ the sample axis),\ne.g. `input_shape=(128, 128, 128, 3)` for a 128x128x128 volume\
    \ with 3 channels\nif `data_format=\"channels_last\"`.\n\n# Arguments\n    filters:\
    \ Integer, the dimensionality of the output space\n        (i.e. the number of\
    \ output filters in the convolution).\n    kernel_size: An integer or tuple/list\
    \ of 3 integers, specifying the\n        depth, height and width of the 3D convolution\
    \ window.\n        Can be a single integer to specify the same value for\n   \
    \     all spatial dimensions.\n    strides: An integer or tuple/list of 3 integers,\n\
    \        specifying the strides of the convolution\n        along the depth, height\
    \ and width.\n        Can be a single integer to specify the same value for\n\
    \        all spatial dimensions.\n        Specifying any stride value != 1 is\
    \ incompatible with specifying\n        any `dilation_rate` value != 1.\n    padding:\
    \ one of `\"valid\"` or `\"same\"` (case-insensitive).\n    output_padding: An\
    \ integer or tuple/list of 3 integers,\n        specifying the amount of padding\
    \ along the depth, height, and\n        width.\n        Can be a single integer\
    \ to specify the same value for all\n        spatial dimensions.\n        The\
    \ amount of output padding along a given dimension must be\n        lower than\
    \ the stride along that same dimension.\n        If set to `None` (default), the\
    \ output shape is inferred.\n    data_format: A string,\n        one of `\"channels_last\"\
    ` or `\"channels_first\"`.\n        The ordering of the dimensions in the inputs.\n\
    \        `\"channels_last\"` corresponds to inputs with shape\n        `(batch,\
    \ depth, height, width, channels)` while `\"channels_first\"`\n        corresponds\
    \ to inputs with shape\n        `(batch, channels, depth, height, width)`.\n \
    \       It defaults to the `image_data_format` value found in your\n        Keras\
    \ config file at `~/.keras/keras.json`.\n        If you never set it, then it\
    \ will be \"channels_last\".\n    dilation_rate: an integer or tuple/list of 3\
    \ integers, specifying\n        the dilation rate to use for dilated convolution.\n\
    \        Can be a single integer to specify the same value for\n        all spatial\
    \ dimensions.\n        Currently, specifying any `dilation_rate` value != 1 is\n\
    \        incompatible with specifying any stride value != 1.\n    activation:\
    \ Activation function to use\n        (see [activations](../activations.md)).\n\
    \        If you don't specify anything, no activation is applied\n        (ie.\
    \ \"linear\" activation: `a(x) = x`).\n    use_bias: Boolean, whether the layer\
    \ uses a bias vector.\n    kernel_initializer: Initializer for the `kernel` weights\
    \ matrix\n        (see [initializers](../initializers.md)).\n    bias_initializer:\
    \ Initializer for the bias vector\n        (see [initializers](../initializers.md)).\n\
    \    kernel_regularizer: Regularizer function applied to\n        the `kernel`\
    \ weights matrix\n        (see [regularizer](../regularizers.md)).\n    bias_regularizer:\
    \ Regularizer function applied to the bias vector\n        (see [regularizer](../regularizers.md)).\n\
    \    activity_regularizer: Regularizer function applied to\n        the output\
    \ of the layer (its \"activation\").\n        (see [regularizer](../regularizers.md)).\n\
    \    kernel_constraint: Constraint function applied to the kernel matrix\n   \
    \     (see [constraints](../constraints.md)).\n    bias_constraint: Constraint\
    \ function applied to the bias vector\n        (see [constraints](../constraints.md)).\n\
    \n# Input shape\n    5D tensor with shape:\n    `(batch, channels, depth, rows,\
    \ cols)`\n    if `data_format` is `\"channels_first\"`\n    or 5D tensor with\
    \ shape:\n    `(batch, depth, rows, cols, channels)`\n    if `data_format` is\
    \ `\"channels_last\"`.\n\n# Output shape\n    5D tensor with shape:\n    `(batch,\
    \ filters, new_depth, new_rows, new_cols)`\n    if `data_format` is `\"channels_first\"\
    `\n    or 5D tensor with shape:\n    `(batch, new_depth, new_rows, new_cols, filters)`\n\
    \    if `data_format` is `\"channels_last\"`.\n    `depth` and `rows` and `cols`\
    \ values might have changed due to padding.\n    If `output_padding` is specified::\n\
    \n    ```\n    new_depth = ((depth - 1) * strides[0] + kernel_size[0]\n      \
    \           - 2 * padding[0] + output_padding[0])\n    new_rows = ((rows - 1)\
    \ * strides[1] + kernel_size[1]\n                - 2 * padding[1] + output_padding[1])\n\
    \    new_cols = ((cols - 1) * strides[2] + kernel_size[2]\n                - 2\
    \ * padding[2] + output_padding[2])\n    ```\n\n# References\n    - [A guide to\
    \ convolution arithmetic for deep learning]\n      (https://arxiv.org/abs/1603.07285v1)\n\
    \    - [Deconvolutional Networks]\n      (http://www.matthewzeiler.com/pubs/cvpr2010/cvpr2010.pdf)"
  kind: Layer
  name: Conv3DTranspose
  parameters:
  - {kind: any, name: filters}
  - {kind: any, name: kernel_size}
  - {defaultValue: '(1, 1, 1)', kind: any, name: strides}
  - {defaultValue: valid, kind: any, name: padding}
  - {defaultValue: None, kind: any, name: output_padding}
  - {defaultValue: None, kind: any, name: data_format}
  - {defaultValue: None, kind: any, name: activation}
  - {defaultValue: 'True', kind: any, name: use_bias}
  - {defaultValue: glorot_uniform, kind: any, name: kernel_initializer}
  - {defaultValue: zeros, kind: any, name: bias_initializer}
  - {defaultValue: None, kind: any, name: kernel_regularizer}
  - {defaultValue: None, kind: any, name: bias_regularizer}
  - {defaultValue: None, kind: any, name: activity_regularizer}
  - {defaultValue: None, kind: any, name: kernel_constraint}
  - {defaultValue: None, kind: any, name: bias_constraint}
  - {defaultValue: 'true', name: trainable, type: bool}
  source: "class Conv3DTranspose(Conv3D):\n    \"\"\"Transposed convolution layer\
    \ (sometimes called Deconvolution).\n\n    The need for transposed convolutions\
    \ generally arises\n    from the desire to use a transformation going in the opposite\
    \ direction\n    of a normal convolution, i.e., from something that has the shape\
    \ of the\n    output of some convolution to something that has the shape of its\
    \ input\n    while maintaining a connectivity pattern that is compatible with\n\
    \    said convolution.\n\n    When using this layer as the first layer in a model,\n\
    \    provide the keyword argument `input_shape`\n    (tuple of integers, does\
    \ not include the sample axis),\n    e.g. `input_shape=(128, 128, 128, 3)` for\
    \ a 128x128x128 volume with 3 channels\n    if `data_format=\"channels_last\"\
    `.\n\n    # Arguments\n        filters: Integer, the dimensionality of the output\
    \ space\n            (i.e. the number of output filters in the convolution).\n\
    \        kernel_size: An integer or tuple/list of 3 integers, specifying the\n\
    \            depth, height and width of the 3D convolution window.\n         \
    \   Can be a single integer to specify the same value for\n            all spatial\
    \ dimensions.\n        strides: An integer or tuple/list of 3 integers,\n    \
    \        specifying the strides of the convolution\n            along the depth,\
    \ height and width.\n            Can be a single integer to specify the same value\
    \ for\n            all spatial dimensions.\n            Specifying any stride\
    \ value != 1 is incompatible with specifying\n            any `dilation_rate`\
    \ value != 1.\n        padding: one of `\"valid\"` or `\"same\"` (case-insensitive).\n\
    \        output_padding: An integer or tuple/list of 3 integers,\n           \
    \ specifying the amount of padding along the depth, height, and\n            width.\n\
    \            Can be a single integer to specify the same value for all\n     \
    \       spatial dimensions.\n            The amount of output padding along a\
    \ given dimension must be\n            lower than the stride along that same dimension.\n\
    \            If set to `None` (default), the output shape is inferred.\n     \
    \   data_format: A string,\n            one of `\"channels_last\"` or `\"channels_first\"\
    `.\n            The ordering of the dimensions in the inputs.\n            `\"\
    channels_last\"` corresponds to inputs with shape\n            `(batch, depth,\
    \ height, width, channels)` while `\"channels_first\"`\n            corresponds\
    \ to inputs with shape\n            `(batch, channels, depth, height, width)`.\n\
    \            It defaults to the `image_data_format` value found in your\n    \
    \        Keras config file at `~/.keras/keras.json`.\n            If you never\
    \ set it, then it will be \"channels_last\".\n        dilation_rate: an integer\
    \ or tuple/list of 3 integers, specifying\n            the dilation rate to use\
    \ for dilated convolution.\n            Can be a single integer to specify the\
    \ same value for\n            all spatial dimensions.\n            Currently,\
    \ specifying any `dilation_rate` value != 1 is\n            incompatible with\
    \ specifying any stride value != 1.\n        activation: Activation function to\
    \ use\n            (see [activations](../activations.md)).\n            If you\
    \ don't specify anything, no activation is applied\n            (ie. \"linear\"\
    \ activation: `a(x) = x`).\n        use_bias: Boolean, whether the layer uses\
    \ a bias vector.\n        kernel_initializer: Initializer for the `kernel` weights\
    \ matrix\n            (see [initializers](../initializers.md)).\n        bias_initializer:\
    \ Initializer for the bias vector\n            (see [initializers](../initializers.md)).\n\
    \        kernel_regularizer: Regularizer function applied to\n            the\
    \ `kernel` weights matrix\n            (see [regularizer](../regularizers.md)).\n\
    \        bias_regularizer: Regularizer function applied to the bias vector\n \
    \           (see [regularizer](../regularizers.md)).\n        activity_regularizer:\
    \ Regularizer function applied to\n            the output of the layer (its \"\
    activation\").\n            (see [regularizer](../regularizers.md)).\n       \
    \ kernel_constraint: Constraint function applied to the kernel matrix\n      \
    \      (see [constraints](../constraints.md)).\n        bias_constraint: Constraint\
    \ function applied to the bias vector\n            (see [constraints](../constraints.md)).\n\
    \n    # Input shape\n        5D tensor with shape:\n        `(batch, channels,\
    \ depth, rows, cols)`\n        if `data_format` is `\"channels_first\"`\n    \
    \    or 5D tensor with shape:\n        `(batch, depth, rows, cols, channels)`\n\
    \        if `data_format` is `\"channels_last\"`.\n\n    # Output shape\n    \
    \    5D tensor with shape:\n        `(batch, filters, new_depth, new_rows, new_cols)`\n\
    \        if `data_format` is `\"channels_first\"`\n        or 5D tensor with shape:\n\
    \        `(batch, new_depth, new_rows, new_cols, filters)`\n        if `data_format`\
    \ is `\"channels_last\"`.\n        `depth` and `rows` and `cols` values might\
    \ have changed due to padding.\n        If `output_padding` is specified::\n\n\
    \        ```\n        new_depth = ((depth - 1) * strides[0] + kernel_size[0]\n\
    \                     - 2 * padding[0] + output_padding[0])\n        new_rows\
    \ = ((rows - 1) * strides[1] + kernel_size[1]\n                    - 2 * padding[1]\
    \ + output_padding[1])\n        new_cols = ((cols - 1) * strides[2] + kernel_size[2]\n\
    \                    - 2 * padding[2] + output_padding[2])\n        ```\n\n  \
    \  # References\n        - [A guide to convolution arithmetic for deep learning]\n\
    \          (https://arxiv.org/abs/1603.07285v1)\n        - [Deconvolutional Networks]\n\
    \          (http://www.matthewzeiler.com/pubs/cvpr2010/cvpr2010.pdf)\n    \"\"\
    \"\n\n    def __init__(self, filters,\n                 kernel_size,\n       \
    \          strides=(1, 1, 1),\n                 padding='valid',\n           \
    \      output_padding=None,\n                 data_format=None,\n            \
    \     activation=None,\n                 use_bias=True,\n                 kernel_initializer='glorot_uniform',\n\
    \                 bias_initializer='zeros',\n                 kernel_regularizer=None,\n\
    \                 bias_regularizer=None,\n                 activity_regularizer=None,\n\
    \                 kernel_constraint=None,\n                 bias_constraint=None,\n\
    \                 **kwargs):\n        super(Conv3DTranspose, self).__init__(\n\
    \            filters,\n            kernel_size,\n            strides=strides,\n\
    \            padding=padding,\n            data_format=data_format,\n        \
    \    activation=activation,\n            use_bias=use_bias,\n            kernel_initializer=kernel_initializer,\n\
    \            bias_initializer=bias_initializer,\n            kernel_regularizer=kernel_regularizer,\n\
    \            bias_regularizer=bias_regularizer,\n            activity_regularizer=activity_regularizer,\n\
    \            kernel_constraint=kernel_constraint,\n            bias_constraint=bias_constraint,\n\
    \            **kwargs)\n\n        self.output_padding = output_padding\n     \
    \   if self.output_padding is not None:\n            self.output_padding = conv_utils.normalize_tuple(\n\
    \                self.output_padding, 3, 'output_padding')\n            for stride,\
    \ out_pad in zip(self.strides, self.output_padding):\n                if out_pad\
    \ >= stride:\n                    raise ValueError('Stride ' + str(self.strides)\
    \ + ' must be '\n                                     'greater than output padding\
    \ ' +\n                                     str(self.output_padding))\n\n    def\
    \ build(self, input_shape):\n        if len(input_shape) != 5:\n            raise\
    \ ValueError('Inputs should have rank ' +\n                             str(5)\
    \ +\n                             '; Received input shape:', str(input_shape))\n\
    \        if self.data_format == 'channels_first':\n            channel_axis =\
    \ 1\n        else:\n            channel_axis = -1\n        if input_shape[channel_axis]\
    \ is None:\n            raise ValueError('The channel dimension of the inputs\
    \ '\n                             'should be defined. Found `None`.')\n      \
    \  input_dim = input_shape[channel_axis]\n        kernel_shape = self.kernel_size\
    \ + (self.filters, input_dim)\n\n        self.kernel = self.add_weight(shape=kernel_shape,\n\
    \                                      initializer=self.kernel_initializer,\n\
    \                                      name='kernel',\n                      \
    \                regularizer=self.kernel_regularizer,\n                      \
    \                constraint=self.kernel_constraint)\n        if self.use_bias:\n\
    \            self.bias = self.add_weight(shape=(self.filters,),\n            \
    \                            initializer=self.bias_initializer,\n            \
    \                            name='bias',\n                                  \
    \      regularizer=self.bias_regularizer,\n                                  \
    \      constraint=self.bias_constraint)\n        else:\n            self.bias\
    \ = None\n        # Set input spec.\n        self.input_spec = InputSpec(ndim=5,\
    \ axes={channel_axis: input_dim})\n        self.built = True\n\n    def call(self,\
    \ inputs):\n        input_shape = K.shape(inputs)\n        batch_size = input_shape[0]\n\
    \        if self.data_format == 'channels_first':\n            d_axis, h_axis,\
    \ w_axis = 2, 3, 4\n        else:\n            d_axis, h_axis, w_axis = 1, 2,\
    \ 3\n\n        depth = input_shape[d_axis]\n        height = input_shape[h_axis]\n\
    \        width = input_shape[w_axis]\n\n        kernel_d, kernel_h, kernel_w =\
    \ self.kernel_size\n        stride_d, stride_h, stride_w = self.strides\n    \
    \    if self.output_padding is None:\n            out_pad_d = out_pad_h = out_pad_w\
    \ = None\n        else:\n            out_pad_d, out_pad_h, out_pad_w = self.output_padding\n\
    \n        # Infer the dynamic output shape:\n        out_depth = conv_utils.deconv_length(depth,\n\
    \                                             stride_d, kernel_d,\n          \
    \                                   self.padding,\n                          \
    \                   out_pad_d)\n        out_height = conv_utils.deconv_length(height,\n\
    \                                              stride_h, kernel_h,\n         \
    \                                     self.padding,\n                        \
    \                      out_pad_h)\n        out_width = conv_utils.deconv_length(width,\n\
    \                                             stride_w, kernel_w,\n          \
    \                                   self.padding,\n                          \
    \                   out_pad_w)\n\n        if self.data_format == 'channels_first':\n\
    \            output_shape = (batch_size, self.filters,\n                     \
    \       out_depth, out_height, out_width)\n        else:\n            output_shape\
    \ = (batch_size, out_depth,\n                            out_height, out_width,\
    \ self.filters)\n\n        outputs = K.conv3d_transpose(inputs,\n            \
    \                         self.kernel,\n                                     output_shape,\n\
    \                                     self.strides,\n                        \
    \             padding=self.padding,\n                                     data_format=self.data_format)\n\
    \n        if self.use_bias:\n            outputs = K.bias_add(\n             \
    \   outputs,\n                self.bias,\n                data_format=self.data_format)\n\
    \n        if self.activation is not None:\n            return self.activation(outputs)\n\
    \        return outputs\n\n    def compute_output_shape(self, input_shape):\n\
    \        output_shape = list(input_shape)\n        if self.data_format == 'channels_first':\n\
    \            c_axis, d_axis, h_axis, w_axis = 1, 2, 3, 4\n        else:\n    \
    \        c_axis, d_axis, h_axis, w_axis = 4, 1, 2, 3\n\n        kernel_d, kernel_h,\
    \ kernel_w = self.kernel_size\n        stride_d, stride_h, stride_w = self.strides\n\
    \        if self.output_padding is None:\n            out_pad_d = out_pad_h =\
    \ out_pad_w = None\n        else:\n            out_pad_d, out_pad_h, out_pad_w\
    \ = self.output_padding\n\n        output_shape[c_axis] = self.filters\n     \
    \   output_shape[d_axis] = conv_utils.deconv_length(output_shape[d_axis],\n  \
    \                                                      stride_d,\n           \
    \                                             kernel_d,\n                    \
    \                                    self.padding,\n                         \
    \                               out_pad_d)\n        output_shape[h_axis] = conv_utils.deconv_length(output_shape[h_axis],\n\
    \                                                        stride_h,\n         \
    \                                               kernel_h,\n                  \
    \                                      self.padding,\n                       \
    \                                 out_pad_h)\n        output_shape[w_axis] = conv_utils.deconv_length(output_shape[w_axis],\n\
    \                                                        stride_w,\n         \
    \                                               kernel_w,\n                  \
    \                                      self.padding,\n                       \
    \                                 out_pad_w)\n\n        return tuple(output_shape)\n\
    \n    def get_config(self):\n        config = super(Conv3DTranspose, self).get_config()\n\
    \        config.pop('dilation_rate')\n        config['output_padding'] = self.output_padding\n\
    \        return config\n"
  sourcefile: D:\Python36\lib\site-packages\keras\layers\convolutional.py
- doc: "Just your regular densely-connected NN layer.\n\n`Dense` implements the operation:\n\
    `output = activation(dot(input, kernel) + bias)`\nwhere `activation` is the element-wise\
    \ activation function\npassed as the `activation` argument, `kernel` is a weights\
    \ matrix\ncreated by the layer, and `bias` is a bias vector created by the layer\n\
    (only applicable if `use_bias` is `True`).\n\nNote: if the input to the layer\
    \ has a rank greater than 2, then\nit is flattened prior to the initial dot product\
    \ with `kernel`.\n\n# Example\n\n```python\n    # as first layer in a sequential\
    \ model:\n    model = Sequential()\n    model.add(Dense(32, input_shape=(16,)))\n\
    \    # now the model will take as input arrays of shape (*, 16)\n    # and output\
    \ arrays of shape (*, 32)\n\n    # after the first layer, you don't need to specify\n\
    \    # the size of the input anymore:\n    model.add(Dense(32))\n```\n\n# Arguments\n\
    \    units: Positive integer, dimensionality of the output space.\n    activation:\
    \ Activation function to use\n        (see [activations](../activations.md)).\n\
    \        If you don't specify anything, no activation is applied\n        (ie.\
    \ \"linear\" activation: `a(x) = x`).\n    use_bias: Boolean, whether the layer\
    \ uses a bias vector.\n    kernel_initializer: Initializer for the `kernel` weights\
    \ matrix\n        (see [initializers](../initializers.md)).\n    bias_initializer:\
    \ Initializer for the bias vector\n        (see [initializers](../initializers.md)).\n\
    \    kernel_regularizer: Regularizer function applied to\n        the `kernel`\
    \ weights matrix\n        (see [regularizer](../regularizers.md)).\n    bias_regularizer:\
    \ Regularizer function applied to the bias vector\n        (see [regularizer](../regularizers.md)).\n\
    \    activity_regularizer: Regularizer function applied to\n        the output\
    \ of the layer (its \"activation\").\n        (see [regularizer](../regularizers.md)).\n\
    \    kernel_constraint: Constraint function applied to\n        the `kernel` weights\
    \ matrix\n        (see [constraints](../constraints.md)).\n    bias_constraint:\
    \ Constraint function applied to the bias vector\n        (see [constraints](../constraints.md)).\n\
    \n# Input shape\n    nD tensor with shape: `(batch_size, ..., input_dim)`.\n \
    \   The most common situation would be\n    a 2D input with shape `(batch_size,\
    \ input_dim)`.\n\n# Output shape\n    nD tensor with shape: `(batch_size, ...,\
    \ units)`.\n    For instance, for a 2D input with shape `(batch_size, input_dim)`,\n\
    \    the output would have shape `(batch_size, units)`."
  kind: Layer
  name: Dense
  parameters:
  - {kind: any, name: units}
  - {defaultValue: None, kind: any, name: activation}
  - {defaultValue: 'True', kind: any, name: use_bias}
  - {defaultValue: glorot_uniform, kind: any, name: kernel_initializer}
  - {defaultValue: zeros, kind: any, name: bias_initializer}
  - {defaultValue: None, kind: any, name: kernel_regularizer}
  - {defaultValue: None, kind: any, name: bias_regularizer}
  - {defaultValue: None, kind: any, name: activity_regularizer}
  - {defaultValue: None, kind: any, name: kernel_constraint}
  - {defaultValue: None, kind: any, name: bias_constraint}
  - {defaultValue: 'true', name: trainable, type: bool}
  source: "class Dense(Layer):\n    \"\"\"Just your regular densely-connected NN layer.\n\
    \n    `Dense` implements the operation:\n    `output = activation(dot(input, kernel)\
    \ + bias)`\n    where `activation` is the element-wise activation function\n \
    \   passed as the `activation` argument, `kernel` is a weights matrix\n    created\
    \ by the layer, and `bias` is a bias vector created by the layer\n    (only applicable\
    \ if `use_bias` is `True`).\n\n    Note: if the input to the layer has a rank\
    \ greater than 2, then\n    it is flattened prior to the initial dot product with\
    \ `kernel`.\n\n    # Example\n\n    ```python\n        # as first layer in a sequential\
    \ model:\n        model = Sequential()\n        model.add(Dense(32, input_shape=(16,)))\n\
    \        # now the model will take as input arrays of shape (*, 16)\n        #\
    \ and output arrays of shape (*, 32)\n\n        # after the first layer, you don't\
    \ need to specify\n        # the size of the input anymore:\n        model.add(Dense(32))\n\
    \    ```\n\n    # Arguments\n        units: Positive integer, dimensionality of\
    \ the output space.\n        activation: Activation function to use\n        \
    \    (see [activations](../activations.md)).\n            If you don't specify\
    \ anything, no activation is applied\n            (ie. \"linear\" activation:\
    \ `a(x) = x`).\n        use_bias: Boolean, whether the layer uses a bias vector.\n\
    \        kernel_initializer: Initializer for the `kernel` weights matrix\n   \
    \         (see [initializers](../initializers.md)).\n        bias_initializer:\
    \ Initializer for the bias vector\n            (see [initializers](../initializers.md)).\n\
    \        kernel_regularizer: Regularizer function applied to\n            the\
    \ `kernel` weights matrix\n            (see [regularizer](../regularizers.md)).\n\
    \        bias_regularizer: Regularizer function applied to the bias vector\n \
    \           (see [regularizer](../regularizers.md)).\n        activity_regularizer:\
    \ Regularizer function applied to\n            the output of the layer (its \"\
    activation\").\n            (see [regularizer](../regularizers.md)).\n       \
    \ kernel_constraint: Constraint function applied to\n            the `kernel`\
    \ weights matrix\n            (see [constraints](../constraints.md)).\n      \
    \  bias_constraint: Constraint function applied to the bias vector\n         \
    \   (see [constraints](../constraints.md)).\n\n    # Input shape\n        nD tensor\
    \ with shape: `(batch_size, ..., input_dim)`.\n        The most common situation\
    \ would be\n        a 2D input with shape `(batch_size, input_dim)`.\n\n    #\
    \ Output shape\n        nD tensor with shape: `(batch_size, ..., units)`.\n  \
    \      For instance, for a 2D input with shape `(batch_size, input_dim)`,\n  \
    \      the output would have shape `(batch_size, units)`.\n    \"\"\"\n\n    @interfaces.legacy_dense_support\n\
    \    def __init__(self, units,\n                 activation=None,\n          \
    \       use_bias=True,\n                 kernel_initializer='glorot_uniform',\n\
    \                 bias_initializer='zeros',\n                 kernel_regularizer=None,\n\
    \                 bias_regularizer=None,\n                 activity_regularizer=None,\n\
    \                 kernel_constraint=None,\n                 bias_constraint=None,\n\
    \                 **kwargs):\n        if 'input_shape' not in kwargs and 'input_dim'\
    \ in kwargs:\n            kwargs['input_shape'] = (kwargs.pop('input_dim'),)\n\
    \        super(Dense, self).__init__(**kwargs)\n        self.units = units\n \
    \       self.activation = activations.get(activation)\n        self.use_bias =\
    \ use_bias\n        self.kernel_initializer = initializers.get(kernel_initializer)\n\
    \        self.bias_initializer = initializers.get(bias_initializer)\n        self.kernel_regularizer\
    \ = regularizers.get(kernel_regularizer)\n        self.bias_regularizer = regularizers.get(bias_regularizer)\n\
    \        self.activity_regularizer = regularizers.get(activity_regularizer)\n\
    \        self.kernel_constraint = constraints.get(kernel_constraint)\n       \
    \ self.bias_constraint = constraints.get(bias_constraint)\n        self.input_spec\
    \ = InputSpec(min_ndim=2)\n        self.supports_masking = True\n\n    def build(self,\
    \ input_shape):\n        assert len(input_shape) >= 2\n        input_dim = input_shape[-1]\n\
    \n        self.kernel = self.add_weight(shape=(input_dim, self.units),\n     \
    \                                 initializer=self.kernel_initializer,\n     \
    \                                 name='kernel',\n                           \
    \           regularizer=self.kernel_regularizer,\n                           \
    \           constraint=self.kernel_constraint)\n        if self.use_bias:\n  \
    \          self.bias = self.add_weight(shape=(self.units,),\n                \
    \                        initializer=self.bias_initializer,\n                \
    \                        name='bias',\n                                      \
    \  regularizer=self.bias_regularizer,\n                                      \
    \  constraint=self.bias_constraint)\n        else:\n            self.bias = None\n\
    \        self.input_spec = InputSpec(min_ndim=2, axes={-1: input_dim})\n     \
    \   self.built = True\n\n    def call(self, inputs):\n        output = K.dot(inputs,\
    \ self.kernel)\n        if self.use_bias:\n            output = K.bias_add(output,\
    \ self.bias, data_format='channels_last')\n        if self.activation is not None:\n\
    \            output = self.activation(output)\n        return output\n\n    def\
    \ compute_output_shape(self, input_shape):\n        assert input_shape and len(input_shape)\
    \ >= 2\n        assert input_shape[-1]\n        output_shape = list(input_shape)\n\
    \        output_shape[-1] = self.units\n        return tuple(output_shape)\n\n\
    \    def get_config(self):\n        config = {\n            'units': self.units,\n\
    \            'activation': activations.serialize(self.activation),\n         \
    \   'use_bias': self.use_bias,\n            'kernel_initializer': initializers.serialize(self.kernel_initializer),\n\
    \            'bias_initializer': initializers.serialize(self.bias_initializer),\n\
    \            'kernel_regularizer': regularizers.serialize(self.kernel_regularizer),\n\
    \            'bias_regularizer': regularizers.serialize(self.bias_regularizer),\n\
    \            'activity_regularizer':\n                regularizers.serialize(self.activity_regularizer),\n\
    \            'kernel_constraint': constraints.serialize(self.kernel_constraint),\n\
    \            'bias_constraint': constraints.serialize(self.bias_constraint)\n\
    \        }\n        base_config = super(Dense, self).get_config()\n        return\
    \ dict(list(base_config.items()) + list(config.items()))\n"
  sourcefile: D:\Python36\lib\site-packages\keras\layers\core.py
- doc: "Depthwise separable 2D convolution.\n\nDepthwise Separable convolutions consists\
    \ in performing\njust the first step in a depthwise spatial convolution\n(which\
    \ acts on each input channel separately).\nThe `depth_multiplier` argument controls\
    \ how many\noutput channels are generated per input channel in the depthwise step.\n\
    \n# Arguments\n    kernel_size: An integer or tuple/list of 2 integers, specifying\
    \ the\n        height and width of the 2D convolution window.\n        Can be\
    \ a single integer to specify the same value for\n        all spatial dimensions.\n\
    \    strides: An integer or tuple/list of 2 integers,\n        specifying the\
    \ strides of the convolution\n        along the height and width.\n        Can\
    \ be a single integer to specify the same value for\n        all spatial dimensions.\n\
    \        Specifying any stride value != 1 is incompatible with specifying\n  \
    \      any `dilation_rate` value != 1.\n    padding: one of `\"valid\"` or `\"\
    same\"` (case-insensitive).\n    depth_multiplier: The number of depthwise convolution\
    \ output channels\n        for each input channel.\n        The total number of\
    \ depthwise convolution output\n        channels will be equal to `filters_in\
    \ * depth_multiplier`.\n    data_format: A string,\n        one of `\"channels_last\"\
    ` or `\"channels_first\"`.\n        The ordering of the dimensions in the inputs.\n\
    \        `\"channels_last\"` corresponds to inputs with shape\n        `(batch,\
    \ height, width, channels)` while `\"channels_first\"`\n        corresponds to\
    \ inputs with shape\n        `(batch, channels, height, width)`.\n        It defaults\
    \ to the `image_data_format` value found in your\n        Keras config file at\
    \ `~/.keras/keras.json`.\n        If you never set it, then it will be 'channels_last'.\n\
    \    activation: Activation function to use\n        (see [activations](../activations.md)).\n\
    \        If you don't specify anything, no activation is applied\n        (ie.\
    \ 'linear' activation: `a(x) = x`).\n    use_bias: Boolean, whether the layer\
    \ uses a bias vector.\n    depthwise_initializer: Initializer for the depthwise\
    \ kernel matrix\n        (see [initializers](../initializers.md)).\n    bias_initializer:\
    \ Initializer for the bias vector\n        (see [initializers](../initializers.md)).\n\
    \    depthwise_regularizer: Regularizer function applied to\n        the depthwise\
    \ kernel matrix\n        (see [regularizer](../regularizers.md)).\n    bias_regularizer:\
    \ Regularizer function applied to the bias vector\n        (see [regularizer](../regularizers.md)).\n\
    \    activity_regularizer: Regularizer function applied to\n        the output\
    \ of the layer (its 'activation').\n        (see [regularizer](../regularizers.md)).\n\
    \    depthwise_constraint: Constraint function applied to\n        the depthwise\
    \ kernel matrix\n        (see [constraints](../constraints.md)).\n    bias_constraint:\
    \ Constraint function applied to the bias vector\n        (see [constraints](../constraints.md)).\n\
    \n# Input shape\n    4D tensor with shape:\n    `(batch, channels, rows, cols)`\n\
    \    if `data_format` is `\"channels_first\"`\n    or 4D tensor with shape:\n\
    \    `(batch, rows, cols, channels)`\n    if `data_format` is `\"channels_last\"\
    `.\n\n# Output shape\n    4D tensor with shape:\n    `(batch, filters, new_rows,\
    \ new_cols)`\n    if `data_format` is `\"channels_first\"`\n    or 4D tensor with\
    \ shape:\n    `(batch, new_rows, new_cols, filters)`\n    if `data_format` is\
    \ `\"channels_last\"`.\n    `rows` and `cols` values might have changed due to\
    \ padding."
  kind: Layer
  name: DepthwiseConv2D
  parameters:
  - {kind: any, name: kernel_size}
  - {defaultValue: '(1, 1)', kind: any, name: strides}
  - {defaultValue: valid, kind: any, name: padding}
  - {defaultValue: '1', kind: any, name: depth_multiplier}
  - {defaultValue: None, kind: any, name: data_format}
  - {defaultValue: None, kind: any, name: activation}
  - {defaultValue: 'True', kind: any, name: use_bias}
  - {defaultValue: glorot_uniform, kind: any, name: depthwise_initializer}
  - {defaultValue: zeros, kind: any, name: bias_initializer}
  - {defaultValue: None, kind: any, name: depthwise_regularizer}
  - {defaultValue: None, kind: any, name: bias_regularizer}
  - {defaultValue: None, kind: any, name: activity_regularizer}
  - {defaultValue: None, kind: any, name: depthwise_constraint}
  - {defaultValue: None, kind: any, name: bias_constraint}
  - {defaultValue: 'true', name: trainable, type: bool}
  source: "class DepthwiseConv2D(Conv2D):\n    \"\"\"Depthwise separable 2D convolution.\n\
    \n    Depthwise Separable convolutions consists in performing\n    just the first\
    \ step in a depthwise spatial convolution\n    (which acts on each input channel\
    \ separately).\n    The `depth_multiplier` argument controls how many\n    output\
    \ channels are generated per input channel in the depthwise step.\n\n    # Arguments\n\
    \        kernel_size: An integer or tuple/list of 2 integers, specifying the\n\
    \            height and width of the 2D convolution window.\n            Can be\
    \ a single integer to specify the same value for\n            all spatial dimensions.\n\
    \        strides: An integer or tuple/list of 2 integers,\n            specifying\
    \ the strides of the convolution\n            along the height and width.\n  \
    \          Can be a single integer to specify the same value for\n           \
    \ all spatial dimensions.\n            Specifying any stride value != 1 is incompatible\
    \ with specifying\n            any `dilation_rate` value != 1.\n        padding:\
    \ one of `\"valid\"` or `\"same\"` (case-insensitive).\n        depth_multiplier:\
    \ The number of depthwise convolution output channels\n            for each input\
    \ channel.\n            The total number of depthwise convolution output\n   \
    \         channels will be equal to `filters_in * depth_multiplier`.\n       \
    \ data_format: A string,\n            one of `\"channels_last\"` or `\"channels_first\"\
    `.\n            The ordering of the dimensions in the inputs.\n            `\"\
    channels_last\"` corresponds to inputs with shape\n            `(batch, height,\
    \ width, channels)` while `\"channels_first\"`\n            corresponds to inputs\
    \ with shape\n            `(batch, channels, height, width)`.\n            It\
    \ defaults to the `image_data_format` value found in your\n            Keras config\
    \ file at `~/.keras/keras.json`.\n            If you never set it, then it will\
    \ be 'channels_last'.\n        activation: Activation function to use\n      \
    \      (see [activations](../activations.md)).\n            If you don't specify\
    \ anything, no activation is applied\n            (ie. 'linear' activation: `a(x)\
    \ = x`).\n        use_bias: Boolean, whether the layer uses a bias vector.\n \
    \       depthwise_initializer: Initializer for the depthwise kernel matrix\n \
    \           (see [initializers](../initializers.md)).\n        bias_initializer:\
    \ Initializer for the bias vector\n            (see [initializers](../initializers.md)).\n\
    \        depthwise_regularizer: Regularizer function applied to\n            the\
    \ depthwise kernel matrix\n            (see [regularizer](../regularizers.md)).\n\
    \        bias_regularizer: Regularizer function applied to the bias vector\n \
    \           (see [regularizer](../regularizers.md)).\n        activity_regularizer:\
    \ Regularizer function applied to\n            the output of the layer (its 'activation').\n\
    \            (see [regularizer](../regularizers.md)).\n        depthwise_constraint:\
    \ Constraint function applied to\n            the depthwise kernel matrix\n  \
    \          (see [constraints](../constraints.md)).\n        bias_constraint: Constraint\
    \ function applied to the bias vector\n            (see [constraints](../constraints.md)).\n\
    \n    # Input shape\n        4D tensor with shape:\n        `(batch, channels,\
    \ rows, cols)`\n        if `data_format` is `\"channels_first\"`\n        or 4D\
    \ tensor with shape:\n        `(batch, rows, cols, channels)`\n        if `data_format`\
    \ is `\"channels_last\"`.\n\n    # Output shape\n        4D tensor with shape:\n\
    \        `(batch, filters, new_rows, new_cols)`\n        if `data_format` is `\"\
    channels_first\"`\n        or 4D tensor with shape:\n        `(batch, new_rows,\
    \ new_cols, filters)`\n        if `data_format` is `\"channels_last\"`.\n    \
    \    `rows` and `cols` values might have changed due to padding.\n    \"\"\"\n\
    \n    def __init__(self,\n                 kernel_size,\n                 strides=(1,\
    \ 1),\n                 padding='valid',\n                 depth_multiplier=1,\n\
    \                 data_format=None,\n                 activation=None,\n     \
    \            use_bias=True,\n                 depthwise_initializer='glorot_uniform',\n\
    \                 bias_initializer='zeros',\n                 depthwise_regularizer=None,\n\
    \                 bias_regularizer=None,\n                 activity_regularizer=None,\n\
    \                 depthwise_constraint=None,\n                 bias_constraint=None,\n\
    \                 **kwargs):\n        super(DepthwiseConv2D, self).__init__(\n\
    \            filters=None,\n            kernel_size=kernel_size,\n           \
    \ strides=strides,\n            padding=padding,\n            data_format=data_format,\n\
    \            activation=activation,\n            use_bias=use_bias,\n        \
    \    bias_regularizer=bias_regularizer,\n            activity_regularizer=activity_regularizer,\n\
    \            bias_constraint=bias_constraint,\n            **kwargs)\n       \
    \ self.depth_multiplier = depth_multiplier\n        self.depthwise_initializer\
    \ = initializers.get(depthwise_initializer)\n        self.depthwise_regularizer\
    \ = regularizers.get(depthwise_regularizer)\n        self.depthwise_constraint\
    \ = constraints.get(depthwise_constraint)\n        self.bias_initializer = initializers.get(bias_initializer)\n\
    \n    def build(self, input_shape):\n        if len(input_shape) < 4:\n      \
    \      raise ValueError('Inputs to `DepthwiseConv2D` should have rank 4. '\n \
    \                            'Received input shape:', str(input_shape))\n    \
    \    if self.data_format == 'channels_first':\n            channel_axis = 1\n\
    \        else:\n            channel_axis = 3\n        if input_shape[channel_axis]\
    \ is None:\n            raise ValueError('The channel dimension of the inputs\
    \ to '\n                             '`DepthwiseConv2D` '\n                  \
    \           'should be defined. Found `None`.')\n        input_dim = int(input_shape[channel_axis])\n\
    \        depthwise_kernel_shape = (self.kernel_size[0],\n                    \
    \              self.kernel_size[1],\n                                  input_dim,\n\
    \                                  self.depth_multiplier)\n\n        self.depthwise_kernel\
    \ = self.add_weight(\n            shape=depthwise_kernel_shape,\n            initializer=self.depthwise_initializer,\n\
    \            name='depthwise_kernel',\n            regularizer=self.depthwise_regularizer,\n\
    \            constraint=self.depthwise_constraint)\n\n        if self.use_bias:\n\
    \            self.bias = self.add_weight(shape=(input_dim * self.depth_multiplier,),\n\
    \                                        initializer=self.bias_initializer,\n\
    \                                        name='bias',\n                      \
    \                  regularizer=self.bias_regularizer,\n                      \
    \                  constraint=self.bias_constraint)\n        else:\n         \
    \   self.bias = None\n        # Set input spec.\n        self.input_spec = InputSpec(ndim=4,\
    \ axes={channel_axis: input_dim})\n        self.built = True\n\n    def call(self,\
    \ inputs, training=None):\n        outputs = K.depthwise_conv2d(\n           \
    \ inputs,\n            self.depthwise_kernel,\n            strides=self.strides,\n\
    \            padding=self.padding,\n            dilation_rate=self.dilation_rate,\n\
    \            data_format=self.data_format)\n\n        if self.use_bias:\n    \
    \        outputs = K.bias_add(\n                outputs,\n                self.bias,\n\
    \                data_format=self.data_format)\n\n        if self.activation is\
    \ not None:\n            return self.activation(outputs)\n\n        return outputs\n\
    \n    def compute_output_shape(self, input_shape):\n        if self.data_format\
    \ == 'channels_first':\n            rows = input_shape[2]\n            cols =\
    \ input_shape[3]\n            out_filters = input_shape[1] * self.depth_multiplier\n\
    \        elif self.data_format == 'channels_last':\n            rows = input_shape[1]\n\
    \            cols = input_shape[2]\n            out_filters = input_shape[3] *\
    \ self.depth_multiplier\n\n        rows = conv_utils.conv_output_length(rows,\
    \ self.kernel_size[0],\n                                             self.padding,\n\
    \                                             self.strides[0])\n        cols =\
    \ conv_utils.conv_output_length(cols, self.kernel_size[1],\n                 \
    \                            self.padding,\n                                 \
    \            self.strides[1])\n        if self.data_format == 'channels_first':\n\
    \            return (input_shape[0], out_filters, rows, cols)\n        elif self.data_format\
    \ == 'channels_last':\n            return (input_shape[0], rows, cols, out_filters)\n\
    \n    def get_config(self):\n        config = super(DepthwiseConv2D, self).get_config()\n\
    \        config.pop('filters')\n        config.pop('kernel_initializer')\n   \
    \     config.pop('kernel_regularizer')\n        config.pop('kernel_constraint')\n\
    \        config['depth_multiplier'] = self.depth_multiplier\n        config['depthwise_initializer']\
    \ = (\n            initializers.serialize(self.depthwise_initializer))\n     \
    \   config['depthwise_regularizer'] = (\n            regularizers.serialize(self.depthwise_regularizer))\n\
    \        config['depthwise_constraint'] = (\n            constraints.serialize(self.depthwise_constraint))\n\
    \        return config\n"
  sourcefile: D:\Python36\lib\site-packages\keras\layers\convolutional.py
- doc: "Layer that computes a dot product between samples in two tensors.\n\nE.g.\
    \ if applied to a list of two tensors `a` and `b` of shape `(batch_size, n)`,\n\
    the output will be a tensor of shape `(batch_size, 1)`\nwhere each entry `i` will\
    \ be the dot product between\n`a[i]` and `b[i]`.\n\n# Arguments\n    axes: Integer\
    \ or tuple of integers,\n        axis or axes along which to take the dot product.\n\
    \    normalize: Whether to L2-normalize samples along the\n        dot product\
    \ axis before taking the dot product.\n        If set to True, then the output\
    \ of the dot product\n        is the cosine proximity between the two samples.\n\
    \    **kwargs: Standard layer keyword arguments."
  kind: Layer
  name: Dot
  parameters:
  - {kind: any, name: axes}
  - {defaultValue: 'False', kind: any, name: normalize}
  - {defaultValue: 'true', name: trainable, type: bool}
  source: "class Dot(_Merge):\n    \"\"\"Layer that computes a dot product between\
    \ samples in two tensors.\n\n    E.g. if applied to a list of two tensors `a`\
    \ and `b` of shape `(batch_size, n)`,\n    the output will be a tensor of shape\
    \ `(batch_size, 1)`\n    where each entry `i` will be the dot product between\n\
    \    `a[i]` and `b[i]`.\n\n    # Arguments\n        axes: Integer or tuple of\
    \ integers,\n            axis or axes along which to take the dot product.\n \
    \       normalize: Whether to L2-normalize samples along the\n            dot\
    \ product axis before taking the dot product.\n            If set to True, then\
    \ the output of the dot product\n            is the cosine proximity between the\
    \ two samples.\n        **kwargs: Standard layer keyword arguments.\n    \"\"\"\
    \n\n    def __init__(self, axes, normalize=False, **kwargs):\n        super(Dot,\
    \ self).__init__(**kwargs)\n        if not isinstance(axes, int):\n          \
    \  if not isinstance(axes, (list, tuple)):\n                raise TypeError('Invalid\
    \ type for `axes` - '\n                                'should be a list or an\
    \ int.')\n            if len(axes) != 2:\n                raise ValueError('Invalid\
    \ format for `axes` - '\n                                 'should contain two\
    \ elements.')\n            if not isinstance(axes[0], int) or not isinstance(axes[1],\
    \ int):\n                raise ValueError('Invalid format for `axes` - '\n   \
    \                              'list elements should be \"int\".')\n        self.axes\
    \ = axes\n        self.normalize = normalize\n        self.supports_masking =\
    \ True\n        self._reshape_required = False\n\n    def build(self, input_shape):\n\
    \        # Used purely for shape validation.\n        if not isinstance(input_shape,\
    \ list) or len(input_shape) != 2:\n            raise ValueError('A `Dot` layer\
    \ should be called '\n                             'on a list of 2 inputs.')\n\
    \        shape1 = input_shape[0]\n        shape2 = input_shape[1]\n        if\
    \ shape1 is None or shape2 is None:\n            return\n        if isinstance(self.axes,\
    \ int):\n            if self.axes < 0:\n                axes = [self.axes % len(shape1),\
    \ self.axes % len(shape2)]\n            else:\n                axes = [self.axes]\
    \ * 2\n        else:\n            axes = self.axes\n        if shape1[axes[0]]\
    \ != shape2[axes[1]]:\n            raise ValueError(\n                'Dimension\
    \ incompatibility '\n                '%s != %s. ' % (shape1[axes[0]], shape2[axes[1]])\
    \ +\n                'Layer shapes: %s, %s' % (shape1, shape2))\n\n    def _merge_function(self,\
    \ inputs):\n        if len(inputs) != 2:\n            raise ValueError('A `Dot`\
    \ layer should be called '\n                             'on exactly 2 inputs')\n\
    \        x1 = inputs[0]\n        x2 = inputs[1]\n        if isinstance(self.axes,\
    \ int):\n            if self.axes < 0:\n                axes = [self.axes % K.ndim(x1),\
    \ self.axes % K.ndim(x2)]\n            else:\n                axes = [self.axes]\
    \ * 2\n        else:\n            axes = []\n            for i in range(len(self.axes)):\n\
    \                if self.axes[i] < 0:\n                    axes.append(self.axes[i]\
    \ % K.ndim(inputs[i]))\n                else:\n                    axes.append(self.axes[i])\n\
    \        if self.normalize:\n            x1 = K.l2_normalize(x1, axis=axes[0])\n\
    \            x2 = K.l2_normalize(x2, axis=axes[1])\n        output = K.batch_dot(x1,\
    \ x2, axes)\n        return output\n\n    def compute_output_shape(self, input_shape):\n\
    \        if not isinstance(input_shape, list) or len(input_shape) != 2:\n    \
    \        raise ValueError('A `Dot` layer should be called '\n                \
    \             'on a list of 2 inputs.')\n        shape1 = list(input_shape[0])\n\
    \        shape2 = list(input_shape[1])\n        if isinstance(self.axes, int):\n\
    \            if self.axes < 0:\n                axes = [self.axes % len(shape1),\
    \ self.axes % len(shape2)]\n            else:\n                axes = [self.axes]\
    \ * 2\n        else:\n            axes = self.axes\n        shape1.pop(axes[0])\n\
    \        shape2.pop(axes[1])\n        shape2.pop(0)\n        output_shape = shape1\
    \ + shape2\n        if len(output_shape) == 1:\n            output_shape += [1]\n\
    \        return tuple(output_shape)\n\n    def compute_mask(self, inputs, mask=None):\n\
    \        return None\n\n    def get_config(self):\n        config = {\n      \
    \      'axes': self.axes,\n            'normalize': self.normalize,\n        }\n\
    \        base_config = super(Dot, self).get_config()\n        return dict(list(base_config.items())\
    \ + list(config.items()))\n"
  sourcefile: D:\Python36\lib\site-packages\keras\layers\merge.py
- doc: "Applies Dropout to the input.\n\nDropout consists in randomly setting\na fraction\
    \ `rate` of input units to 0 at each update during training time,\nwhich helps\
    \ prevent overfitting.\n\n# Arguments\n    rate: float between 0 and 1. Fraction\
    \ of the input units to drop.\n    noise_shape: 1D integer tensor representing\
    \ the shape of the\n        binary dropout mask that will be multiplied with the\
    \ input.\n        For instance, if your inputs have shape\n        `(batch_size,\
    \ timesteps, features)` and\n        you want the dropout mask to be the same\
    \ for all timesteps,\n        you can use `noise_shape=(batch_size, 1, features)`.\n\
    \    seed: A Python integer to use as random seed.\n\n# References\n    - [Dropout:\
    \ A Simple Way to Prevent Neural Networks from Overfitting]\n      (http://www.jmlr.org/papers/volume15/srivastava14a/srivastava14a.pdf)"
  kind: Layer
  name: Dropout
  parameters:
  - {kind: any, name: rate}
  - {defaultValue: None, kind: any, name: noise_shape}
  - {defaultValue: None, kind: any, name: seed}
  - {defaultValue: 'true', name: trainable, type: bool}
  source: "class Dropout(Layer):\n    \"\"\"Applies Dropout to the input.\n\n    Dropout\
    \ consists in randomly setting\n    a fraction `rate` of input units to 0 at each\
    \ update during training time,\n    which helps prevent overfitting.\n\n    #\
    \ Arguments\n        rate: float between 0 and 1. Fraction of the input units\
    \ to drop.\n        noise_shape: 1D integer tensor representing the shape of the\n\
    \            binary dropout mask that will be multiplied with the input.\n   \
    \         For instance, if your inputs have shape\n            `(batch_size, timesteps,\
    \ features)` and\n            you want the dropout mask to be the same for all\
    \ timesteps,\n            you can use `noise_shape=(batch_size, 1, features)`.\n\
    \        seed: A Python integer to use as random seed.\n\n    # References\n \
    \       - [Dropout: A Simple Way to Prevent Neural Networks from Overfitting]\n\
    \          (http://www.jmlr.org/papers/volume15/srivastava14a/srivastava14a.pdf)\n\
    \    \"\"\"\n    @interfaces.legacy_dropout_support\n    def __init__(self, rate,\
    \ noise_shape=None, seed=None, **kwargs):\n        super(Dropout, self).__init__(**kwargs)\n\
    \        self.rate = min(1., max(0., rate))\n        self.noise_shape = noise_shape\n\
    \        self.seed = seed\n        self.supports_masking = True\n\n    def _get_noise_shape(self,\
    \ inputs):\n        if self.noise_shape is None:\n            return self.noise_shape\n\
    \n        symbolic_shape = K.shape(inputs)\n        noise_shape = [symbolic_shape[axis]\
    \ if shape is None else shape\n                       for axis, shape in enumerate(self.noise_shape)]\n\
    \        return tuple(noise_shape)\n\n    def call(self, inputs, training=None):\n\
    \        if 0. < self.rate < 1.:\n            noise_shape = self._get_noise_shape(inputs)\n\
    \n            def dropped_inputs():\n                return K.dropout(inputs,\
    \ self.rate, noise_shape,\n                                 seed=self.seed)\n\
    \            return K.in_train_phase(dropped_inputs, inputs,\n               \
    \                     training=training)\n        return inputs\n\n    def get_config(self):\n\
    \        config = {'rate': self.rate,\n                  'noise_shape': self.noise_shape,\n\
    \                  'seed': self.seed}\n        base_config = super(Dropout, self).get_config()\n\
    \        return dict(list(base_config.items()) + list(config.items()))\n\n   \
    \ def compute_output_shape(self, input_shape):\n        return input_shape\n"
  sourcefile: D:\Python36\lib\site-packages\keras\layers\core.py
- doc: "Exponential Linear Unit.\n\nIt follows:\n`f(x) =  alpha * (exp(x) - 1.) for\
    \ x < 0`,\n`f(x) = x for x >= 0`.\n\n# Input shape\n    Arbitrary. Use the keyword\
    \ argument `input_shape`\n    (tuple of integers, does not include the samples\
    \ axis)\n    when using this layer as the first layer in a model.\n\n# Output\
    \ shape\n    Same shape as the input.\n\n# Arguments\n    alpha: scale for the\
    \ negative factor.\n\n# References\n    - [Fast and Accurate Deep Network Learning\
    \ by Exponential Linear Units\n       (ELUs)](https://arxiv.org/abs/1511.07289v1)"
  kind: Layer
  name: ELU
  parameters:
  - {defaultValue: '1.0', kind: any, name: alpha}
  - {defaultValue: 'true', name: trainable, type: bool}
  source: "class ELU(Layer):\n    \"\"\"Exponential Linear Unit.\n\n    It follows:\n\
    \    `f(x) =  alpha * (exp(x) - 1.) for x < 0`,\n    `f(x) = x for x >= 0`.\n\n\
    \    # Input shape\n        Arbitrary. Use the keyword argument `input_shape`\n\
    \        (tuple of integers, does not include the samples axis)\n        when\
    \ using this layer as the first layer in a model.\n\n    # Output shape\n    \
    \    Same shape as the input.\n\n    # Arguments\n        alpha: scale for the\
    \ negative factor.\n\n    # References\n        - [Fast and Accurate Deep Network\
    \ Learning by Exponential Linear Units\n           (ELUs)](https://arxiv.org/abs/1511.07289v1)\n\
    \    \"\"\"\n\n    def __init__(self, alpha=1.0, **kwargs):\n        super(ELU,\
    \ self).__init__(**kwargs)\n        self.supports_masking = True\n        self.alpha\
    \ = K.cast_to_floatx(alpha)\n\n    def call(self, inputs):\n        return K.elu(inputs,\
    \ self.alpha)\n\n    def get_config(self):\n        config = {'alpha': float(self.alpha)}\n\
    \        base_config = super(ELU, self).get_config()\n        return dict(list(base_config.items())\
    \ + list(config.items()))\n\n    def compute_output_shape(self, input_shape):\n\
    \        return input_shape\n"
  sourcefile: D:\Python36\lib\site-packages\keras\layers\advanced_activations.py
- doc: "Turns positive integers (indexes) into dense vectors of fixed size.\neg. [[4],\
    \ [20]] -> [[0.25, 0.1], [0.6, -0.2]]\n\nThis layer can only be used as the first\
    \ layer in a model.\n\n# Example\n\n```python\n  model = Sequential()\n  model.add(Embedding(1000,\
    \ 64, input_length=10))\n  # the model will take as input an integer matrix of\
    \ size (batch, input_length).\n  # the largest integer (i.e. word index) in the\
    \ input should be\n  # no larger than 999 (vocabulary size).\n  # now model.output_shape\
    \ == (None, 10, 64), where None is the batch dimension.\n\n  input_array = np.random.randint(1000,\
    \ size=(32, 10))\n\n  model.compile('rmsprop', 'mse')\n  output_array = model.predict(input_array)\n\
    \  assert output_array.shape == (32, 10, 64)\n```\n\n# Arguments\n    input_dim:\
    \ int > 0. Size of the vocabulary,\n        i.e. maximum integer index + 1.\n\
    \    output_dim: int >= 0. Dimension of the dense embedding.\n    embeddings_initializer:\
    \ Initializer for the `embeddings` matrix\n        (see [initializers](../initializers.md)).\n\
    \    embeddings_regularizer: Regularizer function applied to\n        the `embeddings`\
    \ matrix\n        (see [regularizer](../regularizers.md)).\n    embeddings_constraint:\
    \ Constraint function applied to\n        the `embeddings` matrix\n        (see\
    \ [constraints](../constraints.md)).\n    mask_zero: Whether or not the input\
    \ value 0 is a special \"padding\"\n        value that should be masked out.\n\
    \        This is useful when using [recurrent layers](recurrent.md)\n        which\
    \ may take variable length input.\n        If this is `True` then all subsequent\
    \ layers\n        in the model need to support masking or an exception will be\
    \ raised.\n        If mask_zero is set to True, as a consequence, index 0 cannot\
    \ be\n        used in the vocabulary (input_dim should equal size of\n       \
    \ vocabulary + 1).\n    input_length: Length of input sequences, when it is constant.\n\
    \        This argument is required if you are going to connect\n        `Flatten`\
    \ then `Dense` layers upstream\n        (without it, the shape of the dense outputs\
    \ cannot be computed).\n\n# Input shape\n    2D tensor with shape: `(batch_size,\
    \ sequence_length)`.\n\n# Output shape\n    3D tensor with shape: `(batch_size,\
    \ sequence_length, output_dim)`.\n\n# References\n    - [A Theoretically Grounded\
    \ Application of Dropout in\n       Recurrent Neural Networks](http://arxiv.org/abs/1512.05287)"
  kind: Layer
  name: Embedding
  parameters:
  - {kind: any, name: input_dim}
  - {kind: any, name: output_dim}
  - {defaultValue: uniform, kind: any, name: embeddings_initializer}
  - {defaultValue: None, kind: any, name: embeddings_regularizer}
  - {defaultValue: None, kind: any, name: activity_regularizer}
  - {defaultValue: None, kind: any, name: embeddings_constraint}
  - {defaultValue: 'False', kind: any, name: mask_zero}
  - {defaultValue: None, kind: any, name: input_length}
  - {defaultValue: 'true', name: trainable, type: bool}
  source: "class Embedding(Layer):\n    \"\"\"Turns positive integers (indexes) into\
    \ dense vectors of fixed size.\n    eg. [[4], [20]] -> [[0.25, 0.1], [0.6, -0.2]]\n\
    \n    This layer can only be used as the first layer in a model.\n\n    # Example\n\
    \n    ```python\n      model = Sequential()\n      model.add(Embedding(1000, 64,\
    \ input_length=10))\n      # the model will take as input an integer matrix of\
    \ size (batch, input_length).\n      # the largest integer (i.e. word index) in\
    \ the input should be\n      # no larger than 999 (vocabulary size).\n      #\
    \ now model.output_shape == (None, 10, 64), where None is the batch dimension.\n\
    \n      input_array = np.random.randint(1000, size=(32, 10))\n\n      model.compile('rmsprop',\
    \ 'mse')\n      output_array = model.predict(input_array)\n      assert output_array.shape\
    \ == (32, 10, 64)\n    ```\n\n    # Arguments\n        input_dim: int > 0. Size\
    \ of the vocabulary,\n            i.e. maximum integer index + 1.\n        output_dim:\
    \ int >= 0. Dimension of the dense embedding.\n        embeddings_initializer:\
    \ Initializer for the `embeddings` matrix\n            (see [initializers](../initializers.md)).\n\
    \        embeddings_regularizer: Regularizer function applied to\n           \
    \ the `embeddings` matrix\n            (see [regularizer](../regularizers.md)).\n\
    \        embeddings_constraint: Constraint function applied to\n            the\
    \ `embeddings` matrix\n            (see [constraints](../constraints.md)).\n \
    \       mask_zero: Whether or not the input value 0 is a special \"padding\"\n\
    \            value that should be masked out.\n            This is useful when\
    \ using [recurrent layers](recurrent.md)\n            which may take variable\
    \ length input.\n            If this is `True` then all subsequent layers\n  \
    \          in the model need to support masking or an exception will be raised.\n\
    \            If mask_zero is set to True, as a consequence, index 0 cannot be\n\
    \            used in the vocabulary (input_dim should equal size of\n        \
    \    vocabulary + 1).\n        input_length: Length of input sequences, when it\
    \ is constant.\n            This argument is required if you are going to connect\n\
    \            `Flatten` then `Dense` layers upstream\n            (without it,\
    \ the shape of the dense outputs cannot be computed).\n\n    # Input shape\n \
    \       2D tensor with shape: `(batch_size, sequence_length)`.\n\n    # Output\
    \ shape\n        3D tensor with shape: `(batch_size, sequence_length, output_dim)`.\n\
    \n    # References\n        - [A Theoretically Grounded Application of Dropout\
    \ in\n           Recurrent Neural Networks](http://arxiv.org/abs/1512.05287)\n\
    \    \"\"\"\n\n    @interfaces.legacy_embedding_support\n    def __init__(self,\
    \ input_dim, output_dim,\n                 embeddings_initializer='uniform',\n\
    \                 embeddings_regularizer=None,\n                 activity_regularizer=None,\n\
    \                 embeddings_constraint=None,\n                 mask_zero=False,\n\
    \                 input_length=None,\n                 **kwargs):\n        if\
    \ 'input_shape' not in kwargs:\n            if input_length:\n               \
    \ kwargs['input_shape'] = (input_length,)\n            else:\n               \
    \ kwargs['input_shape'] = (None,)\n        super(Embedding, self).__init__(**kwargs)\n\
    \n        self.input_dim = input_dim\n        self.output_dim = output_dim\n \
    \       self.embeddings_initializer = initializers.get(embeddings_initializer)\n\
    \        self.embeddings_regularizer = regularizers.get(embeddings_regularizer)\n\
    \        self.activity_regularizer = regularizers.get(activity_regularizer)\n\
    \        self.embeddings_constraint = constraints.get(embeddings_constraint)\n\
    \        self.mask_zero = mask_zero\n        self.supports_masking = mask_zero\n\
    \        self.input_length = input_length\n\n    def build(self, input_shape):\n\
    \        self.embeddings = self.add_weight(\n            shape=(self.input_dim,\
    \ self.output_dim),\n            initializer=self.embeddings_initializer,\n  \
    \          name='embeddings',\n            regularizer=self.embeddings_regularizer,\n\
    \            constraint=self.embeddings_constraint,\n            dtype=self.dtype)\n\
    \        self.built = True\n\n    def compute_mask(self, inputs, mask=None):\n\
    \        if not self.mask_zero:\n            return None\n        output_mask\
    \ = K.not_equal(inputs, 0)\n        return output_mask\n\n    def compute_output_shape(self,\
    \ input_shape):\n        if self.input_length is None:\n            return input_shape\
    \ + (self.output_dim,)\n        else:\n            # input_length can be tuple\
    \ if input is 3D or higher\n            in_lens = to_list(self.input_length, allow_tuple=True)\n\
    \            if len(in_lens) != len(input_shape) - 1:\n                raise ValueError(\n\
    \                    '\"input_length\" is %s, but received input has shape %s'\
    \ %\n                    (str(self.input_length), str(input_shape)))\n       \
    \     else:\n                for i, (s1, s2) in enumerate(zip(in_lens, input_shape[1:])):\n\
    \                    if s1 is not None and s2 is not None and s1 != s2:\n    \
    \                    raise ValueError(\n                            '\"input_length\"\
    \ is %s, but received input has shape %s' %\n                            (str(self.input_length),\
    \ str(input_shape)))\n                    elif s1 is None:\n                 \
    \       in_lens[i] = s2\n            return (input_shape[0],) + tuple(in_lens)\
    \ + (self.output_dim,)\n\n    def call(self, inputs):\n        if K.dtype(inputs)\
    \ != 'int32':\n            inputs = K.cast(inputs, 'int32')\n        out = K.gather(self.embeddings,\
    \ inputs)\n        return out\n\n    def get_config(self):\n        config = {'input_dim':\
    \ self.input_dim,\n                  'output_dim': self.output_dim,\n        \
    \          'embeddings_initializer':\n                      initializers.serialize(self.embeddings_initializer),\n\
    \                  'embeddings_regularizer':\n                      regularizers.serialize(self.embeddings_regularizer),\n\
    \                  'activity_regularizer':\n                      regularizers.serialize(self.activity_regularizer),\n\
    \                  'embeddings_constraint':\n                      constraints.serialize(self.embeddings_constraint),\n\
    \                  'mask_zero': self.mask_zero,\n                  'input_length':\
    \ self.input_length}\n        base_config = super(Embedding, self).get_config()\n\
    \        return dict(list(base_config.items()) + list(config.items()))\n"
  sourcefile: D:\Python36\lib\site-packages\keras\layers\embeddings.py
- doc: "Flattens the input. Does not affect the batch size.\n\n# Arguments\n    data_format:\
    \ A string,\n        one of `channels_last` (default) or `channels_first`.\n \
    \       The ordering of the dimensions in the inputs.\n        The purpose of\
    \ this argument is to preserve weight\n        ordering when switching a model\
    \ from one data format\n        to another.\n        `channels_last` corresponds\
    \ to inputs with shape\n        `(batch, ..., channels)` while `channels_first`\
    \ corresponds to\n        inputs with shape `(batch, channels, ...)`.\n      \
    \  It defaults to the `image_data_format` value found in your\n        Keras config\
    \ file at `~/.keras/keras.json`.\n        If you never set it, then it will be\
    \ \"channels_last\".\n\n# Example\n\n```python\n    model = Sequential()\n   \
    \ model.add(Conv2D(64, (3, 3),\n                     input_shape=(3, 32, 32),\
    \ padding='same',))\n    # now: model.output_shape == (None, 64, 32, 32)\n\n \
    \   model.add(Flatten())\n    # now: model.output_shape == (None, 65536)\n```"
  kind: Layer
  name: Flatten
  parameters:
  - {defaultValue: None, kind: any, name: data_format}
  - {defaultValue: 'true', name: trainable, type: bool}
  source: "class Flatten(Layer):\n    \"\"\"Flattens the input. Does not affect the\
    \ batch size.\n\n    # Arguments\n        data_format: A string,\n           \
    \ one of `channels_last` (default) or `channels_first`.\n            The ordering\
    \ of the dimensions in the inputs.\n            The purpose of this argument is\
    \ to preserve weight\n            ordering when switching a model from one data\
    \ format\n            to another.\n            `channels_last` corresponds to\
    \ inputs with shape\n            `(batch, ..., channels)` while `channels_first`\
    \ corresponds to\n            inputs with shape `(batch, channels, ...)`.\n  \
    \          It defaults to the `image_data_format` value found in your\n      \
    \      Keras config file at `~/.keras/keras.json`.\n            If you never set\
    \ it, then it will be \"channels_last\".\n\n    # Example\n\n    ```python\n \
    \       model = Sequential()\n        model.add(Conv2D(64, (3, 3),\n         \
    \                input_shape=(3, 32, 32), padding='same',))\n        # now: model.output_shape\
    \ == (None, 64, 32, 32)\n\n        model.add(Flatten())\n        # now: model.output_shape\
    \ == (None, 65536)\n    ```\n    \"\"\"\n\n    def __init__(self, data_format=None,\
    \ **kwargs):\n        super(Flatten, self).__init__(**kwargs)\n        self.input_spec\
    \ = InputSpec(min_ndim=3)\n        self.data_format = K.normalize_data_format(data_format)\n\
    \n    def compute_output_shape(self, input_shape):\n        if not all(input_shape[1:]):\n\
    \            raise ValueError('The shape of the input to \"Flatten\" '\n     \
    \                        'is not fully defined '\n                           \
    \  '(got ' + str(input_shape[1:]) + '. '\n                             'Make sure\
    \ to pass a complete \"input_shape\" '\n                             'or \"batch_input_shape\"\
    \ argument to the first '\n                             'layer in your model.')\n\
    \        return (input_shape[0], np.prod(input_shape[1:]))\n\n    def call(self,\
    \ inputs):\n        if self.data_format == 'channels_first':\n            # Ensure\
    \ works for any dim\n            permutation = [0]\n            permutation.extend([i\
    \ for i in\n                                range(2, K.ndim(inputs))])\n     \
    \       permutation.append(1)\n            inputs = K.permute_dimensions(inputs,\
    \ permutation)\n\n        return K.batch_flatten(inputs)\n\n    def get_config(self):\n\
    \        config = {'data_format': self.data_format}\n        base_config = super(Flatten,\
    \ self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))\n"
  sourcefile: D:\Python36\lib\site-packages\keras\layers\core.py
- doc: "Gated Recurrent Unit - Cho et al. 2014.\n\nThere are two variants. The default\
    \ one is based on 1406.1078v3 and\nhas reset gate applied to hidden state before\
    \ matrix multiplication. The\nother one is based on original 1406.1078v1 and has\
    \ the order reversed.\n\nThe second variant is compatible with CuDNNGRU (GPU-only)\
    \ and allows\ninference on CPU. Thus it has separate biases for `kernel` and\n\
    `recurrent_kernel`. Use `'reset_after'=True` and\n`recurrent_activation='sigmoid'`.\n\
    \n# Arguments\n    units: Positive integer, dimensionality of the output space.\n\
    \    activation: Activation function to use\n        (see [activations](../activations.md)).\n\
    \        Default: hyperbolic tangent (`tanh`).\n        If you pass `None`, no\
    \ activation is applied\n        (ie. \"linear\" activation: `a(x) = x`).\n  \
    \  recurrent_activation: Activation function to use\n        for the recurrent\
    \ step\n        (see [activations](../activations.md)).\n        Default: hard\
    \ sigmoid (`hard_sigmoid`).\n        If you pass `None`, no activation is applied\n\
    \        (ie. \"linear\" activation: `a(x) = x`).\n    use_bias: Boolean, whether\
    \ the layer uses a bias vector.\n    kernel_initializer: Initializer for the `kernel`\
    \ weights matrix,\n        used for the linear transformation of the inputs\n\
    \        (see [initializers](../initializers.md)).\n    recurrent_initializer:\
    \ Initializer for the `recurrent_kernel`\n        weights matrix,\n        used\
    \ for the linear transformation of the recurrent state\n        (see [initializers](../initializers.md)).\n\
    \    bias_initializer: Initializer for the bias vector\n        (see [initializers](../initializers.md)).\n\
    \    kernel_regularizer: Regularizer function applied to\n        the `kernel`\
    \ weights matrix\n        (see [regularizer](../regularizers.md)).\n    recurrent_regularizer:\
    \ Regularizer function applied to\n        the `recurrent_kernel` weights matrix\n\
    \        (see [regularizer](../regularizers.md)).\n    bias_regularizer: Regularizer\
    \ function applied to the bias vector\n        (see [regularizer](../regularizers.md)).\n\
    \    activity_regularizer: Regularizer function applied to\n        the output\
    \ of the layer (its \"activation\").\n        (see [regularizer](../regularizers.md)).\n\
    \    kernel_constraint: Constraint function applied to\n        the `kernel` weights\
    \ matrix\n        (see [constraints](../constraints.md)).\n    recurrent_constraint:\
    \ Constraint function applied to\n        the `recurrent_kernel` weights matrix\n\
    \        (see [constraints](../constraints.md)).\n    bias_constraint: Constraint\
    \ function applied to the bias vector\n        (see [constraints](../constraints.md)).\n\
    \    dropout: Float between 0 and 1.\n        Fraction of the units to drop for\n\
    \        the linear transformation of the inputs.\n    recurrent_dropout: Float\
    \ between 0 and 1.\n        Fraction of the units to drop for\n        the linear\
    \ transformation of the recurrent state.\n    implementation: Implementation mode,\
    \ either 1 or 2.\n        Mode 1 will structure its operations as a larger number\
    \ of\n        smaller dot products and additions, whereas mode 2 will\n      \
    \  batch them into fewer, larger operations. These modes will\n        have different\
    \ performance profiles on different hardware and\n        for different applications.\n\
    \    return_sequences: Boolean. Whether to return the last output\n        in\
    \ the output sequence, or the full sequence.\n    return_state: Boolean. Whether\
    \ to return the last state\n        in addition to the output.\n    go_backwards:\
    \ Boolean (default False).\n        If True, process the input sequence backwards\
    \ and return the\n        reversed sequence.\n    stateful: Boolean (default False).\
    \ If True, the last state\n        for each sample at index i in a batch will\
    \ be used as initial\n        state for the sample of index i in the following\
    \ batch.\n    unroll: Boolean (default False).\n        If True, the network will\
    \ be unrolled,\n        else a symbolic loop will be used.\n        Unrolling\
    \ can speed-up a RNN,\n        although it tends to be more memory-intensive.\n\
    \        Unrolling is only suitable for short sequences.\n    reset_after: GRU\
    \ convention (whether to apply reset gate after or\n        before matrix multiplication).\
    \ False = \"before\" (default),\n        True = \"after\" (CuDNN compatible).\n\
    \n# References\n    - [Learning Phrase Representations using RNN Encoder-Decoder\
    \ for\n       Statistical Machine Translation](https://arxiv.org/abs/1406.1078)\n\
    \    - [On the Properties of Neural Machine Translation:\n       Encoder-Decoder\
    \ Approaches](https://arxiv.org/abs/1409.1259)\n    - [Empirical Evaluation of\
    \ Gated Recurrent Neural Networks on\n       Sequence Modeling](https://arxiv.org/abs/1412.3555v1)\n\
    \    - [A Theoretically Grounded Application of Dropout in\n       Recurrent Neural\
    \ Networks](https://arxiv.org/abs/1512.05287)"
  kind: Layer
  name: GRU
  parameters:
  - {kind: any, name: units}
  - {defaultValue: tanh, kind: any, name: activation}
  - {defaultValue: hard_sigmoid, kind: any, name: recurrent_activation}
  - {defaultValue: 'True', kind: any, name: use_bias}
  - {defaultValue: glorot_uniform, kind: any, name: kernel_initializer}
  - {defaultValue: orthogonal, kind: any, name: recurrent_initializer}
  - {defaultValue: zeros, kind: any, name: bias_initializer}
  - {defaultValue: None, kind: any, name: kernel_regularizer}
  - {defaultValue: None, kind: any, name: recurrent_regularizer}
  - {defaultValue: None, kind: any, name: bias_regularizer}
  - {defaultValue: None, kind: any, name: activity_regularizer}
  - {defaultValue: None, kind: any, name: kernel_constraint}
  - {defaultValue: None, kind: any, name: recurrent_constraint}
  - {defaultValue: None, kind: any, name: bias_constraint}
  - {defaultValue: '0.0', kind: any, name: dropout}
  - {defaultValue: '0.0', kind: any, name: recurrent_dropout}
  - {defaultValue: '1', kind: any, name: implementation}
  - {defaultValue: 'False', kind: any, name: return_sequences}
  - {defaultValue: 'False', kind: any, name: return_state}
  - {defaultValue: 'False', kind: any, name: go_backwards}
  - {defaultValue: 'False', kind: any, name: stateful}
  - {defaultValue: 'False', kind: any, name: unroll}
  - {defaultValue: 'False', kind: any, name: reset_after}
  - {defaultValue: 'true', name: trainable, type: bool}
  source: "class GRU(RNN):\n    \"\"\"Gated Recurrent Unit - Cho et al. 2014.\n\n\
    \    There are two variants. The default one is based on 1406.1078v3 and\n   \
    \ has reset gate applied to hidden state before matrix multiplication. The\n \
    \   other one is based on original 1406.1078v1 and has the order reversed.\n\n\
    \    The second variant is compatible with CuDNNGRU (GPU-only) and allows\n  \
    \  inference on CPU. Thus it has separate biases for `kernel` and\n    `recurrent_kernel`.\
    \ Use `'reset_after'=True` and\n    `recurrent_activation='sigmoid'`.\n\n    #\
    \ Arguments\n        units: Positive integer, dimensionality of the output space.\n\
    \        activation: Activation function to use\n            (see [activations](../activations.md)).\n\
    \            Default: hyperbolic tangent (`tanh`).\n            If you pass `None`,\
    \ no activation is applied\n            (ie. \"linear\" activation: `a(x) = x`).\n\
    \        recurrent_activation: Activation function to use\n            for the\
    \ recurrent step\n            (see [activations](../activations.md)).\n      \
    \      Default: hard sigmoid (`hard_sigmoid`).\n            If you pass `None`,\
    \ no activation is applied\n            (ie. \"linear\" activation: `a(x) = x`).\n\
    \        use_bias: Boolean, whether the layer uses a bias vector.\n        kernel_initializer:\
    \ Initializer for the `kernel` weights matrix,\n            used for the linear\
    \ transformation of the inputs\n            (see [initializers](../initializers.md)).\n\
    \        recurrent_initializer: Initializer for the `recurrent_kernel`\n     \
    \       weights matrix,\n            used for the linear transformation of the\
    \ recurrent state\n            (see [initializers](../initializers.md)).\n   \
    \     bias_initializer: Initializer for the bias vector\n            (see [initializers](../initializers.md)).\n\
    \        kernel_regularizer: Regularizer function applied to\n            the\
    \ `kernel` weights matrix\n            (see [regularizer](../regularizers.md)).\n\
    \        recurrent_regularizer: Regularizer function applied to\n            the\
    \ `recurrent_kernel` weights matrix\n            (see [regularizer](../regularizers.md)).\n\
    \        bias_regularizer: Regularizer function applied to the bias vector\n \
    \           (see [regularizer](../regularizers.md)).\n        activity_regularizer:\
    \ Regularizer function applied to\n            the output of the layer (its \"\
    activation\").\n            (see [regularizer](../regularizers.md)).\n       \
    \ kernel_constraint: Constraint function applied to\n            the `kernel`\
    \ weights matrix\n            (see [constraints](../constraints.md)).\n      \
    \  recurrent_constraint: Constraint function applied to\n            the `recurrent_kernel`\
    \ weights matrix\n            (see [constraints](../constraints.md)).\n      \
    \  bias_constraint: Constraint function applied to the bias vector\n         \
    \   (see [constraints](../constraints.md)).\n        dropout: Float between 0\
    \ and 1.\n            Fraction of the units to drop for\n            the linear\
    \ transformation of the inputs.\n        recurrent_dropout: Float between 0 and\
    \ 1.\n            Fraction of the units to drop for\n            the linear transformation\
    \ of the recurrent state.\n        implementation: Implementation mode, either\
    \ 1 or 2.\n            Mode 1 will structure its operations as a larger number\
    \ of\n            smaller dot products and additions, whereas mode 2 will\n  \
    \          batch them into fewer, larger operations. These modes will\n      \
    \      have different performance profiles on different hardware and\n       \
    \     for different applications.\n        return_sequences: Boolean. Whether\
    \ to return the last output\n            in the output sequence, or the full sequence.\n\
    \        return_state: Boolean. Whether to return the last state\n           \
    \ in addition to the output.\n        go_backwards: Boolean (default False).\n\
    \            If True, process the input sequence backwards and return the\n  \
    \          reversed sequence.\n        stateful: Boolean (default False). If True,\
    \ the last state\n            for each sample at index i in a batch will be used\
    \ as initial\n            state for the sample of index i in the following batch.\n\
    \        unroll: Boolean (default False).\n            If True, the network will\
    \ be unrolled,\n            else a symbolic loop will be used.\n            Unrolling\
    \ can speed-up a RNN,\n            although it tends to be more memory-intensive.\n\
    \            Unrolling is only suitable for short sequences.\n        reset_after:\
    \ GRU convention (whether to apply reset gate after or\n            before matrix\
    \ multiplication). False = \"before\" (default),\n            True = \"after\"\
    \ (CuDNN compatible).\n\n    # References\n        - [Learning Phrase Representations\
    \ using RNN Encoder-Decoder for\n           Statistical Machine Translation](https://arxiv.org/abs/1406.1078)\n\
    \        - [On the Properties of Neural Machine Translation:\n           Encoder-Decoder\
    \ Approaches](https://arxiv.org/abs/1409.1259)\n        - [Empirical Evaluation\
    \ of Gated Recurrent Neural Networks on\n           Sequence Modeling](https://arxiv.org/abs/1412.3555v1)\n\
    \        - [A Theoretically Grounded Application of Dropout in\n           Recurrent\
    \ Neural Networks](https://arxiv.org/abs/1512.05287)\n    \"\"\"\n\n    @interfaces.legacy_recurrent_support\n\
    \    def __init__(self, units,\n                 activation='tanh',\n        \
    \         recurrent_activation='hard_sigmoid',\n                 use_bias=True,\n\
    \                 kernel_initializer='glorot_uniform',\n                 recurrent_initializer='orthogonal',\n\
    \                 bias_initializer='zeros',\n                 kernel_regularizer=None,\n\
    \                 recurrent_regularizer=None,\n                 bias_regularizer=None,\n\
    \                 activity_regularizer=None,\n                 kernel_constraint=None,\n\
    \                 recurrent_constraint=None,\n                 bias_constraint=None,\n\
    \                 dropout=0.,\n                 recurrent_dropout=0.,\n      \
    \           implementation=1,\n                 return_sequences=False,\n    \
    \             return_state=False,\n                 go_backwards=False,\n    \
    \             stateful=False,\n                 unroll=False,\n              \
    \   reset_after=False,\n                 **kwargs):\n        if implementation\
    \ == 0:\n            warnings.warn('`implementation=0` has been deprecated, '\n\
    \                          'and now defaults to `implementation=1`.'\n       \
    \                   'Please update your layer call.')\n        if K.backend()\
    \ == 'theano' and (dropout or recurrent_dropout):\n            warnings.warn(\n\
    \                'RNN dropout is no longer supported with the Theano backend '\n\
    \                'due to technical limitations. '\n                'You can either\
    \ set `dropout` and `recurrent_dropout` to 0, '\n                'or use the TensorFlow\
    \ backend.')\n            dropout = 0.\n            recurrent_dropout = 0.\n\n\
    \        cell = GRUCell(units,\n                       activation=activation,\n\
    \                       recurrent_activation=recurrent_activation,\n         \
    \              use_bias=use_bias,\n                       kernel_initializer=kernel_initializer,\n\
    \                       recurrent_initializer=recurrent_initializer,\n       \
    \                bias_initializer=bias_initializer,\n                       kernel_regularizer=kernel_regularizer,\n\
    \                       recurrent_regularizer=recurrent_regularizer,\n       \
    \                bias_regularizer=bias_regularizer,\n                       kernel_constraint=kernel_constraint,\n\
    \                       recurrent_constraint=recurrent_constraint,\n         \
    \              bias_constraint=bias_constraint,\n                       dropout=dropout,\n\
    \                       recurrent_dropout=recurrent_dropout,\n               \
    \        implementation=implementation,\n                       reset_after=reset_after)\n\
    \        super(GRU, self).__init__(cell,\n                                  return_sequences=return_sequences,\n\
    \                                  return_state=return_state,\n              \
    \                    go_backwards=go_backwards,\n                            \
    \      stateful=stateful,\n                                  unroll=unroll,\n\
    \                                  **kwargs)\n        self.activity_regularizer\
    \ = regularizers.get(activity_regularizer)\n\n    def call(self, inputs, mask=None,\
    \ training=None, initial_state=None):\n        self.cell._dropout_mask = None\n\
    \        self.cell._recurrent_dropout_mask = None\n        return super(GRU, self).call(inputs,\n\
    \                                     mask=mask,\n                           \
    \          training=training,\n                                     initial_state=initial_state)\n\
    \n    @property\n    def units(self):\n        return self.cell.units\n\n    @property\n\
    \    def activation(self):\n        return self.cell.activation\n\n    @property\n\
    \    def recurrent_activation(self):\n        return self.cell.recurrent_activation\n\
    \n    @property\n    def use_bias(self):\n        return self.cell.use_bias\n\n\
    \    @property\n    def kernel_initializer(self):\n        return self.cell.kernel_initializer\n\
    \n    @property\n    def recurrent_initializer(self):\n        return self.cell.recurrent_initializer\n\
    \n    @property\n    def bias_initializer(self):\n        return self.cell.bias_initializer\n\
    \n    @property\n    def kernel_regularizer(self):\n        return self.cell.kernel_regularizer\n\
    \n    @property\n    def recurrent_regularizer(self):\n        return self.cell.recurrent_regularizer\n\
    \n    @property\n    def bias_regularizer(self):\n        return self.cell.bias_regularizer\n\
    \n    @property\n    def kernel_constraint(self):\n        return self.cell.kernel_constraint\n\
    \n    @property\n    def recurrent_constraint(self):\n        return self.cell.recurrent_constraint\n\
    \n    @property\n    def bias_constraint(self):\n        return self.cell.bias_constraint\n\
    \n    @property\n    def dropout(self):\n        return self.cell.dropout\n\n\
    \    @property\n    def recurrent_dropout(self):\n        return self.cell.recurrent_dropout\n\
    \n    @property\n    def implementation(self):\n        return self.cell.implementation\n\
    \n    @property\n    def reset_after(self):\n        return self.cell.reset_after\n\
    \n    def get_config(self):\n        config = {'units': self.units,\n        \
    \          'activation': activations.serialize(self.activation),\n           \
    \       'recurrent_activation':\n                      activations.serialize(self.recurrent_activation),\n\
    \                  'use_bias': self.use_bias,\n                  'kernel_initializer':\n\
    \                      initializers.serialize(self.kernel_initializer),\n    \
    \              'recurrent_initializer':\n                      initializers.serialize(self.recurrent_initializer),\n\
    \                  'bias_initializer': initializers.serialize(self.bias_initializer),\n\
    \                  'kernel_regularizer':\n                      regularizers.serialize(self.kernel_regularizer),\n\
    \                  'recurrent_regularizer':\n                      regularizers.serialize(self.recurrent_regularizer),\n\
    \                  'bias_regularizer': regularizers.serialize(self.bias_regularizer),\n\
    \                  'activity_regularizer':\n                      regularizers.serialize(self.activity_regularizer),\n\
    \                  'kernel_constraint': constraints.serialize(self.kernel_constraint),\n\
    \                  'recurrent_constraint':\n                      constraints.serialize(self.recurrent_constraint),\n\
    \                  'bias_constraint': constraints.serialize(self.bias_constraint),\n\
    \                  'dropout': self.dropout,\n                  'recurrent_dropout':\
    \ self.recurrent_dropout,\n                  'implementation': self.implementation,\n\
    \                  'reset_after': self.reset_after}\n        base_config = super(GRU,\
    \ self).get_config()\n        del base_config['cell']\n        return dict(list(base_config.items())\
    \ + list(config.items()))\n\n    @classmethod\n    def from_config(cls, config):\n\
    \        if 'implementation' in config and config['implementation'] == 0:\n  \
    \          config['implementation'] = 1\n        return cls(**config)\n"
  sourcefile: D:\Python36\lib\site-packages\keras\layers\recurrent.py
- doc: "Cell class for the GRU layer.\n\n# Arguments\n    units: Positive integer,\
    \ dimensionality of the output space.\n    activation: Activation function to\
    \ use\n        (see [activations](../activations.md)).\n        Default: hyperbolic\
    \ tangent (`tanh`).\n        If you pass `None`, no activation is applied\n  \
    \      (ie. \"linear\" activation: `a(x) = x`).\n    recurrent_activation: Activation\
    \ function to use\n        for the recurrent step\n        (see [activations](../activations.md)).\n\
    \        Default: hard sigmoid (`hard_sigmoid`).\n        If you pass `None`,\
    \ no activation is applied\n        (ie. \"linear\" activation: `a(x) = x`).\n\
    \    use_bias: Boolean, whether the layer uses a bias vector.\n    kernel_initializer:\
    \ Initializer for the `kernel` weights matrix,\n        used for the linear transformation\
    \ of the inputs\n        (see [initializers](../initializers.md)).\n    recurrent_initializer:\
    \ Initializer for the `recurrent_kernel`\n        weights matrix,\n        used\
    \ for the linear transformation of the recurrent state\n        (see [initializers](../initializers.md)).\n\
    \    bias_initializer: Initializer for the bias vector\n        (see [initializers](../initializers.md)).\n\
    \    kernel_regularizer: Regularizer function applied to\n        the `kernel`\
    \ weights matrix\n        (see [regularizer](../regularizers.md)).\n    recurrent_regularizer:\
    \ Regularizer function applied to\n        the `recurrent_kernel` weights matrix\n\
    \        (see [regularizer](../regularizers.md)).\n    bias_regularizer: Regularizer\
    \ function applied to the bias vector\n        (see [regularizer](../regularizers.md)).\n\
    \    kernel_constraint: Constraint function applied to\n        the `kernel` weights\
    \ matrix\n        (see [constraints](../constraints.md)).\n    recurrent_constraint:\
    \ Constraint function applied to\n        the `recurrent_kernel` weights matrix\n\
    \        (see [constraints](../constraints.md)).\n    bias_constraint: Constraint\
    \ function applied to the bias vector\n        (see [constraints](../constraints.md)).\n\
    \    dropout: Float between 0 and 1.\n        Fraction of the units to drop for\n\
    \        the linear transformation of the inputs.\n    recurrent_dropout: Float\
    \ between 0 and 1.\n        Fraction of the units to drop for\n        the linear\
    \ transformation of the recurrent state.\n    implementation: Implementation mode,\
    \ either 1 or 2.\n        Mode 1 will structure its operations as a larger number\
    \ of\n        smaller dot products and additions, whereas mode 2 will\n      \
    \  batch them into fewer, larger operations. These modes will\n        have different\
    \ performance profiles on different hardware and\n        for different applications.\n\
    \    reset_after: GRU convention (whether to apply reset gate after or\n     \
    \   before matrix multiplication). False = \"before\" (default),\n        True\
    \ = \"after\" (CuDNN compatible)."
  kind: Layer
  name: GRUCell
  parameters:
  - {kind: any, name: units}
  - {defaultValue: tanh, kind: any, name: activation}
  - {defaultValue: hard_sigmoid, kind: any, name: recurrent_activation}
  - {defaultValue: 'True', kind: any, name: use_bias}
  - {defaultValue: glorot_uniform, kind: any, name: kernel_initializer}
  - {defaultValue: orthogonal, kind: any, name: recurrent_initializer}
  - {defaultValue: zeros, kind: any, name: bias_initializer}
  - {defaultValue: None, kind: any, name: kernel_regularizer}
  - {defaultValue: None, kind: any, name: recurrent_regularizer}
  - {defaultValue: None, kind: any, name: bias_regularizer}
  - {defaultValue: None, kind: any, name: kernel_constraint}
  - {defaultValue: None, kind: any, name: recurrent_constraint}
  - {defaultValue: None, kind: any, name: bias_constraint}
  - {defaultValue: '0.0', kind: any, name: dropout}
  - {defaultValue: '0.0', kind: any, name: recurrent_dropout}
  - {defaultValue: '1', kind: any, name: implementation}
  - {defaultValue: 'False', kind: any, name: reset_after}
  - {defaultValue: 'true', name: trainable, type: bool}
  source: "class GRUCell(Layer):\n    \"\"\"Cell class for the GRU layer.\n\n    #\
    \ Arguments\n        units: Positive integer, dimensionality of the output space.\n\
    \        activation: Activation function to use\n            (see [activations](../activations.md)).\n\
    \            Default: hyperbolic tangent (`tanh`).\n            If you pass `None`,\
    \ no activation is applied\n            (ie. \"linear\" activation: `a(x) = x`).\n\
    \        recurrent_activation: Activation function to use\n            for the\
    \ recurrent step\n            (see [activations](../activations.md)).\n      \
    \      Default: hard sigmoid (`hard_sigmoid`).\n            If you pass `None`,\
    \ no activation is applied\n            (ie. \"linear\" activation: `a(x) = x`).\n\
    \        use_bias: Boolean, whether the layer uses a bias vector.\n        kernel_initializer:\
    \ Initializer for the `kernel` weights matrix,\n            used for the linear\
    \ transformation of the inputs\n            (see [initializers](../initializers.md)).\n\
    \        recurrent_initializer: Initializer for the `recurrent_kernel`\n     \
    \       weights matrix,\n            used for the linear transformation of the\
    \ recurrent state\n            (see [initializers](../initializers.md)).\n   \
    \     bias_initializer: Initializer for the bias vector\n            (see [initializers](../initializers.md)).\n\
    \        kernel_regularizer: Regularizer function applied to\n            the\
    \ `kernel` weights matrix\n            (see [regularizer](../regularizers.md)).\n\
    \        recurrent_regularizer: Regularizer function applied to\n            the\
    \ `recurrent_kernel` weights matrix\n            (see [regularizer](../regularizers.md)).\n\
    \        bias_regularizer: Regularizer function applied to the bias vector\n \
    \           (see [regularizer](../regularizers.md)).\n        kernel_constraint:\
    \ Constraint function applied to\n            the `kernel` weights matrix\n  \
    \          (see [constraints](../constraints.md)).\n        recurrent_constraint:\
    \ Constraint function applied to\n            the `recurrent_kernel` weights matrix\n\
    \            (see [constraints](../constraints.md)).\n        bias_constraint:\
    \ Constraint function applied to the bias vector\n            (see [constraints](../constraints.md)).\n\
    \        dropout: Float between 0 and 1.\n            Fraction of the units to\
    \ drop for\n            the linear transformation of the inputs.\n        recurrent_dropout:\
    \ Float between 0 and 1.\n            Fraction of the units to drop for\n    \
    \        the linear transformation of the recurrent state.\n        implementation:\
    \ Implementation mode, either 1 or 2.\n            Mode 1 will structure its operations\
    \ as a larger number of\n            smaller dot products and additions, whereas\
    \ mode 2 will\n            batch them into fewer, larger operations. These modes\
    \ will\n            have different performance profiles on different hardware\
    \ and\n            for different applications.\n        reset_after: GRU convention\
    \ (whether to apply reset gate after or\n            before matrix multiplication).\
    \ False = \"before\" (default),\n            True = \"after\" (CuDNN compatible).\n\
    \    \"\"\"\n\n    def __init__(self, units,\n                 activation='tanh',\n\
    \                 recurrent_activation='hard_sigmoid',\n                 use_bias=True,\n\
    \                 kernel_initializer='glorot_uniform',\n                 recurrent_initializer='orthogonal',\n\
    \                 bias_initializer='zeros',\n                 kernel_regularizer=None,\n\
    \                 recurrent_regularizer=None,\n                 bias_regularizer=None,\n\
    \                 kernel_constraint=None,\n                 recurrent_constraint=None,\n\
    \                 bias_constraint=None,\n                 dropout=0.,\n      \
    \           recurrent_dropout=0.,\n                 implementation=1,\n      \
    \           reset_after=False,\n                 **kwargs):\n        super(GRUCell,\
    \ self).__init__(**kwargs)\n        self.units = units\n        self.activation\
    \ = activations.get(activation)\n        self.recurrent_activation = activations.get(recurrent_activation)\n\
    \        self.use_bias = use_bias\n\n        self.kernel_initializer = initializers.get(kernel_initializer)\n\
    \        self.recurrent_initializer = initializers.get(recurrent_initializer)\n\
    \        self.bias_initializer = initializers.get(bias_initializer)\n\n      \
    \  self.kernel_regularizer = regularizers.get(kernel_regularizer)\n        self.recurrent_regularizer\
    \ = regularizers.get(recurrent_regularizer)\n        self.bias_regularizer = regularizers.get(bias_regularizer)\n\
    \n        self.kernel_constraint = constraints.get(kernel_constraint)\n      \
    \  self.recurrent_constraint = constraints.get(recurrent_constraint)\n       \
    \ self.bias_constraint = constraints.get(bias_constraint)\n\n        self.dropout\
    \ = min(1., max(0., dropout))\n        self.recurrent_dropout = min(1., max(0.,\
    \ recurrent_dropout))\n        self.implementation = implementation\n        self.reset_after\
    \ = reset_after\n        self.state_size = self.units\n        self.output_size\
    \ = self.units\n        self._dropout_mask = None\n        self._recurrent_dropout_mask\
    \ = None\n\n    def build(self, input_shape):\n        input_dim = input_shape[-1]\n\
    \        self.kernel = self.add_weight(shape=(input_dim, self.units * 3),\n  \
    \                                    name='kernel',\n                        \
    \              initializer=self.kernel_initializer,\n                        \
    \              regularizer=self.kernel_regularizer,\n                        \
    \              constraint=self.kernel_constraint)\n        self.recurrent_kernel\
    \ = self.add_weight(\n            shape=(self.units, self.units * 3),\n      \
    \      name='recurrent_kernel',\n            initializer=self.recurrent_initializer,\n\
    \            regularizer=self.recurrent_regularizer,\n            constraint=self.recurrent_constraint)\n\
    \n        if self.use_bias:\n            if not self.reset_after:\n          \
    \      bias_shape = (3 * self.units,)\n            else:\n                # separate\
    \ biases for input and recurrent kernels\n                # Note: the shape is\
    \ intentionally different from CuDNNGRU biases\n                # `(2 * 3 * self.units,)`,\
    \ so that we can distinguish the classes\n                # when loading and converting\
    \ saved weights.\n                bias_shape = (2, 3 * self.units)\n         \
    \   self.bias = self.add_weight(shape=bias_shape,\n                          \
    \              name='bias',\n                                        initializer=self.bias_initializer,\n\
    \                                        regularizer=self.bias_regularizer,\n\
    \                                        constraint=self.bias_constraint)\n  \
    \          if not self.reset_after:\n                self.input_bias, self.recurrent_bias\
    \ = self.bias, None\n            else:\n                # NOTE: need to flatten,\
    \ since slicing in CNTK gives 2D array\n                self.input_bias = K.flatten(self.bias[0])\n\
    \                self.recurrent_bias = K.flatten(self.bias[1])\n        else:\n\
    \            self.bias = None\n\n        # update gate\n        self.kernel_z\
    \ = self.kernel[:, :self.units]\n        self.recurrent_kernel_z = self.recurrent_kernel[:,\
    \ :self.units]\n        # reset gate\n        self.kernel_r = self.kernel[:, self.units:\
    \ self.units * 2]\n        self.recurrent_kernel_r = self.recurrent_kernel[:,\n\
    \                                                        self.units:\n       \
    \                                                 self.units * 2]\n        # new\
    \ gate\n        self.kernel_h = self.kernel[:, self.units * 2:]\n        self.recurrent_kernel_h\
    \ = self.recurrent_kernel[:, self.units * 2:]\n\n        if self.use_bias:\n \
    \           # bias for inputs\n            self.input_bias_z = self.input_bias[:self.units]\n\
    \            self.input_bias_r = self.input_bias[self.units: self.units * 2]\n\
    \            self.input_bias_h = self.input_bias[self.units * 2:]\n          \
    \  # bias for hidden state - just for compatibility with CuDNN\n            if\
    \ self.reset_after:\n                self.recurrent_bias_z = self.recurrent_bias[:self.units]\n\
    \                self.recurrent_bias_r = (\n                    self.recurrent_bias[self.units:\
    \ self.units * 2])\n                self.recurrent_bias_h = self.recurrent_bias[self.units\
    \ * 2:]\n        else:\n            self.input_bias_z = None\n            self.input_bias_r\
    \ = None\n            self.input_bias_h = None\n            if self.reset_after:\n\
    \                self.recurrent_bias_z = None\n                self.recurrent_bias_r\
    \ = None\n                self.recurrent_bias_h = None\n        self.built = True\n\
    \n    def call(self, inputs, states, training=None):\n        h_tm1 = states[0]\
    \  # previous memory\n\n        if 0 < self.dropout < 1 and self._dropout_mask\
    \ is None:\n            self._dropout_mask = _generate_dropout_mask(\n       \
    \         K.ones_like(inputs),\n                self.dropout,\n              \
    \  training=training,\n                count=3)\n        if (0 < self.recurrent_dropout\
    \ < 1 and\n                self._recurrent_dropout_mask is None):\n          \
    \  self._recurrent_dropout_mask = _generate_dropout_mask(\n                K.ones_like(h_tm1),\n\
    \                self.recurrent_dropout,\n                training=training,\n\
    \                count=3)\n\n        # dropout matrices for input units\n    \
    \    dp_mask = self._dropout_mask\n        # dropout matrices for recurrent units\n\
    \        rec_dp_mask = self._recurrent_dropout_mask\n\n        if self.implementation\
    \ == 1:\n            if 0. < self.dropout < 1.:\n                inputs_z = inputs\
    \ * dp_mask[0]\n                inputs_r = inputs * dp_mask[1]\n             \
    \   inputs_h = inputs * dp_mask[2]\n            else:\n                inputs_z\
    \ = inputs\n                inputs_r = inputs\n                inputs_h = inputs\n\
    \n            x_z = K.dot(inputs_z, self.kernel_z)\n            x_r = K.dot(inputs_r,\
    \ self.kernel_r)\n            x_h = K.dot(inputs_h, self.kernel_h)\n         \
    \   if self.use_bias:\n                x_z = K.bias_add(x_z, self.input_bias_z)\n\
    \                x_r = K.bias_add(x_r, self.input_bias_r)\n                x_h\
    \ = K.bias_add(x_h, self.input_bias_h)\n\n            if 0. < self.recurrent_dropout\
    \ < 1.:\n                h_tm1_z = h_tm1 * rec_dp_mask[0]\n                h_tm1_r\
    \ = h_tm1 * rec_dp_mask[1]\n                h_tm1_h = h_tm1 * rec_dp_mask[2]\n\
    \            else:\n                h_tm1_z = h_tm1\n                h_tm1_r =\
    \ h_tm1\n                h_tm1_h = h_tm1\n\n            recurrent_z = K.dot(h_tm1_z,\
    \ self.recurrent_kernel_z)\n            recurrent_r = K.dot(h_tm1_r, self.recurrent_kernel_r)\n\
    \            if self.reset_after and self.use_bias:\n                recurrent_z\
    \ = K.bias_add(recurrent_z, self.recurrent_bias_z)\n                recurrent_r\
    \ = K.bias_add(recurrent_r, self.recurrent_bias_r)\n\n            z = self.recurrent_activation(x_z\
    \ + recurrent_z)\n            r = self.recurrent_activation(x_r + recurrent_r)\n\
    \n            # reset gate applied after/before matrix multiplication\n      \
    \      if self.reset_after:\n                recurrent_h = K.dot(h_tm1_h, self.recurrent_kernel_h)\n\
    \                if self.use_bias:\n                    recurrent_h = K.bias_add(recurrent_h,\
    \ self.recurrent_bias_h)\n                recurrent_h = r * recurrent_h\n    \
    \        else:\n                recurrent_h = K.dot(r * h_tm1_h, self.recurrent_kernel_h)\n\
    \n            hh = self.activation(x_h + recurrent_h)\n        else:\n       \
    \     if 0. < self.dropout < 1.:\n                inputs *= dp_mask[0]\n\n   \
    \         # inputs projected by all gate matrices at once\n            matrix_x\
    \ = K.dot(inputs, self.kernel)\n            if self.use_bias:\n              \
    \  # biases: bias_z_i, bias_r_i, bias_h_i\n                matrix_x = K.bias_add(matrix_x,\
    \ self.input_bias)\n            x_z = matrix_x[:, :self.units]\n            x_r\
    \ = matrix_x[:, self.units: 2 * self.units]\n            x_h = matrix_x[:, 2 *\
    \ self.units:]\n\n            if 0. < self.recurrent_dropout < 1.:\n         \
    \       h_tm1 *= rec_dp_mask[0]\n\n            if self.reset_after:\n        \
    \        # hidden state projected by all gate matrices at once\n             \
    \   matrix_inner = K.dot(h_tm1, self.recurrent_kernel)\n                if self.use_bias:\n\
    \                    matrix_inner = K.bias_add(matrix_inner, self.recurrent_bias)\n\
    \            else:\n                # hidden state projected separately for update/reset\
    \ and new\n                matrix_inner = K.dot(h_tm1,\n                     \
    \                self.recurrent_kernel[:, :2 * self.units])\n\n            recurrent_z\
    \ = matrix_inner[:, :self.units]\n            recurrent_r = matrix_inner[:, self.units:\
    \ 2 * self.units]\n\n            z = self.recurrent_activation(x_z + recurrent_z)\n\
    \            r = self.recurrent_activation(x_r + recurrent_r)\n\n            if\
    \ self.reset_after:\n                recurrent_h = r * matrix_inner[:, 2 * self.units:]\n\
    \            else:\n                recurrent_h = K.dot(r * h_tm1,\n         \
    \                           self.recurrent_kernel[:, 2 * self.units:])\n\n   \
    \         hh = self.activation(x_h + recurrent_h)\n\n        # previous and candidate\
    \ state mixed by update gate\n        h = z * h_tm1 + (1 - z) * hh\n\n       \
    \ if 0 < self.dropout + self.recurrent_dropout:\n            if training is None:\n\
    \                h._uses_learning_phase = True\n\n        return h, [h]\n\n  \
    \  def get_config(self):\n        config = {'units': self.units,\n           \
    \       'activation': activations.serialize(self.activation),\n              \
    \    'recurrent_activation':\n                      activations.serialize(self.recurrent_activation),\n\
    \                  'use_bias': self.use_bias,\n                  'kernel_initializer':\n\
    \                      initializers.serialize(self.kernel_initializer),\n    \
    \              'recurrent_initializer':\n                      initializers.serialize(self.recurrent_initializer),\n\
    \                  'bias_initializer': initializers.serialize(self.bias_initializer),\n\
    \                  'kernel_regularizer':\n                      regularizers.serialize(self.kernel_regularizer),\n\
    \                  'recurrent_regularizer':\n                      regularizers.serialize(self.recurrent_regularizer),\n\
    \                  'bias_regularizer': regularizers.serialize(self.bias_regularizer),\n\
    \                  'kernel_constraint': constraints.serialize(self.kernel_constraint),\n\
    \                  'recurrent_constraint':\n                      constraints.serialize(self.recurrent_constraint),\n\
    \                  'bias_constraint': constraints.serialize(self.bias_constraint),\n\
    \                  'dropout': self.dropout,\n                  'recurrent_dropout':\
    \ self.recurrent_dropout,\n                  'implementation': self.implementation,\n\
    \                  'reset_after': self.reset_after}\n        base_config = super(GRUCell,\
    \ self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))\n"
  sourcefile: D:\Python36\lib\site-packages\keras\layers\recurrent.py
- doc: "Apply multiplicative 1-centered Gaussian noise.\n\nAs it is a regularization\
    \ layer, it is only active at training time.\n\n# Arguments\n    rate: float,\
    \ drop probability (as with `Dropout`).\n        The multiplicative noise will\
    \ have\n        standard deviation `sqrt(rate / (1 - rate))`.\n\n# Input shape\n\
    \    Arbitrary. Use the keyword argument `input_shape`\n    (tuple of integers,\
    \ does not include the samples axis)\n    when using this layer as the first layer\
    \ in a model.\n\n# Output shape\n    Same shape as input.\n\n# References\n  \
    \  - [Dropout: A Simple Way to Prevent Neural Networks from Overfitting]\n   \
    \   (http://www.cs.toronto.edu/~rsalakhu/papers/srivastava14a.pdf)"
  kind: Layer
  name: GaussianDropout
  parameters:
  - {kind: any, name: rate}
  - {defaultValue: 'true', name: trainable, type: bool}
  source: "class GaussianDropout(Layer):\n    \"\"\"Apply multiplicative 1-centered\
    \ Gaussian noise.\n\n    As it is a regularization layer, it is only active at\
    \ training time.\n\n    # Arguments\n        rate: float, drop probability (as\
    \ with `Dropout`).\n            The multiplicative noise will have\n         \
    \   standard deviation `sqrt(rate / (1 - rate))`.\n\n    # Input shape\n     \
    \   Arbitrary. Use the keyword argument `input_shape`\n        (tuple of integers,\
    \ does not include the samples axis)\n        when using this layer as the first\
    \ layer in a model.\n\n    # Output shape\n        Same shape as input.\n\n  \
    \  # References\n        - [Dropout: A Simple Way to Prevent Neural Networks from\
    \ Overfitting]\n          (http://www.cs.toronto.edu/~rsalakhu/papers/srivastava14a.pdf)\n\
    \    \"\"\"\n\n    @interfaces.legacy_gaussiandropout_support\n    def __init__(self,\
    \ rate, **kwargs):\n        super(GaussianDropout, self).__init__(**kwargs)\n\
    \        self.supports_masking = True\n        self.rate = rate\n\n    def call(self,\
    \ inputs, training=None):\n        if 0 < self.rate < 1:\n            def noised():\n\
    \                stddev = np.sqrt(self.rate / (1.0 - self.rate))\n           \
    \     return inputs * K.random_normal(shape=K.shape(inputs),\n               \
    \                                 mean=1.0,\n                                \
    \                stddev=stddev)\n            return K.in_train_phase(noised, inputs,\
    \ training=training)\n        return inputs\n\n    def get_config(self):\n   \
    \     config = {'rate': self.rate}\n        base_config = super(GaussianDropout,\
    \ self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))\n\
    \n    def compute_output_shape(self, input_shape):\n        return input_shape\n"
  sourcefile: D:\Python36\lib\site-packages\keras\layers\noise.py
- doc: "Apply additive zero-centered Gaussian noise.\n\nThis is useful to mitigate\
    \ overfitting\n(you could see it as a form of random data augmentation).\nGaussian\
    \ Noise (GS) is a natural choice as corruption process\nfor real valued inputs.\n\
    \nAs it is a regularization layer, it is only active at training time.\n\n# Arguments\n\
    \    stddev: float, standard deviation of the noise distribution.\n\n# Input shape\n\
    \    Arbitrary. Use the keyword argument `input_shape`\n    (tuple of integers,\
    \ does not include the samples axis)\n    when using this layer as the first layer\
    \ in a model.\n\n# Output shape\n    Same shape as input."
  kind: Layer
  name: GaussianNoise
  parameters:
  - {kind: any, name: stddev}
  - {defaultValue: 'true', name: trainable, type: bool}
  source: "class GaussianNoise(Layer):\n    \"\"\"Apply additive zero-centered Gaussian\
    \ noise.\n\n    This is useful to mitigate overfitting\n    (you could see it\
    \ as a form of random data augmentation).\n    Gaussian Noise (GS) is a natural\
    \ choice as corruption process\n    for real valued inputs.\n\n    As it is a\
    \ regularization layer, it is only active at training time.\n\n    # Arguments\n\
    \        stddev: float, standard deviation of the noise distribution.\n\n    #\
    \ Input shape\n        Arbitrary. Use the keyword argument `input_shape`\n   \
    \     (tuple of integers, does not include the samples axis)\n        when using\
    \ this layer as the first layer in a model.\n\n    # Output shape\n        Same\
    \ shape as input.\n    \"\"\"\n\n    @interfaces.legacy_gaussiannoise_support\n\
    \    def __init__(self, stddev, **kwargs):\n        super(GaussianNoise, self).__init__(**kwargs)\n\
    \        self.supports_masking = True\n        self.stddev = stddev\n\n    def\
    \ call(self, inputs, training=None):\n        def noised():\n            return\
    \ inputs + K.random_normal(shape=K.shape(inputs),\n                          \
    \                  mean=0.,\n                                            stddev=self.stddev)\n\
    \        return K.in_train_phase(noised, inputs, training=training)\n\n    def\
    \ get_config(self):\n        config = {'stddev': self.stddev}\n        base_config\
    \ = super(GaussianNoise, self).get_config()\n        return dict(list(base_config.items())\
    \ + list(config.items()))\n\n    def compute_output_shape(self, input_shape):\n\
    \        return input_shape\n"
  sourcefile: D:\Python36\lib\site-packages\keras\layers\noise.py
- doc: "Global average pooling operation for temporal data.\n\n# Arguments\n    data_format:\
    \ A string,\n        one of `channels_last` (default) or `channels_first`.\n \
    \       The ordering of the dimensions in the inputs.\n        `channels_last`\
    \ corresponds to inputs with shape\n        `(batch, steps, features)` while `channels_first`\n\
    \        corresponds to inputs with shape\n        `(batch, features, steps)`.\n\
    \n# Input shape\n    - If `data_format='channels_last'`:\n        3D tensor with\
    \ shape:\n        `(batch_size, steps, features)`\n    - If `data_format='channels_first'`:\n\
    \        3D tensor with shape:\n        `(batch_size, features, steps)`\n\n# Output\
    \ shape\n    2D tensor with shape:\n    `(batch_size, features)`"
  kind: Layer
  name: GlobalAveragePooling1D
  parameters:
  - {defaultValue: channels_last, kind: any, name: data_format}
  - {defaultValue: 'true', name: trainable, type: bool}
  source: "class GlobalAveragePooling1D(_GlobalPooling1D):\n    \"\"\"Global average\
    \ pooling operation for temporal data.\n\n    # Arguments\n        data_format:\
    \ A string,\n            one of `channels_last` (default) or `channels_first`.\n\
    \            The ordering of the dimensions in the inputs.\n            `channels_last`\
    \ corresponds to inputs with shape\n            `(batch, steps, features)` while\
    \ `channels_first`\n            corresponds to inputs with shape\n           \
    \ `(batch, features, steps)`.\n\n    # Input shape\n        - If `data_format='channels_last'`:\n\
    \            3D tensor with shape:\n            `(batch_size, steps, features)`\n\
    \        - If `data_format='channels_first'`:\n            3D tensor with shape:\n\
    \            `(batch_size, features, steps)`\n\n    # Output shape\n        2D\
    \ tensor with shape:\n        `(batch_size, features)`\n    \"\"\"\n\n    def\
    \ __init__(self, data_format='channels_last', **kwargs):\n        super(GlobalAveragePooling1D,\
    \ self).__init__(data_format,\n                                              \
    \       **kwargs)\n        self.supports_masking = True\n\n    def call(self,\
    \ inputs, mask=None):\n        steps_axis = 1 if self.data_format == 'channels_last'\
    \ else 2\n        if mask is not None:\n            mask = K.cast(mask, K.floatx())\n\
    \            input_shape = K.int_shape(inputs)\n            broadcast_shape =\
    \ [-1, input_shape[steps_axis], 1]\n            mask = K.reshape(mask, broadcast_shape)\n\
    \            inputs *= mask\n            return K.sum(inputs, axis=steps_axis)\
    \ / K.sum(mask, axis=steps_axis)\n        else:\n            return K.mean(inputs,\
    \ axis=steps_axis)\n\n    def compute_mask(self, inputs, mask=None):\n       \
    \ return None\n"
  sourcefile: D:\Python36\lib\site-packages\keras\layers\pooling.py
- doc: "Global average pooling operation for spatial data.\n\n# Arguments\n    data_format:\
    \ A string,\n        one of `channels_last` (default) or `channels_first`.\n \
    \       The ordering of the dimensions in the inputs.\n        `channels_last`\
    \ corresponds to inputs with shape\n        `(batch, height, width, channels)`\
    \ while `channels_first`\n        corresponds to inputs with shape\n        `(batch,\
    \ channels, height, width)`.\n        It defaults to the `image_data_format` value\
    \ found in your\n        Keras config file at `~/.keras/keras.json`.\n       \
    \ If you never set it, then it will be \"channels_last\".\n\n# Input shape\n \
    \   - If `data_format='channels_last'`:\n        4D tensor with shape:\n     \
    \   `(batch_size, rows, cols, channels)`\n    - If `data_format='channels_first'`:\n\
    \        4D tensor with shape:\n        `(batch_size, channels, rows, cols)`\n\
    \n# Output shape\n    2D tensor with shape:\n    `(batch_size, channels)`"
  kind: Layer
  name: GlobalAveragePooling2D
  parameters:
  - {defaultValue: None, kind: any, name: data_format}
  - {defaultValue: 'true', name: trainable, type: bool}
  source: "class GlobalAveragePooling2D(_GlobalPooling2D):\n    \"\"\"Global average\
    \ pooling operation for spatial data.\n\n    # Arguments\n        data_format:\
    \ A string,\n            one of `channels_last` (default) or `channels_first`.\n\
    \            The ordering of the dimensions in the inputs.\n            `channels_last`\
    \ corresponds to inputs with shape\n            `(batch, height, width, channels)`\
    \ while `channels_first`\n            corresponds to inputs with shape\n     \
    \       `(batch, channels, height, width)`.\n            It defaults to the `image_data_format`\
    \ value found in your\n            Keras config file at `~/.keras/keras.json`.\n\
    \            If you never set it, then it will be \"channels_last\".\n\n    #\
    \ Input shape\n        - If `data_format='channels_last'`:\n            4D tensor\
    \ with shape:\n            `(batch_size, rows, cols, channels)`\n        - If\
    \ `data_format='channels_first'`:\n            4D tensor with shape:\n       \
    \     `(batch_size, channels, rows, cols)`\n\n    # Output shape\n        2D tensor\
    \ with shape:\n        `(batch_size, channels)`\n    \"\"\"\n\n    def call(self,\
    \ inputs):\n        if self.data_format == 'channels_last':\n            return\
    \ K.mean(inputs, axis=[1, 2])\n        else:\n            return K.mean(inputs,\
    \ axis=[2, 3])\n"
  sourcefile: D:\Python36\lib\site-packages\keras\layers\pooling.py
- doc: "Global Average pooling operation for 3D data.\n\n# Arguments\n    data_format:\
    \ A string,\n        one of `channels_last` (default) or `channels_first`.\n \
    \       The ordering of the dimensions in the inputs.\n        `channels_last`\
    \ corresponds to inputs with shape\n        `(batch, spatial_dim1, spatial_dim2,\
    \ spatial_dim3, channels)`\n        while `channels_first` corresponds to inputs\
    \ with shape\n        `(batch, channels, spatial_dim1, spatial_dim2, spatial_dim3)`.\n\
    \        It defaults to the `image_data_format` value found in your\n        Keras\
    \ config file at `~/.keras/keras.json`.\n        If you never set it, then it\
    \ will be \"channels_last\".\n\n# Input shape\n    - If `data_format='channels_last'`:\n\
    \        5D tensor with shape:\n        `(batch_size, spatial_dim1, spatial_dim2,\
    \ spatial_dim3, channels)`\n    - If `data_format='channels_first'`:\n       \
    \ 5D tensor with shape:\n        `(batch_size, channels, spatial_dim1, spatial_dim2,\
    \ spatial_dim3)`\n\n# Output shape\n    2D tensor with shape:\n    `(batch_size,\
    \ channels)`"
  kind: Layer
  name: GlobalAveragePooling3D
  parameters:
  - {defaultValue: None, kind: any, name: data_format}
  - {defaultValue: 'true', name: trainable, type: bool}
  source: "class GlobalAveragePooling3D(_GlobalPooling3D):\n    \"\"\"Global Average\
    \ pooling operation for 3D data.\n\n    # Arguments\n        data_format: A string,\n\
    \            one of `channels_last` (default) or `channels_first`.\n         \
    \   The ordering of the dimensions in the inputs.\n            `channels_last`\
    \ corresponds to inputs with shape\n            `(batch, spatial_dim1, spatial_dim2,\
    \ spatial_dim3, channels)`\n            while `channels_first` corresponds to\
    \ inputs with shape\n            `(batch, channels, spatial_dim1, spatial_dim2,\
    \ spatial_dim3)`.\n            It defaults to the `image_data_format` value found\
    \ in your\n            Keras config file at `~/.keras/keras.json`.\n         \
    \   If you never set it, then it will be \"channels_last\".\n\n    # Input shape\n\
    \        - If `data_format='channels_last'`:\n            5D tensor with shape:\n\
    \            `(batch_size, spatial_dim1, spatial_dim2, spatial_dim3, channels)`\n\
    \        - If `data_format='channels_first'`:\n            5D tensor with shape:\n\
    \            `(batch_size, channels, spatial_dim1, spatial_dim2, spatial_dim3)`\n\
    \n    # Output shape\n        2D tensor with shape:\n        `(batch_size, channels)`\n\
    \    \"\"\"\n\n    def call(self, inputs):\n        if self.data_format == 'channels_last':\n\
    \            return K.mean(inputs, axis=[1, 2, 3])\n        else:\n          \
    \  return K.mean(inputs, axis=[2, 3, 4])\n"
  sourcefile: D:\Python36\lib\site-packages\keras\layers\pooling.py
- doc: "Global average pooling operation for temporal data.\n\n# Arguments\n    data_format:\
    \ A string,\n        one of `channels_last` (default) or `channels_first`.\n \
    \       The ordering of the dimensions in the inputs.\n        `channels_last`\
    \ corresponds to inputs with shape\n        `(batch, steps, features)` while `channels_first`\n\
    \        corresponds to inputs with shape\n        `(batch, features, steps)`.\n\
    \n# Input shape\n    - If `data_format='channels_last'`:\n        3D tensor with\
    \ shape:\n        `(batch_size, steps, features)`\n    - If `data_format='channels_first'`:\n\
    \        3D tensor with shape:\n        `(batch_size, features, steps)`\n\n# Output\
    \ shape\n    2D tensor with shape:\n    `(batch_size, features)`"
  kind: Layer
  name: GlobalAveragePooling1D
  parameters:
  - {defaultValue: channels_last, kind: any, name: data_format}
  - {defaultValue: 'true', name: trainable, type: bool}
  source: "class GlobalAveragePooling1D(_GlobalPooling1D):\n    \"\"\"Global average\
    \ pooling operation for temporal data.\n\n    # Arguments\n        data_format:\
    \ A string,\n            one of `channels_last` (default) or `channels_first`.\n\
    \            The ordering of the dimensions in the inputs.\n            `channels_last`\
    \ corresponds to inputs with shape\n            `(batch, steps, features)` while\
    \ `channels_first`\n            corresponds to inputs with shape\n           \
    \ `(batch, features, steps)`.\n\n    # Input shape\n        - If `data_format='channels_last'`:\n\
    \            3D tensor with shape:\n            `(batch_size, steps, features)`\n\
    \        - If `data_format='channels_first'`:\n            3D tensor with shape:\n\
    \            `(batch_size, features, steps)`\n\n    # Output shape\n        2D\
    \ tensor with shape:\n        `(batch_size, features)`\n    \"\"\"\n\n    def\
    \ __init__(self, data_format='channels_last', **kwargs):\n        super(GlobalAveragePooling1D,\
    \ self).__init__(data_format,\n                                              \
    \       **kwargs)\n        self.supports_masking = True\n\n    def call(self,\
    \ inputs, mask=None):\n        steps_axis = 1 if self.data_format == 'channels_last'\
    \ else 2\n        if mask is not None:\n            mask = K.cast(mask, K.floatx())\n\
    \            input_shape = K.int_shape(inputs)\n            broadcast_shape =\
    \ [-1, input_shape[steps_axis], 1]\n            mask = K.reshape(mask, broadcast_shape)\n\
    \            inputs *= mask\n            return K.sum(inputs, axis=steps_axis)\
    \ / K.sum(mask, axis=steps_axis)\n        else:\n            return K.mean(inputs,\
    \ axis=steps_axis)\n\n    def compute_mask(self, inputs, mask=None):\n       \
    \ return None\n"
  sourcefile: D:\Python36\lib\site-packages\keras\layers\pooling.py
- doc: "Global average pooling operation for spatial data.\n\n# Arguments\n    data_format:\
    \ A string,\n        one of `channels_last` (default) or `channels_first`.\n \
    \       The ordering of the dimensions in the inputs.\n        `channels_last`\
    \ corresponds to inputs with shape\n        `(batch, height, width, channels)`\
    \ while `channels_first`\n        corresponds to inputs with shape\n        `(batch,\
    \ channels, height, width)`.\n        It defaults to the `image_data_format` value\
    \ found in your\n        Keras config file at `~/.keras/keras.json`.\n       \
    \ If you never set it, then it will be \"channels_last\".\n\n# Input shape\n \
    \   - If `data_format='channels_last'`:\n        4D tensor with shape:\n     \
    \   `(batch_size, rows, cols, channels)`\n    - If `data_format='channels_first'`:\n\
    \        4D tensor with shape:\n        `(batch_size, channels, rows, cols)`\n\
    \n# Output shape\n    2D tensor with shape:\n    `(batch_size, channels)`"
  kind: Layer
  name: GlobalAveragePooling2D
  parameters:
  - {defaultValue: None, kind: any, name: data_format}
  - {defaultValue: 'true', name: trainable, type: bool}
  source: "class GlobalAveragePooling2D(_GlobalPooling2D):\n    \"\"\"Global average\
    \ pooling operation for spatial data.\n\n    # Arguments\n        data_format:\
    \ A string,\n            one of `channels_last` (default) or `channels_first`.\n\
    \            The ordering of the dimensions in the inputs.\n            `channels_last`\
    \ corresponds to inputs with shape\n            `(batch, height, width, channels)`\
    \ while `channels_first`\n            corresponds to inputs with shape\n     \
    \       `(batch, channels, height, width)`.\n            It defaults to the `image_data_format`\
    \ value found in your\n            Keras config file at `~/.keras/keras.json`.\n\
    \            If you never set it, then it will be \"channels_last\".\n\n    #\
    \ Input shape\n        - If `data_format='channels_last'`:\n            4D tensor\
    \ with shape:\n            `(batch_size, rows, cols, channels)`\n        - If\
    \ `data_format='channels_first'`:\n            4D tensor with shape:\n       \
    \     `(batch_size, channels, rows, cols)`\n\n    # Output shape\n        2D tensor\
    \ with shape:\n        `(batch_size, channels)`\n    \"\"\"\n\n    def call(self,\
    \ inputs):\n        if self.data_format == 'channels_last':\n            return\
    \ K.mean(inputs, axis=[1, 2])\n        else:\n            return K.mean(inputs,\
    \ axis=[2, 3])\n"
  sourcefile: D:\Python36\lib\site-packages\keras\layers\pooling.py
- doc: "Global Average pooling operation for 3D data.\n\n# Arguments\n    data_format:\
    \ A string,\n        one of `channels_last` (default) or `channels_first`.\n \
    \       The ordering of the dimensions in the inputs.\n        `channels_last`\
    \ corresponds to inputs with shape\n        `(batch, spatial_dim1, spatial_dim2,\
    \ spatial_dim3, channels)`\n        while `channels_first` corresponds to inputs\
    \ with shape\n        `(batch, channels, spatial_dim1, spatial_dim2, spatial_dim3)`.\n\
    \        It defaults to the `image_data_format` value found in your\n        Keras\
    \ config file at `~/.keras/keras.json`.\n        If you never set it, then it\
    \ will be \"channels_last\".\n\n# Input shape\n    - If `data_format='channels_last'`:\n\
    \        5D tensor with shape:\n        `(batch_size, spatial_dim1, spatial_dim2,\
    \ spatial_dim3, channels)`\n    - If `data_format='channels_first'`:\n       \
    \ 5D tensor with shape:\n        `(batch_size, channels, spatial_dim1, spatial_dim2,\
    \ spatial_dim3)`\n\n# Output shape\n    2D tensor with shape:\n    `(batch_size,\
    \ channels)`"
  kind: Layer
  name: GlobalAveragePooling3D
  parameters:
  - {defaultValue: None, kind: any, name: data_format}
  - {defaultValue: 'true', name: trainable, type: bool}
  source: "class GlobalAveragePooling3D(_GlobalPooling3D):\n    \"\"\"Global Average\
    \ pooling operation for 3D data.\n\n    # Arguments\n        data_format: A string,\n\
    \            one of `channels_last` (default) or `channels_first`.\n         \
    \   The ordering of the dimensions in the inputs.\n            `channels_last`\
    \ corresponds to inputs with shape\n            `(batch, spatial_dim1, spatial_dim2,\
    \ spatial_dim3, channels)`\n            while `channels_first` corresponds to\
    \ inputs with shape\n            `(batch, channels, spatial_dim1, spatial_dim2,\
    \ spatial_dim3)`.\n            It defaults to the `image_data_format` value found\
    \ in your\n            Keras config file at `~/.keras/keras.json`.\n         \
    \   If you never set it, then it will be \"channels_last\".\n\n    # Input shape\n\
    \        - If `data_format='channels_last'`:\n            5D tensor with shape:\n\
    \            `(batch_size, spatial_dim1, spatial_dim2, spatial_dim3, channels)`\n\
    \        - If `data_format='channels_first'`:\n            5D tensor with shape:\n\
    \            `(batch_size, channels, spatial_dim1, spatial_dim2, spatial_dim3)`\n\
    \n    # Output shape\n        2D tensor with shape:\n        `(batch_size, channels)`\n\
    \    \"\"\"\n\n    def call(self, inputs):\n        if self.data_format == 'channels_last':\n\
    \            return K.mean(inputs, axis=[1, 2, 3])\n        else:\n          \
    \  return K.mean(inputs, axis=[2, 3, 4])\n"
  sourcefile: D:\Python36\lib\site-packages\keras\layers\pooling.py
- doc: "Global max pooling operation for temporal data.\n\n# Arguments\n    data_format:\
    \ A string,\n        one of `channels_last` (default) or `channels_first`.\n \
    \       The ordering of the dimensions in the inputs.\n        `channels_last`\
    \ corresponds to inputs with shape\n        `(batch, steps, features)` while `channels_first`\n\
    \        corresponds to inputs with shape\n        `(batch, features, steps)`.\n\
    \n# Input shape\n    - If `data_format='channels_last'`:\n        3D tensor with\
    \ shape:\n        `(batch_size, steps, features)`\n    - If `data_format='channels_first'`:\n\
    \        3D tensor with shape:\n        `(batch_size, features, steps)`\n\n# Output\
    \ shape\n    2D tensor with shape:\n    `(batch_size, features)`"
  kind: Layer
  name: GlobalMaxPooling1D
  parameters:
  - {defaultValue: channels_last, kind: any, name: data_format}
  - {defaultValue: 'true', name: trainable, type: bool}
  source: "class GlobalMaxPooling1D(_GlobalPooling1D):\n    \"\"\"Global max pooling\
    \ operation for temporal data.\n\n    # Arguments\n        data_format: A string,\n\
    \            one of `channels_last` (default) or `channels_first`.\n         \
    \   The ordering of the dimensions in the inputs.\n            `channels_last`\
    \ corresponds to inputs with shape\n            `(batch, steps, features)` while\
    \ `channels_first`\n            corresponds to inputs with shape\n           \
    \ `(batch, features, steps)`.\n\n    # Input shape\n        - If `data_format='channels_last'`:\n\
    \            3D tensor with shape:\n            `(batch_size, steps, features)`\n\
    \        - If `data_format='channels_first'`:\n            3D tensor with shape:\n\
    \            `(batch_size, features, steps)`\n\n    # Output shape\n        2D\
    \ tensor with shape:\n        `(batch_size, features)`\n    \"\"\"\n\n    def\
    \ call(self, inputs):\n        steps_axis = 1 if self.data_format == 'channels_last'\
    \ else 2\n        return K.max(inputs, axis=steps_axis)\n"
  sourcefile: D:\Python36\lib\site-packages\keras\layers\pooling.py
- doc: "Global max pooling operation for spatial data.\n\n# Arguments\n    data_format:\
    \ A string,\n        one of `channels_last` (default) or `channels_first`.\n \
    \       The ordering of the dimensions in the inputs.\n        `channels_last`\
    \ corresponds to inputs with shape\n        `(batch, height, width, channels)`\
    \ while `channels_first`\n        corresponds to inputs with shape\n        `(batch,\
    \ channels, height, width)`.\n        It defaults to the `image_data_format` value\
    \ found in your\n        Keras config file at `~/.keras/keras.json`.\n       \
    \ If you never set it, then it will be \"channels_last\".\n\n# Input shape\n \
    \   - If `data_format='channels_last'`:\n        4D tensor with shape:\n     \
    \   `(batch_size, rows, cols, channels)`\n    - If `data_format='channels_first'`:\n\
    \        4D tensor with shape:\n        `(batch_size, channels, rows, cols)`\n\
    \n# Output shape\n    2D tensor with shape:\n    `(batch_size, channels)`"
  kind: Layer
  name: GlobalMaxPooling2D
  parameters:
  - {defaultValue: None, kind: any, name: data_format}
  - {defaultValue: 'true', name: trainable, type: bool}
  source: "class GlobalMaxPooling2D(_GlobalPooling2D):\n    \"\"\"Global max pooling\
    \ operation for spatial data.\n\n    # Arguments\n        data_format: A string,\n\
    \            one of `channels_last` (default) or `channels_first`.\n         \
    \   The ordering of the dimensions in the inputs.\n            `channels_last`\
    \ corresponds to inputs with shape\n            `(batch, height, width, channels)`\
    \ while `channels_first`\n            corresponds to inputs with shape\n     \
    \       `(batch, channels, height, width)`.\n            It defaults to the `image_data_format`\
    \ value found in your\n            Keras config file at `~/.keras/keras.json`.\n\
    \            If you never set it, then it will be \"channels_last\".\n\n    #\
    \ Input shape\n        - If `data_format='channels_last'`:\n            4D tensor\
    \ with shape:\n            `(batch_size, rows, cols, channels)`\n        - If\
    \ `data_format='channels_first'`:\n            4D tensor with shape:\n       \
    \     `(batch_size, channels, rows, cols)`\n\n    # Output shape\n        2D tensor\
    \ with shape:\n        `(batch_size, channels)`\n    \"\"\"\n\n    def call(self,\
    \ inputs):\n        if self.data_format == 'channels_last':\n            return\
    \ K.max(inputs, axis=[1, 2])\n        else:\n            return K.max(inputs,\
    \ axis=[2, 3])\n"
  sourcefile: D:\Python36\lib\site-packages\keras\layers\pooling.py
- doc: "Global Max pooling operation for 3D data.\n\n# Arguments\n    data_format:\
    \ A string,\n        one of `channels_last` (default) or `channels_first`.\n \
    \       The ordering of the dimensions in the inputs.\n        `channels_last`\
    \ corresponds to inputs with shape\n        `(batch, spatial_dim1, spatial_dim2,\
    \ spatial_dim3, channels)`\n        while `channels_first` corresponds to inputs\
    \ with shape\n        `(batch, channels, spatial_dim1, spatial_dim2, spatial_dim3)`.\n\
    \        It defaults to the `image_data_format` value found in your\n        Keras\
    \ config file at `~/.keras/keras.json`.\n        If you never set it, then it\
    \ will be \"channels_last\".\n\n# Input shape\n    - If `data_format='channels_last'`:\n\
    \        5D tensor with shape:\n        `(batch_size, spatial_dim1, spatial_dim2,\
    \ spatial_dim3, channels)`\n    - If `data_format='channels_first'`:\n       \
    \ 5D tensor with shape:\n        `(batch_size, channels, spatial_dim1, spatial_dim2,\
    \ spatial_dim3)`\n\n# Output shape\n    2D tensor with shape:\n    `(batch_size,\
    \ channels)`"
  kind: Layer
  name: GlobalMaxPooling3D
  parameters:
  - {defaultValue: None, kind: any, name: data_format}
  - {defaultValue: 'true', name: trainable, type: bool}
  source: "class GlobalMaxPooling3D(_GlobalPooling3D):\n    \"\"\"Global Max pooling\
    \ operation for 3D data.\n\n    # Arguments\n        data_format: A string,\n\
    \            one of `channels_last` (default) or `channels_first`.\n         \
    \   The ordering of the dimensions in the inputs.\n            `channels_last`\
    \ corresponds to inputs with shape\n            `(batch, spatial_dim1, spatial_dim2,\
    \ spatial_dim3, channels)`\n            while `channels_first` corresponds to\
    \ inputs with shape\n            `(batch, channels, spatial_dim1, spatial_dim2,\
    \ spatial_dim3)`.\n            It defaults to the `image_data_format` value found\
    \ in your\n            Keras config file at `~/.keras/keras.json`.\n         \
    \   If you never set it, then it will be \"channels_last\".\n\n    # Input shape\n\
    \        - If `data_format='channels_last'`:\n            5D tensor with shape:\n\
    \            `(batch_size, spatial_dim1, spatial_dim2, spatial_dim3, channels)`\n\
    \        - If `data_format='channels_first'`:\n            5D tensor with shape:\n\
    \            `(batch_size, channels, spatial_dim1, spatial_dim2, spatial_dim3)`\n\
    \n    # Output shape\n        2D tensor with shape:\n        `(batch_size, channels)`\n\
    \    \"\"\"\n\n    def call(self, inputs):\n        if self.data_format == 'channels_last':\n\
    \            return K.max(inputs, axis=[1, 2, 3])\n        else:\n           \
    \ return K.max(inputs, axis=[2, 3, 4])\n"
  sourcefile: D:\Python36\lib\site-packages\keras\layers\pooling.py
- doc: "Global max pooling operation for temporal data.\n\n# Arguments\n    data_format:\
    \ A string,\n        one of `channels_last` (default) or `channels_first`.\n \
    \       The ordering of the dimensions in the inputs.\n        `channels_last`\
    \ corresponds to inputs with shape\n        `(batch, steps, features)` while `channels_first`\n\
    \        corresponds to inputs with shape\n        `(batch, features, steps)`.\n\
    \n# Input shape\n    - If `data_format='channels_last'`:\n        3D tensor with\
    \ shape:\n        `(batch_size, steps, features)`\n    - If `data_format='channels_first'`:\n\
    \        3D tensor with shape:\n        `(batch_size, features, steps)`\n\n# Output\
    \ shape\n    2D tensor with shape:\n    `(batch_size, features)`"
  kind: Layer
  name: GlobalMaxPooling1D
  parameters:
  - {defaultValue: channels_last, kind: any, name: data_format}
  - {defaultValue: 'true', name: trainable, type: bool}
  source: "class GlobalMaxPooling1D(_GlobalPooling1D):\n    \"\"\"Global max pooling\
    \ operation for temporal data.\n\n    # Arguments\n        data_format: A string,\n\
    \            one of `channels_last` (default) or `channels_first`.\n         \
    \   The ordering of the dimensions in the inputs.\n            `channels_last`\
    \ corresponds to inputs with shape\n            `(batch, steps, features)` while\
    \ `channels_first`\n            corresponds to inputs with shape\n           \
    \ `(batch, features, steps)`.\n\n    # Input shape\n        - If `data_format='channels_last'`:\n\
    \            3D tensor with shape:\n            `(batch_size, steps, features)`\n\
    \        - If `data_format='channels_first'`:\n            3D tensor with shape:\n\
    \            `(batch_size, features, steps)`\n\n    # Output shape\n        2D\
    \ tensor with shape:\n        `(batch_size, features)`\n    \"\"\"\n\n    def\
    \ call(self, inputs):\n        steps_axis = 1 if self.data_format == 'channels_last'\
    \ else 2\n        return K.max(inputs, axis=steps_axis)\n"
  sourcefile: D:\Python36\lib\site-packages\keras\layers\pooling.py
- doc: "Global max pooling operation for spatial data.\n\n# Arguments\n    data_format:\
    \ A string,\n        one of `channels_last` (default) or `channels_first`.\n \
    \       The ordering of the dimensions in the inputs.\n        `channels_last`\
    \ corresponds to inputs with shape\n        `(batch, height, width, channels)`\
    \ while `channels_first`\n        corresponds to inputs with shape\n        `(batch,\
    \ channels, height, width)`.\n        It defaults to the `image_data_format` value\
    \ found in your\n        Keras config file at `~/.keras/keras.json`.\n       \
    \ If you never set it, then it will be \"channels_last\".\n\n# Input shape\n \
    \   - If `data_format='channels_last'`:\n        4D tensor with shape:\n     \
    \   `(batch_size, rows, cols, channels)`\n    - If `data_format='channels_first'`:\n\
    \        4D tensor with shape:\n        `(batch_size, channels, rows, cols)`\n\
    \n# Output shape\n    2D tensor with shape:\n    `(batch_size, channels)`"
  kind: Layer
  name: GlobalMaxPooling2D
  parameters:
  - {defaultValue: None, kind: any, name: data_format}
  - {defaultValue: 'true', name: trainable, type: bool}
  source: "class GlobalMaxPooling2D(_GlobalPooling2D):\n    \"\"\"Global max pooling\
    \ operation for spatial data.\n\n    # Arguments\n        data_format: A string,\n\
    \            one of `channels_last` (default) or `channels_first`.\n         \
    \   The ordering of the dimensions in the inputs.\n            `channels_last`\
    \ corresponds to inputs with shape\n            `(batch, height, width, channels)`\
    \ while `channels_first`\n            corresponds to inputs with shape\n     \
    \       `(batch, channels, height, width)`.\n            It defaults to the `image_data_format`\
    \ value found in your\n            Keras config file at `~/.keras/keras.json`.\n\
    \            If you never set it, then it will be \"channels_last\".\n\n    #\
    \ Input shape\n        - If `data_format='channels_last'`:\n            4D tensor\
    \ with shape:\n            `(batch_size, rows, cols, channels)`\n        - If\
    \ `data_format='channels_first'`:\n            4D tensor with shape:\n       \
    \     `(batch_size, channels, rows, cols)`\n\n    # Output shape\n        2D tensor\
    \ with shape:\n        `(batch_size, channels)`\n    \"\"\"\n\n    def call(self,\
    \ inputs):\n        if self.data_format == 'channels_last':\n            return\
    \ K.max(inputs, axis=[1, 2])\n        else:\n            return K.max(inputs,\
    \ axis=[2, 3])\n"
  sourcefile: D:\Python36\lib\site-packages\keras\layers\pooling.py
- doc: "Global Max pooling operation for 3D data.\n\n# Arguments\n    data_format:\
    \ A string,\n        one of `channels_last` (default) or `channels_first`.\n \
    \       The ordering of the dimensions in the inputs.\n        `channels_last`\
    \ corresponds to inputs with shape\n        `(batch, spatial_dim1, spatial_dim2,\
    \ spatial_dim3, channels)`\n        while `channels_first` corresponds to inputs\
    \ with shape\n        `(batch, channels, spatial_dim1, spatial_dim2, spatial_dim3)`.\n\
    \        It defaults to the `image_data_format` value found in your\n        Keras\
    \ config file at `~/.keras/keras.json`.\n        If you never set it, then it\
    \ will be \"channels_last\".\n\n# Input shape\n    - If `data_format='channels_last'`:\n\
    \        5D tensor with shape:\n        `(batch_size, spatial_dim1, spatial_dim2,\
    \ spatial_dim3, channels)`\n    - If `data_format='channels_first'`:\n       \
    \ 5D tensor with shape:\n        `(batch_size, channels, spatial_dim1, spatial_dim2,\
    \ spatial_dim3)`\n\n# Output shape\n    2D tensor with shape:\n    `(batch_size,\
    \ channels)`"
  kind: Layer
  name: GlobalMaxPooling3D
  parameters:
  - {defaultValue: None, kind: any, name: data_format}
  - {defaultValue: 'true', name: trainable, type: bool}
  source: "class GlobalMaxPooling3D(_GlobalPooling3D):\n    \"\"\"Global Max pooling\
    \ operation for 3D data.\n\n    # Arguments\n        data_format: A string,\n\
    \            one of `channels_last` (default) or `channels_first`.\n         \
    \   The ordering of the dimensions in the inputs.\n            `channels_last`\
    \ corresponds to inputs with shape\n            `(batch, spatial_dim1, spatial_dim2,\
    \ spatial_dim3, channels)`\n            while `channels_first` corresponds to\
    \ inputs with shape\n            `(batch, channels, spatial_dim1, spatial_dim2,\
    \ spatial_dim3)`.\n            It defaults to the `image_data_format` value found\
    \ in your\n            Keras config file at `~/.keras/keras.json`.\n         \
    \   If you never set it, then it will be \"channels_last\".\n\n    # Input shape\n\
    \        - If `data_format='channels_last'`:\n            5D tensor with shape:\n\
    \            `(batch_size, spatial_dim1, spatial_dim2, spatial_dim3, channels)`\n\
    \        - If `data_format='channels_first'`:\n            5D tensor with shape:\n\
    \            `(batch_size, channels, spatial_dim1, spatial_dim2, spatial_dim3)`\n\
    \n    # Output shape\n        2D tensor with shape:\n        `(batch_size, channels)`\n\
    \    \"\"\"\n\n    def call(self, inputs):\n        if self.data_format == 'channels_last':\n\
    \            return K.max(inputs, axis=[1, 2, 3])\n        else:\n           \
    \ return K.max(inputs, axis=[2, 3, 4])\n"
  sourcefile: D:\Python36\lib\site-packages\keras\layers\pooling.py
- doc: "Densely connected highway network.\nHighway layers are a natural extension\
    \ of LSTMs to feedforward networks.\n# Arguments\n    init: name of initialization\
    \ function for the weights of the layer\n        (see [initializations](../initializations.md)),\n\
    \        or alternatively, Theano function to use for weights\n        initialization.\
    \ This parameter is only relevant\n        if you don't pass a `weights` argument.\n\
    \    activation: name of activation function to use\n        (see [activations](../activations.md)),\n\
    \        or alternatively, elementwise Theano function.\n        If you don't\
    \ specify anything, no activation is applied\n        (ie. \"linear\" activation:\
    \ a(x) = x).\n    weights: list of Numpy arrays to set as initial weights.\n \
    \       The list should have 2 elements, of shape `(input_dim, output_dim)`\n\
    \        and (output_dim,) for weights and biases respectively.\n    W_regularizer:\
    \ instance of [WeightRegularizer](../regularizers.md)\n        (eg. L1 or L2 regularization),\
    \ applied to the main weights matrix.\n    b_regularizer: instance of [WeightRegularizer](../regularizers.md),\n\
    \        applied to the bias.\n    activity_regularizer: instance of [ActivityRegularizer](../regularizers.md),\n\
    \        applied to the network output.\n    W_constraint: instance of the [constraints](../constraints.md)\
    \ module\n        (eg. maxnorm, nonneg), applied to the main weights matrix.\n\
    \    b_constraint: instance of the [constraints](../constraints.md) module,\n\
    \        applied to the bias.\n    bias: whether to include a bias\n        (i.e.\
    \ make the layer affine rather than linear).\n    input_dim: dimensionality of\
    \ the input (integer). This argument\n        (or alternatively, the keyword argument\
    \ `input_shape`)\n        is required when using this layer as the first layer\
    \ in a model.\n# Input shape\n    2D tensor with shape: `(nb_samples, input_dim)`.\n\
    # Output shape\n    2D tensor with shape: `(nb_samples, input_dim)`.\n# References\n\
    \    - [Highway Networks](http://arxiv.org/abs/1505.00387v2)"
  kind: Layer
  name: Highway
  parameters:
  - {defaultValue: glorot_uniform, kind: any, name: init}
  - {defaultValue: None, kind: any, name: activation}
  - {defaultValue: None, kind: any, name: weights}
  - {defaultValue: None, kind: any, name: W_regularizer}
  - {defaultValue: None, kind: any, name: b_regularizer}
  - {defaultValue: None, kind: any, name: activity_regularizer}
  - {defaultValue: None, kind: any, name: W_constraint}
  - {defaultValue: None, kind: any, name: b_constraint}
  - {defaultValue: 'True', kind: any, name: bias}
  - {defaultValue: None, kind: any, name: input_dim}
  - {defaultValue: 'true', name: trainable, type: bool}
  source: "class Highway(Layer):\n    \"\"\"Densely connected highway network.\n \
    \   Highway layers are a natural extension of LSTMs to feedforward networks.\n\
    \    # Arguments\n        init: name of initialization function for the weights\
    \ of the layer\n            (see [initializations](../initializations.md)),\n\
    \            or alternatively, Theano function to use for weights\n          \
    \  initialization. This parameter is only relevant\n            if you don't pass\
    \ a `weights` argument.\n        activation: name of activation function to use\n\
    \            (see [activations](../activations.md)),\n            or alternatively,\
    \ elementwise Theano function.\n            If you don't specify anything, no\
    \ activation is applied\n            (ie. \"linear\" activation: a(x) = x).\n\
    \        weights: list of Numpy arrays to set as initial weights.\n          \
    \  The list should have 2 elements, of shape `(input_dim, output_dim)`\n     \
    \       and (output_dim,) for weights and biases respectively.\n        W_regularizer:\
    \ instance of [WeightRegularizer](../regularizers.md)\n            (eg. L1 or\
    \ L2 regularization), applied to the main weights matrix.\n        b_regularizer:\
    \ instance of [WeightRegularizer](../regularizers.md),\n            applied to\
    \ the bias.\n        activity_regularizer: instance of [ActivityRegularizer](../regularizers.md),\n\
    \            applied to the network output.\n        W_constraint: instance of\
    \ the [constraints](../constraints.md) module\n            (eg. maxnorm, nonneg),\
    \ applied to the main weights matrix.\n        b_constraint: instance of the [constraints](../constraints.md)\
    \ module,\n            applied to the bias.\n        bias: whether to include\
    \ a bias\n            (i.e. make the layer affine rather than linear).\n     \
    \   input_dim: dimensionality of the input (integer). This argument\n        \
    \    (or alternatively, the keyword argument `input_shape`)\n            is required\
    \ when using this layer as the first layer in a model.\n    # Input shape\n  \
    \      2D tensor with shape: `(nb_samples, input_dim)`.\n    # Output shape\n\
    \        2D tensor with shape: `(nb_samples, input_dim)`.\n    # References\n\
    \        - [Highway Networks](http://arxiv.org/abs/1505.00387v2)\n    \"\"\"\n\
    \n    def __init__(self,\n                 init='glorot_uniform',\n          \
    \       activation=None,\n                 weights=None,\n                 W_regularizer=None,\n\
    \                 b_regularizer=None,\n                 activity_regularizer=None,\n\
    \                 W_constraint=None,\n                 b_constraint=None,\n  \
    \               bias=True,\n                 input_dim=None,\n               \
    \  **kwargs):\n        warnings.warn('The `Highway` layer is deprecated '\n  \
    \                    'and will be removed after 06/2017.')\n        if 'transform_bias'\
    \ in kwargs:\n            kwargs.pop('transform_bias')\n            warnings.warn('`transform_bias`\
    \ argument is deprecated and '\n                          'has been removed.')\n\
    \        self.init = initializers.get(init)\n        self.activation = activations.get(activation)\n\
    \n        self.W_regularizer = regularizers.get(W_regularizer)\n        self.b_regularizer\
    \ = regularizers.get(b_regularizer)\n        self.activity_regularizer = regularizers.get(activity_regularizer)\n\
    \n        self.W_constraint = constraints.get(W_constraint)\n        self.b_constraint\
    \ = constraints.get(b_constraint)\n\n        self.bias = bias\n        self.initial_weights\
    \ = weights\n        self.input_spec = InputSpec(ndim=2)\n\n        self.input_dim\
    \ = input_dim\n        if self.input_dim:\n            kwargs['input_shape'] =\
    \ (self.input_dim,)\n        super(Highway, self).__init__(**kwargs)\n\n    def\
    \ build(self, input_shape):\n        input_dim = input_shape[1]\n        self.input_spec\
    \ = InputSpec(dtype=K.floatx(),\n                                    shape=(None,\
    \ input_dim))\n\n        self.W = self.add_weight((input_dim, input_dim),\n  \
    \                               initializer=self.init,\n                     \
    \            name='W',\n                                 regularizer=self.W_regularizer,\n\
    \                                 constraint=self.W_constraint)\n        self.W_carry\
    \ = self.add_weight((input_dim, input_dim),\n                                \
    \       initializer=self.init,\n                                       name='W_carry')\n\
    \        if self.bias:\n            self.b = self.add_weight((input_dim,),\n \
    \                                    initializer='zero',\n                   \
    \                  name='b',\n                                     regularizer=self.b_regularizer,\n\
    \                                     constraint=self.b_constraint)\n        \
    \    self.b_carry = self.add_weight((input_dim,),\n                          \
    \                 initializer='one',\n                                       \
    \    name='b_carry')\n        else:\n            self.b_carry = None\n\n     \
    \   if self.initial_weights is not None:\n            self.set_weights(self.initial_weights)\n\
    \            del self.initial_weights\n        self.built = True\n\n    def call(self,\
    \ x):\n        y = K.dot(x, self.W_carry)\n        if self.bias:\n           \
    \ y += self.b_carry\n        transform_weight = activations.sigmoid(y)\n     \
    \   y = K.dot(x, self.W)\n        if self.bias:\n            y += self.b\n   \
    \     act = self.activation(y)\n        act *= transform_weight\n        output\
    \ = act + (1 - transform_weight) * x\n        return output\n\n    def get_config(self):\n\
    \        config = {'init': initializers.serialize(self.init),\n              \
    \    'activation': activations.serialize(self.activation),\n                 \
    \ 'W_regularizer': regularizers.serialize(self.W_regularizer),\n             \
    \     'b_regularizer': regularizers.serialize(self.b_regularizer),\n         \
    \         'activity_regularizer':\n                      regularizers.serialize(self.activity_regularizer),\n\
    \                  'W_constraint': constraints.serialize(self.W_constraint),\n\
    \                  'b_constraint': constraints.serialize(self.b_constraint),\n\
    \                  'bias': self.bias,\n                  'input_dim': self.input_dim}\n\
    \        base_config = super(Highway, self).get_config()\n        return dict(list(base_config.items())\
    \ + list(config.items()))\n"
  sourcefile: D:\Python36\lib\site-packages\keras\legacy\layers.py
- doc: "Layer to be used as an entry point into a model.\n\nIt can either wrap an\
    \ existing tensor (pass an `input_tensor` argument)\nor create its a placeholder\
    \ tensor (pass arguments `input_shape`\nor `batch_input_shape` as well as `dtype`).\n\
    \n# Arguments\n    input_shape: Shape tuple, not including the batch axis.\n \
    \   batch_size: Optional input batch size (integer or None).\n    batch_input_shape:\
    \ Shape tuple, including the batch axis.\n    dtype: Datatype of the input.\n\
    \    input_tensor: Optional tensor to use as layer input\n        instead of creating\
    \ a placeholder.\n    sparse: Boolean, whether the placeholder created\n     \
    \   is meant to be sparse.\n    name: Name of the layer (string)."
  kind: Layer
  name: InputLayer
  parameters:
  - {defaultValue: None, kind: any, name: input_shape}
  - {defaultValue: None, kind: any, name: batch_size}
  - {defaultValue: None, kind: any, name: batch_input_shape}
  - {defaultValue: None, kind: any, name: dtype}
  - {defaultValue: None, kind: any, name: input_tensor}
  - {defaultValue: 'False', kind: any, name: sparse}
  - {defaultValue: None, kind: any, name: name}
  - {defaultValue: 'true', name: trainable, type: bool}
  source: "class InputLayer(Layer):\n    \"\"\"Layer to be used as an entry point\
    \ into a model.\n\n    It can either wrap an existing tensor (pass an `input_tensor`\
    \ argument)\n    or create its a placeholder tensor (pass arguments `input_shape`\n\
    \    or `batch_input_shape` as well as `dtype`).\n\n    # Arguments\n        input_shape:\
    \ Shape tuple, not including the batch axis.\n        batch_size: Optional input\
    \ batch size (integer or None).\n        batch_input_shape: Shape tuple, including\
    \ the batch axis.\n        dtype: Datatype of the input.\n        input_tensor:\
    \ Optional tensor to use as layer input\n            instead of creating a placeholder.\n\
    \        sparse: Boolean, whether the placeholder created\n            is meant\
    \ to be sparse.\n        name: Name of the layer (string).\n    \"\"\"\n\n   \
    \ @interfaces.legacy_input_support\n    def __init__(self, input_shape=None, batch_size=None,\n\
    \                 batch_input_shape=None,\n                 dtype=None, input_tensor=None,\
    \ sparse=False, name=None):\n        if not name:\n            prefix = 'input'\n\
    \            name = prefix + '_' + str(K.get_uid(prefix))\n        super(InputLayer,\
    \ self).__init__(dtype=dtype, name=name)\n\n        self.trainable = False\n \
    \       self.built = True\n        self.sparse = sparse\n        self.supports_masking\
    \ = True\n\n        if input_shape and batch_input_shape:\n            raise ValueError('Only\
    \ provide the input_shape OR '\n                             'batch_input_shape\
    \ argument to '\n                             'InputLayer, not both at the same\
    \ time.')\n        if input_tensor is not None and batch_input_shape is None:\n\
    \            # If input_tensor is set, and batch_input_shape is not set:\n   \
    \         # Attempt automatic input shape inference.\n            try:\n     \
    \           batch_input_shape = K.int_shape(input_tensor)\n            except\
    \ TypeError:\n                if not input_shape and not batch_input_shape:\n\
    \                    raise ValueError('InputLayer was provided '\n           \
    \                          'an input_tensor argument, '\n                    \
    \                 'but its input shape cannot be '\n                         \
    \            'automatically inferred. '\n                                    \
    \ 'You should pass an input_shape or '\n                                     'batch_input_shape\
    \ argument.')\n        if not batch_input_shape:\n            if not input_shape:\n\
    \                raise ValueError('An Input layer should be passed either '\n\
    \                                 'a `batch_input_shape` or an `input_shape`.')\n\
    \            else:\n                batch_input_shape = (batch_size,) + tuple(input_shape)\n\
    \        else:\n            batch_input_shape = tuple(batch_input_shape)\n\n \
    \       if not dtype:\n            if input_tensor is None:\n                dtype\
    \ = K.floatx()\n            else:\n                dtype = K.dtype(input_tensor)\n\
    \n        self.batch_input_shape = batch_input_shape\n        self.dtype = dtype\n\
    \n        if input_tensor is None:\n            self.is_placeholder = True\n \
    \           input_tensor = K.placeholder(shape=batch_input_shape,\n          \
    \                               dtype=dtype,\n                               \
    \          sparse=self.sparse,\n                                         name=self.name)\n\
    \        else:\n            self.is_placeholder = False\n            input_tensor._keras_shape\
    \ = batch_input_shape\n        # Create an input node to add to self.outbound_node\n\
    \        # and set output_tensors' _keras_history.\n        input_tensor._uses_learning_phase\
    \ = False\n        input_tensor._keras_history = (self, 0, 0)\n        Node(self,\n\
    \             inbound_layers=[],\n             node_indices=[],\n            \
    \ tensor_indices=[],\n             input_tensors=[input_tensor],\n           \
    \  output_tensors=[input_tensor],\n             input_masks=[None],\n        \
    \     output_masks=[None],\n             input_shapes=[batch_input_shape],\n \
    \            output_shapes=[batch_input_shape])\n\n    def get_config(self):\n\
    \        config = {'batch_input_shape': self.batch_input_shape,\n            \
    \      'dtype': self.dtype,\n                  'sparse': self.sparse,\n      \
    \            'name': self.name}\n        return config\n"
  sourcefile: D:\Python36\lib\site-packages\keras\engine\input_layer.py
- doc: "Long Short-Term Memory layer - Hochreiter 1997.\n\n# Arguments\n    units:\
    \ Positive integer, dimensionality of the output space.\n    activation: Activation\
    \ function to use\n        (see [activations](../activations.md)).\n        Default:\
    \ hyperbolic tangent (`tanh`).\n        If you pass `None`, no activation is applied\n\
    \        (ie. \"linear\" activation: `a(x) = x`).\n    recurrent_activation: Activation\
    \ function to use\n        for the recurrent step\n        (see [activations](../activations.md)).\n\
    \        Default: hard sigmoid (`hard_sigmoid`).\n        If you pass `None`,\
    \ no activation is applied\n        (ie. \"linear\" activation: `a(x) = x`).\n\
    \    use_bias: Boolean, whether the layer uses a bias vector.\n    kernel_initializer:\
    \ Initializer for the `kernel` weights matrix,\n        used for the linear transformation\
    \ of the inputs.\n        (see [initializers](../initializers.md)).\n    recurrent_initializer:\
    \ Initializer for the `recurrent_kernel`\n        weights matrix,\n        used\
    \ for the linear transformation of the recurrent state.\n        (see [initializers](../initializers.md)).\n\
    \    bias_initializer: Initializer for the bias vector\n        (see [initializers](../initializers.md)).\n\
    \    unit_forget_bias: Boolean.\n        If True, add 1 to the bias of the forget\
    \ gate at initialization.\n        Setting it to true will also force `bias_initializer=\"\
    zeros\"`.\n        This is recommended in [Jozefowicz et al.]\n        (http://www.jmlr.org/proceedings/papers/v37/jozefowicz15.pdf).\n\
    \    kernel_regularizer: Regularizer function applied to\n        the `kernel`\
    \ weights matrix\n        (see [regularizer](../regularizers.md)).\n    recurrent_regularizer:\
    \ Regularizer function applied to\n        the `recurrent_kernel` weights matrix\n\
    \        (see [regularizer](../regularizers.md)).\n    bias_regularizer: Regularizer\
    \ function applied to the bias vector\n        (see [regularizer](../regularizers.md)).\n\
    \    activity_regularizer: Regularizer function applied to\n        the output\
    \ of the layer (its \"activation\").\n        (see [regularizer](../regularizers.md)).\n\
    \    kernel_constraint: Constraint function applied to\n        the `kernel` weights\
    \ matrix\n        (see [constraints](../constraints.md)).\n    recurrent_constraint:\
    \ Constraint function applied to\n        the `recurrent_kernel` weights matrix\n\
    \        (see [constraints](../constraints.md)).\n    bias_constraint: Constraint\
    \ function applied to the bias vector\n        (see [constraints](../constraints.md)).\n\
    \    dropout: Float between 0 and 1.\n        Fraction of the units to drop for\n\
    \        the linear transformation of the inputs.\n    recurrent_dropout: Float\
    \ between 0 and 1.\n        Fraction of the units to drop for\n        the linear\
    \ transformation of the recurrent state.\n    implementation: Implementation mode,\
    \ either 1 or 2.\n        Mode 1 will structure its operations as a larger number\
    \ of\n        smaller dot products and additions, whereas mode 2 will\n      \
    \  batch them into fewer, larger operations. These modes will\n        have different\
    \ performance profiles on different hardware and\n        for different applications.\n\
    \    return_sequences: Boolean. Whether to return the last output\n        in\
    \ the output sequence, or the full sequence.\n    return_state: Boolean. Whether\
    \ to return the last state\n        in addition to the output.\n    go_backwards:\
    \ Boolean (default False).\n        If True, process the input sequence backwards\
    \ and return the\n        reversed sequence.\n    stateful: Boolean (default False).\
    \ If True, the last state\n        for each sample at index i in a batch will\
    \ be used as initial\n        state for the sample of index i in the following\
    \ batch.\n    unroll: Boolean (default False).\n        If True, the network will\
    \ be unrolled,\n        else a symbolic loop will be used.\n        Unrolling\
    \ can speed-up a RNN,\n        although it tends to be more memory-intensive.\n\
    \        Unrolling is only suitable for short sequences.\n\n# References\n   \
    \ - [Long short-term memory]\n      (http://www.bioinf.jku.at/publications/older/2604.pdf)\n\
    \    - [Learning to forget: Continual prediction with LSTM]\n      (http://www.mitpressjournals.org/doi/pdf/10.1162/089976600300015015)\n\
    \    - [Supervised sequence labeling with recurrent neural networks]\n      (http://www.cs.toronto.edu/~graves/preprint.pdf)\n\
    \    - [A Theoretically Grounded Application of Dropout in\n       Recurrent Neural\
    \ Networks](https://arxiv.org/abs/1512.05287)"
  kind: Layer
  name: LSTM
  parameters:
  - {kind: any, name: units}
  - {defaultValue: tanh, kind: any, name: activation}
  - {defaultValue: hard_sigmoid, kind: any, name: recurrent_activation}
  - {defaultValue: 'True', kind: any, name: use_bias}
  - {defaultValue: glorot_uniform, kind: any, name: kernel_initializer}
  - {defaultValue: orthogonal, kind: any, name: recurrent_initializer}
  - {defaultValue: zeros, kind: any, name: bias_initializer}
  - {defaultValue: 'True', kind: any, name: unit_forget_bias}
  - {defaultValue: None, kind: any, name: kernel_regularizer}
  - {defaultValue: None, kind: any, name: recurrent_regularizer}
  - {defaultValue: None, kind: any, name: bias_regularizer}
  - {defaultValue: None, kind: any, name: activity_regularizer}
  - {defaultValue: None, kind: any, name: kernel_constraint}
  - {defaultValue: None, kind: any, name: recurrent_constraint}
  - {defaultValue: None, kind: any, name: bias_constraint}
  - {defaultValue: '0.0', kind: any, name: dropout}
  - {defaultValue: '0.0', kind: any, name: recurrent_dropout}
  - {defaultValue: '1', kind: any, name: implementation}
  - {defaultValue: 'False', kind: any, name: return_sequences}
  - {defaultValue: 'False', kind: any, name: return_state}
  - {defaultValue: 'False', kind: any, name: go_backwards}
  - {defaultValue: 'False', kind: any, name: stateful}
  - {defaultValue: 'False', kind: any, name: unroll}
  - {defaultValue: 'true', name: trainable, type: bool}
  source: "class LSTM(RNN):\n    \"\"\"Long Short-Term Memory layer - Hochreiter 1997.\n\
    \n    # Arguments\n        units: Positive integer, dimensionality of the output\
    \ space.\n        activation: Activation function to use\n            (see [activations](../activations.md)).\n\
    \            Default: hyperbolic tangent (`tanh`).\n            If you pass `None`,\
    \ no activation is applied\n            (ie. \"linear\" activation: `a(x) = x`).\n\
    \        recurrent_activation: Activation function to use\n            for the\
    \ recurrent step\n            (see [activations](../activations.md)).\n      \
    \      Default: hard sigmoid (`hard_sigmoid`).\n            If you pass `None`,\
    \ no activation is applied\n            (ie. \"linear\" activation: `a(x) = x`).\n\
    \        use_bias: Boolean, whether the layer uses a bias vector.\n        kernel_initializer:\
    \ Initializer for the `kernel` weights matrix,\n            used for the linear\
    \ transformation of the inputs.\n            (see [initializers](../initializers.md)).\n\
    \        recurrent_initializer: Initializer for the `recurrent_kernel`\n     \
    \       weights matrix,\n            used for the linear transformation of the\
    \ recurrent state.\n            (see [initializers](../initializers.md)).\n  \
    \      bias_initializer: Initializer for the bias vector\n            (see [initializers](../initializers.md)).\n\
    \        unit_forget_bias: Boolean.\n            If True, add 1 to the bias of\
    \ the forget gate at initialization.\n            Setting it to true will also\
    \ force `bias_initializer=\"zeros\"`.\n            This is recommended in [Jozefowicz\
    \ et al.]\n            (http://www.jmlr.org/proceedings/papers/v37/jozefowicz15.pdf).\n\
    \        kernel_regularizer: Regularizer function applied to\n            the\
    \ `kernel` weights matrix\n            (see [regularizer](../regularizers.md)).\n\
    \        recurrent_regularizer: Regularizer function applied to\n            the\
    \ `recurrent_kernel` weights matrix\n            (see [regularizer](../regularizers.md)).\n\
    \        bias_regularizer: Regularizer function applied to the bias vector\n \
    \           (see [regularizer](../regularizers.md)).\n        activity_regularizer:\
    \ Regularizer function applied to\n            the output of the layer (its \"\
    activation\").\n            (see [regularizer](../regularizers.md)).\n       \
    \ kernel_constraint: Constraint function applied to\n            the `kernel`\
    \ weights matrix\n            (see [constraints](../constraints.md)).\n      \
    \  recurrent_constraint: Constraint function applied to\n            the `recurrent_kernel`\
    \ weights matrix\n            (see [constraints](../constraints.md)).\n      \
    \  bias_constraint: Constraint function applied to the bias vector\n         \
    \   (see [constraints](../constraints.md)).\n        dropout: Float between 0\
    \ and 1.\n            Fraction of the units to drop for\n            the linear\
    \ transformation of the inputs.\n        recurrent_dropout: Float between 0 and\
    \ 1.\n            Fraction of the units to drop for\n            the linear transformation\
    \ of the recurrent state.\n        implementation: Implementation mode, either\
    \ 1 or 2.\n            Mode 1 will structure its operations as a larger number\
    \ of\n            smaller dot products and additions, whereas mode 2 will\n  \
    \          batch them into fewer, larger operations. These modes will\n      \
    \      have different performance profiles on different hardware and\n       \
    \     for different applications.\n        return_sequences: Boolean. Whether\
    \ to return the last output\n            in the output sequence, or the full sequence.\n\
    \        return_state: Boolean. Whether to return the last state\n           \
    \ in addition to the output.\n        go_backwards: Boolean (default False).\n\
    \            If True, process the input sequence backwards and return the\n  \
    \          reversed sequence.\n        stateful: Boolean (default False). If True,\
    \ the last state\n            for each sample at index i in a batch will be used\
    \ as initial\n            state for the sample of index i in the following batch.\n\
    \        unroll: Boolean (default False).\n            If True, the network will\
    \ be unrolled,\n            else a symbolic loop will be used.\n            Unrolling\
    \ can speed-up a RNN,\n            although it tends to be more memory-intensive.\n\
    \            Unrolling is only suitable for short sequences.\n\n    # References\n\
    \        - [Long short-term memory]\n          (http://www.bioinf.jku.at/publications/older/2604.pdf)\n\
    \        - [Learning to forget: Continual prediction with LSTM]\n          (http://www.mitpressjournals.org/doi/pdf/10.1162/089976600300015015)\n\
    \        - [Supervised sequence labeling with recurrent neural networks]\n   \
    \       (http://www.cs.toronto.edu/~graves/preprint.pdf)\n        - [A Theoretically\
    \ Grounded Application of Dropout in\n           Recurrent Neural Networks](https://arxiv.org/abs/1512.05287)\n\
    \    \"\"\"\n\n    @interfaces.legacy_recurrent_support\n    def __init__(self,\
    \ units,\n                 activation='tanh',\n                 recurrent_activation='hard_sigmoid',\n\
    \                 use_bias=True,\n                 kernel_initializer='glorot_uniform',\n\
    \                 recurrent_initializer='orthogonal',\n                 bias_initializer='zeros',\n\
    \                 unit_forget_bias=True,\n                 kernel_regularizer=None,\n\
    \                 recurrent_regularizer=None,\n                 bias_regularizer=None,\n\
    \                 activity_regularizer=None,\n                 kernel_constraint=None,\n\
    \                 recurrent_constraint=None,\n                 bias_constraint=None,\n\
    \                 dropout=0.,\n                 recurrent_dropout=0.,\n      \
    \           implementation=1,\n                 return_sequences=False,\n    \
    \             return_state=False,\n                 go_backwards=False,\n    \
    \             stateful=False,\n                 unroll=False,\n              \
    \   **kwargs):\n        if implementation == 0:\n            warnings.warn('`implementation=0`\
    \ has been deprecated, '\n                          'and now defaults to `implementation=1`.'\n\
    \                          'Please update your layer call.')\n        if K.backend()\
    \ == 'theano' and (dropout or recurrent_dropout):\n            warnings.warn(\n\
    \                'RNN dropout is no longer supported with the Theano backend '\n\
    \                'due to technical limitations. '\n                'You can either\
    \ set `dropout` and `recurrent_dropout` to 0, '\n                'or use the TensorFlow\
    \ backend.')\n            dropout = 0.\n            recurrent_dropout = 0.\n\n\
    \        cell = LSTMCell(units,\n                        activation=activation,\n\
    \                        recurrent_activation=recurrent_activation,\n        \
    \                use_bias=use_bias,\n                        kernel_initializer=kernel_initializer,\n\
    \                        recurrent_initializer=recurrent_initializer,\n      \
    \                  unit_forget_bias=unit_forget_bias,\n                      \
    \  bias_initializer=bias_initializer,\n                        kernel_regularizer=kernel_regularizer,\n\
    \                        recurrent_regularizer=recurrent_regularizer,\n      \
    \                  bias_regularizer=bias_regularizer,\n                      \
    \  kernel_constraint=kernel_constraint,\n                        recurrent_constraint=recurrent_constraint,\n\
    \                        bias_constraint=bias_constraint,\n                  \
    \      dropout=dropout,\n                        recurrent_dropout=recurrent_dropout,\n\
    \                        implementation=implementation)\n        super(LSTM, self).__init__(cell,\n\
    \                                   return_sequences=return_sequences,\n     \
    \                              return_state=return_state,\n                  \
    \                 go_backwards=go_backwards,\n                               \
    \    stateful=stateful,\n                                   unroll=unroll,\n \
    \                                  **kwargs)\n        self.activity_regularizer\
    \ = regularizers.get(activity_regularizer)\n\n    def call(self, inputs, mask=None,\
    \ training=None, initial_state=None):\n        self.cell._dropout_mask = None\n\
    \        self.cell._recurrent_dropout_mask = None\n        return super(LSTM,\
    \ self).call(inputs,\n                                      mask=mask,\n     \
    \                                 training=training,\n                       \
    \               initial_state=initial_state)\n\n    @property\n    def units(self):\n\
    \        return self.cell.units\n\n    @property\n    def activation(self):\n\
    \        return self.cell.activation\n\n    @property\n    def recurrent_activation(self):\n\
    \        return self.cell.recurrent_activation\n\n    @property\n    def use_bias(self):\n\
    \        return self.cell.use_bias\n\n    @property\n    def kernel_initializer(self):\n\
    \        return self.cell.kernel_initializer\n\n    @property\n    def recurrent_initializer(self):\n\
    \        return self.cell.recurrent_initializer\n\n    @property\n    def bias_initializer(self):\n\
    \        return self.cell.bias_initializer\n\n    @property\n    def unit_forget_bias(self):\n\
    \        return self.cell.unit_forget_bias\n\n    @property\n    def kernel_regularizer(self):\n\
    \        return self.cell.kernel_regularizer\n\n    @property\n    def recurrent_regularizer(self):\n\
    \        return self.cell.recurrent_regularizer\n\n    @property\n    def bias_regularizer(self):\n\
    \        return self.cell.bias_regularizer\n\n    @property\n    def kernel_constraint(self):\n\
    \        return self.cell.kernel_constraint\n\n    @property\n    def recurrent_constraint(self):\n\
    \        return self.cell.recurrent_constraint\n\n    @property\n    def bias_constraint(self):\n\
    \        return self.cell.bias_constraint\n\n    @property\n    def dropout(self):\n\
    \        return self.cell.dropout\n\n    @property\n    def recurrent_dropout(self):\n\
    \        return self.cell.recurrent_dropout\n\n    @property\n    def implementation(self):\n\
    \        return self.cell.implementation\n\n    def get_config(self):\n      \
    \  config = {'units': self.units,\n                  'activation': activations.serialize(self.activation),\n\
    \                  'recurrent_activation':\n                      activations.serialize(self.recurrent_activation),\n\
    \                  'use_bias': self.use_bias,\n                  'kernel_initializer':\n\
    \                      initializers.serialize(self.kernel_initializer),\n    \
    \              'recurrent_initializer':\n                      initializers.serialize(self.recurrent_initializer),\n\
    \                  'bias_initializer': initializers.serialize(self.bias_initializer),\n\
    \                  'unit_forget_bias': self.unit_forget_bias,\n              \
    \    'kernel_regularizer':\n                      regularizers.serialize(self.kernel_regularizer),\n\
    \                  'recurrent_regularizer':\n                      regularizers.serialize(self.recurrent_regularizer),\n\
    \                  'bias_regularizer': regularizers.serialize(self.bias_regularizer),\n\
    \                  'activity_regularizer':\n                      regularizers.serialize(self.activity_regularizer),\n\
    \                  'kernel_constraint': constraints.serialize(self.kernel_constraint),\n\
    \                  'recurrent_constraint':\n                      constraints.serialize(self.recurrent_constraint),\n\
    \                  'bias_constraint': constraints.serialize(self.bias_constraint),\n\
    \                  'dropout': self.dropout,\n                  'recurrent_dropout':\
    \ self.recurrent_dropout,\n                  'implementation': self.implementation}\n\
    \        base_config = super(LSTM, self).get_config()\n        del base_config['cell']\n\
    \        return dict(list(base_config.items()) + list(config.items()))\n\n   \
    \ @classmethod\n    def from_config(cls, config):\n        if 'implementation'\
    \ in config and config['implementation'] == 0:\n            config['implementation']\
    \ = 1\n        return cls(**config)\n"
  sourcefile: D:\Python36\lib\site-packages\keras\layers\recurrent.py
- doc: "Cell class for the LSTM layer.\n\n# Arguments\n    units: Positive integer,\
    \ dimensionality of the output space.\n    activation: Activation function to\
    \ use\n        (see [activations](../activations.md)).\n        Default: hyperbolic\
    \ tangent (`tanh`).\n        If you pass `None`, no activation is applied\n  \
    \      (ie. \"linear\" activation: `a(x) = x`).\n    recurrent_activation: Activation\
    \ function to use\n        for the recurrent step\n        (see [activations](../activations.md)).\n\
    \        Default: hard sigmoid (`hard_sigmoid`).\n        If you pass `None`,\
    \ no activation is applied\n        (ie. \"linear\" activation: `a(x) = x`).x\n\
    \    use_bias: Boolean, whether the layer uses a bias vector.\n    kernel_initializer:\
    \ Initializer for the `kernel` weights matrix,\n        used for the linear transformation\
    \ of the inputs\n        (see [initializers](../initializers.md)).\n    recurrent_initializer:\
    \ Initializer for the `recurrent_kernel`\n        weights matrix,\n        used\
    \ for the linear transformation of the recurrent state\n        (see [initializers](../initializers.md)).\n\
    \    bias_initializer: Initializer for the bias vector\n        (see [initializers](../initializers.md)).\n\
    \    unit_forget_bias: Boolean.\n        If True, add 1 to the bias of the forget\
    \ gate at initialization.\n        Setting it to true will also force `bias_initializer=\"\
    zeros\"`.\n        This is recommended in [Jozefowicz et al.]\n        (http://www.jmlr.org/proceedings/papers/v37/jozefowicz15.pdf).\n\
    \    kernel_regularizer: Regularizer function applied to\n        the `kernel`\
    \ weights matrix\n        (see [regularizer](../regularizers.md)).\n    recurrent_regularizer:\
    \ Regularizer function applied to\n        the `recurrent_kernel` weights matrix\n\
    \        (see [regularizer](../regularizers.md)).\n    bias_regularizer: Regularizer\
    \ function applied to the bias vector\n        (see [regularizer](../regularizers.md)).\n\
    \    kernel_constraint: Constraint function applied to\n        the `kernel` weights\
    \ matrix\n        (see [constraints](../constraints.md)).\n    recurrent_constraint:\
    \ Constraint function applied to\n        the `recurrent_kernel` weights matrix\n\
    \        (see [constraints](../constraints.md)).\n    bias_constraint: Constraint\
    \ function applied to the bias vector\n        (see [constraints](../constraints.md)).\n\
    \    dropout: Float between 0 and 1.\n        Fraction of the units to drop for\n\
    \        the linear transformation of the inputs.\n    recurrent_dropout: Float\
    \ between 0 and 1.\n        Fraction of the units to drop for\n        the linear\
    \ transformation of the recurrent state.\n    implementation: Implementation mode,\
    \ either 1 or 2.\n        Mode 1 will structure its operations as a larger number\
    \ of\n        smaller dot products and additions, whereas mode 2 will\n      \
    \  batch them into fewer, larger operations. These modes will\n        have different\
    \ performance profiles on different hardware and\n        for different applications."
  kind: Layer
  name: LSTMCell
  parameters:
  - {kind: any, name: units}
  - {defaultValue: tanh, kind: any, name: activation}
  - {defaultValue: hard_sigmoid, kind: any, name: recurrent_activation}
  - {defaultValue: 'True', kind: any, name: use_bias}
  - {defaultValue: glorot_uniform, kind: any, name: kernel_initializer}
  - {defaultValue: orthogonal, kind: any, name: recurrent_initializer}
  - {defaultValue: zeros, kind: any, name: bias_initializer}
  - {defaultValue: 'True', kind: any, name: unit_forget_bias}
  - {defaultValue: None, kind: any, name: kernel_regularizer}
  - {defaultValue: None, kind: any, name: recurrent_regularizer}
  - {defaultValue: None, kind: any, name: bias_regularizer}
  - {defaultValue: None, kind: any, name: kernel_constraint}
  - {defaultValue: None, kind: any, name: recurrent_constraint}
  - {defaultValue: None, kind: any, name: bias_constraint}
  - {defaultValue: '0.0', kind: any, name: dropout}
  - {defaultValue: '0.0', kind: any, name: recurrent_dropout}
  - {defaultValue: '1', kind: any, name: implementation}
  - {defaultValue: 'true', name: trainable, type: bool}
  source: "class LSTMCell(Layer):\n    \"\"\"Cell class for the LSTM layer.\n\n  \
    \  # Arguments\n        units: Positive integer, dimensionality of the output\
    \ space.\n        activation: Activation function to use\n            (see [activations](../activations.md)).\n\
    \            Default: hyperbolic tangent (`tanh`).\n            If you pass `None`,\
    \ no activation is applied\n            (ie. \"linear\" activation: `a(x) = x`).\n\
    \        recurrent_activation: Activation function to use\n            for the\
    \ recurrent step\n            (see [activations](../activations.md)).\n      \
    \      Default: hard sigmoid (`hard_sigmoid`).\n            If you pass `None`,\
    \ no activation is applied\n            (ie. \"linear\" activation: `a(x) = x`).x\n\
    \        use_bias: Boolean, whether the layer uses a bias vector.\n        kernel_initializer:\
    \ Initializer for the `kernel` weights matrix,\n            used for the linear\
    \ transformation of the inputs\n            (see [initializers](../initializers.md)).\n\
    \        recurrent_initializer: Initializer for the `recurrent_kernel`\n     \
    \       weights matrix,\n            used for the linear transformation of the\
    \ recurrent state\n            (see [initializers](../initializers.md)).\n   \
    \     bias_initializer: Initializer for the bias vector\n            (see [initializers](../initializers.md)).\n\
    \        unit_forget_bias: Boolean.\n            If True, add 1 to the bias of\
    \ the forget gate at initialization.\n            Setting it to true will also\
    \ force `bias_initializer=\"zeros\"`.\n            This is recommended in [Jozefowicz\
    \ et al.]\n            (http://www.jmlr.org/proceedings/papers/v37/jozefowicz15.pdf).\n\
    \        kernel_regularizer: Regularizer function applied to\n            the\
    \ `kernel` weights matrix\n            (see [regularizer](../regularizers.md)).\n\
    \        recurrent_regularizer: Regularizer function applied to\n            the\
    \ `recurrent_kernel` weights matrix\n            (see [regularizer](../regularizers.md)).\n\
    \        bias_regularizer: Regularizer function applied to the bias vector\n \
    \           (see [regularizer](../regularizers.md)).\n        kernel_constraint:\
    \ Constraint function applied to\n            the `kernel` weights matrix\n  \
    \          (see [constraints](../constraints.md)).\n        recurrent_constraint:\
    \ Constraint function applied to\n            the `recurrent_kernel` weights matrix\n\
    \            (see [constraints](../constraints.md)).\n        bias_constraint:\
    \ Constraint function applied to the bias vector\n            (see [constraints](../constraints.md)).\n\
    \        dropout: Float between 0 and 1.\n            Fraction of the units to\
    \ drop for\n            the linear transformation of the inputs.\n        recurrent_dropout:\
    \ Float between 0 and 1.\n            Fraction of the units to drop for\n    \
    \        the linear transformation of the recurrent state.\n        implementation:\
    \ Implementation mode, either 1 or 2.\n            Mode 1 will structure its operations\
    \ as a larger number of\n            smaller dot products and additions, whereas\
    \ mode 2 will\n            batch them into fewer, larger operations. These modes\
    \ will\n            have different performance profiles on different hardware\
    \ and\n            for different applications.\n    \"\"\"\n\n    def __init__(self,\
    \ units,\n                 activation='tanh',\n                 recurrent_activation='hard_sigmoid',\n\
    \                 use_bias=True,\n                 kernel_initializer='glorot_uniform',\n\
    \                 recurrent_initializer='orthogonal',\n                 bias_initializer='zeros',\n\
    \                 unit_forget_bias=True,\n                 kernel_regularizer=None,\n\
    \                 recurrent_regularizer=None,\n                 bias_regularizer=None,\n\
    \                 kernel_constraint=None,\n                 recurrent_constraint=None,\n\
    \                 bias_constraint=None,\n                 dropout=0.,\n      \
    \           recurrent_dropout=0.,\n                 implementation=1,\n      \
    \           **kwargs):\n        super(LSTMCell, self).__init__(**kwargs)\n   \
    \     self.units = units\n        self.activation = activations.get(activation)\n\
    \        self.recurrent_activation = activations.get(recurrent_activation)\n \
    \       self.use_bias = use_bias\n\n        self.kernel_initializer = initializers.get(kernel_initializer)\n\
    \        self.recurrent_initializer = initializers.get(recurrent_initializer)\n\
    \        self.bias_initializer = initializers.get(bias_initializer)\n        self.unit_forget_bias\
    \ = unit_forget_bias\n\n        self.kernel_regularizer = regularizers.get(kernel_regularizer)\n\
    \        self.recurrent_regularizer = regularizers.get(recurrent_regularizer)\n\
    \        self.bias_regularizer = regularizers.get(bias_regularizer)\n\n      \
    \  self.kernel_constraint = constraints.get(kernel_constraint)\n        self.recurrent_constraint\
    \ = constraints.get(recurrent_constraint)\n        self.bias_constraint = constraints.get(bias_constraint)\n\
    \n        self.dropout = min(1., max(0., dropout))\n        self.recurrent_dropout\
    \ = min(1., max(0., recurrent_dropout))\n        self.implementation = implementation\n\
    \        self.state_size = (self.units, self.units)\n        self.output_size\
    \ = self.units\n        self._dropout_mask = None\n        self._recurrent_dropout_mask\
    \ = None\n\n    def build(self, input_shape):\n        input_dim = input_shape[-1]\n\
    \        self.kernel = self.add_weight(shape=(input_dim, self.units * 4),\n  \
    \                                    name='kernel',\n                        \
    \              initializer=self.kernel_initializer,\n                        \
    \              regularizer=self.kernel_regularizer,\n                        \
    \              constraint=self.kernel_constraint)\n        self.recurrent_kernel\
    \ = self.add_weight(\n            shape=(self.units, self.units * 4),\n      \
    \      name='recurrent_kernel',\n            initializer=self.recurrent_initializer,\n\
    \            regularizer=self.recurrent_regularizer,\n            constraint=self.recurrent_constraint)\n\
    \n        if self.use_bias:\n            if self.unit_forget_bias:\n         \
    \       def bias_initializer(_, *args, **kwargs):\n                    return\
    \ K.concatenate([\n                        self.bias_initializer((self.units,),\
    \ *args, **kwargs),\n                        initializers.Ones()((self.units,),\
    \ *args, **kwargs),\n                        self.bias_initializer((self.units\
    \ * 2,), *args, **kwargs),\n                    ])\n            else:\n      \
    \          bias_initializer = self.bias_initializer\n            self.bias = self.add_weight(shape=(self.units\
    \ * 4,),\n                                        name='bias',\n             \
    \                           initializer=bias_initializer,\n                  \
    \                      regularizer=self.bias_regularizer,\n                  \
    \                      constraint=self.bias_constraint)\n        else:\n     \
    \       self.bias = None\n\n        self.kernel_i = self.kernel[:, :self.units]\n\
    \        self.kernel_f = self.kernel[:, self.units: self.units * 2]\n        self.kernel_c\
    \ = self.kernel[:, self.units * 2: self.units * 3]\n        self.kernel_o = self.kernel[:,\
    \ self.units * 3:]\n\n        self.recurrent_kernel_i = self.recurrent_kernel[:,\
    \ :self.units]\n        self.recurrent_kernel_f = (\n            self.recurrent_kernel[:,\
    \ self.units: self.units * 2])\n        self.recurrent_kernel_c = (\n        \
    \    self.recurrent_kernel[:, self.units * 2: self.units * 3])\n        self.recurrent_kernel_o\
    \ = self.recurrent_kernel[:, self.units * 3:]\n\n        if self.use_bias:\n \
    \           self.bias_i = self.bias[:self.units]\n            self.bias_f = self.bias[self.units:\
    \ self.units * 2]\n            self.bias_c = self.bias[self.units * 2: self.units\
    \ * 3]\n            self.bias_o = self.bias[self.units * 3:]\n        else:\n\
    \            self.bias_i = None\n            self.bias_f = None\n            self.bias_c\
    \ = None\n            self.bias_o = None\n        self.built = True\n\n    def\
    \ call(self, inputs, states, training=None):\n        if 0 < self.dropout < 1\
    \ and self._dropout_mask is None:\n            self._dropout_mask = _generate_dropout_mask(\n\
    \                K.ones_like(inputs),\n                self.dropout,\n       \
    \         training=training,\n                count=4)\n        if (0 < self.recurrent_dropout\
    \ < 1 and\n                self._recurrent_dropout_mask is None):\n          \
    \  self._recurrent_dropout_mask = _generate_dropout_mask(\n                K.ones_like(states[0]),\n\
    \                self.recurrent_dropout,\n                training=training,\n\
    \                count=4)\n\n        # dropout matrices for input units\n    \
    \    dp_mask = self._dropout_mask\n        # dropout matrices for recurrent units\n\
    \        rec_dp_mask = self._recurrent_dropout_mask\n\n        h_tm1 = states[0]\
    \  # previous memory state\n        c_tm1 = states[1]  # previous carry state\n\
    \n        if self.implementation == 1:\n            if 0 < self.dropout < 1.:\n\
    \                inputs_i = inputs * dp_mask[0]\n                inputs_f = inputs\
    \ * dp_mask[1]\n                inputs_c = inputs * dp_mask[2]\n             \
    \   inputs_o = inputs * dp_mask[3]\n            else:\n                inputs_i\
    \ = inputs\n                inputs_f = inputs\n                inputs_c = inputs\n\
    \                inputs_o = inputs\n            x_i = K.dot(inputs_i, self.kernel_i)\n\
    \            x_f = K.dot(inputs_f, self.kernel_f)\n            x_c = K.dot(inputs_c,\
    \ self.kernel_c)\n            x_o = K.dot(inputs_o, self.kernel_o)\n         \
    \   if self.use_bias:\n                x_i = K.bias_add(x_i, self.bias_i)\n  \
    \              x_f = K.bias_add(x_f, self.bias_f)\n                x_c = K.bias_add(x_c,\
    \ self.bias_c)\n                x_o = K.bias_add(x_o, self.bias_o)\n\n       \
    \     if 0 < self.recurrent_dropout < 1.:\n                h_tm1_i = h_tm1 * rec_dp_mask[0]\n\
    \                h_tm1_f = h_tm1 * rec_dp_mask[1]\n                h_tm1_c = h_tm1\
    \ * rec_dp_mask[2]\n                h_tm1_o = h_tm1 * rec_dp_mask[3]\n       \
    \     else:\n                h_tm1_i = h_tm1\n                h_tm1_f = h_tm1\n\
    \                h_tm1_c = h_tm1\n                h_tm1_o = h_tm1\n          \
    \  i = self.recurrent_activation(x_i + K.dot(h_tm1_i,\n                      \
    \                                self.recurrent_kernel_i))\n            f = self.recurrent_activation(x_f\
    \ + K.dot(h_tm1_f,\n                                                      self.recurrent_kernel_f))\n\
    \            c = f * c_tm1 + i * self.activation(x_c + K.dot(h_tm1_c,\n      \
    \                                                      self.recurrent_kernel_c))\n\
    \            o = self.recurrent_activation(x_o + K.dot(h_tm1_o,\n            \
    \                                          self.recurrent_kernel_o))\n       \
    \ else:\n            if 0. < self.dropout < 1.:\n                inputs *= dp_mask[0]\n\
    \            z = K.dot(inputs, self.kernel)\n            if 0. < self.recurrent_dropout\
    \ < 1.:\n                h_tm1 *= rec_dp_mask[0]\n            z += K.dot(h_tm1,\
    \ self.recurrent_kernel)\n            if self.use_bias:\n                z = K.bias_add(z,\
    \ self.bias)\n\n            z0 = z[:, :self.units]\n            z1 = z[:, self.units:\
    \ 2 * self.units]\n            z2 = z[:, 2 * self.units: 3 * self.units]\n   \
    \         z3 = z[:, 3 * self.units:]\n\n            i = self.recurrent_activation(z0)\n\
    \            f = self.recurrent_activation(z1)\n            c = f * c_tm1 + i\
    \ * self.activation(z2)\n            o = self.recurrent_activation(z3)\n\n   \
    \     h = o * self.activation(c)\n        if 0 < self.dropout + self.recurrent_dropout:\n\
    \            if training is None:\n                h._uses_learning_phase = True\n\
    \        return h, [h, c]\n\n    def get_config(self):\n        config = {'units':\
    \ self.units,\n                  'activation': activations.serialize(self.activation),\n\
    \                  'recurrent_activation':\n                      activations.serialize(self.recurrent_activation),\n\
    \                  'use_bias': self.use_bias,\n                  'kernel_initializer':\n\
    \                      initializers.serialize(self.kernel_initializer),\n    \
    \              'recurrent_initializer':\n                      initializers.serialize(self.recurrent_initializer),\n\
    \                  'bias_initializer': initializers.serialize(self.bias_initializer),\n\
    \                  'unit_forget_bias': self.unit_forget_bias,\n              \
    \    'kernel_regularizer':\n                      regularizers.serialize(self.kernel_regularizer),\n\
    \                  'recurrent_regularizer':\n                      regularizers.serialize(self.recurrent_regularizer),\n\
    \                  'bias_regularizer': regularizers.serialize(self.bias_regularizer),\n\
    \                  'kernel_constraint': constraints.serialize(self.kernel_constraint),\n\
    \                  'recurrent_constraint':\n                      constraints.serialize(self.recurrent_constraint),\n\
    \                  'bias_constraint': constraints.serialize(self.bias_constraint),\n\
    \                  'dropout': self.dropout,\n                  'recurrent_dropout':\
    \ self.recurrent_dropout,\n                  'implementation': self.implementation}\n\
    \        base_config = super(LSTMCell, self).get_config()\n        return dict(list(base_config.items())\
    \ + list(config.items()))\n"
  sourcefile: D:\Python36\lib\site-packages\keras\layers\recurrent.py
- doc: "Wraps arbitrary expression as a `Layer` object.\n\n# Examples\n\n```python\n\
    \    # add a x -> x^2 layer\n    model.add(Lambda(lambda x: x ** 2))\n```\n```python\n\
    \    # add a layer that returns the concatenation\n    # of the positive part\
    \ of the input and\n    # the opposite of the negative part\n\n    def antirectifier(x):\n\
    \        x -= K.mean(x, axis=1, keepdims=True)\n        x = K.l2_normalize(x,\
    \ axis=1)\n        pos = K.relu(x)\n        neg = K.relu(-x)\n        return K.concatenate([pos,\
    \ neg], axis=1)\n\n    def antirectifier_output_shape(input_shape):\n        shape\
    \ = list(input_shape)\n        assert len(shape) == 2  # only valid for 2D tensors\n\
    \        shape[-1] *= 2\n        return tuple(shape)\n\n    model.add(Lambda(antirectifier,\n\
    \                     output_shape=antirectifier_output_shape))\n```\n\n# Arguments\n\
    \    function: The function to be evaluated.\n        Takes input tensor as first\
    \ argument.\n    output_shape: Expected output shape from function.\n        Only\
    \ relevant when using Theano.\n        Can be a tuple or function.\n        If\
    \ a tuple, it only specifies the first dimension onward;\n             sample\
    \ dimension is assumed either the same as the input:\n             `output_shape\
    \ = (input_shape[0], ) + output_shape`\n             or, the input is `None` and\n\
    \             the sample dimension is also `None`:\n             `output_shape\
    \ = (None, ) + output_shape`\n        If a function, it specifies the entire shape\
    \ as a function of the\n        input shape: `output_shape = f(input_shape)`\n\
    \    arguments: optional dictionary of keyword arguments to be passed\n      \
    \  to the function.\n\n# Input shape\n    Arbitrary. Use the keyword argument\
    \ input_shape\n    (tuple of integers, does not include the samples axis)\n  \
    \  when using this layer as the first layer in a model.\n\n# Output shape\n  \
    \  Specified by `output_shape` argument\n    (or auto-inferred when using TensorFlow\
    \ or CNTK)."
  kind: Layer
  name: Lambda
  parameters:
  - {kind: any, name: function}
  - {defaultValue: None, kind: any, name: output_shape}
  - {defaultValue: None, kind: any, name: mask}
  - {defaultValue: None, kind: any, name: arguments}
  - {defaultValue: 'true', name: trainable, type: bool}
  source: "class Lambda(Layer):\n    \"\"\"Wraps arbitrary expression as a `Layer`\
    \ object.\n\n    # Examples\n\n    ```python\n        # add a x -> x^2 layer\n\
    \        model.add(Lambda(lambda x: x ** 2))\n    ```\n    ```python\n       \
    \ # add a layer that returns the concatenation\n        # of the positive part\
    \ of the input and\n        # the opposite of the negative part\n\n        def\
    \ antirectifier(x):\n            x -= K.mean(x, axis=1, keepdims=True)\n     \
    \       x = K.l2_normalize(x, axis=1)\n            pos = K.relu(x)\n         \
    \   neg = K.relu(-x)\n            return K.concatenate([pos, neg], axis=1)\n\n\
    \        def antirectifier_output_shape(input_shape):\n            shape = list(input_shape)\n\
    \            assert len(shape) == 2  # only valid for 2D tensors\n           \
    \ shape[-1] *= 2\n            return tuple(shape)\n\n        model.add(Lambda(antirectifier,\n\
    \                         output_shape=antirectifier_output_shape))\n    ```\n\
    \n    # Arguments\n        function: The function to be evaluated.\n         \
    \   Takes input tensor as first argument.\n        output_shape: Expected output\
    \ shape from function.\n            Only relevant when using Theano.\n       \
    \     Can be a tuple or function.\n            If a tuple, it only specifies the\
    \ first dimension onward;\n                 sample dimension is assumed either\
    \ the same as the input:\n                 `output_shape = (input_shape[0], )\
    \ + output_shape`\n                 or, the input is `None` and\n            \
    \     the sample dimension is also `None`:\n                 `output_shape = (None,\
    \ ) + output_shape`\n            If a function, it specifies the entire shape\
    \ as a function of the\n            input shape: `output_shape = f(input_shape)`\n\
    \        arguments: optional dictionary of keyword arguments to be passed\n  \
    \          to the function.\n\n    # Input shape\n        Arbitrary. Use the keyword\
    \ argument input_shape\n        (tuple of integers, does not include the samples\
    \ axis)\n        when using this layer as the first layer in a model.\n\n    #\
    \ Output shape\n        Specified by `output_shape` argument\n        (or auto-inferred\
    \ when using TensorFlow or CNTK).\n    \"\"\"\n\n    @interfaces.legacy_lambda_support\n\
    \    def __init__(self, function, output_shape=None,\n                 mask=None,\
    \ arguments=None, **kwargs):\n        super(Lambda, self).__init__(**kwargs)\n\
    \        self.function = function\n        self.arguments = arguments if arguments\
    \ else {}\n        if mask is not None:\n            self.supports_masking = True\n\
    \        self.mask = mask\n\n        if output_shape is None:\n            self._output_shape\
    \ = None\n        elif isinstance(output_shape, (tuple, list)):\n            self._output_shape\
    \ = tuple(output_shape)\n        else:\n            if not callable(output_shape):\n\
    \                raise TypeError('In Lambda, `output_shape` '\n              \
    \                  'must be a list, a tuple, or a function.')\n            self._output_shape\
    \ = output_shape\n\n    def compute_output_shape(self, input_shape):\n       \
    \ if self._output_shape is None:\n            # With TensorFlow or CNTK, we can\
    \ infer the output shape directly:\n            if K.backend() in ('tensorflow',\
    \ 'cntk'):\n                if isinstance(input_shape, list):\n              \
    \      xs = [K.placeholder(shape=shape) for shape in input_shape]\n          \
    \          x = self.call(xs)\n                else:\n                    x = K.placeholder(shape=input_shape)\n\
    \                    x = self.call(x)\n                if isinstance(x, list):\n\
    \                    return [K.int_shape(x_elem) for x_elem in x]\n          \
    \      else:\n                    return K.int_shape(x)\n            # Otherwise,\
    \ we default to the input shape.\n            warnings.warn('`output_shape` argument\
    \ not specified for layer {} '\n                          'and cannot be automatically\
    \ inferred '\n                          'with the Theano backend. '\n        \
    \                  'Defaulting to output shape `{}` '\n                      \
    \    '(same as input shape). '\n                          'If the expected output\
    \ shape is different, '\n                          'specify it via the `output_shape`\
    \ argument.'\n                          .format(self.name, input_shape))\n   \
    \         return input_shape\n        elif isinstance(self._output_shape, (tuple,\
    \ list)):\n            if isinstance(input_shape, list):\n                num_samples\
    \ = input_shape[0][0]\n            else:\n                num_samples = input_shape[0]\
    \ if input_shape else None\n            return (num_samples,) + tuple(self._output_shape)\n\
    \        else:\n            shape = self._output_shape(input_shape)\n        \
    \    if not isinstance(shape, (list, tuple)):\n                raise ValueError('`output_shape`\
    \ function must return a tuple or '\n                                 'a list\
    \ of tuples.')\n            if isinstance(shape, list):\n                if isinstance(shape[0],\
    \ int) or shape[0] is None:\n                    shape = tuple(shape)\n      \
    \      return shape\n\n    def call(self, inputs, mask=None):\n        arguments\
    \ = self.arguments\n        if has_arg(self.function, 'mask'):\n            arguments['mask']\
    \ = mask\n        return self.function(inputs, **arguments)\n\n    def compute_mask(self,\
    \ inputs, mask=None):\n        if callable(self.mask):\n            return self.mask(inputs,\
    \ mask)\n        return self.mask\n\n    def get_config(self):\n        if isinstance(self.function,\
    \ python_types.LambdaType):\n            function = func_dump(self.function)\n\
    \            function_type = 'lambda'\n        else:\n            function = self.function.__name__\n\
    \            function_type = 'function'\n\n        if isinstance(self._output_shape,\
    \ python_types.LambdaType):\n            output_shape = func_dump(self._output_shape)\n\
    \            output_shape_type = 'lambda'\n        elif callable(self._output_shape):\n\
    \            output_shape = self._output_shape.__name__\n            output_shape_type\
    \ = 'function'\n        else:\n            output_shape = self._output_shape\n\
    \            output_shape_type = 'raw'\n\n        config = {'function': function,\n\
    \                  'function_type': function_type,\n                  'output_shape':\
    \ output_shape,\n                  'output_shape_type': output_shape_type,\n \
    \                 'arguments': self.arguments}\n        base_config = super(Lambda,\
    \ self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))\n\
    \n    @classmethod\n    def from_config(cls, config, custom_objects=None):\n \
    \       config = config.copy()\n        globs = globals()\n        if custom_objects:\n\
    \            globs = dict(list(globs.items()) + list(custom_objects.items()))\n\
    \        function_type = config.pop('function_type')\n        if function_type\
    \ == 'function':\n            # Simple lookup in custom objects\n            function\
    \ = deserialize_keras_object(\n                config['function'],\n         \
    \       custom_objects=custom_objects,\n                printable_module_name='function\
    \ in Lambda layer')\n        elif function_type == 'lambda':\n            # Unsafe\
    \ deserialization from bytecode\n            function = func_load(config['function'],\
    \ globs=globs)\n        else:\n            raise TypeError('Unknown function type:',\
    \ function_type)\n\n        output_shape_type = config.pop('output_shape_type')\n\
    \        if output_shape_type == 'function':\n            # Simple lookup in custom\
    \ objects\n            output_shape = deserialize_keras_object(\n            \
    \    config['output_shape'],\n                custom_objects=custom_objects,\n\
    \                printable_module_name='output_shape function in Lambda layer')\n\
    \        elif output_shape_type == 'lambda':\n            # Unsafe deserialization\
    \ from bytecode\n            output_shape = func_load(config['output_shape'],\
    \ globs=globs)\n        else:\n            output_shape = config['output_shape']\n\
    \n        # If arguments were numpy array, they have been saved as\n        #\
    \ list. We need to recover the ndarray\n        if 'arguments' in config:\n  \
    \          for key in config['arguments']:\n                if isinstance(config['arguments'][key],\
    \ dict):\n                    arg_dict = config['arguments'][key]\n          \
    \          if 'type' in arg_dict and arg_dict['type'] == 'ndarray':\n        \
    \                # Overwrite the argument with its numpy translation\n       \
    \                 config['arguments'][key] = np.array(arg_dict['value'])\n\n \
    \       config['function'] = function\n        config['output_shape'] = output_shape\n\
    \        return cls(**config)\n"
  sourcefile: D:\Python36\lib\site-packages\keras\layers\core.py
- doc: "Leaky version of a Rectified Linear Unit.\n\nIt allows a small gradient when\
    \ the unit is not active:\n`f(x) = alpha * x for x < 0`,\n`f(x) = x for x >= 0`.\n\
    \n# Input shape\n    Arbitrary. Use the keyword argument `input_shape`\n    (tuple\
    \ of integers, does not include the samples axis)\n    when using this layer as\
    \ the first layer in a model.\n\n# Output shape\n    Same shape as the input.\n\
    \n# Arguments\n    alpha: float >= 0. Negative slope coefficient.\n\n# References\n\
    \    - [Rectifier Nonlinearities Improve Neural Network Acoustic Models]\n   \
    \   (https://ai.stanford.edu/~amaas/papers/relu_hybrid_icml2013_final.pdf)"
  kind: Layer
  name: LeakyReLU
  parameters:
  - {defaultValue: '0.3', kind: any, name: alpha}
  - {defaultValue: 'true', name: trainable, type: bool}
  source: "class LeakyReLU(Layer):\n    \"\"\"Leaky version of a Rectified Linear\
    \ Unit.\n\n    It allows a small gradient when the unit is not active:\n    `f(x)\
    \ = alpha * x for x < 0`,\n    `f(x) = x for x >= 0`.\n\n    # Input shape\n \
    \       Arbitrary. Use the keyword argument `input_shape`\n        (tuple of integers,\
    \ does not include the samples axis)\n        when using this layer as the first\
    \ layer in a model.\n\n    # Output shape\n        Same shape as the input.\n\n\
    \    # Arguments\n        alpha: float >= 0. Negative slope coefficient.\n\n \
    \   # References\n        - [Rectifier Nonlinearities Improve Neural Network Acoustic\
    \ Models]\n          (https://ai.stanford.edu/~amaas/papers/relu_hybrid_icml2013_final.pdf)\n\
    \    \"\"\"\n\n    def __init__(self, alpha=0.3, **kwargs):\n        super(LeakyReLU,\
    \ self).__init__(**kwargs)\n        self.supports_masking = True\n        self.alpha\
    \ = K.cast_to_floatx(alpha)\n\n    def call(self, inputs):\n        return K.relu(inputs,\
    \ alpha=self.alpha)\n\n    def get_config(self):\n        config = {'alpha': float(self.alpha)}\n\
    \        base_config = super(LeakyReLU, self).get_config()\n        return dict(list(base_config.items())\
    \ + list(config.items()))\n\n    def compute_output_shape(self, input_shape):\n\
    \        return input_shape\n"
  sourcefile: D:\Python36\lib\site-packages\keras\layers\advanced_activations.py
- doc: "Locally-connected layer for 1D inputs.\n\nThe `LocallyConnected1D` layer works\
    \ similarly to\nthe `Conv1D` layer, except that weights are unshared,\nthat is,\
    \ a different set of filters is applied at each different patch\nof the input.\n\
    \n# Example\n```python\n    # apply a unshared weight convolution 1d of length\
    \ 3 to a sequence with\n    # 10 timesteps, with 64 output filters\n    model\
    \ = Sequential()\n    model.add(LocallyConnected1D(64, 3, input_shape=(10, 32)))\n\
    \    # now model.output_shape == (None, 8, 64)\n    # add a new conv1d on top\n\
    \    model.add(LocallyConnected1D(32, 3))\n    # now model.output_shape == (None,\
    \ 6, 32)\n```\n\n# Arguments\n    filters: Integer, the dimensionality of the\
    \ output space\n        (i.e. the number of output filters in the convolution).\n\
    \    kernel_size: An integer or tuple/list of a single integer,\n        specifying\
    \ the length of the 1D convolution window.\n    strides: An integer or tuple/list\
    \ of a single integer,\n        specifying the stride length of the convolution.\n\
    \        Specifying any stride value != 1 is incompatible with specifying\n  \
    \      any `dilation_rate` value != 1.\n    padding: Currently only supports `\"\
    valid\"` (case-insensitive).\n        `\"same\"` may be supported in the future.\n\
    \    activation: Activation function to use\n        (see [activations](../activations.md)).\n\
    \        If you don't specify anything, no activation is applied\n        (ie.\
    \ \"linear\" activation: `a(x) = x`).\n    use_bias: Boolean, whether the layer\
    \ uses a bias vector.\n    kernel_initializer: Initializer for the `kernel` weights\
    \ matrix\n        (see [initializers](../initializers.md)).\n    bias_initializer:\
    \ Initializer for the bias vector\n        (see [initializers](../initializers.md)).\n\
    \    kernel_regularizer: Regularizer function applied to\n        the `kernel`\
    \ weights matrix\n        (see [regularizer](../regularizers.md)).\n    bias_regularizer:\
    \ Regularizer function applied to the bias vector\n        (see [regularizer](../regularizers.md)).\n\
    \    activity_regularizer: Regularizer function applied to\n        the output\
    \ of the layer (its \"activation\").\n        (see [regularizer](../regularizers.md)).\n\
    \    kernel_constraint: Constraint function applied to the kernel matrix\n   \
    \     (see [constraints](../constraints.md)).\n    bias_constraint: Constraint\
    \ function applied to the bias vector\n        (see [constraints](../constraints.md)).\n\
    \n# Input shape\n    3D tensor with shape: `(batch_size, steps, input_dim)`\n\n\
    # Output shape\n    3D tensor with shape: `(batch_size, new_steps, filters)`\n\
    \    `steps` value might have changed due to padding or strides."
  kind: Layer
  name: LocallyConnected1D
  parameters:
  - {kind: any, name: filters}
  - {kind: any, name: kernel_size}
  - {defaultValue: '1', kind: any, name: strides}
  - {defaultValue: valid, kind: any, name: padding}
  - {defaultValue: None, kind: any, name: data_format}
  - {defaultValue: None, kind: any, name: activation}
  - {defaultValue: 'True', kind: any, name: use_bias}
  - {defaultValue: glorot_uniform, kind: any, name: kernel_initializer}
  - {defaultValue: zeros, kind: any, name: bias_initializer}
  - {defaultValue: None, kind: any, name: kernel_regularizer}
  - {defaultValue: None, kind: any, name: bias_regularizer}
  - {defaultValue: None, kind: any, name: activity_regularizer}
  - {defaultValue: None, kind: any, name: kernel_constraint}
  - {defaultValue: None, kind: any, name: bias_constraint}
  - {defaultValue: 'true', name: trainable, type: bool}
  source: "class LocallyConnected1D(Layer):\n    \"\"\"Locally-connected layer for\
    \ 1D inputs.\n\n    The `LocallyConnected1D` layer works similarly to\n    the\
    \ `Conv1D` layer, except that weights are unshared,\n    that is, a different\
    \ set of filters is applied at each different patch\n    of the input.\n\n   \
    \ # Example\n    ```python\n        # apply a unshared weight convolution 1d of\
    \ length 3 to a sequence with\n        # 10 timesteps, with 64 output filters\n\
    \        model = Sequential()\n        model.add(LocallyConnected1D(64, 3, input_shape=(10,\
    \ 32)))\n        # now model.output_shape == (None, 8, 64)\n        # add a new\
    \ conv1d on top\n        model.add(LocallyConnected1D(32, 3))\n        # now model.output_shape\
    \ == (None, 6, 32)\n    ```\n\n    # Arguments\n        filters: Integer, the\
    \ dimensionality of the output space\n            (i.e. the number of output filters\
    \ in the convolution).\n        kernel_size: An integer or tuple/list of a single\
    \ integer,\n            specifying the length of the 1D convolution window.\n\
    \        strides: An integer or tuple/list of a single integer,\n            specifying\
    \ the stride length of the convolution.\n            Specifying any stride value\
    \ != 1 is incompatible with specifying\n            any `dilation_rate` value\
    \ != 1.\n        padding: Currently only supports `\"valid\"` (case-insensitive).\n\
    \            `\"same\"` may be supported in the future.\n        activation: Activation\
    \ function to use\n            (see [activations](../activations.md)).\n     \
    \       If you don't specify anything, no activation is applied\n            (ie.\
    \ \"linear\" activation: `a(x) = x`).\n        use_bias: Boolean, whether the\
    \ layer uses a bias vector.\n        kernel_initializer: Initializer for the `kernel`\
    \ weights matrix\n            (see [initializers](../initializers.md)).\n    \
    \    bias_initializer: Initializer for the bias vector\n            (see [initializers](../initializers.md)).\n\
    \        kernel_regularizer: Regularizer function applied to\n            the\
    \ `kernel` weights matrix\n            (see [regularizer](../regularizers.md)).\n\
    \        bias_regularizer: Regularizer function applied to the bias vector\n \
    \           (see [regularizer](../regularizers.md)).\n        activity_regularizer:\
    \ Regularizer function applied to\n            the output of the layer (its \"\
    activation\").\n            (see [regularizer](../regularizers.md)).\n       \
    \ kernel_constraint: Constraint function applied to the kernel matrix\n      \
    \      (see [constraints](../constraints.md)).\n        bias_constraint: Constraint\
    \ function applied to the bias vector\n            (see [constraints](../constraints.md)).\n\
    \n    # Input shape\n        3D tensor with shape: `(batch_size, steps, input_dim)`\n\
    \n    # Output shape\n        3D tensor with shape: `(batch_size, new_steps, filters)`\n\
    \        `steps` value might have changed due to padding or strides.\n    \"\"\
    \"\n\n    @interfaces.legacy_conv1d_support\n    def __init__(self, filters,\n\
    \                 kernel_size,\n                 strides=1,\n                \
    \ padding='valid',\n                 data_format=None,\n                 activation=None,\n\
    \                 use_bias=True,\n                 kernel_initializer='glorot_uniform',\n\
    \                 bias_initializer='zeros',\n                 kernel_regularizer=None,\n\
    \                 bias_regularizer=None,\n                 activity_regularizer=None,\n\
    \                 kernel_constraint=None,\n                 bias_constraint=None,\n\
    \                 **kwargs):\n        super(LocallyConnected1D, self).__init__(**kwargs)\n\
    \        self.filters = filters\n        self.kernel_size = conv_utils.normalize_tuple(kernel_size,\
    \ 1, 'kernel_size')\n        self.strides = conv_utils.normalize_tuple(strides,\
    \ 1, 'strides')\n        self.padding = conv_utils.normalize_padding(padding)\n\
    \        if self.padding != 'valid':\n            raise ValueError('Invalid border\
    \ mode for LocallyConnected1D '\n                             '(only \"valid\"\
    \ is supported): ' + padding)\n        self.data_format = K.normalize_data_format(data_format)\n\
    \        self.activation = activations.get(activation)\n        self.use_bias\
    \ = use_bias\n        self.kernel_initializer = initializers.get(kernel_initializer)\n\
    \        self.bias_initializer = initializers.get(bias_initializer)\n        self.kernel_regularizer\
    \ = regularizers.get(kernel_regularizer)\n        self.bias_regularizer = regularizers.get(bias_regularizer)\n\
    \        self.activity_regularizer = regularizers.get(activity_regularizer)\n\
    \        self.kernel_constraint = constraints.get(kernel_constraint)\n       \
    \ self.bias_constraint = constraints.get(bias_constraint)\n        self.input_spec\
    \ = InputSpec(ndim=3)\n\n    def build(self, input_shape):\n        input_dim\
    \ = input_shape[2]\n        if input_dim is None:\n            raise ValueError('Axis\
    \ 2 of input should be fully-defined. '\n                             'Found shape:',\
    \ input_shape)\n        output_length = conv_utils.conv_output_length(input_shape[1],\n\
    \                                                      self.kernel_size[0],\n\
    \                                                      self.padding,\n       \
    \                                               self.strides[0])\n        self.kernel_shape\
    \ = (output_length,\n                             self.kernel_size[0] * input_dim,\n\
    \                             self.filters)\n        self.kernel = self.add_weight(\n\
    \            shape=self.kernel_shape,\n            initializer=self.kernel_initializer,\n\
    \            name='kernel',\n            regularizer=self.kernel_regularizer,\n\
    \            constraint=self.kernel_constraint)\n        if self.use_bias:\n \
    \           self.bias = self.add_weight(\n                shape=(output_length,\
    \ self.filters),\n                initializer=self.bias_initializer,\n       \
    \         name='bias',\n                regularizer=self.bias_regularizer,\n \
    \               constraint=self.bias_constraint)\n        else:\n            self.bias\
    \ = None\n        self.input_spec = InputSpec(ndim=3, axes={2: input_dim})\n \
    \       self.built = True\n\n    def compute_output_shape(self, input_shape):\n\
    \        length = conv_utils.conv_output_length(input_shape[1],\n            \
    \                                   self.kernel_size[0],\n                   \
    \                            self.padding,\n                                 \
    \              self.strides[0])\n        return (input_shape[0], length, self.filters)\n\
    \n    def call(self, inputs):\n        output = K.local_conv1d(inputs, self.kernel,\
    \ self.kernel_size, self.strides)\n        if self.use_bias:\n            output\
    \ = K.bias_add(output, self.bias)\n        if self.activation is not None:\n \
    \           output = self.activation(output)\n        return output\n\n    def\
    \ get_config(self):\n        config = {\n            'filters': self.filters,\n\
    \            'kernel_size': self.kernel_size,\n            'strides': self.strides,\n\
    \            'padding': self.padding,\n            'activation': activations.serialize(self.activation),\n\
    \            'use_bias': self.use_bias,\n            'kernel_initializer': initializers.serialize(self.kernel_initializer),\n\
    \            'bias_initializer': initializers.serialize(self.bias_initializer),\n\
    \            'kernel_regularizer': regularizers.serialize(self.kernel_regularizer),\n\
    \            'bias_regularizer': regularizers.serialize(self.bias_regularizer),\n\
    \            'activity_regularizer':\n                regularizers.serialize(self.activity_regularizer),\n\
    \            'kernel_constraint': constraints.serialize(self.kernel_constraint),\n\
    \            'bias_constraint': constraints.serialize(self.bias_constraint)\n\
    \        }\n        base_config = super(LocallyConnected1D, self).get_config()\n\
    \        return dict(list(base_config.items()) + list(config.items()))\n"
  sourcefile: D:\Python36\lib\site-packages\keras\layers\local.py
- doc: "Locally-connected layer for 2D inputs.\n\nThe `LocallyConnected2D` layer works\
    \ similarly\nto the `Conv2D` layer, except that weights are unshared,\nthat is,\
    \ a different set of filters is applied at each\ndifferent patch of the input.\n\
    \n# Examples\n```python\n    # apply a 3x3 unshared weights convolution with 64\
    \ output filters\n    # on a 32x32 image with `data_format=\"channels_last\"`:\n\
    \    model = Sequential()\n    model.add(LocallyConnected2D(64, (3, 3), input_shape=(32,\
    \ 32, 3)))\n    # now model.output_shape == (None, 30, 30, 64)\n    # notice that\
    \ this layer will consume (30*30)*(3*3*3*64)\n    # + (30*30)*64 parameters\n\n\
    \    # add a 3x3 unshared weights convolution on top, with 32 output filters:\n\
    \    model.add(LocallyConnected2D(32, (3, 3)))\n    # now model.output_shape ==\
    \ (None, 28, 28, 32)\n```\n\n# Arguments\n    filters: Integer, the dimensionality\
    \ of the output space\n        (i.e. the number of output filters in the convolution).\n\
    \    kernel_size: An integer or tuple/list of 2 integers, specifying the\n   \
    \     width and height of the 2D convolution window.\n        Can be a single\
    \ integer to specify the same value for\n        all spatial dimensions.\n   \
    \ strides: An integer or tuple/list of 2 integers,\n        specifying the strides\
    \ of the convolution along the width and height.\n        Can be a single integer\
    \ to specify the same value for\n        all spatial dimensions.\n    padding:\
    \ Currently only support `\"valid\"` (case-insensitive).\n        `\"same\"` will\
    \ be supported in future.\n    data_format: A string,\n        one of `channels_last`\
    \ (default) or `channels_first`.\n        The ordering of the dimensions in the\
    \ inputs.\n        `channels_last` corresponds to inputs with shape\n        `(batch,\
    \ height, width, channels)` while `channels_first`\n        corresponds to inputs\
    \ with shape\n        `(batch, channels, height, width)`.\n        It defaults\
    \ to the `image_data_format` value found in your\n        Keras config file at\
    \ `~/.keras/keras.json`.\n        If you never set it, then it will be \"channels_last\"\
    .\n    activation: Activation function to use\n        (see [activations](../activations.md)).\n\
    \        If you don't specify anything, no activation is applied\n        (ie.\
    \ \"linear\" activation: `a(x) = x`).\n    use_bias: Boolean, whether the layer\
    \ uses a bias vector.\n    kernel_initializer: Initializer for the `kernel` weights\
    \ matrix\n        (see [initializers](../initializers.md)).\n    bias_initializer:\
    \ Initializer for the bias vector\n        (see [initializers](../initializers.md)).\n\
    \    kernel_regularizer: Regularizer function applied to\n        the `kernel`\
    \ weights matrix\n        (see [regularizer](../regularizers.md)).\n    bias_regularizer:\
    \ Regularizer function applied to the bias vector\n        (see [regularizer](../regularizers.md)).\n\
    \    activity_regularizer: Regularizer function applied to\n        the output\
    \ of the layer (its \"activation\").\n        (see [regularizer](../regularizers.md)).\n\
    \    kernel_constraint: Constraint function applied to the kernel matrix\n   \
    \     (see [constraints](../constraints.md)).\n    bias_constraint: Constraint\
    \ function applied to the bias vector\n        (see [constraints](../constraints.md)).\n\
    \n# Input shape\n    4D tensor with shape:\n    `(samples, channels, rows, cols)`\
    \ if data_format='channels_first'\n    or 4D tensor with shape:\n    `(samples,\
    \ rows, cols, channels)` if data_format='channels_last'.\n\n# Output shape\n \
    \   4D tensor with shape:\n    `(samples, filters, new_rows, new_cols)` if data_format='channels_first'\n\
    \    or 4D tensor with shape:\n    `(samples, new_rows, new_cols, filters)` if\
    \ data_format='channels_last'.\n    `rows` and `cols` values might have changed\
    \ due to padding."
  kind: Layer
  name: LocallyConnected2D
  parameters:
  - {kind: any, name: filters}
  - {kind: any, name: kernel_size}
  - {defaultValue: '(1, 1)', kind: any, name: strides}
  - {defaultValue: valid, kind: any, name: padding}
  - {defaultValue: None, kind: any, name: data_format}
  - {defaultValue: None, kind: any, name: activation}
  - {defaultValue: 'True', kind: any, name: use_bias}
  - {defaultValue: glorot_uniform, kind: any, name: kernel_initializer}
  - {defaultValue: zeros, kind: any, name: bias_initializer}
  - {defaultValue: None, kind: any, name: kernel_regularizer}
  - {defaultValue: None, kind: any, name: bias_regularizer}
  - {defaultValue: None, kind: any, name: activity_regularizer}
  - {defaultValue: None, kind: any, name: kernel_constraint}
  - {defaultValue: None, kind: any, name: bias_constraint}
  - {defaultValue: 'true', name: trainable, type: bool}
  source: "class LocallyConnected2D(Layer):\n    \"\"\"Locally-connected layer for\
    \ 2D inputs.\n\n    The `LocallyConnected2D` layer works similarly\n    to the\
    \ `Conv2D` layer, except that weights are unshared,\n    that is, a different\
    \ set of filters is applied at each\n    different patch of the input.\n\n   \
    \ # Examples\n    ```python\n        # apply a 3x3 unshared weights convolution\
    \ with 64 output filters\n        # on a 32x32 image with `data_format=\"channels_last\"\
    `:\n        model = Sequential()\n        model.add(LocallyConnected2D(64, (3,\
    \ 3), input_shape=(32, 32, 3)))\n        # now model.output_shape == (None, 30,\
    \ 30, 64)\n        # notice that this layer will consume (30*30)*(3*3*3*64)\n\
    \        # + (30*30)*64 parameters\n\n        # add a 3x3 unshared weights convolution\
    \ on top, with 32 output filters:\n        model.add(LocallyConnected2D(32, (3,\
    \ 3)))\n        # now model.output_shape == (None, 28, 28, 32)\n    ```\n\n  \
    \  # Arguments\n        filters: Integer, the dimensionality of the output space\n\
    \            (i.e. the number of output filters in the convolution).\n       \
    \ kernel_size: An integer or tuple/list of 2 integers, specifying the\n      \
    \      width and height of the 2D convolution window.\n            Can be a single\
    \ integer to specify the same value for\n            all spatial dimensions.\n\
    \        strides: An integer or tuple/list of 2 integers,\n            specifying\
    \ the strides of the convolution along the width and height.\n            Can\
    \ be a single integer to specify the same value for\n            all spatial dimensions.\n\
    \        padding: Currently only support `\"valid\"` (case-insensitive).\n   \
    \         `\"same\"` will be supported in future.\n        data_format: A string,\n\
    \            one of `channels_last` (default) or `channels_first`.\n         \
    \   The ordering of the dimensions in the inputs.\n            `channels_last`\
    \ corresponds to inputs with shape\n            `(batch, height, width, channels)`\
    \ while `channels_first`\n            corresponds to inputs with shape\n     \
    \       `(batch, channels, height, width)`.\n            It defaults to the `image_data_format`\
    \ value found in your\n            Keras config file at `~/.keras/keras.json`.\n\
    \            If you never set it, then it will be \"channels_last\".\n       \
    \ activation: Activation function to use\n            (see [activations](../activations.md)).\n\
    \            If you don't specify anything, no activation is applied\n       \
    \     (ie. \"linear\" activation: `a(x) = x`).\n        use_bias: Boolean, whether\
    \ the layer uses a bias vector.\n        kernel_initializer: Initializer for the\
    \ `kernel` weights matrix\n            (see [initializers](../initializers.md)).\n\
    \        bias_initializer: Initializer for the bias vector\n            (see [initializers](../initializers.md)).\n\
    \        kernel_regularizer: Regularizer function applied to\n            the\
    \ `kernel` weights matrix\n            (see [regularizer](../regularizers.md)).\n\
    \        bias_regularizer: Regularizer function applied to the bias vector\n \
    \           (see [regularizer](../regularizers.md)).\n        activity_regularizer:\
    \ Regularizer function applied to\n            the output of the layer (its \"\
    activation\").\n            (see [regularizer](../regularizers.md)).\n       \
    \ kernel_constraint: Constraint function applied to the kernel matrix\n      \
    \      (see [constraints](../constraints.md)).\n        bias_constraint: Constraint\
    \ function applied to the bias vector\n            (see [constraints](../constraints.md)).\n\
    \n    # Input shape\n        4D tensor with shape:\n        `(samples, channels,\
    \ rows, cols)` if data_format='channels_first'\n        or 4D tensor with shape:\n\
    \        `(samples, rows, cols, channels)` if data_format='channels_last'.\n\n\
    \    # Output shape\n        4D tensor with shape:\n        `(samples, filters,\
    \ new_rows, new_cols)` if data_format='channels_first'\n        or 4D tensor with\
    \ shape:\n        `(samples, new_rows, new_cols, filters)` if data_format='channels_last'.\n\
    \        `rows` and `cols` values might have changed due to padding.\n    \"\"\
    \"\n\n    @interfaces.legacy_conv2d_support\n    def __init__(self, filters,\n\
    \                 kernel_size,\n                 strides=(1, 1),\n           \
    \      padding='valid',\n                 data_format=None,\n                \
    \ activation=None,\n                 use_bias=True,\n                 kernel_initializer='glorot_uniform',\n\
    \                 bias_initializer='zeros',\n                 kernel_regularizer=None,\n\
    \                 bias_regularizer=None,\n                 activity_regularizer=None,\n\
    \                 kernel_constraint=None,\n                 bias_constraint=None,\n\
    \                 **kwargs):\n        super(LocallyConnected2D, self).__init__(**kwargs)\n\
    \        self.filters = filters\n        self.kernel_size = conv_utils.normalize_tuple(kernel_size,\
    \ 2, 'kernel_size')\n        self.strides = conv_utils.normalize_tuple(strides,\
    \ 2, 'strides')\n        self.padding = conv_utils.normalize_padding(padding)\n\
    \        if self.padding != 'valid':\n            raise ValueError('Invalid border\
    \ mode for LocallyConnected2D '\n                             '(only \"valid\"\
    \ is supported): ' + padding)\n        self.data_format = K.normalize_data_format(data_format)\n\
    \        self.activation = activations.get(activation)\n        self.use_bias\
    \ = use_bias\n        self.kernel_initializer = initializers.get(kernel_initializer)\n\
    \        self.bias_initializer = initializers.get(bias_initializer)\n        self.kernel_regularizer\
    \ = regularizers.get(kernel_regularizer)\n        self.bias_regularizer = regularizers.get(bias_regularizer)\n\
    \        self.activity_regularizer = regularizers.get(activity_regularizer)\n\
    \        self.kernel_constraint = constraints.get(kernel_constraint)\n       \
    \ self.bias_constraint = constraints.get(bias_constraint)\n        self.input_spec\
    \ = InputSpec(ndim=4)\n\n    def build(self, input_shape):\n        if self.data_format\
    \ == 'channels_last':\n            input_row, input_col = input_shape[1:-1]\n\
    \            input_filter = input_shape[3]\n        else:\n            input_row,\
    \ input_col = input_shape[2:]\n            input_filter = input_shape[1]\n   \
    \     if input_row is None or input_col is None:\n            raise ValueError('The\
    \ spatial dimensions of the inputs to '\n                             ' a LocallyConnected2D\
    \ layer '\n                             'should be fully-defined, but layer received\
    \ '\n                             'the inputs shape ' + str(input_shape))\n  \
    \      output_row = conv_utils.conv_output_length(input_row, self.kernel_size[0],\n\
    \                                                   self.padding, self.strides[0])\n\
    \        output_col = conv_utils.conv_output_length(input_col, self.kernel_size[1],\n\
    \                                                   self.padding, self.strides[1])\n\
    \        self.output_row = output_row\n        self.output_col = output_col\n\
    \        self.kernel_shape = (\n            output_row * output_col,\n       \
    \     self.kernel_size[0] * self.kernel_size[1] * input_filter,\n            self.filters)\n\
    \        self.kernel = self.add_weight(shape=self.kernel_shape,\n            \
    \                          initializer=self.kernel_initializer,\n            \
    \                          name='kernel',\n                                  \
    \    regularizer=self.kernel_regularizer,\n                                  \
    \    constraint=self.kernel_constraint)\n        if self.use_bias:\n         \
    \   self.bias = self.add_weight(shape=(output_row, output_col, self.filters),\n\
    \                                        initializer=self.bias_initializer,\n\
    \                                        name='bias',\n                      \
    \                  regularizer=self.bias_regularizer,\n                      \
    \                  constraint=self.bias_constraint)\n        else:\n         \
    \   self.bias = None\n        if self.data_format == 'channels_first':\n     \
    \       self.input_spec = InputSpec(ndim=4, axes={1: input_filter})\n        else:\n\
    \            self.input_spec = InputSpec(ndim=4, axes={-1: input_filter})\n  \
    \      self.built = True\n\n    def compute_output_shape(self, input_shape):\n\
    \        if self.data_format == 'channels_first':\n            rows = input_shape[2]\n\
    \            cols = input_shape[3]\n        elif self.data_format == 'channels_last':\n\
    \            rows = input_shape[1]\n            cols = input_shape[2]\n\n    \
    \    rows = conv_utils.conv_output_length(rows, self.kernel_size[0],\n       \
    \                                      self.padding, self.strides[0])\n      \
    \  cols = conv_utils.conv_output_length(cols, self.kernel_size[1],\n         \
    \                                    self.padding, self.strides[1])\n\n      \
    \  if self.data_format == 'channels_first':\n            return (input_shape[0],\
    \ self.filters, rows, cols)\n        elif self.data_format == 'channels_last':\n\
    \            return (input_shape[0], rows, cols, self.filters)\n\n    def call(self,\
    \ inputs):\n        output = K.local_conv2d(inputs,\n                        \
    \        self.kernel,\n                                self.kernel_size,\n   \
    \                             self.strides,\n                                (self.output_row,\
    \ self.output_col),\n                                self.data_format)\n\n   \
    \     if self.use_bias:\n            output = K.bias_add(output, self.bias, data_format=self.data_format)\n\
    \n        output = self.activation(output)\n        return output\n\n    def get_config(self):\n\
    \        config = {\n            'filters': self.filters,\n            'kernel_size':\
    \ self.kernel_size,\n            'strides': self.strides,\n            'padding':\
    \ self.padding,\n            'data_format': self.data_format,\n            'activation':\
    \ activations.serialize(self.activation),\n            'use_bias': self.use_bias,\n\
    \            'kernel_initializer': initializers.serialize(self.kernel_initializer),\n\
    \            'bias_initializer': initializers.serialize(self.bias_initializer),\n\
    \            'kernel_regularizer': regularizers.serialize(self.kernel_regularizer),\n\
    \            'bias_regularizer': regularizers.serialize(self.bias_regularizer),\n\
    \            'activity_regularizer':\n                regularizers.serialize(self.activity_regularizer),\n\
    \            'kernel_constraint': constraints.serialize(self.kernel_constraint),\n\
    \            'bias_constraint': constraints.serialize(self.bias_constraint)\n\
    \        }\n        base_config = super(LocallyConnected2D, self).get_config()\n\
    \        return dict(list(base_config.items()) + list(config.items()))\n"
  sourcefile: D:\Python36\lib\site-packages\keras\layers\local.py
- doc: "Masks a sequence by using a mask value to skip timesteps.\n\nFor each timestep\
    \ in the input tensor (dimension #1 in the tensor),\nif all values in the input\
    \ tensor at that timestep\nare equal to `mask_value`, then the timestep will be\
    \ masked (skipped)\nin all downstream layers (as long as they support masking).\n\
    \nIf any downstream layer does not support masking yet receives such\nan input\
    \ mask, an exception will be raised.\n\n# Example\n\nConsider a Numpy data array\
    \ `x` of shape `(samples, timesteps, features)`,\nto be fed to an LSTM layer.\n\
    You want to mask timestep #3 and #5 because you lack data for\nthese timesteps.\
    \ You can:\n\n    - set `x[:, 3, :] = 0.` and `x[:, 5, :] = 0.`\n    - insert\
    \ a `Masking` layer with `mask_value=0.` before the LSTM layer:\n\n```python\n\
    \    model = Sequential()\n    model.add(Masking(mask_value=0., input_shape=(timesteps,\
    \ features)))\n    model.add(LSTM(32))\n```"
  kind: Layer
  name: Masking
  parameters:
  - {defaultValue: '0.0', kind: any, name: mask_value}
  - {defaultValue: 'true', name: trainable, type: bool}
  source: "class Masking(Layer):\n    \"\"\"Masks a sequence by using a mask value\
    \ to skip timesteps.\n\n    For each timestep in the input tensor (dimension #1\
    \ in the tensor),\n    if all values in the input tensor at that timestep\n  \
    \  are equal to `mask_value`, then the timestep will be masked (skipped)\n   \
    \ in all downstream layers (as long as they support masking).\n\n    If any downstream\
    \ layer does not support masking yet receives such\n    an input mask, an exception\
    \ will be raised.\n\n    # Example\n\n    Consider a Numpy data array `x` of shape\
    \ `(samples, timesteps, features)`,\n    to be fed to an LSTM layer.\n    You\
    \ want to mask timestep #3 and #5 because you lack data for\n    these timesteps.\
    \ You can:\n\n        - set `x[:, 3, :] = 0.` and `x[:, 5, :] = 0.`\n        -\
    \ insert a `Masking` layer with `mask_value=0.` before the LSTM layer:\n\n   \
    \ ```python\n        model = Sequential()\n        model.add(Masking(mask_value=0.,\
    \ input_shape=(timesteps, features)))\n        model.add(LSTM(32))\n    ```\n\
    \    \"\"\"\n\n    def __init__(self, mask_value=0., **kwargs):\n        super(Masking,\
    \ self).__init__(**kwargs)\n        self.supports_masking = True\n        self.mask_value\
    \ = mask_value\n\n    def compute_mask(self, inputs, mask=None):\n        output_mask\
    \ = K.any(K.not_equal(inputs, self.mask_value), axis=-1)\n        return output_mask\n\
    \n    def call(self, inputs):\n        boolean_mask = K.any(K.not_equal(inputs,\
    \ self.mask_value),\n                             axis=-1, keepdims=True)\n  \
    \      return inputs * K.cast(boolean_mask, K.dtype(inputs))\n\n    def get_config(self):\n\
    \        config = {'mask_value': self.mask_value}\n        base_config = super(Masking,\
    \ self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))\n\
    \n    def compute_output_shape(self, input_shape):\n        return input_shape\n"
  sourcefile: D:\Python36\lib\site-packages\keras\layers\core.py
- doc: "Max pooling operation for temporal data.\n\n# Arguments\n    pool_size: Integer,\
    \ size of the max pooling windows.\n    strides: Integer, or None. Factor by which\
    \ to downscale.\n        E.g. 2 will halve the input.\n        If None, it will\
    \ default to `pool_size`.\n    padding: One of `\"valid\"` or `\"same\"` (case-insensitive).\n\
    \    data_format: A string,\n        one of `channels_last` (default) or `channels_first`.\n\
    \        The ordering of the dimensions in the inputs.\n        `channels_last`\
    \ corresponds to inputs with shape\n        `(batch, steps, features)` while `channels_first`\n\
    \        corresponds to inputs with shape\n        `(batch, features, steps)`.\n\
    \n# Input shape\n    - If `data_format='channels_last'`:\n        3D tensor with\
    \ shape:\n        `(batch_size, steps, features)`\n    - If `data_format='channels_first'`:\n\
    \        3D tensor with shape:\n        `(batch_size, features, steps)`\n\n# Output\
    \ shape\n    - If `data_format='channels_last'`:\n        3D tensor with shape:\n\
    \        `(batch_size, downsampled_steps, features)`\n    - If `data_format='channels_first'`:\n\
    \        3D tensor with shape:\n        `(batch_size, features, downsampled_steps)`"
  kind: Layer
  name: MaxPooling1D
  parameters:
  - {defaultValue: '2', kind: any, name: pool_size}
  - {defaultValue: None, kind: any, name: strides}
  - {defaultValue: valid, kind: any, name: padding}
  - {defaultValue: channels_last, kind: any, name: data_format}
  - {defaultValue: 'true', name: trainable, type: bool}
  source: "class MaxPooling1D(_Pooling1D):\n    \"\"\"Max pooling operation for temporal\
    \ data.\n\n    # Arguments\n        pool_size: Integer, size of the max pooling\
    \ windows.\n        strides: Integer, or None. Factor by which to downscale.\n\
    \            E.g. 2 will halve the input.\n            If None, it will default\
    \ to `pool_size`.\n        padding: One of `\"valid\"` or `\"same\"` (case-insensitive).\n\
    \        data_format: A string,\n            one of `channels_last` (default)\
    \ or `channels_first`.\n            The ordering of the dimensions in the inputs.\n\
    \            `channels_last` corresponds to inputs with shape\n            `(batch,\
    \ steps, features)` while `channels_first`\n            corresponds to inputs\
    \ with shape\n            `(batch, features, steps)`.\n\n    # Input shape\n \
    \       - If `data_format='channels_last'`:\n            3D tensor with shape:\n\
    \            `(batch_size, steps, features)`\n        - If `data_format='channels_first'`:\n\
    \            3D tensor with shape:\n            `(batch_size, features, steps)`\n\
    \n    # Output shape\n        - If `data_format='channels_last'`:\n          \
    \  3D tensor with shape:\n            `(batch_size, downsampled_steps, features)`\n\
    \        - If `data_format='channels_first'`:\n            3D tensor with shape:\n\
    \            `(batch_size, features, downsampled_steps)`\n    \"\"\"\n\n    @interfaces.legacy_pooling1d_support\n\
    \    def __init__(self, pool_size=2, strides=None,\n                 padding='valid',\
    \ data_format='channels_last', **kwargs):\n        super(MaxPooling1D, self).__init__(pool_size,\
    \ strides,\n                                           padding, data_format,\n\
    \                                           **kwargs)\n\n    def _pooling_function(self,\
    \ inputs, pool_size, strides,\n                          padding, data_format):\n\
    \        output = K.pool2d(inputs, pool_size, strides,\n                     \
    \     padding, data_format, pool_mode='max')\n        return output\n"
  sourcefile: D:\Python36\lib\site-packages\keras\layers\pooling.py
- doc: "Max pooling operation for spatial data.\n\n# Arguments\n    pool_size: integer\
    \ or tuple of 2 integers,\n        factors by which to downscale (vertical, horizontal).\n\
    \        (2, 2) will halve the input in both spatial dimension.\n        If only\
    \ one integer is specified, the same window length\n        will be used for both\
    \ dimensions.\n    strides: Integer, tuple of 2 integers, or None.\n        Strides\
    \ values.\n        If None, it will default to `pool_size`.\n    padding: One\
    \ of `\"valid\"` or `\"same\"` (case-insensitive).\n    data_format: A string,\n\
    \        one of `channels_last` (default) or `channels_first`.\n        The ordering\
    \ of the dimensions in the inputs.\n        `channels_last` corresponds to inputs\
    \ with shape\n        `(batch, height, width, channels)` while `channels_first`\n\
    \        corresponds to inputs with shape\n        `(batch, channels, height,\
    \ width)`.\n        It defaults to the `image_data_format` value found in your\n\
    \        Keras config file at `~/.keras/keras.json`.\n        If you never set\
    \ it, then it will be \"channels_last\".\n\n# Input shape\n    - If `data_format='channels_last'`:\n\
    \        4D tensor with shape:\n        `(batch_size, rows, cols, channels)`\n\
    \    - If `data_format='channels_first'`:\n        4D tensor with shape:\n   \
    \     `(batch_size, channels, rows, cols)`\n\n# Output shape\n    - If `data_format='channels_last'`:\n\
    \        4D tensor with shape:\n        `(batch_size, pooled_rows, pooled_cols,\
    \ channels)`\n    - If `data_format='channels_first'`:\n        4D tensor with\
    \ shape:\n        `(batch_size, channels, pooled_rows, pooled_cols)`"
  kind: Layer
  name: MaxPooling2D
  parameters:
  - {defaultValue: '(2, 2)', kind: any, name: pool_size}
  - {defaultValue: None, kind: any, name: strides}
  - {defaultValue: valid, kind: any, name: padding}
  - {defaultValue: None, kind: any, name: data_format}
  - {defaultValue: 'true', name: trainable, type: bool}
  source: "class MaxPooling2D(_Pooling2D):\n    \"\"\"Max pooling operation for spatial\
    \ data.\n\n    # Arguments\n        pool_size: integer or tuple of 2 integers,\n\
    \            factors by which to downscale (vertical, horizontal).\n         \
    \   (2, 2) will halve the input in both spatial dimension.\n            If only\
    \ one integer is specified, the same window length\n            will be used for\
    \ both dimensions.\n        strides: Integer, tuple of 2 integers, or None.\n\
    \            Strides values.\n            If None, it will default to `pool_size`.\n\
    \        padding: One of `\"valid\"` or `\"same\"` (case-insensitive).\n     \
    \   data_format: A string,\n            one of `channels_last` (default) or `channels_first`.\n\
    \            The ordering of the dimensions in the inputs.\n            `channels_last`\
    \ corresponds to inputs with shape\n            `(batch, height, width, channels)`\
    \ while `channels_first`\n            corresponds to inputs with shape\n     \
    \       `(batch, channels, height, width)`.\n            It defaults to the `image_data_format`\
    \ value found in your\n            Keras config file at `~/.keras/keras.json`.\n\
    \            If you never set it, then it will be \"channels_last\".\n\n    #\
    \ Input shape\n        - If `data_format='channels_last'`:\n            4D tensor\
    \ with shape:\n            `(batch_size, rows, cols, channels)`\n        - If\
    \ `data_format='channels_first'`:\n            4D tensor with shape:\n       \
    \     `(batch_size, channels, rows, cols)`\n\n    # Output shape\n        - If\
    \ `data_format='channels_last'`:\n            4D tensor with shape:\n        \
    \    `(batch_size, pooled_rows, pooled_cols, channels)`\n        - If `data_format='channels_first'`:\n\
    \            4D tensor with shape:\n            `(batch_size, channels, pooled_rows,\
    \ pooled_cols)`\n    \"\"\"\n\n    @interfaces.legacy_pooling2d_support\n    def\
    \ __init__(self, pool_size=(2, 2), strides=None, padding='valid',\n          \
    \       data_format=None, **kwargs):\n        super(MaxPooling2D, self).__init__(pool_size,\
    \ strides, padding,\n                                           data_format, **kwargs)\n\
    \n    def _pooling_function(self, inputs, pool_size, strides,\n              \
    \            padding, data_format):\n        output = K.pool2d(inputs, pool_size,\
    \ strides,\n                          padding, data_format,\n                \
    \          pool_mode='max')\n        return output\n"
  sourcefile: D:\Python36\lib\site-packages\keras\layers\pooling.py
- doc: "Max pooling operation for 3D data (spatial or spatio-temporal).\n\n# Arguments\n\
    \    pool_size: tuple of 3 integers,\n        factors by which to downscale (dim1,\
    \ dim2, dim3).\n        (2, 2, 2) will halve the size of the 3D input in each\
    \ dimension.\n    strides: tuple of 3 integers, or None. Strides values.\n   \
    \ padding: One of `\"valid\"` or `\"same\"` (case-insensitive).\n    data_format:\
    \ A string,\n        one of `channels_last` (default) or `channels_first`.\n \
    \       The ordering of the dimensions in the inputs.\n        `channels_last`\
    \ corresponds to inputs with shape\n        `(batch, spatial_dim1, spatial_dim2,\
    \ spatial_dim3, channels)`\n        while `channels_first` corresponds to inputs\
    \ with shape\n        `(batch, channels, spatial_dim1, spatial_dim2, spatial_dim3)`.\n\
    \        It defaults to the `image_data_format` value found in your\n        Keras\
    \ config file at `~/.keras/keras.json`.\n        If you never set it, then it\
    \ will be \"channels_last\".\n\n# Input shape\n    - If `data_format='channels_last'`:\n\
    \        5D tensor with shape:\n        `(batch_size, spatial_dim1, spatial_dim2,\
    \ spatial_dim3, channels)`\n    - If `data_format='channels_first'`:\n       \
    \ 5D tensor with shape:\n        `(batch_size, channels, spatial_dim1, spatial_dim2,\
    \ spatial_dim3)`\n\n# Output shape\n    - If `data_format='channels_last'`:\n\
    \        5D tensor with shape:\n        `(batch_size, pooled_dim1, pooled_dim2,\
    \ pooled_dim3, channels)`\n    - If `data_format='channels_first'`:\n        5D\
    \ tensor with shape:\n        `(batch_size, channels, pooled_dim1, pooled_dim2,\
    \ pooled_dim3)`"
  kind: Layer
  name: MaxPooling3D
  parameters:
  - {defaultValue: '(2, 2, 2)', kind: any, name: pool_size}
  - {defaultValue: None, kind: any, name: strides}
  - {defaultValue: valid, kind: any, name: padding}
  - {defaultValue: None, kind: any, name: data_format}
  - {defaultValue: 'true', name: trainable, type: bool}
  source: "class MaxPooling3D(_Pooling3D):\n    \"\"\"Max pooling operation for 3D\
    \ data (spatial or spatio-temporal).\n\n    # Arguments\n        pool_size: tuple\
    \ of 3 integers,\n            factors by which to downscale (dim1, dim2, dim3).\n\
    \            (2, 2, 2) will halve the size of the 3D input in each dimension.\n\
    \        strides: tuple of 3 integers, or None. Strides values.\n        padding:\
    \ One of `\"valid\"` or `\"same\"` (case-insensitive).\n        data_format: A\
    \ string,\n            one of `channels_last` (default) or `channels_first`.\n\
    \            The ordering of the dimensions in the inputs.\n            `channels_last`\
    \ corresponds to inputs with shape\n            `(batch, spatial_dim1, spatial_dim2,\
    \ spatial_dim3, channels)`\n            while `channels_first` corresponds to\
    \ inputs with shape\n            `(batch, channels, spatial_dim1, spatial_dim2,\
    \ spatial_dim3)`.\n            It defaults to the `image_data_format` value found\
    \ in your\n            Keras config file at `~/.keras/keras.json`.\n         \
    \   If you never set it, then it will be \"channels_last\".\n\n    # Input shape\n\
    \        - If `data_format='channels_last'`:\n            5D tensor with shape:\n\
    \            `(batch_size, spatial_dim1, spatial_dim2, spatial_dim3, channels)`\n\
    \        - If `data_format='channels_first'`:\n            5D tensor with shape:\n\
    \            `(batch_size, channels, spatial_dim1, spatial_dim2, spatial_dim3)`\n\
    \n    # Output shape\n        - If `data_format='channels_last'`:\n          \
    \  5D tensor with shape:\n            `(batch_size, pooled_dim1, pooled_dim2,\
    \ pooled_dim3, channels)`\n        - If `data_format='channels_first'`:\n    \
    \        5D tensor with shape:\n            `(batch_size, channels, pooled_dim1,\
    \ pooled_dim2, pooled_dim3)`\n    \"\"\"\n\n    @interfaces.legacy_pooling3d_support\n\
    \    def __init__(self, pool_size=(2, 2, 2), strides=None, padding='valid',\n\
    \                 data_format=None, **kwargs):\n        super(MaxPooling3D, self).__init__(pool_size,\
    \ strides, padding,\n                                           data_format, **kwargs)\n\
    \n    def _pooling_function(self, inputs, pool_size, strides,\n              \
    \            padding, data_format):\n        output = K.pool3d(inputs, pool_size,\
    \ strides,\n                          padding, data_format, pool_mode='max')\n\
    \        return output\n"
  sourcefile: D:\Python36\lib\site-packages\keras\layers\pooling.py
- doc: "Max pooling operation for temporal data.\n\n# Arguments\n    pool_size: Integer,\
    \ size of the max pooling windows.\n    strides: Integer, or None. Factor by which\
    \ to downscale.\n        E.g. 2 will halve the input.\n        If None, it will\
    \ default to `pool_size`.\n    padding: One of `\"valid\"` or `\"same\"` (case-insensitive).\n\
    \    data_format: A string,\n        one of `channels_last` (default) or `channels_first`.\n\
    \        The ordering of the dimensions in the inputs.\n        `channels_last`\
    \ corresponds to inputs with shape\n        `(batch, steps, features)` while `channels_first`\n\
    \        corresponds to inputs with shape\n        `(batch, features, steps)`.\n\
    \n# Input shape\n    - If `data_format='channels_last'`:\n        3D tensor with\
    \ shape:\n        `(batch_size, steps, features)`\n    - If `data_format='channels_first'`:\n\
    \        3D tensor with shape:\n        `(batch_size, features, steps)`\n\n# Output\
    \ shape\n    - If `data_format='channels_last'`:\n        3D tensor with shape:\n\
    \        `(batch_size, downsampled_steps, features)`\n    - If `data_format='channels_first'`:\n\
    \        3D tensor with shape:\n        `(batch_size, features, downsampled_steps)`"
  kind: Layer
  name: MaxPooling1D
  parameters:
  - {defaultValue: '2', kind: any, name: pool_size}
  - {defaultValue: None, kind: any, name: strides}
  - {defaultValue: valid, kind: any, name: padding}
  - {defaultValue: channels_last, kind: any, name: data_format}
  - {defaultValue: 'true', name: trainable, type: bool}
  source: "class MaxPooling1D(_Pooling1D):\n    \"\"\"Max pooling operation for temporal\
    \ data.\n\n    # Arguments\n        pool_size: Integer, size of the max pooling\
    \ windows.\n        strides: Integer, or None. Factor by which to downscale.\n\
    \            E.g. 2 will halve the input.\n            If None, it will default\
    \ to `pool_size`.\n        padding: One of `\"valid\"` or `\"same\"` (case-insensitive).\n\
    \        data_format: A string,\n            one of `channels_last` (default)\
    \ or `channels_first`.\n            The ordering of the dimensions in the inputs.\n\
    \            `channels_last` corresponds to inputs with shape\n            `(batch,\
    \ steps, features)` while `channels_first`\n            corresponds to inputs\
    \ with shape\n            `(batch, features, steps)`.\n\n    # Input shape\n \
    \       - If `data_format='channels_last'`:\n            3D tensor with shape:\n\
    \            `(batch_size, steps, features)`\n        - If `data_format='channels_first'`:\n\
    \            3D tensor with shape:\n            `(batch_size, features, steps)`\n\
    \n    # Output shape\n        - If `data_format='channels_last'`:\n          \
    \  3D tensor with shape:\n            `(batch_size, downsampled_steps, features)`\n\
    \        - If `data_format='channels_first'`:\n            3D tensor with shape:\n\
    \            `(batch_size, features, downsampled_steps)`\n    \"\"\"\n\n    @interfaces.legacy_pooling1d_support\n\
    \    def __init__(self, pool_size=2, strides=None,\n                 padding='valid',\
    \ data_format='channels_last', **kwargs):\n        super(MaxPooling1D, self).__init__(pool_size,\
    \ strides,\n                                           padding, data_format,\n\
    \                                           **kwargs)\n\n    def _pooling_function(self,\
    \ inputs, pool_size, strides,\n                          padding, data_format):\n\
    \        output = K.pool2d(inputs, pool_size, strides,\n                     \
    \     padding, data_format, pool_mode='max')\n        return output\n"
  sourcefile: D:\Python36\lib\site-packages\keras\layers\pooling.py
- doc: "Max pooling operation for spatial data.\n\n# Arguments\n    pool_size: integer\
    \ or tuple of 2 integers,\n        factors by which to downscale (vertical, horizontal).\n\
    \        (2, 2) will halve the input in both spatial dimension.\n        If only\
    \ one integer is specified, the same window length\n        will be used for both\
    \ dimensions.\n    strides: Integer, tuple of 2 integers, or None.\n        Strides\
    \ values.\n        If None, it will default to `pool_size`.\n    padding: One\
    \ of `\"valid\"` or `\"same\"` (case-insensitive).\n    data_format: A string,\n\
    \        one of `channels_last` (default) or `channels_first`.\n        The ordering\
    \ of the dimensions in the inputs.\n        `channels_last` corresponds to inputs\
    \ with shape\n        `(batch, height, width, channels)` while `channels_first`\n\
    \        corresponds to inputs with shape\n        `(batch, channels, height,\
    \ width)`.\n        It defaults to the `image_data_format` value found in your\n\
    \        Keras config file at `~/.keras/keras.json`.\n        If you never set\
    \ it, then it will be \"channels_last\".\n\n# Input shape\n    - If `data_format='channels_last'`:\n\
    \        4D tensor with shape:\n        `(batch_size, rows, cols, channels)`\n\
    \    - If `data_format='channels_first'`:\n        4D tensor with shape:\n   \
    \     `(batch_size, channels, rows, cols)`\n\n# Output shape\n    - If `data_format='channels_last'`:\n\
    \        4D tensor with shape:\n        `(batch_size, pooled_rows, pooled_cols,\
    \ channels)`\n    - If `data_format='channels_first'`:\n        4D tensor with\
    \ shape:\n        `(batch_size, channels, pooled_rows, pooled_cols)`"
  kind: Layer
  name: MaxPooling2D
  parameters:
  - {defaultValue: '(2, 2)', kind: any, name: pool_size}
  - {defaultValue: None, kind: any, name: strides}
  - {defaultValue: valid, kind: any, name: padding}
  - {defaultValue: None, kind: any, name: data_format}
  - {defaultValue: 'true', name: trainable, type: bool}
  source: "class MaxPooling2D(_Pooling2D):\n    \"\"\"Max pooling operation for spatial\
    \ data.\n\n    # Arguments\n        pool_size: integer or tuple of 2 integers,\n\
    \            factors by which to downscale (vertical, horizontal).\n         \
    \   (2, 2) will halve the input in both spatial dimension.\n            If only\
    \ one integer is specified, the same window length\n            will be used for\
    \ both dimensions.\n        strides: Integer, tuple of 2 integers, or None.\n\
    \            Strides values.\n            If None, it will default to `pool_size`.\n\
    \        padding: One of `\"valid\"` or `\"same\"` (case-insensitive).\n     \
    \   data_format: A string,\n            one of `channels_last` (default) or `channels_first`.\n\
    \            The ordering of the dimensions in the inputs.\n            `channels_last`\
    \ corresponds to inputs with shape\n            `(batch, height, width, channels)`\
    \ while `channels_first`\n            corresponds to inputs with shape\n     \
    \       `(batch, channels, height, width)`.\n            It defaults to the `image_data_format`\
    \ value found in your\n            Keras config file at `~/.keras/keras.json`.\n\
    \            If you never set it, then it will be \"channels_last\".\n\n    #\
    \ Input shape\n        - If `data_format='channels_last'`:\n            4D tensor\
    \ with shape:\n            `(batch_size, rows, cols, channels)`\n        - If\
    \ `data_format='channels_first'`:\n            4D tensor with shape:\n       \
    \     `(batch_size, channels, rows, cols)`\n\n    # Output shape\n        - If\
    \ `data_format='channels_last'`:\n            4D tensor with shape:\n        \
    \    `(batch_size, pooled_rows, pooled_cols, channels)`\n        - If `data_format='channels_first'`:\n\
    \            4D tensor with shape:\n            `(batch_size, channels, pooled_rows,\
    \ pooled_cols)`\n    \"\"\"\n\n    @interfaces.legacy_pooling2d_support\n    def\
    \ __init__(self, pool_size=(2, 2), strides=None, padding='valid',\n          \
    \       data_format=None, **kwargs):\n        super(MaxPooling2D, self).__init__(pool_size,\
    \ strides, padding,\n                                           data_format, **kwargs)\n\
    \n    def _pooling_function(self, inputs, pool_size, strides,\n              \
    \            padding, data_format):\n        output = K.pool2d(inputs, pool_size,\
    \ strides,\n                          padding, data_format,\n                \
    \          pool_mode='max')\n        return output\n"
  sourcefile: D:\Python36\lib\site-packages\keras\layers\pooling.py
- doc: "Max pooling operation for 3D data (spatial or spatio-temporal).\n\n# Arguments\n\
    \    pool_size: tuple of 3 integers,\n        factors by which to downscale (dim1,\
    \ dim2, dim3).\n        (2, 2, 2) will halve the size of the 3D input in each\
    \ dimension.\n    strides: tuple of 3 integers, or None. Strides values.\n   \
    \ padding: One of `\"valid\"` or `\"same\"` (case-insensitive).\n    data_format:\
    \ A string,\n        one of `channels_last` (default) or `channels_first`.\n \
    \       The ordering of the dimensions in the inputs.\n        `channels_last`\
    \ corresponds to inputs with shape\n        `(batch, spatial_dim1, spatial_dim2,\
    \ spatial_dim3, channels)`\n        while `channels_first` corresponds to inputs\
    \ with shape\n        `(batch, channels, spatial_dim1, spatial_dim2, spatial_dim3)`.\n\
    \        It defaults to the `image_data_format` value found in your\n        Keras\
    \ config file at `~/.keras/keras.json`.\n        If you never set it, then it\
    \ will be \"channels_last\".\n\n# Input shape\n    - If `data_format='channels_last'`:\n\
    \        5D tensor with shape:\n        `(batch_size, spatial_dim1, spatial_dim2,\
    \ spatial_dim3, channels)`\n    - If `data_format='channels_first'`:\n       \
    \ 5D tensor with shape:\n        `(batch_size, channels, spatial_dim1, spatial_dim2,\
    \ spatial_dim3)`\n\n# Output shape\n    - If `data_format='channels_last'`:\n\
    \        5D tensor with shape:\n        `(batch_size, pooled_dim1, pooled_dim2,\
    \ pooled_dim3, channels)`\n    - If `data_format='channels_first'`:\n        5D\
    \ tensor with shape:\n        `(batch_size, channels, pooled_dim1, pooled_dim2,\
    \ pooled_dim3)`"
  kind: Layer
  name: MaxPooling3D
  parameters:
  - {defaultValue: '(2, 2, 2)', kind: any, name: pool_size}
  - {defaultValue: None, kind: any, name: strides}
  - {defaultValue: valid, kind: any, name: padding}
  - {defaultValue: None, kind: any, name: data_format}
  - {defaultValue: 'true', name: trainable, type: bool}
  source: "class MaxPooling3D(_Pooling3D):\n    \"\"\"Max pooling operation for 3D\
    \ data (spatial or spatio-temporal).\n\n    # Arguments\n        pool_size: tuple\
    \ of 3 integers,\n            factors by which to downscale (dim1, dim2, dim3).\n\
    \            (2, 2, 2) will halve the size of the 3D input in each dimension.\n\
    \        strides: tuple of 3 integers, or None. Strides values.\n        padding:\
    \ One of `\"valid\"` or `\"same\"` (case-insensitive).\n        data_format: A\
    \ string,\n            one of `channels_last` (default) or `channels_first`.\n\
    \            The ordering of the dimensions in the inputs.\n            `channels_last`\
    \ corresponds to inputs with shape\n            `(batch, spatial_dim1, spatial_dim2,\
    \ spatial_dim3, channels)`\n            while `channels_first` corresponds to\
    \ inputs with shape\n            `(batch, channels, spatial_dim1, spatial_dim2,\
    \ spatial_dim3)`.\n            It defaults to the `image_data_format` value found\
    \ in your\n            Keras config file at `~/.keras/keras.json`.\n         \
    \   If you never set it, then it will be \"channels_last\".\n\n    # Input shape\n\
    \        - If `data_format='channels_last'`:\n            5D tensor with shape:\n\
    \            `(batch_size, spatial_dim1, spatial_dim2, spatial_dim3, channels)`\n\
    \        - If `data_format='channels_first'`:\n            5D tensor with shape:\n\
    \            `(batch_size, channels, spatial_dim1, spatial_dim2, spatial_dim3)`\n\
    \n    # Output shape\n        - If `data_format='channels_last'`:\n          \
    \  5D tensor with shape:\n            `(batch_size, pooled_dim1, pooled_dim2,\
    \ pooled_dim3, channels)`\n        - If `data_format='channels_first'`:\n    \
    \        5D tensor with shape:\n            `(batch_size, channels, pooled_dim1,\
    \ pooled_dim2, pooled_dim3)`\n    \"\"\"\n\n    @interfaces.legacy_pooling3d_support\n\
    \    def __init__(self, pool_size=(2, 2, 2), strides=None, padding='valid',\n\
    \                 data_format=None, **kwargs):\n        super(MaxPooling3D, self).__init__(pool_size,\
    \ strides, padding,\n                                           data_format, **kwargs)\n\
    \n    def _pooling_function(self, inputs, pool_size, strides,\n              \
    \            padding, data_format):\n        output = K.pool3d(inputs, pool_size,\
    \ strides,\n                          padding, data_format, pool_mode='max')\n\
    \        return output\n"
  sourcefile: D:\Python36\lib\site-packages\keras\layers\pooling.py
- doc: 'Layer that computes the maximum (element-wise) a list of inputs.


    It takes as input a list of tensors,

    all of the same shape, and returns

    a single tensor (also of the same shape).'
  kind: Layer
  name: Maximum
  parameters:
  - {defaultValue: 'true', name: trainable, type: bool}
  source: "class Maximum(_Merge):\n    \"\"\"Layer that computes the maximum (element-wise)\
    \ a list of inputs.\n\n    It takes as input a list of tensors,\n    all of the\
    \ same shape, and returns\n    a single tensor (also of the same shape).\n   \
    \ \"\"\"\n\n    def _merge_function(self, inputs):\n        output = inputs[0]\n\
    \        for i in range(1, len(inputs)):\n            output = K.maximum(output,\
    \ inputs[i])\n        return output\n"
  sourcefile: D:\Python36\lib\site-packages\keras\layers\merge.py
- doc: "A dense maxout layer.\nA `MaxoutDense` layer takes the element-wise maximum\
    \ of\n`nb_feature` `Dense(input_dim, output_dim)` linear layers.\nThis allows\
    \ the layer to learn a convex,\npiecewise linear activation function over the\
    \ inputs.\nNote that this is a *linear* layer;\nif you wish to apply activation\
    \ function\n(you shouldn't need to --they are universal function approximators),\n\
    an `Activation` layer must be added after.\n# Arguments\n    output_dim: int >\
    \ 0.\n    nb_feature: number of Dense layers to use internally.\n    init: name\
    \ of initialization function for the weights of the layer\n        (see [initializations](../initializations.md)),\n\
    \        or alternatively, Theano function to use for weights\n        initialization.\
    \ This parameter is only relevant\n        if you don't pass a `weights` argument.\n\
    \    weights: list of Numpy arrays to set as initial weights.\n        The list\
    \ should have 2 elements, of shape `(input_dim, output_dim)`\n        and (output_dim,)\
    \ for weights and biases respectively.\n    W_regularizer: instance of [WeightRegularizer](../regularizers.md)\n\
    \        (eg. L1 or L2 regularization), applied to the main weights matrix.\n\
    \    b_regularizer: instance of [WeightRegularizer](../regularizers.md),\n   \
    \     applied to the bias.\n    activity_regularizer: instance of [ActivityRegularizer](../regularizers.md),\n\
    \        applied to the network output.\n    W_constraint: instance of the [constraints](../constraints.md)\
    \ module\n        (eg. maxnorm, nonneg), applied to the main weights matrix.\n\
    \    b_constraint: instance of the [constraints](../constraints.md) module,\n\
    \        applied to the bias.\n    bias: whether to include a bias\n        (i.e.\
    \ make the layer affine rather than linear).\n    input_dim: dimensionality of\
    \ the input (integer). This argument\n        (or alternatively, the keyword argument\
    \ `input_shape`)\n        is required when using this layer as the first layer\
    \ in a model.\n# Input shape\n    2D tensor with shape: `(nb_samples, input_dim)`.\n\
    # Output shape\n    2D tensor with shape: `(nb_samples, output_dim)`.\n# References\n\
    \    - [Maxout Networks](http://arxiv.org/abs/1302.4389)"
  kind: Layer
  name: MaxoutDense
  parameters:
  - {kind: any, name: output_dim}
  - {defaultValue: '4', kind: any, name: nb_feature}
  - {defaultValue: glorot_uniform, kind: any, name: init}
  - {defaultValue: None, kind: any, name: weights}
  - {defaultValue: None, kind: any, name: W_regularizer}
  - {defaultValue: None, kind: any, name: b_regularizer}
  - {defaultValue: None, kind: any, name: activity_regularizer}
  - {defaultValue: None, kind: any, name: W_constraint}
  - {defaultValue: None, kind: any, name: b_constraint}
  - {defaultValue: 'True', kind: any, name: bias}
  - {defaultValue: None, kind: any, name: input_dim}
  - {defaultValue: 'true', name: trainable, type: bool}
  source: "class MaxoutDense(Layer):\n    \"\"\"A dense maxout layer.\n    A `MaxoutDense`\
    \ layer takes the element-wise maximum of\n    `nb_feature` `Dense(input_dim,\
    \ output_dim)` linear layers.\n    This allows the layer to learn a convex,\n\
    \    piecewise linear activation function over the inputs.\n    Note that this\
    \ is a *linear* layer;\n    if you wish to apply activation function\n    (you\
    \ shouldn't need to --they are universal function approximators),\n    an `Activation`\
    \ layer must be added after.\n    # Arguments\n        output_dim: int > 0.\n\
    \        nb_feature: number of Dense layers to use internally.\n        init:\
    \ name of initialization function for the weights of the layer\n            (see\
    \ [initializations](../initializations.md)),\n            or alternatively, Theano\
    \ function to use for weights\n            initialization. This parameter is only\
    \ relevant\n            if you don't pass a `weights` argument.\n        weights:\
    \ list of Numpy arrays to set as initial weights.\n            The list should\
    \ have 2 elements, of shape `(input_dim, output_dim)`\n            and (output_dim,)\
    \ for weights and biases respectively.\n        W_regularizer: instance of [WeightRegularizer](../regularizers.md)\n\
    \            (eg. L1 or L2 regularization), applied to the main weights matrix.\n\
    \        b_regularizer: instance of [WeightRegularizer](../regularizers.md),\n\
    \            applied to the bias.\n        activity_regularizer: instance of [ActivityRegularizer](../regularizers.md),\n\
    \            applied to the network output.\n        W_constraint: instance of\
    \ the [constraints](../constraints.md) module\n            (eg. maxnorm, nonneg),\
    \ applied to the main weights matrix.\n        b_constraint: instance of the [constraints](../constraints.md)\
    \ module,\n            applied to the bias.\n        bias: whether to include\
    \ a bias\n            (i.e. make the layer affine rather than linear).\n     \
    \   input_dim: dimensionality of the input (integer). This argument\n        \
    \    (or alternatively, the keyword argument `input_shape`)\n            is required\
    \ when using this layer as the first layer in a model.\n    # Input shape\n  \
    \      2D tensor with shape: `(nb_samples, input_dim)`.\n    # Output shape\n\
    \        2D tensor with shape: `(nb_samples, output_dim)`.\n    # References\n\
    \        - [Maxout Networks](http://arxiv.org/abs/1302.4389)\n    \"\"\"\n\n \
    \   def __init__(self, output_dim,\n                 nb_feature=4,\n         \
    \        init='glorot_uniform',\n                 weights=None,\n            \
    \     W_regularizer=None,\n                 b_regularizer=None,\n            \
    \     activity_regularizer=None,\n                 W_constraint=None,\n      \
    \           b_constraint=None,\n                 bias=True,\n                \
    \ input_dim=None,\n                 **kwargs):\n        warnings.warn('The `MaxoutDense`\
    \ layer is deprecated '\n                      'and will be removed after 06/2017.')\n\
    \        self.output_dim = output_dim\n        self.nb_feature = nb_feature\n\
    \        self.init = initializers.get(init)\n\n        self.W_regularizer = regularizers.get(W_regularizer)\n\
    \        self.b_regularizer = regularizers.get(b_regularizer)\n        self.activity_regularizer\
    \ = regularizers.get(activity_regularizer)\n\n        self.W_constraint = constraints.get(W_constraint)\n\
    \        self.b_constraint = constraints.get(b_constraint)\n\n        self.bias\
    \ = bias\n        self.initial_weights = weights\n        self.input_spec = InputSpec(ndim=2)\n\
    \n        self.input_dim = input_dim\n        if self.input_dim:\n           \
    \ kwargs['input_shape'] = (self.input_dim,)\n        super(MaxoutDense, self).__init__(**kwargs)\n\
    \n    def build(self, input_shape):\n        input_dim = input_shape[1]\n    \
    \    self.input_spec = InputSpec(dtype=K.floatx(),\n                         \
    \           shape=(None, input_dim))\n\n        self.W = self.add_weight((self.nb_feature,\
    \ input_dim, self.output_dim),\n                                 initializer=self.init,\n\
    \                                 name='W',\n                                \
    \ regularizer=self.W_regularizer,\n                                 constraint=self.W_constraint)\n\
    \        if self.bias:\n            self.b = self.add_weight((self.nb_feature,\
    \ self.output_dim,),\n                                     initializer='zero',\n\
    \                                     name='b',\n                            \
    \         regularizer=self.b_regularizer,\n                                  \
    \   constraint=self.b_constraint)\n        else:\n            self.b = None\n\n\
    \        if self.initial_weights is not None:\n            self.set_weights(self.initial_weights)\n\
    \            del self.initial_weights\n        self.built = True\n\n    def compute_output_shape(self,\
    \ input_shape):\n        assert input_shape and len(input_shape) == 2\n      \
    \  return (input_shape[0], self.output_dim)\n\n    def call(self, x):\n      \
    \  # no activation, this layer is only linear.\n        output = K.dot(x, self.W)\n\
    \        if self.bias:\n            output += self.b\n        output = K.max(output,\
    \ axis=1)\n        return output\n\n    def get_config(self):\n        config\
    \ = {'output_dim': self.output_dim,\n                  'init': initializers.serialize(self.init),\n\
    \                  'nb_feature': self.nb_feature,\n                  'W_regularizer':\
    \ regularizers.serialize(self.W_regularizer),\n                  'b_regularizer':\
    \ regularizers.serialize(self.b_regularizer),\n                  'activity_regularizer':\n\
    \                      regularizers.serialize(self.activity_regularizer),\n  \
    \                'W_constraint': constraints.serialize(self.W_constraint),\n \
    \                 'b_constraint': constraints.serialize(self.b_constraint),\n\
    \                  'bias': self.bias,\n                  'input_dim': self.input_dim}\n\
    \        base_config = super(MaxoutDense, self).get_config()\n        return dict(list(base_config.items())\
    \ + list(config.items()))\n"
  sourcefile: D:\Python36\lib\site-packages\keras\legacy\layers.py
- doc: 'Layer that computes the minimum (element-wise) a list of inputs.


    It takes as input a list of tensors,

    all of the same shape, and returns

    a single tensor (also of the same shape).'
  kind: Layer
  name: Minimum
  parameters:
  - {defaultValue: 'true', name: trainable, type: bool}
  source: "class Minimum(_Merge):\n    \"\"\"Layer that computes the minimum (element-wise)\
    \ a list of inputs.\n\n    It takes as input a list of tensors,\n    all of the\
    \ same shape, and returns\n    a single tensor (also of the same shape).\n   \
    \ \"\"\"\n\n    def _merge_function(self, inputs):\n        output = inputs[0]\n\
    \        for i in range(1, len(inputs)):\n            output = K.minimum(output,\
    \ inputs[i])\n        return output\n"
  sourcefile: D:\Python36\lib\site-packages\keras\layers\merge.py
- doc: 'Layer that multiplies (element-wise) a list of inputs.


    It takes as input a list of tensors,

    all of the same shape, and returns

    a single tensor (also of the same shape).'
  kind: Layer
  name: Multiply
  parameters:
  - {defaultValue: 'true', name: trainable, type: bool}
  source: "class Multiply(_Merge):\n    \"\"\"Layer that multiplies (element-wise)\
    \ a list of inputs.\n\n    It takes as input a list of tensors,\n    all of the\
    \ same shape, and returns\n    a single tensor (also of the same shape).\n   \
    \ \"\"\"\n\n    def _merge_function(self, inputs):\n        output = inputs[0]\n\
    \        for i in range(1, len(inputs)):\n            output *= inputs[i]\n  \
    \      return output\n"
  sourcefile: D:\Python36\lib\site-packages\keras\layers\merge.py
- doc: "Parametric Rectified Linear Unit.\n\nIt follows:\n`f(x) = alpha * x for x\
    \ < 0`,\n`f(x) = x for x >= 0`,\nwhere `alpha` is a learned array with the same\
    \ shape as x.\n\n# Input shape\n    Arbitrary. Use the keyword argument `input_shape`\n\
    \    (tuple of integers, does not include the samples axis)\n    when using this\
    \ layer as the first layer in a model.\n\n# Output shape\n    Same shape as the\
    \ input.\n\n# Arguments\n    alpha_initializer: initializer function for the weights.\n\
    \    alpha_regularizer: regularizer for the weights.\n    alpha_constraint: constraint\
    \ for the weights.\n    shared_axes: the axes along which to share learnable\n\
    \        parameters for the activation function.\n        For example, if the\
    \ incoming feature maps\n        are from a 2D convolution\n        with output\
    \ shape `(batch, height, width, channels)`,\n        and you wish to share parameters\
    \ across space\n        so that each filter only has one set of parameters,\n\
    \        set `shared_axes=[1, 2]`.\n\n# References\n    - [Delving Deep into Rectifiers:\
    \ Surpassing Human-Level Performance on\n       ImageNet Classification](https://arxiv.org/abs/1502.01852)"
  kind: Layer
  name: PReLU
  parameters:
  - {defaultValue: zeros, kind: any, name: alpha_initializer}
  - {defaultValue: None, kind: any, name: alpha_regularizer}
  - {defaultValue: None, kind: any, name: alpha_constraint}
  - {defaultValue: None, kind: any, name: shared_axes}
  - {defaultValue: 'true', name: trainable, type: bool}
  source: "class PReLU(Layer):\n    \"\"\"Parametric Rectified Linear Unit.\n\n  \
    \  It follows:\n    `f(x) = alpha * x for x < 0`,\n    `f(x) = x for x >= 0`,\n\
    \    where `alpha` is a learned array with the same shape as x.\n\n    # Input\
    \ shape\n        Arbitrary. Use the keyword argument `input_shape`\n        (tuple\
    \ of integers, does not include the samples axis)\n        when using this layer\
    \ as the first layer in a model.\n\n    # Output shape\n        Same shape as\
    \ the input.\n\n    # Arguments\n        alpha_initializer: initializer function\
    \ for the weights.\n        alpha_regularizer: regularizer for the weights.\n\
    \        alpha_constraint: constraint for the weights.\n        shared_axes: the\
    \ axes along which to share learnable\n            parameters for the activation\
    \ function.\n            For example, if the incoming feature maps\n         \
    \   are from a 2D convolution\n            with output shape `(batch, height,\
    \ width, channels)`,\n            and you wish to share parameters across space\n\
    \            so that each filter only has one set of parameters,\n           \
    \ set `shared_axes=[1, 2]`.\n\n    # References\n        - [Delving Deep into\
    \ Rectifiers: Surpassing Human-Level Performance on\n           ImageNet Classification](https://arxiv.org/abs/1502.01852)\n\
    \    \"\"\"\n\n    @interfaces.legacy_prelu_support\n    def __init__(self, alpha_initializer='zeros',\n\
    \                 alpha_regularizer=None,\n                 alpha_constraint=None,\n\
    \                 shared_axes=None,\n                 **kwargs):\n        super(PReLU,\
    \ self).__init__(**kwargs)\n        self.supports_masking = True\n        self.alpha_initializer\
    \ = initializers.get(alpha_initializer)\n        self.alpha_regularizer = regularizers.get(alpha_regularizer)\n\
    \        self.alpha_constraint = constraints.get(alpha_constraint)\n        if\
    \ shared_axes is None:\n            self.shared_axes = None\n        else:\n \
    \           self.shared_axes = to_list(shared_axes, allow_tuple=True)\n\n    def\
    \ build(self, input_shape):\n        param_shape = list(input_shape[1:])\n   \
    \     self.param_broadcast = [False] * len(param_shape)\n        if self.shared_axes\
    \ is not None:\n            for i in self.shared_axes:\n                param_shape[i\
    \ - 1] = 1\n                self.param_broadcast[i - 1] = True\n        self.alpha\
    \ = self.add_weight(shape=param_shape,\n                                     name='alpha',\n\
    \                                     initializer=self.alpha_initializer,\n  \
    \                                   regularizer=self.alpha_regularizer,\n    \
    \                                 constraint=self.alpha_constraint)\n        #\
    \ Set input spec\n        axes = {}\n        if self.shared_axes:\n          \
    \  for i in range(1, len(input_shape)):\n                if i not in self.shared_axes:\n\
    \                    axes[i] = input_shape[i]\n        self.input_spec = InputSpec(ndim=len(input_shape),\
    \ axes=axes)\n        self.built = True\n\n    def call(self, inputs, mask=None):\n\
    \        pos = K.relu(inputs)\n        if K.backend() == 'theano':\n         \
    \   neg = (K.pattern_broadcast(self.alpha, self.param_broadcast) *\n         \
    \          (inputs - K.abs(inputs)) * 0.5)\n        else:\n            neg = -self.alpha\
    \ * K.relu(-inputs)\n        return pos + neg\n\n    def get_config(self):\n \
    \       config = {\n            'alpha_initializer': initializers.serialize(self.alpha_initializer),\n\
    \            'alpha_regularizer': regularizers.serialize(self.alpha_regularizer),\n\
    \            'alpha_constraint': constraints.serialize(self.alpha_constraint),\n\
    \            'shared_axes': self.shared_axes\n        }\n        base_config =\
    \ super(PReLU, self).get_config()\n        return dict(list(base_config.items())\
    \ + list(config.items()))\n\n    def compute_output_shape(self, input_shape):\n\
    \        return input_shape\n"
  sourcefile: D:\Python36\lib\site-packages\keras\layers\advanced_activations.py
- doc: "Permutes the dimensions of the input according to a given pattern.\n\nUseful\
    \ for e.g. connecting RNNs and convnets together.\n\n# Example\n\n```python\n\
    \    model = Sequential()\n    model.add(Permute((2, 1), input_shape=(10, 64)))\n\
    \    # now: model.output_shape == (None, 64, 10)\n    # note: `None` is the batch\
    \ dimension\n```\n\n# Arguments\n    dims: Tuple of integers. Permutation pattern,\
    \ does not include the\n        samples dimension. Indexing starts at 1.\n   \
    \     For instance, `(2, 1)` permutes the first and second dimension\n       \
    \ of the input.\n\n# Input shape\n    Arbitrary. Use the keyword argument `input_shape`\n\
    \    (tuple of integers, does not include the samples axis)\n    when using this\
    \ layer as the first layer in a model.\n\n# Output shape\n    Same as the input\
    \ shape, but with the dimensions re-ordered according\n    to the specified pattern."
  kind: Layer
  name: Permute
  parameters:
  - {kind: any, name: dims}
  - {defaultValue: 'true', name: trainable, type: bool}
  source: "class Permute(Layer):\n    \"\"\"Permutes the dimensions of the input according\
    \ to a given pattern.\n\n    Useful for e.g. connecting RNNs and convnets together.\n\
    \n    # Example\n\n    ```python\n        model = Sequential()\n        model.add(Permute((2,\
    \ 1), input_shape=(10, 64)))\n        # now: model.output_shape == (None, 64,\
    \ 10)\n        # note: `None` is the batch dimension\n    ```\n\n    # Arguments\n\
    \        dims: Tuple of integers. Permutation pattern, does not include the\n\
    \            samples dimension. Indexing starts at 1.\n            For instance,\
    \ `(2, 1)` permutes the first and second dimension\n            of the input.\n\
    \n    # Input shape\n        Arbitrary. Use the keyword argument `input_shape`\n\
    \        (tuple of integers, does not include the samples axis)\n        when\
    \ using this layer as the first layer in a model.\n\n    # Output shape\n    \
    \    Same as the input shape, but with the dimensions re-ordered according\n \
    \       to the specified pattern.\n    \"\"\"\n\n    def __init__(self, dims,\
    \ **kwargs):\n        super(Permute, self).__init__(**kwargs)\n        self.dims\
    \ = tuple(dims)\n        self.input_spec = InputSpec(ndim=len(self.dims) + 1)\n\
    \n    def compute_output_shape(self, input_shape):\n        input_shape = list(input_shape)\n\
    \        output_shape = copy.copy(input_shape)\n        for i, dim in enumerate(self.dims):\n\
    \            target_dim = input_shape[dim]\n            output_shape[i + 1] =\
    \ target_dim\n        return tuple(output_shape)\n\n    def call(self, inputs):\n\
    \        return K.permute_dimensions(inputs, (0,) + self.dims)\n\n    def get_config(self):\n\
    \        config = {'dims': self.dims}\n        base_config = super(Permute, self).get_config()\n\
    \        return dict(list(base_config.items()) + list(config.items()))\n"
  sourcefile: D:\Python36\lib\site-packages\keras\layers\core.py
- doc: "Base class for recurrent layers.\n\n# Arguments\n    cell: A RNN cell instance.\
    \ A RNN cell is a class that has:\n        - a `call(input_at_t, states_at_t)`\
    \ method, returning\n            `(output_at_t, states_at_t_plus_1)`. The call\
    \ method of the\n            cell can also take the optional argument `constants`,\
    \ see\n            section \"Note on passing external constants\" below.\n   \
    \     - a `state_size` attribute. This can be a single integer\n            (single\
    \ state) in which case it is\n            the size of the recurrent state\n  \
    \          (which should be the same as the size of the cell output).\n      \
    \      This can also be a list/tuple of integers\n            (one size per state).\n\
    \        - a `output_size` attribute. This can be a single integer or a\n    \
    \        TensorShape, which represent the shape of the output. For\n         \
    \   backward compatible reason, if this attribute is not available\n         \
    \   for the cell, the value will be inferred by the first element\n          \
    \  of the `state_size`.\n        It is also possible for `cell` to be a list of\
    \ RNN cell instances,\n        in which cases the cells get stacked on after the\
    \ other in the RNN,\n        implementing an efficient stacked RNN.\n    return_sequences:\
    \ Boolean. Whether to return the last output\n        in the output sequence,\
    \ or the full sequence.\n    return_state: Boolean. Whether to return the last\
    \ state\n        in addition to the output.\n    go_backwards: Boolean (default\
    \ False).\n        If True, process the input sequence backwards and return the\n\
    \        reversed sequence.\n    stateful: Boolean (default False). If True, the\
    \ last state\n        for each sample at index i in a batch will be used as initial\n\
    \        state for the sample of index i in the following batch.\n    unroll:\
    \ Boolean (default False).\n        If True, the network will be unrolled,\n \
    \       else a symbolic loop will be used.\n        Unrolling can speed-up a RNN,\n\
    \        although it tends to be more memory-intensive.\n        Unrolling is\
    \ only suitable for short sequences.\n    input_dim: dimensionality of the input\
    \ (integer).\n        This argument (or alternatively,\n        the keyword argument\
    \ `input_shape`)\n        is required when using this layer as the first layer\
    \ in a model.\n    input_length: Length of input sequences, to be specified\n\
    \        when it is constant.\n        This argument is required if you are going\
    \ to connect\n        `Flatten` then `Dense` layers upstream\n        (without\
    \ it, the shape of the dense outputs cannot be computed).\n        Note that if\
    \ the recurrent layer is not the first layer\n        in your model, you would\
    \ need to specify the input length\n        at the level of the first layer\n\
    \        (e.g. via the `input_shape` argument)\n\n# Input shape\n    3D tensor\
    \ with shape `(batch_size, timesteps, input_dim)`.\n\n# Output shape\n    - if\
    \ `return_state`: a list of tensors. The first tensor is\n        the output.\
    \ The remaining tensors are the last states,\n        each with shape `(batch_size,\
    \ units)`.\n    - if `return_sequences`: 3D tensor with shape\n        `(batch_size,\
    \ timesteps, units)`.\n    - else, 2D tensor with shape `(batch_size, units)`.\n\
    \n# Masking\n    This layer supports masking for input data with a variable number\n\
    \    of timesteps. To introduce masks to your data,\n    use an [Embedding](embeddings.md)\
    \ layer with the `mask_zero` parameter\n    set to `True`.\n\n# Note on using\
    \ statefulness in RNNs\n    You can set RNN layers to be 'stateful', which means\
    \ that the states\n    computed for the samples in one batch will be reused as\
    \ initial states\n    for the samples in the next batch. This assumes a one-to-one\
    \ mapping\n    between samples in different successive batches.\n\n    To enable\
    \ statefulness:\n        - specify `stateful=True` in the layer constructor.\n\
    \        - specify a fixed batch size for your model, by passing\n           \
    \ if sequential model:\n              `batch_input_shape=(...)` to the first layer\
    \ in your model.\n            else for functional model with 1 or more Input layers:\n\
    \              `batch_shape=(...)` to all the first layers in your model.\n  \
    \          This is the expected shape of your inputs\n            *including the\
    \ batch size*.\n            It should be a tuple of integers, e.g. `(32, 10, 100)`.\n\
    \        - specify `shuffle=False` when calling fit().\n\n    To reset the states\
    \ of your model, call `.reset_states()` on either\n    a specific layer, or on\
    \ your entire model.\n\n# Note on specifying the initial state of RNNs\n    You\
    \ can specify the initial state of RNN layers symbolically by\n    calling them\
    \ with the keyword argument `initial_state`. The value of\n    `initial_state`\
    \ should be a tensor or list of tensors representing\n    the initial state of\
    \ the RNN layer.\n\n    You can specify the initial state of RNN layers numerically\
    \ by\n    calling `reset_states` with the keyword argument `states`. The value\
    \ of\n    `states` should be a numpy array or list of numpy arrays representing\n\
    \    the initial state of the RNN layer.\n\n# Note on passing external constants\
    \ to RNNs\n    You can pass \"external\" constants to the cell using the `constants`\n\
    \    keyword argument of `RNN.__call__` (as well as `RNN.call`) method. This\n\
    \    requires that the `cell.call` method accepts the same keyword argument\n\
    \    `constants`. Such constants can be used to condition the cell\n    transformation\
    \ on additional static inputs (not changing over time),\n    a.k.a. an attention\
    \ mechanism.\n\n# Examples\n\n```python\n    # First, let's define a RNN Cell,\
    \ as a layer subclass.\n\n    class MinimalRNNCell(keras.layers.Layer):\n\n  \
    \      def __init__(self, units, **kwargs):\n            self.units = units\n\
    \            self.state_size = units\n            super(MinimalRNNCell, self).__init__(**kwargs)\n\
    \n        def build(self, input_shape):\n            self.kernel = self.add_weight(shape=(input_shape[-1],\
    \ self.units),\n                                          initializer='uniform',\n\
    \                                          name='kernel')\n            self.recurrent_kernel\
    \ = self.add_weight(\n                shape=(self.units, self.units),\n      \
    \          initializer='uniform',\n                name='recurrent_kernel')\n\
    \            self.built = True\n\n        def call(self, inputs, states):\n  \
    \          prev_output = states[0]\n            h = K.dot(inputs, self.kernel)\n\
    \            output = h + K.dot(prev_output, self.recurrent_kernel)\n        \
    \    return output, [output]\n\n    # Let's use this cell in a RNN layer:\n\n\
    \    cell = MinimalRNNCell(32)\n    x = keras.Input((None, 5))\n    layer = RNN(cell)\n\
    \    y = layer(x)\n\n    # Here's how to use the cell to build a stacked RNN:\n\
    \n    cells = [MinimalRNNCell(32), MinimalRNNCell(64)]\n    x = keras.Input((None,\
    \ 5))\n    layer = RNN(cells)\n    y = layer(x)\n```"
  kind: Layer
  name: RNN
  parameters:
  - {kind: any, name: cell}
  - {defaultValue: 'False', kind: any, name: return_sequences}
  - {defaultValue: 'False', kind: any, name: return_state}
  - {defaultValue: 'False', kind: any, name: go_backwards}
  - {defaultValue: 'False', kind: any, name: stateful}
  - {defaultValue: 'False', kind: any, name: unroll}
  - {defaultValue: 'true', name: trainable, type: bool}
  source: "class RNN(Layer):\n    \"\"\"Base class for recurrent layers.\n\n    #\
    \ Arguments\n        cell: A RNN cell instance. A RNN cell is a class that has:\n\
    \            - a `call(input_at_t, states_at_t)` method, returning\n         \
    \       `(output_at_t, states_at_t_plus_1)`. The call method of the\n        \
    \        cell can also take the optional argument `constants`, see\n         \
    \       section \"Note on passing external constants\" below.\n            - a\
    \ `state_size` attribute. This can be a single integer\n                (single\
    \ state) in which case it is\n                the size of the recurrent state\n\
    \                (which should be the same as the size of the cell output).\n\
    \                This can also be a list/tuple of integers\n                (one\
    \ size per state).\n            - a `output_size` attribute. This can be a single\
    \ integer or a\n                TensorShape, which represent the shape of the\
    \ output. For\n                backward compatible reason, if this attribute is\
    \ not available\n                for the cell, the value will be inferred by the\
    \ first element\n                of the `state_size`.\n            It is also\
    \ possible for `cell` to be a list of RNN cell instances,\n            in which\
    \ cases the cells get stacked on after the other in the RNN,\n            implementing\
    \ an efficient stacked RNN.\n        return_sequences: Boolean. Whether to return\
    \ the last output\n            in the output sequence, or the full sequence.\n\
    \        return_state: Boolean. Whether to return the last state\n           \
    \ in addition to the output.\n        go_backwards: Boolean (default False).\n\
    \            If True, process the input sequence backwards and return the\n  \
    \          reversed sequence.\n        stateful: Boolean (default False). If True,\
    \ the last state\n            for each sample at index i in a batch will be used\
    \ as initial\n            state for the sample of index i in the following batch.\n\
    \        unroll: Boolean (default False).\n            If True, the network will\
    \ be unrolled,\n            else a symbolic loop will be used.\n            Unrolling\
    \ can speed-up a RNN,\n            although it tends to be more memory-intensive.\n\
    \            Unrolling is only suitable for short sequences.\n        input_dim:\
    \ dimensionality of the input (integer).\n            This argument (or alternatively,\n\
    \            the keyword argument `input_shape`)\n            is required when\
    \ using this layer as the first layer in a model.\n        input_length: Length\
    \ of input sequences, to be specified\n            when it is constant.\n    \
    \        This argument is required if you are going to connect\n            `Flatten`\
    \ then `Dense` layers upstream\n            (without it, the shape of the dense\
    \ outputs cannot be computed).\n            Note that if the recurrent layer is\
    \ not the first layer\n            in your model, you would need to specify the\
    \ input length\n            at the level of the first layer\n            (e.g.\
    \ via the `input_shape` argument)\n\n    # Input shape\n        3D tensor with\
    \ shape `(batch_size, timesteps, input_dim)`.\n\n    # Output shape\n        -\
    \ if `return_state`: a list of tensors. The first tensor is\n            the output.\
    \ The remaining tensors are the last states,\n            each with shape `(batch_size,\
    \ units)`.\n        - if `return_sequences`: 3D tensor with shape\n          \
    \  `(batch_size, timesteps, units)`.\n        - else, 2D tensor with shape `(batch_size,\
    \ units)`.\n\n    # Masking\n        This layer supports masking for input data\
    \ with a variable number\n        of timesteps. To introduce masks to your data,\n\
    \        use an [Embedding](embeddings.md) layer with the `mask_zero` parameter\n\
    \        set to `True`.\n\n    # Note on using statefulness in RNNs\n        You\
    \ can set RNN layers to be 'stateful', which means that the states\n        computed\
    \ for the samples in one batch will be reused as initial states\n        for the\
    \ samples in the next batch. This assumes a one-to-one mapping\n        between\
    \ samples in different successive batches.\n\n        To enable statefulness:\n\
    \            - specify `stateful=True` in the layer constructor.\n           \
    \ - specify a fixed batch size for your model, by passing\n                if\
    \ sequential model:\n                  `batch_input_shape=(...)` to the first\
    \ layer in your model.\n                else for functional model with 1 or more\
    \ Input layers:\n                  `batch_shape=(...)` to all the first layers\
    \ in your model.\n                This is the expected shape of your inputs\n\
    \                *including the batch size*.\n                It should be a tuple\
    \ of integers, e.g. `(32, 10, 100)`.\n            - specify `shuffle=False` when\
    \ calling fit().\n\n        To reset the states of your model, call `.reset_states()`\
    \ on either\n        a specific layer, or on your entire model.\n\n    # Note\
    \ on specifying the initial state of RNNs\n        You can specify the initial\
    \ state of RNN layers symbolically by\n        calling them with the keyword argument\
    \ `initial_state`. The value of\n        `initial_state` should be a tensor or\
    \ list of tensors representing\n        the initial state of the RNN layer.\n\n\
    \        You can specify the initial state of RNN layers numerically by\n    \
    \    calling `reset_states` with the keyword argument `states`. The value of\n\
    \        `states` should be a numpy array or list of numpy arrays representing\n\
    \        the initial state of the RNN layer.\n\n    # Note on passing external\
    \ constants to RNNs\n        You can pass \"external\" constants to the cell using\
    \ the `constants`\n        keyword argument of `RNN.__call__` (as well as `RNN.call`)\
    \ method. This\n        requires that the `cell.call` method accepts the same\
    \ keyword argument\n        `constants`. Such constants can be used to condition\
    \ the cell\n        transformation on additional static inputs (not changing over\
    \ time),\n        a.k.a. an attention mechanism.\n\n    # Examples\n\n    ```python\n\
    \        # First, let's define a RNN Cell, as a layer subclass.\n\n        class\
    \ MinimalRNNCell(keras.layers.Layer):\n\n            def __init__(self, units,\
    \ **kwargs):\n                self.units = units\n                self.state_size\
    \ = units\n                super(MinimalRNNCell, self).__init__(**kwargs)\n\n\
    \            def build(self, input_shape):\n                self.kernel = self.add_weight(shape=(input_shape[-1],\
    \ self.units),\n                                              initializer='uniform',\n\
    \                                              name='kernel')\n              \
    \  self.recurrent_kernel = self.add_weight(\n                    shape=(self.units,\
    \ self.units),\n                    initializer='uniform',\n                 \
    \   name='recurrent_kernel')\n                self.built = True\n\n          \
    \  def call(self, inputs, states):\n                prev_output = states[0]\n\
    \                h = K.dot(inputs, self.kernel)\n                output = h +\
    \ K.dot(prev_output, self.recurrent_kernel)\n                return output, [output]\n\
    \n        # Let's use this cell in a RNN layer:\n\n        cell = MinimalRNNCell(32)\n\
    \        x = keras.Input((None, 5))\n        layer = RNN(cell)\n        y = layer(x)\n\
    \n        # Here's how to use the cell to build a stacked RNN:\n\n        cells\
    \ = [MinimalRNNCell(32), MinimalRNNCell(64)]\n        x = keras.Input((None, 5))\n\
    \        layer = RNN(cells)\n        y = layer(x)\n    ```\n    \"\"\"\n\n   \
    \ def __init__(self, cell,\n                 return_sequences=False,\n       \
    \          return_state=False,\n                 go_backwards=False,\n       \
    \          stateful=False,\n                 unroll=False,\n                 **kwargs):\n\
    \        if isinstance(cell, (list, tuple)):\n            cell = StackedRNNCells(cell)\n\
    \        if not hasattr(cell, 'call'):\n            raise ValueError('`cell` should\
    \ have a `call` method. '\n                             'The RNN was passed:',\
    \ cell)\n        if not hasattr(cell, 'state_size'):\n            raise ValueError('The\
    \ RNN cell should have '\n                             'an attribute `state_size`\
    \ '\n                             '(tuple of integers, '\n                   \
    \          'one integer per RNN state).')\n        super(RNN, self).__init__(**kwargs)\n\
    \        self.cell = cell\n        self.return_sequences = return_sequences\n\
    \        self.return_state = return_state\n        self.go_backwards = go_backwards\n\
    \        self.stateful = stateful\n        self.unroll = unroll\n\n        self.supports_masking\
    \ = True\n        self.input_spec = [InputSpec(ndim=3)]\n        self.state_spec\
    \ = None\n        self._states = None\n        self.constants_spec = None\n  \
    \      self._num_constants = None\n\n    @property\n    def states(self):\n  \
    \      if self._states is None:\n            if isinstance(self.cell.state_size,\
    \ int):\n                num_states = 1\n            else:\n                num_states\
    \ = len(self.cell.state_size)\n            return [None for _ in range(num_states)]\n\
    \        return self._states\n\n    @states.setter\n    def states(self, states):\n\
    \        self._states = states\n\n    def compute_output_shape(self, input_shape):\n\
    \        if isinstance(input_shape, list):\n            input_shape = input_shape[0]\n\
    \n        if hasattr(self.cell.state_size, '__len__'):\n            state_size\
    \ = self.cell.state_size\n        else:\n            state_size = [self.cell.state_size]\n\
    \n        if getattr(self.cell, 'output_size', None) is not None:\n          \
    \  output_dim = self.cell.output_size\n        else:\n            output_dim =\
    \ state_size[0]\n\n        if self.return_sequences:\n            output_shape\
    \ = (input_shape[0], input_shape[1], output_dim)\n        else:\n            output_shape\
    \ = (input_shape[0], output_dim)\n\n        if self.return_state:\n          \
    \  state_shape = [(input_shape[0], dim) for dim in state_size]\n            return\
    \ [output_shape] + state_shape\n        else:\n            return output_shape\n\
    \n    def compute_mask(self, inputs, mask):\n        if isinstance(mask, list):\n\
    \            mask = mask[0]\n        output_mask = mask if self.return_sequences\
    \ else None\n        if self.return_state:\n            state_mask = [None for\
    \ _ in self.states]\n            return [output_mask] + state_mask\n        else:\n\
    \            return output_mask\n\n    def build(self, input_shape):\n       \
    \ # Note input_shape will be list of shapes of initial states and\n        # constants\
    \ if these are passed in __call__.\n        if self._num_constants is not None:\n\
    \            constants_shape = input_shape[-self._num_constants:]\n        else:\n\
    \            constants_shape = None\n\n        if isinstance(input_shape, list):\n\
    \            input_shape = input_shape[0]\n\n        batch_size = input_shape[0]\
    \ if self.stateful else None\n        input_dim = input_shape[-1]\n        self.input_spec[0]\
    \ = InputSpec(shape=(batch_size, None, input_dim))\n\n        # allow cell (if\
    \ layer) to build before we set or validate state_spec\n        if isinstance(self.cell,\
    \ Layer):\n            step_input_shape = (input_shape[0],) + input_shape[2:]\n\
    \            if constants_shape is not None:\n                self.cell.build([step_input_shape]\
    \ + constants_shape)\n            else:\n                self.cell.build(step_input_shape)\n\
    \n        # set or validate state_spec\n        if hasattr(self.cell.state_size,\
    \ '__len__'):\n            state_size = list(self.cell.state_size)\n        else:\n\
    \            state_size = [self.cell.state_size]\n\n        if self.state_spec\
    \ is not None:\n            # initial_state was passed in call, check compatibility\n\
    \            if [spec.shape[-1] for spec in self.state_spec] != state_size:\n\
    \                raise ValueError(\n                    'An `initial_state` was\
    \ passed that is not compatible with '\n                    '`cell.state_size`.\
    \ Received `state_spec`={}; '\n                    'however `cell.state_size`\
    \ is '\n                    '{}'.format(self.state_spec, self.cell.state_size))\n\
    \        else:\n            self.state_spec = [InputSpec(shape=(None, dim))\n\
    \                               for dim in state_size]\n        if self.stateful:\n\
    \            self.reset_states()\n        self.built = True\n\n    def get_initial_state(self,\
    \ inputs):\n        # build an all-zero tensor of shape (samples, output_dim)\n\
    \        initial_state = K.zeros_like(inputs)  # (samples, timesteps, input_dim)\n\
    \        initial_state = K.sum(initial_state, axis=(1, 2))  # (samples,)\n   \
    \     initial_state = K.expand_dims(initial_state)  # (samples, 1)\n        if\
    \ hasattr(self.cell.state_size, '__len__'):\n            return [K.tile(initial_state,\
    \ [1, dim])\n                    for dim in self.cell.state_size]\n        else:\n\
    \            return [K.tile(initial_state, [1, self.cell.state_size])]\n\n   \
    \ def __call__(self, inputs, initial_state=None, constants=None, **kwargs):\n\
    \        inputs, initial_state, constants = _standardize_args(\n            inputs,\
    \ initial_state, constants, self._num_constants)\n\n        if initial_state is\
    \ None and constants is None:\n            return super(RNN, self).__call__(inputs,\
    \ **kwargs)\n\n        # If any of `initial_state` or `constants` are specified\
    \ and are Keras\n        # tensors, then add them to the inputs and temporarily\
    \ modify the\n        # input_spec to include them.\n\n        additional_inputs\
    \ = []\n        additional_specs = []\n        if initial_state is not None:\n\
    \            kwargs['initial_state'] = initial_state\n            additional_inputs\
    \ += initial_state\n            self.state_spec = [InputSpec(shape=K.int_shape(state))\n\
    \                               for state in initial_state]\n            additional_specs\
    \ += self.state_spec\n        if constants is not None:\n            kwargs['constants']\
    \ = constants\n            additional_inputs += constants\n            self.constants_spec\
    \ = [InputSpec(shape=K.int_shape(constant))\n                                \
    \   for constant in constants]\n            self._num_constants = len(constants)\n\
    \            additional_specs += self.constants_spec\n        # at this point\
    \ additional_inputs cannot be empty\n        is_keras_tensor = K.is_keras_tensor(additional_inputs[0])\n\
    \        for tensor in additional_inputs:\n            if K.is_keras_tensor(tensor)\
    \ != is_keras_tensor:\n                raise ValueError('The initial state or\
    \ constants of an RNN'\n                                 ' layer cannot be specified\
    \ with a mix of'\n                                 ' Keras tensors and non-Keras\
    \ tensors'\n                                 ' (a \"Keras tensor\" is a tensor\
    \ that was'\n                                 ' returned by a Keras layer, or\
    \ by `Input`)')\n\n        if is_keras_tensor:\n            # Compute the full\
    \ input spec, including state and constants\n            full_input = [inputs]\
    \ + additional_inputs\n            full_input_spec = self.input_spec + additional_specs\n\
    \            # Perform the call with temporarily replaced input_spec\n       \
    \     original_input_spec = self.input_spec\n            self.input_spec = full_input_spec\n\
    \            output = super(RNN, self).__call__(full_input, **kwargs)\n      \
    \      self.input_spec = original_input_spec\n            return output\n    \
    \    else:\n            return super(RNN, self).__call__(inputs, **kwargs)\n\n\
    \    def call(self,\n             inputs,\n             mask=None,\n         \
    \    training=None,\n             initial_state=None,\n             constants=None):\n\
    \        # input shape: `(samples, time (padded with zeros), input_dim)`\n   \
    \     # note that the .build() method of subclasses MUST define\n        # self.input_spec\
    \ and self.state_spec with complete input shapes.\n        if isinstance(inputs,\
    \ list):\n            # get initial_state from full input spec\n            #\
    \ as they could be copied to multiple GPU.\n            if self._num_constants\
    \ is None:\n                initial_state = inputs[1:]\n            else:\n  \
    \              initial_state = inputs[1:-self._num_constants]\n            if\
    \ len(initial_state) == 0:\n                initial_state = None\n           \
    \ inputs = inputs[0]\n        if initial_state is not None:\n            pass\n\
    \        elif self.stateful:\n            initial_state = self.states\n      \
    \  else:\n            initial_state = self.get_initial_state(inputs)\n\n     \
    \   if isinstance(mask, list):\n            mask = mask[0]\n\n        if len(initial_state)\
    \ != len(self.states):\n            raise ValueError('Layer has ' + str(len(self.states))\
    \ +\n                             ' states but was passed ' +\n              \
    \               str(len(initial_state)) +\n                             ' initial\
    \ states.')\n        input_shape = K.int_shape(inputs)\n        timesteps = input_shape[1]\n\
    \        if self.unroll and timesteps in [None, 1]:\n            raise ValueError('Cannot\
    \ unroll a RNN if the '\n                             'time dimension is undefined\
    \ or equal to 1. \\n'\n                             '- If using a Sequential model,\
    \ '\n                             'specify the time dimension by passing '\n \
    \                            'an `input_shape` or `batch_input_shape` '\n    \
    \                         'argument to your first layer. If your '\n         \
    \                    'first layer is an Embedding, you can '\n               \
    \              'also use the `input_length` argument.\\n'\n                  \
    \           '- If using the functional API, specify '\n                      \
    \       'the time dimension by passing a `shape` '\n                         \
    \    'or `batch_shape` argument to your Input layer.')\n\n        kwargs = {}\n\
    \        if has_arg(self.cell.call, 'training'):\n            kwargs['training']\
    \ = training\n\n        if constants:\n            if not has_arg(self.cell.call,\
    \ 'constants'):\n                raise ValueError('RNN cell does not support constants')\n\
    \n            def step(inputs, states):\n                constants = states[-self._num_constants:]\n\
    \                states = states[:-self._num_constants]\n                return\
    \ self.cell.call(inputs, states, constants=constants,\n                      \
    \                **kwargs)\n        else:\n            def step(inputs, states):\n\
    \                return self.cell.call(inputs, states, **kwargs)\n\n        last_output,\
    \ outputs, states = K.rnn(step,\n                                            \
    \ inputs,\n                                             initial_state,\n     \
    \                                        constants=constants,\n              \
    \                               go_backwards=self.go_backwards,\n            \
    \                                 mask=mask,\n                               \
    \              unroll=self.unroll,\n                                         \
    \    input_length=timesteps)\n        if self.stateful:\n            updates =\
    \ []\n            for i in range(len(states)):\n                updates.append((self.states[i],\
    \ states[i]))\n            self.add_update(updates, inputs)\n\n        if self.return_sequences:\n\
    \            output = outputs\n        else:\n            output = last_output\n\
    \n        # Properly set learning phase\n        if getattr(last_output, '_uses_learning_phase',\
    \ False):\n            output._uses_learning_phase = True\n            for state\
    \ in states:\n                state._uses_learning_phase = True\n\n        if\
    \ self.return_state:\n            states = to_list(states, allow_tuple=True)\n\
    \            return [output] + states\n        else:\n            return output\n\
    \n    def reset_states(self, states=None):\n        if not self.stateful:\n  \
    \          raise AttributeError('Layer must be stateful.')\n        batch_size\
    \ = self.input_spec[0].shape[0]\n        if not batch_size:\n            raise\
    \ ValueError('If a RNN is stateful, it needs to know '\n                     \
    \        'its batch size. Specify the batch size '\n                         \
    \    'of your input tensors: \\n'\n                             '- If using a\
    \ Sequential model, '\n                             'specify the batch size by\
    \ passing '\n                             'a `batch_input_shape` '\n         \
    \                    'argument to your first layer.\\n'\n                    \
    \         '- If using the functional API, specify '\n                        \
    \     'the batch size by passing a '\n                             '`batch_shape`\
    \ argument to your Input layer.')\n        # initialize state if None\n      \
    \  if self.states[0] is None:\n            if hasattr(self.cell.state_size, '__len__'):\n\
    \                self.states = [K.zeros((batch_size, dim))\n                 \
    \              for dim in self.cell.state_size]\n            else:\n         \
    \       self.states = [K.zeros((batch_size, self.cell.state_size))]\n        elif\
    \ states is None:\n            if hasattr(self.cell.state_size, '__len__'):\n\
    \                for state, dim in zip(self.states, self.cell.state_size):\n \
    \                   K.set_value(state, np.zeros((batch_size, dim)))\n        \
    \    else:\n                K.set_value(self.states[0],\n                    \
    \        np.zeros((batch_size, self.cell.state_size)))\n        else:\n      \
    \      states = to_list(states, allow_tuple=True)\n            if len(states)\
    \ != len(self.states):\n                raise ValueError('Layer ' + self.name\
    \ + ' expects ' +\n                                 str(len(self.states)) + '\
    \ states, '\n                                 'but it received ' + str(len(states))\
    \ +\n                                 ' state values. Input received: ' +\n  \
    \                               str(states))\n            for index, (value, state)\
    \ in enumerate(zip(states, self.states)):\n                if hasattr(self.cell.state_size,\
    \ '__len__'):\n                    dim = self.cell.state_size[index]\n       \
    \         else:\n                    dim = self.cell.state_size\n            \
    \    if value.shape != (batch_size, dim):\n                    raise ValueError('State\
    \ ' + str(index) +\n                                     ' is incompatible with\
    \ layer ' +\n                                     self.name + ': expected shape='\
    \ +\n                                     str((batch_size, dim)) +\n         \
    \                            ', found shape=' + str(value.shape))\n          \
    \      # TODO: consider batch calls to `set_value`.\n                K.set_value(state,\
    \ value)\n\n    def get_config(self):\n        config = {'return_sequences': self.return_sequences,\n\
    \                  'return_state': self.return_state,\n                  'go_backwards':\
    \ self.go_backwards,\n                  'stateful': self.stateful,\n         \
    \         'unroll': self.unroll}\n        if self._num_constants is not None:\n\
    \            config['num_constants'] = self._num_constants\n\n        cell_config\
    \ = self.cell.get_config()\n        config['cell'] = {'class_name': self.cell.__class__.__name__,\n\
    \                          'config': cell_config}\n        base_config = super(RNN,\
    \ self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))\n\
    \n    @classmethod\n    def from_config(cls, config, custom_objects=None):\n \
    \       from . import deserialize as deserialize_layer\n        cell = deserialize_layer(config.pop('cell'),\n\
    \                                 custom_objects=custom_objects)\n        num_constants\
    \ = config.pop('num_constants', None)\n        layer = cls(cell, **config)\n \
    \       layer._num_constants = num_constants\n        return layer\n\n    @property\n\
    \    def trainable_weights(self):\n        if not self.trainable:\n          \
    \  return []\n        if isinstance(self.cell, Layer):\n            return self.cell.trainable_weights\n\
    \        return []\n\n    @property\n    def non_trainable_weights(self):\n  \
    \      if isinstance(self.cell, Layer):\n            if not self.trainable:\n\
    \                return self.cell.weights\n            return self.cell.non_trainable_weights\n\
    \        return []\n\n    @property\n    def losses(self):\n        layer_losses\
    \ = super(RNN, self).losses\n        if isinstance(self.cell, Layer):\n      \
    \      return self.cell.losses + layer_losses\n        return layer_losses\n\n\
    \    def get_losses_for(self, inputs=None):\n        if isinstance(self.cell,\
    \ Layer):\n            cell_losses = self.cell.get_losses_for(inputs)\n      \
    \      return cell_losses + super(RNN, self).get_losses_for(inputs)\n        return\
    \ super(RNN, self).get_losses_for(inputs)\n"
  sourcefile: D:\Python36\lib\site-packages\keras\layers\recurrent.py
- doc: "Rectified Linear Unit activation function.\n\nWith default values, it returns\
    \ element-wise `max(x, 0)`.\n\nOtherwise, it follows:\n`f(x) = max_value` for\
    \ `x >= max_value`,\n`f(x) = x` for `threshold <= x < max_value`,\n`f(x) = negative_slope\
    \ * (x - threshold)` otherwise.\n\n# Input shape\n    Arbitrary. Use the keyword\
    \ argument `input_shape`\n    (tuple of integers, does not include the samples\
    \ axis)\n    when using this layer as the first layer in a model.\n\n# Output\
    \ shape\n    Same shape as the input.\n\n# Arguments\n    max_value: float >=\
    \ 0. Maximum activation value.\n    negative_slope: float >= 0. Negative slope\
    \ coefficient.\n    threshold: float. Threshold value for thresholded activation."
  kind: Layer
  name: ReLU
  parameters:
  - {defaultValue: None, kind: any, name: max_value}
  - {defaultValue: '0.0', kind: any, name: negative_slope}
  - {defaultValue: '0.0', kind: any, name: threshold}
  - {defaultValue: 'true', name: trainable, type: bool}
  source: "class ReLU(Layer):\n    \"\"\"Rectified Linear Unit activation function.\n\
    \n    With default values, it returns element-wise `max(x, 0)`.\n\n    Otherwise,\
    \ it follows:\n    `f(x) = max_value` for `x >= max_value`,\n    `f(x) = x` for\
    \ `threshold <= x < max_value`,\n    `f(x) = negative_slope * (x - threshold)`\
    \ otherwise.\n\n    # Input shape\n        Arbitrary. Use the keyword argument\
    \ `input_shape`\n        (tuple of integers, does not include the samples axis)\n\
    \        when using this layer as the first layer in a model.\n\n    # Output\
    \ shape\n        Same shape as the input.\n\n    # Arguments\n        max_value:\
    \ float >= 0. Maximum activation value.\n        negative_slope: float >= 0. Negative\
    \ slope coefficient.\n        threshold: float. Threshold value for thresholded\
    \ activation.\n    \"\"\"\n\n    def __init__(self, max_value=None, negative_slope=0.,\n\
    \                 threshold=0., **kwargs):\n        super(ReLU, self).__init__(**kwargs)\n\
    \        if max_value is not None and max_value < 0.:\n            raise ValueError('max_value\
    \ of ReLU layer '\n                             'cannot be negative value: %s'\
    \ % str(max_value))\n        if negative_slope < 0.:\n            raise ValueError('negative_slope\
    \ of ReLU layer cannot be '\n                             'negative value: %s'\
    \ % str(negative_slope))\n        self.supports_masking = True\n        if max_value\
    \ is not None:\n            max_value = K.cast_to_floatx(max_value)\n        self.max_value\
    \ = max_value\n        self.negative_slope = K.cast_to_floatx(negative_slope)\n\
    \        self.threshold = K.cast_to_floatx(threshold)\n\n    def call(self, inputs):\n\
    \        return K.relu(inputs,\n                      alpha=self.negative_slope,\n\
    \                      max_value=self.max_value,\n                      threshold=self.threshold)\n\
    \n    def get_config(self):\n        config = {\n            'max_value': self.max_value,\n\
    \            'negative_slope': self.negative_slope,\n            'threshold':\
    \ self.threshold\n        }\n        base_config = super(ReLU, self).get_config()\n\
    \        return dict(list(base_config.items()) + list(config.items()))\n\n   \
    \ def compute_output_shape(self, input_shape):\n        return input_shape\n"
  sourcefile: D:\Python36\lib\site-packages\keras\layers\advanced_activations.py
- doc: "Abstract base class for recurrent layers.\n\nDo not use in a model -- it's\
    \ not a valid layer!\nUse its children classes `LSTM`, `GRU` and `SimpleRNN` instead.\n\
    All recurrent layers (`LSTM`, `GRU`, `SimpleRNN`) also\nfollow the specifications\
    \ of this class and accept\nthe keyword arguments listed below.\n\n# Example\n\
    \n```python\n    # as the first layer in a Sequential model\n    model = Sequential()\n\
    \    model.add(LSTM(32, input_shape=(10, 64)))\n    # now model.output_shape ==\
    \ (None, 32)\n    # note: `None` is the batch dimension.\n    # for subsequent\
    \ layers, no need to specify the input size:\n    model.add(LSTM(16))\n    # to\
    \ stack recurrent layers, you must use return_sequences=True\n    # on any recurrent\
    \ layer that feeds into another recurrent layer.\n    # note that you only need\
    \ to specify the input size on the first layer.\n    model = Sequential()\n  \
    \  model.add(LSTM(64, input_dim=64, input_length=10, return_sequences=True))\n\
    \    model.add(LSTM(32, return_sequences=True))\n    model.add(LSTM(10))\n```\n\
    \n# Arguments\n    weights: list of Numpy arrays to set as initial weights.\n\
    \        The list should have 3 elements, of shapes:\n        `[(input_dim, output_dim),\
    \ (output_dim, output_dim), (output_dim,)]`.\n    return_sequences: Boolean. Whether\
    \ to return the last output\n        in the output sequence, or the full sequence.\n\
    \    return_state: Boolean. Whether to return the last state\n        in addition\
    \ to the output.\n    go_backwards: Boolean (default False).\n        If True,\
    \ process the input sequence backwards and return the\n        reversed sequence.\n\
    \    stateful: Boolean (default False). If True, the last state\n        for each\
    \ sample at index i in a batch will be used as initial\n        state for the\
    \ sample of index i in the following batch.\n    unroll: Boolean (default False).\n\
    \        If True, the network will be unrolled,\n        else a symbolic loop\
    \ will be used.\n        Unrolling can speed-up a RNN,\n        although it tends\
    \ to be more memory-intensive.\n        Unrolling is only suitable for short sequences.\n\
    \    implementation: one of {0, 1, or 2}.\n        If set to 0, the RNN will use\n\
    \        an implementation that uses fewer, larger matrix products,\n        thus\
    \ running faster on CPU but consuming more memory.\n        If set to 1, the RNN\
    \ will use more matrix products,\n        but smaller ones, thus running slower\n\
    \        (may actually be faster on GPU) while consuming less memory.\n      \
    \  If set to 2 (LSTM/GRU only),\n        the RNN will combine the input gate,\n\
    \        the forget gate and the output gate into a single matrix,\n        enabling\
    \ more time-efficient parallelization on the GPU.\n        Note: RNN dropout must\
    \ be shared for all gates,\n        resulting in a slightly reduced regularization.\n\
    \    input_dim: dimensionality of the input (integer).\n        This argument\
    \ (or alternatively, the keyword argument `input_shape`)\n        is required\
    \ when using this layer as the first layer in a model.\n    input_length: Length\
    \ of input sequences, to be specified\n        when it is constant.\n        This\
    \ argument is required if you are going to connect\n        `Flatten` then `Dense`\
    \ layers upstream\n        (without it, the shape of the dense outputs cannot\
    \ be computed).\n        Note that if the recurrent layer is not the first layer\n\
    \        in your model, you would need to specify the input length\n        at\
    \ the level of the first layer\n        (e.g. via the `input_shape` argument)\n\
    \n# Input shapes\n    3D tensor with shape `(batch_size, timesteps, input_dim)`,\n\
    \    (Optional) 2D tensors with shape `(batch_size, output_dim)`.\n\n# Output\
    \ shape\n    - if `return_state`: a list of tensors. The first tensor is\n   \
    \     the output. The remaining tensors are the last states,\n        each with\
    \ shape `(batch_size, units)`.\n    - if `return_sequences`: 3D tensor with shape\n\
    \        `(batch_size, timesteps, units)`.\n    - else, 2D tensor with shape `(batch_size,\
    \ units)`.\n\n# Masking\n    This layer supports masking for input data with a\
    \ variable number\n    of timesteps. To introduce masks to your data,\n    use\
    \ an [Embedding](embeddings.md) layer with the `mask_zero` parameter\n    set\
    \ to `True`.\n\n# Note on using statefulness in RNNs\n    You can set RNN layers\
    \ to be 'stateful', which means that the states\n    computed for the samples\
    \ in one batch will be reused as initial states\n    for the samples in the next\
    \ batch. This assumes a one-to-one mapping\n    between samples in different successive\
    \ batches.\n    To enable statefulness:\n        - specify `stateful=True` in\
    \ the layer constructor.\n        - specify a fixed batch size for your model,\
    \ by passing\n            if sequential model:\n              `batch_input_shape=(...)`\
    \ to the first layer in your model.\n            else for functional model with\
    \ 1 or more Input layers:\n              `batch_shape=(...)` to all the first\
    \ layers in your model.\n            This is the expected shape of your inputs\n\
    \            *including the batch size*.\n            It should be a tuple of\
    \ integers, e.g. `(32, 10, 100)`.\n        - specify `shuffle=False` when calling\
    \ fit().\n    To reset the states of your model, call `.reset_states()` on either\n\
    \    a specific layer, or on your entire model.\n\n# Note on specifying the initial\
    \ state of RNNs\n    You can specify the initial state of RNN layers symbolically\
    \ by\n    calling them with the keyword argument `initial_state`. The value of\n\
    \    `initial_state` should be a tensor or list of tensors representing\n    the\
    \ initial state of the RNN layer.\n    You can specify the initial state of RNN\
    \ layers numerically by\n    calling `reset_states` with the keyword argument\
    \ `states`. The value of\n    `states` should be a numpy array or list of numpy\
    \ arrays representing\n    the initial state of the RNN layer."
  kind: Layer
  name: Recurrent
  parameters:
  - {defaultValue: 'False', kind: any, name: return_sequences}
  - {defaultValue: 'False', kind: any, name: return_state}
  - {defaultValue: 'False', kind: any, name: go_backwards}
  - {defaultValue: 'False', kind: any, name: stateful}
  - {defaultValue: 'False', kind: any, name: unroll}
  - {defaultValue: '0', kind: any, name: implementation}
  - {defaultValue: 'true', name: trainable, type: bool}
  source: "class Recurrent(Layer):\n    \"\"\"Abstract base class for recurrent layers.\n\
    \n    Do not use in a model -- it's not a valid layer!\n    Use its children classes\
    \ `LSTM`, `GRU` and `SimpleRNN` instead.\n    All recurrent layers (`LSTM`, `GRU`,\
    \ `SimpleRNN`) also\n    follow the specifications of this class and accept\n\
    \    the keyword arguments listed below.\n\n    # Example\n\n    ```python\n \
    \       # as the first layer in a Sequential model\n        model = Sequential()\n\
    \        model.add(LSTM(32, input_shape=(10, 64)))\n        # now model.output_shape\
    \ == (None, 32)\n        # note: `None` is the batch dimension.\n        # for\
    \ subsequent layers, no need to specify the input size:\n        model.add(LSTM(16))\n\
    \        # to stack recurrent layers, you must use return_sequences=True\n   \
    \     # on any recurrent layer that feeds into another recurrent layer.\n    \
    \    # note that you only need to specify the input size on the first layer.\n\
    \        model = Sequential()\n        model.add(LSTM(64, input_dim=64, input_length=10,\
    \ return_sequences=True))\n        model.add(LSTM(32, return_sequences=True))\n\
    \        model.add(LSTM(10))\n    ```\n\n    # Arguments\n        weights: list\
    \ of Numpy arrays to set as initial weights.\n            The list should have\
    \ 3 elements, of shapes:\n            `[(input_dim, output_dim), (output_dim,\
    \ output_dim), (output_dim,)]`.\n        return_sequences: Boolean. Whether to\
    \ return the last output\n            in the output sequence, or the full sequence.\n\
    \        return_state: Boolean. Whether to return the last state\n           \
    \ in addition to the output.\n        go_backwards: Boolean (default False).\n\
    \            If True, process the input sequence backwards and return the\n  \
    \          reversed sequence.\n        stateful: Boolean (default False). If True,\
    \ the last state\n            for each sample at index i in a batch will be used\
    \ as initial\n            state for the sample of index i in the following batch.\n\
    \        unroll: Boolean (default False).\n            If True, the network will\
    \ be unrolled,\n            else a symbolic loop will be used.\n            Unrolling\
    \ can speed-up a RNN,\n            although it tends to be more memory-intensive.\n\
    \            Unrolling is only suitable for short sequences.\n        implementation:\
    \ one of {0, 1, or 2}.\n            If set to 0, the RNN will use\n          \
    \  an implementation that uses fewer, larger matrix products,\n            thus\
    \ running faster on CPU but consuming more memory.\n            If set to 1, the\
    \ RNN will use more matrix products,\n            but smaller ones, thus running\
    \ slower\n            (may actually be faster on GPU) while consuming less memory.\n\
    \            If set to 2 (LSTM/GRU only),\n            the RNN will combine the\
    \ input gate,\n            the forget gate and the output gate into a single matrix,\n\
    \            enabling more time-efficient parallelization on the GPU.\n      \
    \      Note: RNN dropout must be shared for all gates,\n            resulting\
    \ in a slightly reduced regularization.\n        input_dim: dimensionality of\
    \ the input (integer).\n            This argument (or alternatively, the keyword\
    \ argument `input_shape`)\n            is required when using this layer as the\
    \ first layer in a model.\n        input_length: Length of input sequences, to\
    \ be specified\n            when it is constant.\n            This argument is\
    \ required if you are going to connect\n            `Flatten` then `Dense` layers\
    \ upstream\n            (without it, the shape of the dense outputs cannot be\
    \ computed).\n            Note that if the recurrent layer is not the first layer\n\
    \            in your model, you would need to specify the input length\n     \
    \       at the level of the first layer\n            (e.g. via the `input_shape`\
    \ argument)\n\n    # Input shapes\n        3D tensor with shape `(batch_size,\
    \ timesteps, input_dim)`,\n        (Optional) 2D tensors with shape `(batch_size,\
    \ output_dim)`.\n\n    # Output shape\n        - if `return_state`: a list of\
    \ tensors. The first tensor is\n            the output. The remaining tensors\
    \ are the last states,\n            each with shape `(batch_size, units)`.\n \
    \       - if `return_sequences`: 3D tensor with shape\n            `(batch_size,\
    \ timesteps, units)`.\n        - else, 2D tensor with shape `(batch_size, units)`.\n\
    \n    # Masking\n        This layer supports masking for input data with a variable\
    \ number\n        of timesteps. To introduce masks to your data,\n        use\
    \ an [Embedding](embeddings.md) layer with the `mask_zero` parameter\n       \
    \ set to `True`.\n\n    # Note on using statefulness in RNNs\n        You can\
    \ set RNN layers to be 'stateful', which means that the states\n        computed\
    \ for the samples in one batch will be reused as initial states\n        for the\
    \ samples in the next batch. This assumes a one-to-one mapping\n        between\
    \ samples in different successive batches.\n        To enable statefulness:\n\
    \            - specify `stateful=True` in the layer constructor.\n           \
    \ - specify a fixed batch size for your model, by passing\n                if\
    \ sequential model:\n                  `batch_input_shape=(...)` to the first\
    \ layer in your model.\n                else for functional model with 1 or more\
    \ Input layers:\n                  `batch_shape=(...)` to all the first layers\
    \ in your model.\n                This is the expected shape of your inputs\n\
    \                *including the batch size*.\n                It should be a tuple\
    \ of integers, e.g. `(32, 10, 100)`.\n            - specify `shuffle=False` when\
    \ calling fit().\n        To reset the states of your model, call `.reset_states()`\
    \ on either\n        a specific layer, or on your entire model.\n\n    # Note\
    \ on specifying the initial state of RNNs\n        You can specify the initial\
    \ state of RNN layers symbolically by\n        calling them with the keyword argument\
    \ `initial_state`. The value of\n        `initial_state` should be a tensor or\
    \ list of tensors representing\n        the initial state of the RNN layer.\n\
    \        You can specify the initial state of RNN layers numerically by\n    \
    \    calling `reset_states` with the keyword argument `states`. The value of\n\
    \        `states` should be a numpy array or list of numpy arrays representing\n\
    \        the initial state of the RNN layer.\n    \"\"\"\n\n    def __init__(self,\
    \ return_sequences=False,\n                 return_state=False,\n            \
    \     go_backwards=False,\n                 stateful=False,\n                \
    \ unroll=False,\n                 implementation=0,\n                 **kwargs):\n\
    \        super(Recurrent, self).__init__(**kwargs)\n        self.return_sequences\
    \ = return_sequences\n        self.return_state = return_state\n        self.go_backwards\
    \ = go_backwards\n\n        self.stateful = stateful\n        self.unroll = unroll\n\
    \        self.implementation = implementation\n        self.supports_masking =\
    \ True\n        self.input_spec = [InputSpec(ndim=3)]\n        self.state_spec\
    \ = None\n        self.dropout = 0\n        self.recurrent_dropout = 0\n\n   \
    \ def compute_output_shape(self, input_shape):\n        if isinstance(input_shape,\
    \ list):\n            input_shape = input_shape[0]\n\n        if self.return_sequences:\n\
    \            output_shape = (input_shape[0], input_shape[1], self.units)\n   \
    \     else:\n            output_shape = (input_shape[0], self.units)\n\n     \
    \   if self.return_state:\n            state_shape = [(input_shape[0], self.units)\
    \ for _ in self.states]\n            return [output_shape] + state_shape\n   \
    \     else:\n            return output_shape\n\n    def compute_mask(self, inputs,\
    \ mask):\n        if isinstance(mask, list):\n            mask = mask[0]\n   \
    \     output_mask = mask if self.return_sequences else None\n        if self.return_state:\n\
    \            state_mask = [None for _ in self.states]\n            return [output_mask]\
    \ + state_mask\n        else:\n            return output_mask\n\n    def step(self,\
    \ inputs, states):\n        raise NotImplementedError\n\n    def get_constants(self,\
    \ inputs, training=None):\n        return []\n\n    def get_initial_state(self,\
    \ inputs):\n        # build an all-zero tensor of shape (samples, output_dim)\n\
    \        initial_state = K.zeros_like(inputs)  # (samples, timesteps, input_dim)\n\
    \        initial_state = K.sum(initial_state, axis=(1, 2))  # (samples,)\n   \
    \     initial_state = K.expand_dims(initial_state)  # (samples, 1)\n        #\
    \ (samples, output_dim)\n        initial_state = K.tile(initial_state, [1, self.units])\n\
    \        initial_state = [initial_state for _ in range(len(self.states))]\n  \
    \      return initial_state\n\n    def preprocess_input(self, inputs, training=None):\n\
    \        return inputs\n\n    def __call__(self, inputs, initial_state=None, **kwargs):\n\
    \n        # If there are multiple inputs, then\n        # they should be the main\
    \ input and `initial_state`\n        # e.g. when loading model from file\n   \
    \     if (isinstance(inputs, (list, tuple))\n                and len(inputs) >\
    \ 1 and initial_state is None):\n            initial_state = inputs[1:]\n    \
    \        inputs = inputs[0]\n\n        # If `initial_state` is specified,\n  \
    \      # and if it a Keras tensor,\n        # then add it to the inputs and temporarily\n\
    \        # modify the input spec to include the state.\n        if initial_state\
    \ is None:\n            return super(Recurrent, self).__call__(inputs, **kwargs)\n\
    \n        initial_state = to_list(initial_state, allow_tuple=True)\n\n       \
    \ is_keras_tensor = hasattr(initial_state[0], '_keras_history')\n        for tensor\
    \ in initial_state:\n            if hasattr(tensor, '_keras_history') != is_keras_tensor:\n\
    \                raise ValueError('The initial state of an RNN layer cannot be'\n\
    \                                 ' specified with a mix of Keras tensors and'\n\
    \                                 ' non-Keras tensors')\n\n        if is_keras_tensor:\n\
    \            # Compute the full input spec, including state\n            input_spec\
    \ = self.input_spec\n            state_spec = self.state_spec\n            input_spec\
    \ = to_list(input_spec)\n            state_spec = to_list(state_spec)\n      \
    \      self.input_spec = input_spec + state_spec\n\n            # Compute the\
    \ full inputs, including state\n            inputs = [inputs] + list(initial_state)\n\
    \n            # Perform the call\n            output = super(Recurrent, self).__call__(inputs,\
    \ **kwargs)\n\n            # Restore original input spec\n            self.input_spec\
    \ = input_spec\n            return output\n        else:\n            kwargs['initial_state']\
    \ = initial_state\n            return super(Recurrent, self).__call__(inputs,\
    \ **kwargs)\n\n    def call(self, inputs, mask=None, training=None, initial_state=None):\n\
    \        # input shape: `(samples, time (padded with zeros), input_dim)`\n   \
    \     # note that the .build() method of subclasses MUST define\n        # self.input_spec\
    \ and self.state_spec with complete input shapes.\n        if isinstance(inputs,\
    \ list):\n            initial_state = inputs[1:]\n            inputs = inputs[0]\n\
    \        elif initial_state is not None:\n            pass\n        elif self.stateful:\n\
    \            initial_state = self.states\n        else:\n            initial_state\
    \ = self.get_initial_state(inputs)\n\n        if isinstance(mask, list):\n   \
    \         mask = mask[0]\n\n        if len(initial_state) != len(self.states):\n\
    \            raise ValueError('Layer has ' + str(len(self.states)) +\n       \
    \                      ' states but was passed ' +\n                         \
    \    str(len(initial_state)) +\n                             ' initial states.')\n\
    \        input_shape = K.int_shape(inputs)\n        timesteps = input_shape[1]\n\
    \        if self.unroll and timesteps in [None, 1]:\n            raise ValueError('Cannot\
    \ unroll a RNN if the '\n                             'time dimension is undefined\
    \ or equal to 1. \\n'\n                             '- If using a Sequential model,\
    \ '\n                             'specify the time dimension by passing '\n \
    \                            'an `input_shape` or `batch_input_shape` '\n    \
    \                         'argument to your first layer. If your '\n         \
    \                    'first layer is an Embedding, you can '\n               \
    \              'also use the `input_length` argument.\\n'\n                  \
    \           '- If using the functional API, specify '\n                      \
    \       'the time dimension by passing a `shape` '\n                         \
    \    'or `batch_shape` argument to your Input layer.')\n        constants = self.get_constants(inputs,\
    \ training=None)\n        preprocessed_input = self.preprocess_input(inputs, training=None)\n\
    \        last_output, outputs, states = K.rnn(self.step,\n                   \
    \                          preprocessed_input,\n                             \
    \                initial_state,\n                                            \
    \ go_backwards=self.go_backwards,\n                                          \
    \   mask=mask,\n                                             constants=constants,\n\
    \                                             unroll=self.unroll,\n          \
    \                                   input_length=timesteps)\n        if self.stateful:\n\
    \            updates = []\n            for i in range(len(states)):\n        \
    \        updates.append((self.states[i], states[i]))\n            self.add_update(updates,\
    \ inputs)\n\n        # Properly set learning phase\n        if 0 < self.dropout\
    \ + self.recurrent_dropout:\n            last_output._uses_learning_phase = True\n\
    \            outputs._uses_learning_phase = True\n\n        if self.return_sequences:\n\
    \            output = outputs\n        else:\n            output = last_output\n\
    \n        if self.return_state:\n            states = to_list(states, allow_tuple=True)\n\
    \            return [output] + states\n        else:\n            return output\n\
    \n    def reset_states(self, states=None):\n        if not self.stateful:\n  \
    \          raise AttributeError('Layer must be stateful.')\n        batch_size\
    \ = self.input_spec[0].shape[0]\n        if not batch_size:\n            raise\
    \ ValueError('If a RNN is stateful, it needs to know '\n                     \
    \        'its batch size. Specify the batch size '\n                         \
    \    'of your input tensors: \\n'\n                             '- If using a\
    \ Sequential model, '\n                             'specify the batch size by\
    \ passing '\n                             'a `batch_input_shape` '\n         \
    \                    'argument to your first layer.\\n'\n                    \
    \         '- If using the functional API, specify '\n                        \
    \     'the time dimension by passing a '\n                             '`batch_shape`\
    \ argument to your Input layer.')\n        # initialize state if None\n      \
    \  if self.states[0] is None:\n            self.states = [K.zeros((batch_size,\
    \ self.units))\n                           for _ in self.states]\n        elif\
    \ states is None:\n            for state in self.states:\n                K.set_value(state,\
    \ np.zeros((batch_size, self.units)))\n        else:\n            states = to_list(states,\
    \ allow_tuple=True)\n            if len(states) != len(self.states):\n       \
    \         raise ValueError('Layer ' + self.name + ' expects ' +\n            \
    \                     str(len(self.states)) + ' states, '\n                  \
    \               'but it received ' + str(len(states)) +\n                    \
    \             ' state values. Input received: ' +\n                          \
    \       str(states))\n            for index, (value, state) in enumerate(zip(states,\
    \ self.states)):\n                if value.shape != (batch_size, self.units):\n\
    \                    raise ValueError('State ' + str(index) +\n              \
    \                       ' is incompatible with layer ' +\n                   \
    \                  self.name + ': expected shape=' +\n                       \
    \              str((batch_size, self.units)) +\n                             \
    \        ', found shape=' + str(value.shape))\n                K.set_value(state,\
    \ value)\n\n    def get_config(self):\n        config = {'return_sequences': self.return_sequences,\n\
    \                  'return_state': self.return_state,\n                  'go_backwards':\
    \ self.go_backwards,\n                  'stateful': self.stateful,\n         \
    \         'unroll': self.unroll,\n                  'implementation': self.implementation}\n\
    \        base_config = super(Recurrent, self).get_config()\n        return dict(list(base_config.items())\
    \ + list(config.items()))\n"
  sourcefile: D:\Python36\lib\site-packages\keras\legacy\layers.py
- doc: "Repeats the input n times.\n\n# Example\n\n```python\n    model = Sequential()\n\
    \    model.add(Dense(32, input_dim=32))\n    # now: model.output_shape == (None,\
    \ 32)\n    # note: `None` is the batch dimension\n\n    model.add(RepeatVector(3))\n\
    \    # now: model.output_shape == (None, 3, 32)\n```\n\n# Arguments\n    n: integer,\
    \ repetition factor.\n\n# Input shape\n    2D tensor of shape `(num_samples, features)`.\n\
    \n# Output shape\n    3D tensor of shape `(num_samples, n, features)`."
  kind: Layer
  name: RepeatVector
  parameters:
  - {kind: any, name: n}
  - {defaultValue: 'true', name: trainable, type: bool}
  source: "class RepeatVector(Layer):\n    \"\"\"Repeats the input n times.\n\n  \
    \  # Example\n\n    ```python\n        model = Sequential()\n        model.add(Dense(32,\
    \ input_dim=32))\n        # now: model.output_shape == (None, 32)\n        # note:\
    \ `None` is the batch dimension\n\n        model.add(RepeatVector(3))\n      \
    \  # now: model.output_shape == (None, 3, 32)\n    ```\n\n    # Arguments\n  \
    \      n: integer, repetition factor.\n\n    # Input shape\n        2D tensor\
    \ of shape `(num_samples, features)`.\n\n    # Output shape\n        3D tensor\
    \ of shape `(num_samples, n, features)`.\n    \"\"\"\n\n    def __init__(self,\
    \ n, **kwargs):\n        super(RepeatVector, self).__init__(**kwargs)\n      \
    \  self.n = n\n        self.input_spec = InputSpec(ndim=2)\n\n    def compute_output_shape(self,\
    \ input_shape):\n        return (input_shape[0], self.n, input_shape[1])\n\n \
    \   def call(self, inputs):\n        return K.repeat(inputs, self.n)\n\n    def\
    \ get_config(self):\n        config = {'n': self.n}\n        base_config = super(RepeatVector,\
    \ self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))\n"
  sourcefile: D:\Python36\lib\site-packages\keras\layers\core.py
- doc: "Reshapes an output to a certain shape.\n\n# Arguments\n    target_shape: target\
    \ shape. Tuple of integers.\n        Does not include the batch axis.\n\n# Input\
    \ shape\n    Arbitrary, although all dimensions in the input shaped must be fixed.\n\
    \    Use the keyword argument `input_shape`\n    (tuple of integers, does not\
    \ include the batch axis)\n    when using this layer as the first layer in a model.\n\
    \n# Output shape\n    `(batch_size,) + target_shape`\n\n# Example\n\n```python\n\
    \    # as first layer in a Sequential model\n    model = Sequential()\n    model.add(Reshape((3,\
    \ 4), input_shape=(12,)))\n    # now: model.output_shape == (None, 3, 4)\n   \
    \ # note: `None` is the batch dimension\n\n    # as intermediate layer in a Sequential\
    \ model\n    model.add(Reshape((6, 2)))\n    # now: model.output_shape == (None,\
    \ 6, 2)\n\n    # also supports shape inference using `-1` as dimension\n    model.add(Reshape((-1,\
    \ 2, 2)))\n    # now: model.output_shape == (None, 3, 2, 2)\n```"
  kind: Layer
  name: Reshape
  parameters:
  - {kind: any, name: target_shape}
  - {defaultValue: 'true', name: trainable, type: bool}
  source: "class Reshape(Layer):\n    \"\"\"Reshapes an output to a certain shape.\n\
    \n    # Arguments\n        target_shape: target shape. Tuple of integers.\n  \
    \          Does not include the batch axis.\n\n    # Input shape\n        Arbitrary,\
    \ although all dimensions in the input shaped must be fixed.\n        Use the\
    \ keyword argument `input_shape`\n        (tuple of integers, does not include\
    \ the batch axis)\n        when using this layer as the first layer in a model.\n\
    \n    # Output shape\n        `(batch_size,) + target_shape`\n\n    # Example\n\
    \n    ```python\n        # as first layer in a Sequential model\n        model\
    \ = Sequential()\n        model.add(Reshape((3, 4), input_shape=(12,)))\n    \
    \    # now: model.output_shape == (None, 3, 4)\n        # note: `None` is the\
    \ batch dimension\n\n        # as intermediate layer in a Sequential model\n \
    \       model.add(Reshape((6, 2)))\n        # now: model.output_shape == (None,\
    \ 6, 2)\n\n        # also supports shape inference using `-1` as dimension\n \
    \       model.add(Reshape((-1, 2, 2)))\n        # now: model.output_shape == (None,\
    \ 3, 2, 2)\n    ```\n    \"\"\"\n\n    def __init__(self, target_shape, **kwargs):\n\
    \        super(Reshape, self).__init__(**kwargs)\n        self.target_shape =\
    \ tuple(target_shape)\n\n    def _fix_unknown_dimension(self, input_shape, output_shape):\n\
    \        \"\"\"Finds and replaces a missing dimension in an output shape.\n\n\
    \        This is a near direct port of the internal Numpy function\n        `_fix_unknown_dimension`\
    \ in `numpy/core/src/multiarray/shape.c`\n\n        # Arguments\n            input_shape:\
    \ original shape of array being reshaped\n            output_shape: target shape\
    \ of the array, with at most\n                a single -1 which indicates a dimension\
    \ that should be\n                derived from the input shape.\n\n        # Returns\n\
    \            The new output shape with a `-1` replaced with its computed value.\n\
    \n        # Raises\n            ValueError: if `input_shape` and `output_shape`\
    \ do not match.\n        \"\"\"\n        output_shape = list(output_shape)\n \
    \       msg = 'total size of new array must be unchanged'\n\n        known, unknown\
    \ = 1, None\n        for index, dim in enumerate(output_shape):\n            if\
    \ dim < 0:\n                if unknown is None:\n                    unknown =\
    \ index\n                else:\n                    raise ValueError('Can only\
    \ specify one unknown dimension.')\n            else:\n                known *=\
    \ dim\n\n        original = np.prod(input_shape, dtype=int)\n        if unknown\
    \ is not None:\n            if known == 0 or original % known != 0:\n        \
    \        raise ValueError(msg)\n            output_shape[unknown] = original //\
    \ known\n        elif original != known:\n            raise ValueError(msg)\n\n\
    \        return tuple(output_shape)\n\n    def compute_output_shape(self, input_shape):\n\
    \        if None in input_shape[1:]:\n            # input shape (partially) unknown?\
    \ replace -1's with None's\n            return ((input_shape[0],) +\n        \
    \            tuple(s if s != -1 else None for s in self.target_shape))\n     \
    \   else:\n            # input shape known? then we can compute the output shape\n\
    \            return (input_shape[0],) + self._fix_unknown_dimension(\n       \
    \         input_shape[1:], self.target_shape)\n\n    def call(self, inputs):\n\
    \        return K.reshape(inputs, (K.shape(inputs)[0],) + self.target_shape)\n\
    \n    def get_config(self):\n        config = {'target_shape': self.target_shape}\n\
    \        base_config = super(Reshape, self).get_config()\n        return dict(list(base_config.items())\
    \ + list(config.items()))\n"
  sourcefile: D:\Python36\lib\site-packages\keras\layers\core.py
- doc: "Depthwise separable 1D convolution.\n\nSeparable convolutions consist in first\
    \ performing\na depthwise spatial convolution\n(which acts on each input channel\
    \ separately)\nfollowed by a pointwise convolution which mixes together the resulting\n\
    output channels. The `depth_multiplier` argument controls how many\noutput channels\
    \ are generated per input channel in the depthwise step.\n\nIntuitively, separable\
    \ convolutions can be understood as\na way to factorize a convolution kernel into\
    \ two smaller kernels,\nor as an extreme version of an Inception block.\n\n# Arguments\n\
    \    filters: Integer, the dimensionality of the output space\n        (i.e. the\
    \ number of output filters in the convolution).\n    kernel_size: An integer or\
    \ tuple/list of single integer,\n        specifying the length of the 1D convolution\
    \ window.\n    strides: An integer or tuple/list of single integer,\n        specifying\
    \ the stride length of the convolution.\n        Specifying any stride value !=\
    \ 1 is incompatible with specifying\n        any `dilation_rate` value != 1.\n\
    \    padding: one of `\"valid\"` or `\"same\"` (case-insensitive).\n    data_format:\
    \ A string,\n        one of `\"channels_last\"` or `\"channels_first\"`.\n   \
    \     The ordering of the dimensions in the inputs.\n        `\"channels_last\"\
    ` corresponds to inputs with shape\n        `(batch, steps, channels)` while `\"\
    channels_first\"`\n        corresponds to inputs with shape\n        `(batch,\
    \ channels, steps)`.\n    dilation_rate: An integer or tuple/list of a single\
    \ integer, specifying\n        the dilation rate to use for dilated convolution.\n\
    \        Currently, specifying any `dilation_rate` value != 1 is\n        incompatible\
    \ with specifying any `strides` value != 1.\n    depth_multiplier: The number\
    \ of depthwise convolution output channels\n        for each input channel.\n\
    \        The total number of depthwise convolution output\n        channels will\
    \ be equal to `filters_in * depth_multiplier`.\n    activation: Activation function\
    \ to use\n        (see [activations](../activations.md)).\n        If you don't\
    \ specify anything, no activation is applied\n        (ie. \"linear\" activation:\
    \ `a(x) = x`).\n    use_bias: Boolean, whether the layer uses a bias vector.\n\
    \    depthwise_initializer: Initializer for the depthwise kernel matrix\n    \
    \    (see [initializers](../initializers.md)).\n    pointwise_initializer: Initializer\
    \ for the pointwise kernel matrix\n        (see [initializers](../initializers.md)).\n\
    \    bias_initializer: Initializer for the bias vector\n        (see [initializers](../initializers.md)).\n\
    \    depthwise_regularizer: Regularizer function applied to\n        the depthwise\
    \ kernel matrix\n        (see [regularizer](../regularizers.md)).\n    pointwise_regularizer:\
    \ Regularizer function applied to\n        the pointwise kernel matrix\n     \
    \   (see [regularizer](../regularizers.md)).\n    bias_regularizer: Regularizer\
    \ function applied to the bias vector\n        (see [regularizer](../regularizers.md)).\n\
    \    activity_regularizer: Regularizer function applied to\n        the output\
    \ of the layer (its \"activation\").\n        (see [regularizer](../regularizers.md)).\n\
    \    depthwise_constraint: Constraint function applied to\n        the depthwise\
    \ kernel matrix\n        (see [constraints](../constraints.md)).\n    pointwise_constraint:\
    \ Constraint function applied to\n        the pointwise kernel matrix\n      \
    \  (see [constraints](../constraints.md)).\n    bias_constraint: Constraint function\
    \ applied to the bias vector\n        (see [constraints](../constraints.md)).\n\
    \n# Input shape\n    3D tensor with shape:\n    `(batch, channels, steps)`\n \
    \   if `data_format` is `\"channels_first\"`\n    or 3D tensor with shape:\n \
    \   `(batch, steps, channels)`\n    if `data_format` is `\"channels_last\"`.\n\
    \n# Output shape\n    3D tensor with shape:\n    `(batch, filters, new_steps)`\n\
    \    if `data_format` is `\"channels_first\"`\n    or 3D tensor with shape:\n\
    \    `(batch, new_steps, filters)`\n    if `data_format` is `\"channels_last\"\
    `.\n    `new_steps` values might have changed due to padding or strides."
  kind: Layer
  name: SeparableConv1D
  parameters:
  - {kind: any, name: filters}
  - {kind: any, name: kernel_size}
  - {defaultValue: '1', kind: any, name: strides}
  - {defaultValue: valid, kind: any, name: padding}
  - {defaultValue: channels_last, kind: any, name: data_format}
  - {defaultValue: '1', kind: any, name: dilation_rate}
  - {defaultValue: '1', kind: any, name: depth_multiplier}
  - {defaultValue: None, kind: any, name: activation}
  - {defaultValue: 'True', kind: any, name: use_bias}
  - {defaultValue: glorot_uniform, kind: any, name: depthwise_initializer}
  - {defaultValue: glorot_uniform, kind: any, name: pointwise_initializer}
  - {defaultValue: zeros, kind: any, name: bias_initializer}
  - {defaultValue: None, kind: any, name: depthwise_regularizer}
  - {defaultValue: None, kind: any, name: pointwise_regularizer}
  - {defaultValue: None, kind: any, name: bias_regularizer}
  - {defaultValue: None, kind: any, name: activity_regularizer}
  - {defaultValue: None, kind: any, name: depthwise_constraint}
  - {defaultValue: None, kind: any, name: pointwise_constraint}
  - {defaultValue: None, kind: any, name: bias_constraint}
  - {defaultValue: 'true', name: trainable, type: bool}
  source: "class SeparableConv1D(_SeparableConv):\n    \"\"\"Depthwise separable 1D\
    \ convolution.\n\n    Separable convolutions consist in first performing\n   \
    \ a depthwise spatial convolution\n    (which acts on each input channel separately)\n\
    \    followed by a pointwise convolution which mixes together the resulting\n\
    \    output channels. The `depth_multiplier` argument controls how many\n    output\
    \ channels are generated per input channel in the depthwise step.\n\n    Intuitively,\
    \ separable convolutions can be understood as\n    a way to factorize a convolution\
    \ kernel into two smaller kernels,\n    or as an extreme version of an Inception\
    \ block.\n\n    # Arguments\n        filters: Integer, the dimensionality of the\
    \ output space\n            (i.e. the number of output filters in the convolution).\n\
    \        kernel_size: An integer or tuple/list of single integer,\n          \
    \  specifying the length of the 1D convolution window.\n        strides: An integer\
    \ or tuple/list of single integer,\n            specifying the stride length of\
    \ the convolution.\n            Specifying any stride value != 1 is incompatible\
    \ with specifying\n            any `dilation_rate` value != 1.\n        padding:\
    \ one of `\"valid\"` or `\"same\"` (case-insensitive).\n        data_format: A\
    \ string,\n            one of `\"channels_last\"` or `\"channels_first\"`.\n \
    \           The ordering of the dimensions in the inputs.\n            `\"channels_last\"\
    ` corresponds to inputs with shape\n            `(batch, steps, channels)` while\
    \ `\"channels_first\"`\n            corresponds to inputs with shape\n       \
    \     `(batch, channels, steps)`.\n        dilation_rate: An integer or tuple/list\
    \ of a single integer, specifying\n            the dilation rate to use for dilated\
    \ convolution.\n            Currently, specifying any `dilation_rate` value !=\
    \ 1 is\n            incompatible with specifying any `strides` value != 1.\n \
    \       depth_multiplier: The number of depthwise convolution output channels\n\
    \            for each input channel.\n            The total number of depthwise\
    \ convolution output\n            channels will be equal to `filters_in * depth_multiplier`.\n\
    \        activation: Activation function to use\n            (see [activations](../activations.md)).\n\
    \            If you don't specify anything, no activation is applied\n       \
    \     (ie. \"linear\" activation: `a(x) = x`).\n        use_bias: Boolean, whether\
    \ the layer uses a bias vector.\n        depthwise_initializer: Initializer for\
    \ the depthwise kernel matrix\n            (see [initializers](../initializers.md)).\n\
    \        pointwise_initializer: Initializer for the pointwise kernel matrix\n\
    \            (see [initializers](../initializers.md)).\n        bias_initializer:\
    \ Initializer for the bias vector\n            (see [initializers](../initializers.md)).\n\
    \        depthwise_regularizer: Regularizer function applied to\n            the\
    \ depthwise kernel matrix\n            (see [regularizer](../regularizers.md)).\n\
    \        pointwise_regularizer: Regularizer function applied to\n            the\
    \ pointwise kernel matrix\n            (see [regularizer](../regularizers.md)).\n\
    \        bias_regularizer: Regularizer function applied to the bias vector\n \
    \           (see [regularizer](../regularizers.md)).\n        activity_regularizer:\
    \ Regularizer function applied to\n            the output of the layer (its \"\
    activation\").\n            (see [regularizer](../regularizers.md)).\n       \
    \ depthwise_constraint: Constraint function applied to\n            the depthwise\
    \ kernel matrix\n            (see [constraints](../constraints.md)).\n       \
    \ pointwise_constraint: Constraint function applied to\n            the pointwise\
    \ kernel matrix\n            (see [constraints](../constraints.md)).\n       \
    \ bias_constraint: Constraint function applied to the bias vector\n          \
    \  (see [constraints](../constraints.md)).\n\n    # Input shape\n        3D tensor\
    \ with shape:\n        `(batch, channels, steps)`\n        if `data_format` is\
    \ `\"channels_first\"`\n        or 3D tensor with shape:\n        `(batch, steps,\
    \ channels)`\n        if `data_format` is `\"channels_last\"`.\n\n    # Output\
    \ shape\n        3D tensor with shape:\n        `(batch, filters, new_steps)`\n\
    \        if `data_format` is `\"channels_first\"`\n        or 3D tensor with shape:\n\
    \        `(batch, new_steps, filters)`\n        if `data_format` is `\"channels_last\"\
    `.\n        `new_steps` values might have changed due to padding or strides.\n\
    \    \"\"\"\n\n    def __init__(self, filters,\n                 kernel_size,\n\
    \                 strides=1,\n                 padding='valid',\n            \
    \     data_format='channels_last',\n                 dilation_rate=1,\n      \
    \           depth_multiplier=1,\n                 activation=None,\n         \
    \        use_bias=True,\n                 depthwise_initializer='glorot_uniform',\n\
    \                 pointwise_initializer='glorot_uniform',\n                 bias_initializer='zeros',\n\
    \                 depthwise_regularizer=None,\n                 pointwise_regularizer=None,\n\
    \                 bias_regularizer=None,\n                 activity_regularizer=None,\n\
    \                 depthwise_constraint=None,\n                 pointwise_constraint=None,\n\
    \                 bias_constraint=None,\n                 **kwargs):\n       \
    \ super(SeparableConv1D, self).__init__(\n            rank=1,\n            filters=filters,\n\
    \            kernel_size=kernel_size,\n            strides=strides,\n        \
    \    padding=padding,\n            data_format=data_format,\n            dilation_rate=dilation_rate,\n\
    \            depth_multiplier=depth_multiplier,\n            activation=activation,\n\
    \            use_bias=use_bias,\n            depthwise_initializer=depthwise_initializer,\n\
    \            pointwise_initializer=pointwise_initializer,\n            bias_initializer=bias_initializer,\n\
    \            depthwise_regularizer=depthwise_regularizer,\n            pointwise_regularizer=pointwise_regularizer,\n\
    \            bias_regularizer=bias_regularizer,\n            activity_regularizer=activity_regularizer,\n\
    \            depthwise_constraint=depthwise_constraint,\n            pointwise_constraint=pointwise_constraint,\n\
    \            bias_constraint=bias_constraint,\n            **kwargs)\n"
  sourcefile: D:\Python36\lib\site-packages\keras\layers\convolutional.py
- doc: "Depthwise separable 2D convolution.\n\nSeparable convolutions consist in first\
    \ performing\na depthwise spatial convolution\n(which acts on each input channel\
    \ separately)\nfollowed by a pointwise convolution which mixes together the resulting\n\
    output channels. The `depth_multiplier` argument controls how many\noutput channels\
    \ are generated per input channel in the depthwise step.\n\nIntuitively, separable\
    \ convolutions can be understood as\na way to factorize a convolution kernel into\
    \ two smaller kernels,\nor as an extreme version of an Inception block.\n\n# Arguments\n\
    \    filters: Integer, the dimensionality of the output space\n        (i.e. the\
    \ number of output filters in the convolution).\n    kernel_size: An integer or\
    \ tuple/list of 2 integers, specifying the\n        height and width of the 2D\
    \ convolution window.\n        Can be a single integer to specify the same value\
    \ for\n        all spatial dimensions.\n    strides: An integer or tuple/list\
    \ of 2 integers,\n        specifying the strides of the convolution\n        along\
    \ the height and width.\n        Can be a single integer to specify the same value\
    \ for\n        all spatial dimensions.\n        Specifying any stride value !=\
    \ 1 is incompatible with specifying\n        any `dilation_rate` value != 1.\n\
    \    padding: one of `\"valid\"` or `\"same\"` (case-insensitive).\n    data_format:\
    \ A string,\n        one of `\"channels_last\"` or `\"channels_first\"`.\n   \
    \     The ordering of the dimensions in the inputs.\n        `\"channels_last\"\
    ` corresponds to inputs with shape\n        `(batch, height, width, channels)`\
    \ while `\"channels_first\"`\n        corresponds to inputs with shape\n     \
    \   `(batch, channels, height, width)`.\n        It defaults to the `image_data_format`\
    \ value found in your\n        Keras config file at `~/.keras/keras.json`.\n \
    \       If you never set it, then it will be \"channels_last\".\n    dilation_rate:\
    \ An integer or tuple/list of 2 integers, specifying\n        the dilation rate\
    \ to use for dilated convolution.\n        Currently, specifying any `dilation_rate`\
    \ value != 1 is\n        incompatible with specifying any `strides` value != 1.\n\
    \    depth_multiplier: The number of depthwise convolution output channels\n \
    \       for each input channel.\n        The total number of depthwise convolution\
    \ output\n        channels will be equal to `filters_in * depth_multiplier`.\n\
    \    activation: Activation function to use\n        (see [activations](../activations.md)).\n\
    \        If you don't specify anything, no activation is applied\n        (ie.\
    \ \"linear\" activation: `a(x) = x`).\n    use_bias: Boolean, whether the layer\
    \ uses a bias vector.\n    depthwise_initializer: Initializer for the depthwise\
    \ kernel matrix\n        (see [initializers](../initializers.md)).\n    pointwise_initializer:\
    \ Initializer for the pointwise kernel matrix\n        (see [initializers](../initializers.md)).\n\
    \    bias_initializer: Initializer for the bias vector\n        (see [initializers](../initializers.md)).\n\
    \    depthwise_regularizer: Regularizer function applied to\n        the depthwise\
    \ kernel matrix\n        (see [regularizer](../regularizers.md)).\n    pointwise_regularizer:\
    \ Regularizer function applied to\n        the pointwise kernel matrix\n     \
    \   (see [regularizer](../regularizers.md)).\n    bias_regularizer: Regularizer\
    \ function applied to the bias vector\n        (see [regularizer](../regularizers.md)).\n\
    \    activity_regularizer: Regularizer function applied to\n        the output\
    \ of the layer (its \"activation\").\n        (see [regularizer](../regularizers.md)).\n\
    \    depthwise_constraint: Constraint function applied to\n        the depthwise\
    \ kernel matrix\n        (see [constraints](../constraints.md)).\n    pointwise_constraint:\
    \ Constraint function applied to\n        the pointwise kernel matrix\n      \
    \  (see [constraints](../constraints.md)).\n    bias_constraint: Constraint function\
    \ applied to the bias vector\n        (see [constraints](../constraints.md)).\n\
    \n# Input shape\n    4D tensor with shape:\n    `(batch, channels, rows, cols)`\n\
    \    if `data_format` is `\"channels_first\"`\n    or 4D tensor with shape:\n\
    \    `(batch, rows, cols, channels)`\n    if `data_format` is `\"channels_last\"\
    `.\n\n# Output shape\n    4D tensor with shape:\n    `(batch, filters, new_rows,\
    \ new_cols)`\n    if `data_format` is `\"channels_first\"`\n    or 4D tensor with\
    \ shape:\n    `(batch, new_rows, new_cols, filters)`\n    if `data_format` is\
    \ `\"channels_last\"`.\n    `rows` and `cols` values might have changed due to\
    \ padding."
  kind: Layer
  name: SeparableConv2D
  parameters:
  - {kind: any, name: filters}
  - {kind: any, name: kernel_size}
  - {defaultValue: '(1, 1)', kind: any, name: strides}
  - {defaultValue: valid, kind: any, name: padding}
  - {defaultValue: None, kind: any, name: data_format}
  - {defaultValue: '(1, 1)', kind: any, name: dilation_rate}
  - {defaultValue: '1', kind: any, name: depth_multiplier}
  - {defaultValue: None, kind: any, name: activation}
  - {defaultValue: 'True', kind: any, name: use_bias}
  - {defaultValue: glorot_uniform, kind: any, name: depthwise_initializer}
  - {defaultValue: glorot_uniform, kind: any, name: pointwise_initializer}
  - {defaultValue: zeros, kind: any, name: bias_initializer}
  - {defaultValue: None, kind: any, name: depthwise_regularizer}
  - {defaultValue: None, kind: any, name: pointwise_regularizer}
  - {defaultValue: None, kind: any, name: bias_regularizer}
  - {defaultValue: None, kind: any, name: activity_regularizer}
  - {defaultValue: None, kind: any, name: depthwise_constraint}
  - {defaultValue: None, kind: any, name: pointwise_constraint}
  - {defaultValue: None, kind: any, name: bias_constraint}
  - {defaultValue: 'true', name: trainable, type: bool}
  source: "class SeparableConv2D(_SeparableConv):\n    \"\"\"Depthwise separable 2D\
    \ convolution.\n\n    Separable convolutions consist in first performing\n   \
    \ a depthwise spatial convolution\n    (which acts on each input channel separately)\n\
    \    followed by a pointwise convolution which mixes together the resulting\n\
    \    output channels. The `depth_multiplier` argument controls how many\n    output\
    \ channels are generated per input channel in the depthwise step.\n\n    Intuitively,\
    \ separable convolutions can be understood as\n    a way to factorize a convolution\
    \ kernel into two smaller kernels,\n    or as an extreme version of an Inception\
    \ block.\n\n    # Arguments\n        filters: Integer, the dimensionality of the\
    \ output space\n            (i.e. the number of output filters in the convolution).\n\
    \        kernel_size: An integer or tuple/list of 2 integers, specifying the\n\
    \            height and width of the 2D convolution window.\n            Can be\
    \ a single integer to specify the same value for\n            all spatial dimensions.\n\
    \        strides: An integer or tuple/list of 2 integers,\n            specifying\
    \ the strides of the convolution\n            along the height and width.\n  \
    \          Can be a single integer to specify the same value for\n           \
    \ all spatial dimensions.\n            Specifying any stride value != 1 is incompatible\
    \ with specifying\n            any `dilation_rate` value != 1.\n        padding:\
    \ one of `\"valid\"` or `\"same\"` (case-insensitive).\n        data_format: A\
    \ string,\n            one of `\"channels_last\"` or `\"channels_first\"`.\n \
    \           The ordering of the dimensions in the inputs.\n            `\"channels_last\"\
    ` corresponds to inputs with shape\n            `(batch, height, width, channels)`\
    \ while `\"channels_first\"`\n            corresponds to inputs with shape\n \
    \           `(batch, channels, height, width)`.\n            It defaults to the\
    \ `image_data_format` value found in your\n            Keras config file at `~/.keras/keras.json`.\n\
    \            If you never set it, then it will be \"channels_last\".\n       \
    \ dilation_rate: An integer or tuple/list of 2 integers, specifying\n        \
    \    the dilation rate to use for dilated convolution.\n            Currently,\
    \ specifying any `dilation_rate` value != 1 is\n            incompatible with\
    \ specifying any `strides` value != 1.\n        depth_multiplier: The number of\
    \ depthwise convolution output channels\n            for each input channel.\n\
    \            The total number of depthwise convolution output\n            channels\
    \ will be equal to `filters_in * depth_multiplier`.\n        activation: Activation\
    \ function to use\n            (see [activations](../activations.md)).\n     \
    \       If you don't specify anything, no activation is applied\n            (ie.\
    \ \"linear\" activation: `a(x) = x`).\n        use_bias: Boolean, whether the\
    \ layer uses a bias vector.\n        depthwise_initializer: Initializer for the\
    \ depthwise kernel matrix\n            (see [initializers](../initializers.md)).\n\
    \        pointwise_initializer: Initializer for the pointwise kernel matrix\n\
    \            (see [initializers](../initializers.md)).\n        bias_initializer:\
    \ Initializer for the bias vector\n            (see [initializers](../initializers.md)).\n\
    \        depthwise_regularizer: Regularizer function applied to\n            the\
    \ depthwise kernel matrix\n            (see [regularizer](../regularizers.md)).\n\
    \        pointwise_regularizer: Regularizer function applied to\n            the\
    \ pointwise kernel matrix\n            (see [regularizer](../regularizers.md)).\n\
    \        bias_regularizer: Regularizer function applied to the bias vector\n \
    \           (see [regularizer](../regularizers.md)).\n        activity_regularizer:\
    \ Regularizer function applied to\n            the output of the layer (its \"\
    activation\").\n            (see [regularizer](../regularizers.md)).\n       \
    \ depthwise_constraint: Constraint function applied to\n            the depthwise\
    \ kernel matrix\n            (see [constraints](../constraints.md)).\n       \
    \ pointwise_constraint: Constraint function applied to\n            the pointwise\
    \ kernel matrix\n            (see [constraints](../constraints.md)).\n       \
    \ bias_constraint: Constraint function applied to the bias vector\n          \
    \  (see [constraints](../constraints.md)).\n\n    # Input shape\n        4D tensor\
    \ with shape:\n        `(batch, channels, rows, cols)`\n        if `data_format`\
    \ is `\"channels_first\"`\n        or 4D tensor with shape:\n        `(batch,\
    \ rows, cols, channels)`\n        if `data_format` is `\"channels_last\"`.\n\n\
    \    # Output shape\n        4D tensor with shape:\n        `(batch, filters,\
    \ new_rows, new_cols)`\n        if `data_format` is `\"channels_first\"`\n   \
    \     or 4D tensor with shape:\n        `(batch, new_rows, new_cols, filters)`\n\
    \        if `data_format` is `\"channels_last\"`.\n        `rows` and `cols` values\
    \ might have changed due to padding.\n    \"\"\"\n\n    @interfaces.legacy_separable_conv2d_support\n\
    \    def __init__(self, filters,\n                 kernel_size,\n            \
    \     strides=(1, 1),\n                 padding='valid',\n                 data_format=None,\n\
    \                 dilation_rate=(1, 1),\n                 depth_multiplier=1,\n\
    \                 activation=None,\n                 use_bias=True,\n        \
    \         depthwise_initializer='glorot_uniform',\n                 pointwise_initializer='glorot_uniform',\n\
    \                 bias_initializer='zeros',\n                 depthwise_regularizer=None,\n\
    \                 pointwise_regularizer=None,\n                 bias_regularizer=None,\n\
    \                 activity_regularizer=None,\n                 depthwise_constraint=None,\n\
    \                 pointwise_constraint=None,\n                 bias_constraint=None,\n\
    \                 **kwargs):\n        super(SeparableConv2D, self).__init__(\n\
    \            rank=2,\n            filters=filters,\n            kernel_size=kernel_size,\n\
    \            strides=strides,\n            padding=padding,\n            data_format=data_format,\n\
    \            dilation_rate=dilation_rate,\n            depth_multiplier=depth_multiplier,\n\
    \            activation=activation,\n            use_bias=use_bias,\n        \
    \    depthwise_initializer=depthwise_initializer,\n            pointwise_initializer=pointwise_initializer,\n\
    \            bias_initializer=bias_initializer,\n            depthwise_regularizer=depthwise_regularizer,\n\
    \            pointwise_regularizer=pointwise_regularizer,\n            bias_regularizer=bias_regularizer,\n\
    \            activity_regularizer=activity_regularizer,\n            depthwise_constraint=depthwise_constraint,\n\
    \            pointwise_constraint=pointwise_constraint,\n            bias_constraint=bias_constraint,\n\
    \            **kwargs)\n"
  sourcefile: D:\Python36\lib\site-packages\keras\layers\convolutional.py
- doc: "Depthwise separable 1D convolution.\n\nSeparable convolutions consist in first\
    \ performing\na depthwise spatial convolution\n(which acts on each input channel\
    \ separately)\nfollowed by a pointwise convolution which mixes together the resulting\n\
    output channels. The `depth_multiplier` argument controls how many\noutput channels\
    \ are generated per input channel in the depthwise step.\n\nIntuitively, separable\
    \ convolutions can be understood as\na way to factorize a convolution kernel into\
    \ two smaller kernels,\nor as an extreme version of an Inception block.\n\n# Arguments\n\
    \    filters: Integer, the dimensionality of the output space\n        (i.e. the\
    \ number of output filters in the convolution).\n    kernel_size: An integer or\
    \ tuple/list of single integer,\n        specifying the length of the 1D convolution\
    \ window.\n    strides: An integer or tuple/list of single integer,\n        specifying\
    \ the stride length of the convolution.\n        Specifying any stride value !=\
    \ 1 is incompatible with specifying\n        any `dilation_rate` value != 1.\n\
    \    padding: one of `\"valid\"` or `\"same\"` (case-insensitive).\n    data_format:\
    \ A string,\n        one of `\"channels_last\"` or `\"channels_first\"`.\n   \
    \     The ordering of the dimensions in the inputs.\n        `\"channels_last\"\
    ` corresponds to inputs with shape\n        `(batch, steps, channels)` while `\"\
    channels_first\"`\n        corresponds to inputs with shape\n        `(batch,\
    \ channels, steps)`.\n    dilation_rate: An integer or tuple/list of a single\
    \ integer, specifying\n        the dilation rate to use for dilated convolution.\n\
    \        Currently, specifying any `dilation_rate` value != 1 is\n        incompatible\
    \ with specifying any `strides` value != 1.\n    depth_multiplier: The number\
    \ of depthwise convolution output channels\n        for each input channel.\n\
    \        The total number of depthwise convolution output\n        channels will\
    \ be equal to `filters_in * depth_multiplier`.\n    activation: Activation function\
    \ to use\n        (see [activations](../activations.md)).\n        If you don't\
    \ specify anything, no activation is applied\n        (ie. \"linear\" activation:\
    \ `a(x) = x`).\n    use_bias: Boolean, whether the layer uses a bias vector.\n\
    \    depthwise_initializer: Initializer for the depthwise kernel matrix\n    \
    \    (see [initializers](../initializers.md)).\n    pointwise_initializer: Initializer\
    \ for the pointwise kernel matrix\n        (see [initializers](../initializers.md)).\n\
    \    bias_initializer: Initializer for the bias vector\n        (see [initializers](../initializers.md)).\n\
    \    depthwise_regularizer: Regularizer function applied to\n        the depthwise\
    \ kernel matrix\n        (see [regularizer](../regularizers.md)).\n    pointwise_regularizer:\
    \ Regularizer function applied to\n        the pointwise kernel matrix\n     \
    \   (see [regularizer](../regularizers.md)).\n    bias_regularizer: Regularizer\
    \ function applied to the bias vector\n        (see [regularizer](../regularizers.md)).\n\
    \    activity_regularizer: Regularizer function applied to\n        the output\
    \ of the layer (its \"activation\").\n        (see [regularizer](../regularizers.md)).\n\
    \    depthwise_constraint: Constraint function applied to\n        the depthwise\
    \ kernel matrix\n        (see [constraints](../constraints.md)).\n    pointwise_constraint:\
    \ Constraint function applied to\n        the pointwise kernel matrix\n      \
    \  (see [constraints](../constraints.md)).\n    bias_constraint: Constraint function\
    \ applied to the bias vector\n        (see [constraints](../constraints.md)).\n\
    \n# Input shape\n    3D tensor with shape:\n    `(batch, channels, steps)`\n \
    \   if `data_format` is `\"channels_first\"`\n    or 3D tensor with shape:\n \
    \   `(batch, steps, channels)`\n    if `data_format` is `\"channels_last\"`.\n\
    \n# Output shape\n    3D tensor with shape:\n    `(batch, filters, new_steps)`\n\
    \    if `data_format` is `\"channels_first\"`\n    or 3D tensor with shape:\n\
    \    `(batch, new_steps, filters)`\n    if `data_format` is `\"channels_last\"\
    `.\n    `new_steps` values might have changed due to padding or strides."
  kind: Layer
  name: SeparableConv1D
  parameters:
  - {kind: any, name: filters}
  - {kind: any, name: kernel_size}
  - {defaultValue: '1', kind: any, name: strides}
  - {defaultValue: valid, kind: any, name: padding}
  - {defaultValue: channels_last, kind: any, name: data_format}
  - {defaultValue: '1', kind: any, name: dilation_rate}
  - {defaultValue: '1', kind: any, name: depth_multiplier}
  - {defaultValue: None, kind: any, name: activation}
  - {defaultValue: 'True', kind: any, name: use_bias}
  - {defaultValue: glorot_uniform, kind: any, name: depthwise_initializer}
  - {defaultValue: glorot_uniform, kind: any, name: pointwise_initializer}
  - {defaultValue: zeros, kind: any, name: bias_initializer}
  - {defaultValue: None, kind: any, name: depthwise_regularizer}
  - {defaultValue: None, kind: any, name: pointwise_regularizer}
  - {defaultValue: None, kind: any, name: bias_regularizer}
  - {defaultValue: None, kind: any, name: activity_regularizer}
  - {defaultValue: None, kind: any, name: depthwise_constraint}
  - {defaultValue: None, kind: any, name: pointwise_constraint}
  - {defaultValue: None, kind: any, name: bias_constraint}
  - {defaultValue: 'true', name: trainable, type: bool}
  source: "class SeparableConv1D(_SeparableConv):\n    \"\"\"Depthwise separable 1D\
    \ convolution.\n\n    Separable convolutions consist in first performing\n   \
    \ a depthwise spatial convolution\n    (which acts on each input channel separately)\n\
    \    followed by a pointwise convolution which mixes together the resulting\n\
    \    output channels. The `depth_multiplier` argument controls how many\n    output\
    \ channels are generated per input channel in the depthwise step.\n\n    Intuitively,\
    \ separable convolutions can be understood as\n    a way to factorize a convolution\
    \ kernel into two smaller kernels,\n    or as an extreme version of an Inception\
    \ block.\n\n    # Arguments\n        filters: Integer, the dimensionality of the\
    \ output space\n            (i.e. the number of output filters in the convolution).\n\
    \        kernel_size: An integer or tuple/list of single integer,\n          \
    \  specifying the length of the 1D convolution window.\n        strides: An integer\
    \ or tuple/list of single integer,\n            specifying the stride length of\
    \ the convolution.\n            Specifying any stride value != 1 is incompatible\
    \ with specifying\n            any `dilation_rate` value != 1.\n        padding:\
    \ one of `\"valid\"` or `\"same\"` (case-insensitive).\n        data_format: A\
    \ string,\n            one of `\"channels_last\"` or `\"channels_first\"`.\n \
    \           The ordering of the dimensions in the inputs.\n            `\"channels_last\"\
    ` corresponds to inputs with shape\n            `(batch, steps, channels)` while\
    \ `\"channels_first\"`\n            corresponds to inputs with shape\n       \
    \     `(batch, channels, steps)`.\n        dilation_rate: An integer or tuple/list\
    \ of a single integer, specifying\n            the dilation rate to use for dilated\
    \ convolution.\n            Currently, specifying any `dilation_rate` value !=\
    \ 1 is\n            incompatible with specifying any `strides` value != 1.\n \
    \       depth_multiplier: The number of depthwise convolution output channels\n\
    \            for each input channel.\n            The total number of depthwise\
    \ convolution output\n            channels will be equal to `filters_in * depth_multiplier`.\n\
    \        activation: Activation function to use\n            (see [activations](../activations.md)).\n\
    \            If you don't specify anything, no activation is applied\n       \
    \     (ie. \"linear\" activation: `a(x) = x`).\n        use_bias: Boolean, whether\
    \ the layer uses a bias vector.\n        depthwise_initializer: Initializer for\
    \ the depthwise kernel matrix\n            (see [initializers](../initializers.md)).\n\
    \        pointwise_initializer: Initializer for the pointwise kernel matrix\n\
    \            (see [initializers](../initializers.md)).\n        bias_initializer:\
    \ Initializer for the bias vector\n            (see [initializers](../initializers.md)).\n\
    \        depthwise_regularizer: Regularizer function applied to\n            the\
    \ depthwise kernel matrix\n            (see [regularizer](../regularizers.md)).\n\
    \        pointwise_regularizer: Regularizer function applied to\n            the\
    \ pointwise kernel matrix\n            (see [regularizer](../regularizers.md)).\n\
    \        bias_regularizer: Regularizer function applied to the bias vector\n \
    \           (see [regularizer](../regularizers.md)).\n        activity_regularizer:\
    \ Regularizer function applied to\n            the output of the layer (its \"\
    activation\").\n            (see [regularizer](../regularizers.md)).\n       \
    \ depthwise_constraint: Constraint function applied to\n            the depthwise\
    \ kernel matrix\n            (see [constraints](../constraints.md)).\n       \
    \ pointwise_constraint: Constraint function applied to\n            the pointwise\
    \ kernel matrix\n            (see [constraints](../constraints.md)).\n       \
    \ bias_constraint: Constraint function applied to the bias vector\n          \
    \  (see [constraints](../constraints.md)).\n\n    # Input shape\n        3D tensor\
    \ with shape:\n        `(batch, channels, steps)`\n        if `data_format` is\
    \ `\"channels_first\"`\n        or 3D tensor with shape:\n        `(batch, steps,\
    \ channels)`\n        if `data_format` is `\"channels_last\"`.\n\n    # Output\
    \ shape\n        3D tensor with shape:\n        `(batch, filters, new_steps)`\n\
    \        if `data_format` is `\"channels_first\"`\n        or 3D tensor with shape:\n\
    \        `(batch, new_steps, filters)`\n        if `data_format` is `\"channels_last\"\
    `.\n        `new_steps` values might have changed due to padding or strides.\n\
    \    \"\"\"\n\n    def __init__(self, filters,\n                 kernel_size,\n\
    \                 strides=1,\n                 padding='valid',\n            \
    \     data_format='channels_last',\n                 dilation_rate=1,\n      \
    \           depth_multiplier=1,\n                 activation=None,\n         \
    \        use_bias=True,\n                 depthwise_initializer='glorot_uniform',\n\
    \                 pointwise_initializer='glorot_uniform',\n                 bias_initializer='zeros',\n\
    \                 depthwise_regularizer=None,\n                 pointwise_regularizer=None,\n\
    \                 bias_regularizer=None,\n                 activity_regularizer=None,\n\
    \                 depthwise_constraint=None,\n                 pointwise_constraint=None,\n\
    \                 bias_constraint=None,\n                 **kwargs):\n       \
    \ super(SeparableConv1D, self).__init__(\n            rank=1,\n            filters=filters,\n\
    \            kernel_size=kernel_size,\n            strides=strides,\n        \
    \    padding=padding,\n            data_format=data_format,\n            dilation_rate=dilation_rate,\n\
    \            depth_multiplier=depth_multiplier,\n            activation=activation,\n\
    \            use_bias=use_bias,\n            depthwise_initializer=depthwise_initializer,\n\
    \            pointwise_initializer=pointwise_initializer,\n            bias_initializer=bias_initializer,\n\
    \            depthwise_regularizer=depthwise_regularizer,\n            pointwise_regularizer=pointwise_regularizer,\n\
    \            bias_regularizer=bias_regularizer,\n            activity_regularizer=activity_regularizer,\n\
    \            depthwise_constraint=depthwise_constraint,\n            pointwise_constraint=pointwise_constraint,\n\
    \            bias_constraint=bias_constraint,\n            **kwargs)\n"
  sourcefile: D:\Python36\lib\site-packages\keras\layers\convolutional.py
- doc: "Depthwise separable 2D convolution.\n\nSeparable convolutions consist in first\
    \ performing\na depthwise spatial convolution\n(which acts on each input channel\
    \ separately)\nfollowed by a pointwise convolution which mixes together the resulting\n\
    output channels. The `depth_multiplier` argument controls how many\noutput channels\
    \ are generated per input channel in the depthwise step.\n\nIntuitively, separable\
    \ convolutions can be understood as\na way to factorize a convolution kernel into\
    \ two smaller kernels,\nor as an extreme version of an Inception block.\n\n# Arguments\n\
    \    filters: Integer, the dimensionality of the output space\n        (i.e. the\
    \ number of output filters in the convolution).\n    kernel_size: An integer or\
    \ tuple/list of 2 integers, specifying the\n        height and width of the 2D\
    \ convolution window.\n        Can be a single integer to specify the same value\
    \ for\n        all spatial dimensions.\n    strides: An integer or tuple/list\
    \ of 2 integers,\n        specifying the strides of the convolution\n        along\
    \ the height and width.\n        Can be a single integer to specify the same value\
    \ for\n        all spatial dimensions.\n        Specifying any stride value !=\
    \ 1 is incompatible with specifying\n        any `dilation_rate` value != 1.\n\
    \    padding: one of `\"valid\"` or `\"same\"` (case-insensitive).\n    data_format:\
    \ A string,\n        one of `\"channels_last\"` or `\"channels_first\"`.\n   \
    \     The ordering of the dimensions in the inputs.\n        `\"channels_last\"\
    ` corresponds to inputs with shape\n        `(batch, height, width, channels)`\
    \ while `\"channels_first\"`\n        corresponds to inputs with shape\n     \
    \   `(batch, channels, height, width)`.\n        It defaults to the `image_data_format`\
    \ value found in your\n        Keras config file at `~/.keras/keras.json`.\n \
    \       If you never set it, then it will be \"channels_last\".\n    dilation_rate:\
    \ An integer or tuple/list of 2 integers, specifying\n        the dilation rate\
    \ to use for dilated convolution.\n        Currently, specifying any `dilation_rate`\
    \ value != 1 is\n        incompatible with specifying any `strides` value != 1.\n\
    \    depth_multiplier: The number of depthwise convolution output channels\n \
    \       for each input channel.\n        The total number of depthwise convolution\
    \ output\n        channels will be equal to `filters_in * depth_multiplier`.\n\
    \    activation: Activation function to use\n        (see [activations](../activations.md)).\n\
    \        If you don't specify anything, no activation is applied\n        (ie.\
    \ \"linear\" activation: `a(x) = x`).\n    use_bias: Boolean, whether the layer\
    \ uses a bias vector.\n    depthwise_initializer: Initializer for the depthwise\
    \ kernel matrix\n        (see [initializers](../initializers.md)).\n    pointwise_initializer:\
    \ Initializer for the pointwise kernel matrix\n        (see [initializers](../initializers.md)).\n\
    \    bias_initializer: Initializer for the bias vector\n        (see [initializers](../initializers.md)).\n\
    \    depthwise_regularizer: Regularizer function applied to\n        the depthwise\
    \ kernel matrix\n        (see [regularizer](../regularizers.md)).\n    pointwise_regularizer:\
    \ Regularizer function applied to\n        the pointwise kernel matrix\n     \
    \   (see [regularizer](../regularizers.md)).\n    bias_regularizer: Regularizer\
    \ function applied to the bias vector\n        (see [regularizer](../regularizers.md)).\n\
    \    activity_regularizer: Regularizer function applied to\n        the output\
    \ of the layer (its \"activation\").\n        (see [regularizer](../regularizers.md)).\n\
    \    depthwise_constraint: Constraint function applied to\n        the depthwise\
    \ kernel matrix\n        (see [constraints](../constraints.md)).\n    pointwise_constraint:\
    \ Constraint function applied to\n        the pointwise kernel matrix\n      \
    \  (see [constraints](../constraints.md)).\n    bias_constraint: Constraint function\
    \ applied to the bias vector\n        (see [constraints](../constraints.md)).\n\
    \n# Input shape\n    4D tensor with shape:\n    `(batch, channels, rows, cols)`\n\
    \    if `data_format` is `\"channels_first\"`\n    or 4D tensor with shape:\n\
    \    `(batch, rows, cols, channels)`\n    if `data_format` is `\"channels_last\"\
    `.\n\n# Output shape\n    4D tensor with shape:\n    `(batch, filters, new_rows,\
    \ new_cols)`\n    if `data_format` is `\"channels_first\"`\n    or 4D tensor with\
    \ shape:\n    `(batch, new_rows, new_cols, filters)`\n    if `data_format` is\
    \ `\"channels_last\"`.\n    `rows` and `cols` values might have changed due to\
    \ padding."
  kind: Layer
  name: SeparableConv2D
  parameters:
  - {kind: any, name: filters}
  - {kind: any, name: kernel_size}
  - {defaultValue: '(1, 1)', kind: any, name: strides}
  - {defaultValue: valid, kind: any, name: padding}
  - {defaultValue: None, kind: any, name: data_format}
  - {defaultValue: '(1, 1)', kind: any, name: dilation_rate}
  - {defaultValue: '1', kind: any, name: depth_multiplier}
  - {defaultValue: None, kind: any, name: activation}
  - {defaultValue: 'True', kind: any, name: use_bias}
  - {defaultValue: glorot_uniform, kind: any, name: depthwise_initializer}
  - {defaultValue: glorot_uniform, kind: any, name: pointwise_initializer}
  - {defaultValue: zeros, kind: any, name: bias_initializer}
  - {defaultValue: None, kind: any, name: depthwise_regularizer}
  - {defaultValue: None, kind: any, name: pointwise_regularizer}
  - {defaultValue: None, kind: any, name: bias_regularizer}
  - {defaultValue: None, kind: any, name: activity_regularizer}
  - {defaultValue: None, kind: any, name: depthwise_constraint}
  - {defaultValue: None, kind: any, name: pointwise_constraint}
  - {defaultValue: None, kind: any, name: bias_constraint}
  - {defaultValue: 'true', name: trainable, type: bool}
  source: "class SeparableConv2D(_SeparableConv):\n    \"\"\"Depthwise separable 2D\
    \ convolution.\n\n    Separable convolutions consist in first performing\n   \
    \ a depthwise spatial convolution\n    (which acts on each input channel separately)\n\
    \    followed by a pointwise convolution which mixes together the resulting\n\
    \    output channels. The `depth_multiplier` argument controls how many\n    output\
    \ channels are generated per input channel in the depthwise step.\n\n    Intuitively,\
    \ separable convolutions can be understood as\n    a way to factorize a convolution\
    \ kernel into two smaller kernels,\n    or as an extreme version of an Inception\
    \ block.\n\n    # Arguments\n        filters: Integer, the dimensionality of the\
    \ output space\n            (i.e. the number of output filters in the convolution).\n\
    \        kernel_size: An integer or tuple/list of 2 integers, specifying the\n\
    \            height and width of the 2D convolution window.\n            Can be\
    \ a single integer to specify the same value for\n            all spatial dimensions.\n\
    \        strides: An integer or tuple/list of 2 integers,\n            specifying\
    \ the strides of the convolution\n            along the height and width.\n  \
    \          Can be a single integer to specify the same value for\n           \
    \ all spatial dimensions.\n            Specifying any stride value != 1 is incompatible\
    \ with specifying\n            any `dilation_rate` value != 1.\n        padding:\
    \ one of `\"valid\"` or `\"same\"` (case-insensitive).\n        data_format: A\
    \ string,\n            one of `\"channels_last\"` or `\"channels_first\"`.\n \
    \           The ordering of the dimensions in the inputs.\n            `\"channels_last\"\
    ` corresponds to inputs with shape\n            `(batch, height, width, channels)`\
    \ while `\"channels_first\"`\n            corresponds to inputs with shape\n \
    \           `(batch, channels, height, width)`.\n            It defaults to the\
    \ `image_data_format` value found in your\n            Keras config file at `~/.keras/keras.json`.\n\
    \            If you never set it, then it will be \"channels_last\".\n       \
    \ dilation_rate: An integer or tuple/list of 2 integers, specifying\n        \
    \    the dilation rate to use for dilated convolution.\n            Currently,\
    \ specifying any `dilation_rate` value != 1 is\n            incompatible with\
    \ specifying any `strides` value != 1.\n        depth_multiplier: The number of\
    \ depthwise convolution output channels\n            for each input channel.\n\
    \            The total number of depthwise convolution output\n            channels\
    \ will be equal to `filters_in * depth_multiplier`.\n        activation: Activation\
    \ function to use\n            (see [activations](../activations.md)).\n     \
    \       If you don't specify anything, no activation is applied\n            (ie.\
    \ \"linear\" activation: `a(x) = x`).\n        use_bias: Boolean, whether the\
    \ layer uses a bias vector.\n        depthwise_initializer: Initializer for the\
    \ depthwise kernel matrix\n            (see [initializers](../initializers.md)).\n\
    \        pointwise_initializer: Initializer for the pointwise kernel matrix\n\
    \            (see [initializers](../initializers.md)).\n        bias_initializer:\
    \ Initializer for the bias vector\n            (see [initializers](../initializers.md)).\n\
    \        depthwise_regularizer: Regularizer function applied to\n            the\
    \ depthwise kernel matrix\n            (see [regularizer](../regularizers.md)).\n\
    \        pointwise_regularizer: Regularizer function applied to\n            the\
    \ pointwise kernel matrix\n            (see [regularizer](../regularizers.md)).\n\
    \        bias_regularizer: Regularizer function applied to the bias vector\n \
    \           (see [regularizer](../regularizers.md)).\n        activity_regularizer:\
    \ Regularizer function applied to\n            the output of the layer (its \"\
    activation\").\n            (see [regularizer](../regularizers.md)).\n       \
    \ depthwise_constraint: Constraint function applied to\n            the depthwise\
    \ kernel matrix\n            (see [constraints](../constraints.md)).\n       \
    \ pointwise_constraint: Constraint function applied to\n            the pointwise\
    \ kernel matrix\n            (see [constraints](../constraints.md)).\n       \
    \ bias_constraint: Constraint function applied to the bias vector\n          \
    \  (see [constraints](../constraints.md)).\n\n    # Input shape\n        4D tensor\
    \ with shape:\n        `(batch, channels, rows, cols)`\n        if `data_format`\
    \ is `\"channels_first\"`\n        or 4D tensor with shape:\n        `(batch,\
    \ rows, cols, channels)`\n        if `data_format` is `\"channels_last\"`.\n\n\
    \    # Output shape\n        4D tensor with shape:\n        `(batch, filters,\
    \ new_rows, new_cols)`\n        if `data_format` is `\"channels_first\"`\n   \
    \     or 4D tensor with shape:\n        `(batch, new_rows, new_cols, filters)`\n\
    \        if `data_format` is `\"channels_last\"`.\n        `rows` and `cols` values\
    \ might have changed due to padding.\n    \"\"\"\n\n    @interfaces.legacy_separable_conv2d_support\n\
    \    def __init__(self, filters,\n                 kernel_size,\n            \
    \     strides=(1, 1),\n                 padding='valid',\n                 data_format=None,\n\
    \                 dilation_rate=(1, 1),\n                 depth_multiplier=1,\n\
    \                 activation=None,\n                 use_bias=True,\n        \
    \         depthwise_initializer='glorot_uniform',\n                 pointwise_initializer='glorot_uniform',\n\
    \                 bias_initializer='zeros',\n                 depthwise_regularizer=None,\n\
    \                 pointwise_regularizer=None,\n                 bias_regularizer=None,\n\
    \                 activity_regularizer=None,\n                 depthwise_constraint=None,\n\
    \                 pointwise_constraint=None,\n                 bias_constraint=None,\n\
    \                 **kwargs):\n        super(SeparableConv2D, self).__init__(\n\
    \            rank=2,\n            filters=filters,\n            kernel_size=kernel_size,\n\
    \            strides=strides,\n            padding=padding,\n            data_format=data_format,\n\
    \            dilation_rate=dilation_rate,\n            depth_multiplier=depth_multiplier,\n\
    \            activation=activation,\n            use_bias=use_bias,\n        \
    \    depthwise_initializer=depthwise_initializer,\n            pointwise_initializer=pointwise_initializer,\n\
    \            bias_initializer=bias_initializer,\n            depthwise_regularizer=depthwise_regularizer,\n\
    \            pointwise_regularizer=pointwise_regularizer,\n            bias_regularizer=bias_regularizer,\n\
    \            activity_regularizer=activity_regularizer,\n            depthwise_constraint=depthwise_constraint,\n\
    \            pointwise_constraint=pointwise_constraint,\n            bias_constraint=bias_constraint,\n\
    \            **kwargs)\n"
  sourcefile: D:\Python36\lib\site-packages\keras\layers\convolutional.py
- doc: "Fully-connected RNN where the output is to be fed back to input.\n\n# Arguments\n\
    \    units: Positive integer, dimensionality of the output space.\n    activation:\
    \ Activation function to use\n        (see [activations](../activations.md)).\n\
    \        Default: hyperbolic tangent (`tanh`).\n        If you pass `None`, no\
    \ activation is applied\n        (ie. \"linear\" activation: `a(x) = x`).\n  \
    \  use_bias: Boolean, whether the layer uses a bias vector.\n    kernel_initializer:\
    \ Initializer for the `kernel` weights matrix,\n        used for the linear transformation\
    \ of the inputs\n        (see [initializers](../initializers.md)).\n    recurrent_initializer:\
    \ Initializer for the `recurrent_kernel`\n        weights matrix,\n        used\
    \ for the linear transformation of the recurrent state\n        (see [initializers](../initializers.md)).\n\
    \    bias_initializer: Initializer for the bias vector\n        (see [initializers](../initializers.md)).\n\
    \    kernel_regularizer: Regularizer function applied to\n        the `kernel`\
    \ weights matrix\n        (see [regularizer](../regularizers.md)).\n    recurrent_regularizer:\
    \ Regularizer function applied to\n        the `recurrent_kernel` weights matrix\n\
    \        (see [regularizer](../regularizers.md)).\n    bias_regularizer: Regularizer\
    \ function applied to the bias vector\n        (see [regularizer](../regularizers.md)).\n\
    \    activity_regularizer: Regularizer function applied to\n        the output\
    \ of the layer (its \"activation\").\n        (see [regularizer](../regularizers.md)).\n\
    \    kernel_constraint: Constraint function applied to\n        the `kernel` weights\
    \ matrix\n        (see [constraints](../constraints.md)).\n    recurrent_constraint:\
    \ Constraint function applied to\n        the `recurrent_kernel` weights matrix\n\
    \        (see [constraints](../constraints.md)).\n    bias_constraint: Constraint\
    \ function applied to the bias vector\n        (see [constraints](../constraints.md)).\n\
    \    dropout: Float between 0 and 1.\n        Fraction of the units to drop for\n\
    \        the linear transformation of the inputs.\n    recurrent_dropout: Float\
    \ between 0 and 1.\n        Fraction of the units to drop for\n        the linear\
    \ transformation of the recurrent state.\n    return_sequences: Boolean. Whether\
    \ to return the last output\n        in the output sequence, or the full sequence.\n\
    \    return_state: Boolean. Whether to return the last state\n        in addition\
    \ to the output.\n    go_backwards: Boolean (default False).\n        If True,\
    \ process the input sequence backwards and return the\n        reversed sequence.\n\
    \    stateful: Boolean (default False). If True, the last state\n        for each\
    \ sample at index i in a batch will be used as initial\n        state for the\
    \ sample of index i in the following batch.\n    unroll: Boolean (default False).\n\
    \        If True, the network will be unrolled,\n        else a symbolic loop\
    \ will be used.\n        Unrolling can speed-up a RNN,\n        although it tends\
    \ to be more memory-intensive.\n        Unrolling is only suitable for short sequences."
  kind: Layer
  name: SimpleRNN
  parameters:
  - {kind: any, name: units}
  - {defaultValue: tanh, kind: any, name: activation}
  - {defaultValue: 'True', kind: any, name: use_bias}
  - {defaultValue: glorot_uniform, kind: any, name: kernel_initializer}
  - {defaultValue: orthogonal, kind: any, name: recurrent_initializer}
  - {defaultValue: zeros, kind: any, name: bias_initializer}
  - {defaultValue: None, kind: any, name: kernel_regularizer}
  - {defaultValue: None, kind: any, name: recurrent_regularizer}
  - {defaultValue: None, kind: any, name: bias_regularizer}
  - {defaultValue: None, kind: any, name: activity_regularizer}
  - {defaultValue: None, kind: any, name: kernel_constraint}
  - {defaultValue: None, kind: any, name: recurrent_constraint}
  - {defaultValue: None, kind: any, name: bias_constraint}
  - {defaultValue: '0.0', kind: any, name: dropout}
  - {defaultValue: '0.0', kind: any, name: recurrent_dropout}
  - {defaultValue: 'False', kind: any, name: return_sequences}
  - {defaultValue: 'False', kind: any, name: return_state}
  - {defaultValue: 'False', kind: any, name: go_backwards}
  - {defaultValue: 'False', kind: any, name: stateful}
  - {defaultValue: 'False', kind: any, name: unroll}
  - {defaultValue: 'true', name: trainable, type: bool}
  source: "class SimpleRNN(RNN):\n    \"\"\"Fully-connected RNN where the output is\
    \ to be fed back to input.\n\n    # Arguments\n        units: Positive integer,\
    \ dimensionality of the output space.\n        activation: Activation function\
    \ to use\n            (see [activations](../activations.md)).\n            Default:\
    \ hyperbolic tangent (`tanh`).\n            If you pass `None`, no activation\
    \ is applied\n            (ie. \"linear\" activation: `a(x) = x`).\n        use_bias:\
    \ Boolean, whether the layer uses a bias vector.\n        kernel_initializer:\
    \ Initializer for the `kernel` weights matrix,\n            used for the linear\
    \ transformation of the inputs\n            (see [initializers](../initializers.md)).\n\
    \        recurrent_initializer: Initializer for the `recurrent_kernel`\n     \
    \       weights matrix,\n            used for the linear transformation of the\
    \ recurrent state\n            (see [initializers](../initializers.md)).\n   \
    \     bias_initializer: Initializer for the bias vector\n            (see [initializers](../initializers.md)).\n\
    \        kernel_regularizer: Regularizer function applied to\n            the\
    \ `kernel` weights matrix\n            (see [regularizer](../regularizers.md)).\n\
    \        recurrent_regularizer: Regularizer function applied to\n            the\
    \ `recurrent_kernel` weights matrix\n            (see [regularizer](../regularizers.md)).\n\
    \        bias_regularizer: Regularizer function applied to the bias vector\n \
    \           (see [regularizer](../regularizers.md)).\n        activity_regularizer:\
    \ Regularizer function applied to\n            the output of the layer (its \"\
    activation\").\n            (see [regularizer](../regularizers.md)).\n       \
    \ kernel_constraint: Constraint function applied to\n            the `kernel`\
    \ weights matrix\n            (see [constraints](../constraints.md)).\n      \
    \  recurrent_constraint: Constraint function applied to\n            the `recurrent_kernel`\
    \ weights matrix\n            (see [constraints](../constraints.md)).\n      \
    \  bias_constraint: Constraint function applied to the bias vector\n         \
    \   (see [constraints](../constraints.md)).\n        dropout: Float between 0\
    \ and 1.\n            Fraction of the units to drop for\n            the linear\
    \ transformation of the inputs.\n        recurrent_dropout: Float between 0 and\
    \ 1.\n            Fraction of the units to drop for\n            the linear transformation\
    \ of the recurrent state.\n        return_sequences: Boolean. Whether to return\
    \ the last output\n            in the output sequence, or the full sequence.\n\
    \        return_state: Boolean. Whether to return the last state\n           \
    \ in addition to the output.\n        go_backwards: Boolean (default False).\n\
    \            If True, process the input sequence backwards and return the\n  \
    \          reversed sequence.\n        stateful: Boolean (default False). If True,\
    \ the last state\n            for each sample at index i in a batch will be used\
    \ as initial\n            state for the sample of index i in the following batch.\n\
    \        unroll: Boolean (default False).\n            If True, the network will\
    \ be unrolled,\n            else a symbolic loop will be used.\n            Unrolling\
    \ can speed-up a RNN,\n            although it tends to be more memory-intensive.\n\
    \            Unrolling is only suitable for short sequences.\n    \"\"\"\n\n \
    \   @interfaces.legacy_recurrent_support\n    def __init__(self, units,\n    \
    \             activation='tanh',\n                 use_bias=True,\n          \
    \       kernel_initializer='glorot_uniform',\n                 recurrent_initializer='orthogonal',\n\
    \                 bias_initializer='zeros',\n                 kernel_regularizer=None,\n\
    \                 recurrent_regularizer=None,\n                 bias_regularizer=None,\n\
    \                 activity_regularizer=None,\n                 kernel_constraint=None,\n\
    \                 recurrent_constraint=None,\n                 bias_constraint=None,\n\
    \                 dropout=0.,\n                 recurrent_dropout=0.,\n      \
    \           return_sequences=False,\n                 return_state=False,\n  \
    \               go_backwards=False,\n                 stateful=False,\n      \
    \           unroll=False,\n                 **kwargs):\n        if 'implementation'\
    \ in kwargs:\n            kwargs.pop('implementation')\n            warnings.warn('The\
    \ `implementation` argument '\n                          'in `SimpleRNN` has been\
    \ deprecated. '\n                          'Please remove it from your layer call.')\n\
    \        if K.backend() == 'theano' and (dropout or recurrent_dropout):\n    \
    \        warnings.warn(\n                'RNN dropout is no longer supported with\
    \ the Theano backend '\n                'due to technical limitations. '\n   \
    \             'You can either set `dropout` and `recurrent_dropout` to 0, '\n\
    \                'or use the TensorFlow backend.')\n            dropout = 0.\n\
    \            recurrent_dropout = 0.\n\n        cell = SimpleRNNCell(units,\n \
    \                            activation=activation,\n                        \
    \     use_bias=use_bias,\n                             kernel_initializer=kernel_initializer,\n\
    \                             recurrent_initializer=recurrent_initializer,\n \
    \                            bias_initializer=bias_initializer,\n            \
    \                 kernel_regularizer=kernel_regularizer,\n                   \
    \          recurrent_regularizer=recurrent_regularizer,\n                    \
    \         bias_regularizer=bias_regularizer,\n                             kernel_constraint=kernel_constraint,\n\
    \                             recurrent_constraint=recurrent_constraint,\n   \
    \                          bias_constraint=bias_constraint,\n                \
    \             dropout=dropout,\n                             recurrent_dropout=recurrent_dropout)\n\
    \        super(SimpleRNN, self).__init__(cell,\n                             \
    \           return_sequences=return_sequences,\n                             \
    \           return_state=return_state,\n                                     \
    \   go_backwards=go_backwards,\n                                        stateful=stateful,\n\
    \                                        unroll=unroll,\n                    \
    \                    **kwargs)\n        self.activity_regularizer = regularizers.get(activity_regularizer)\n\
    \n    def call(self, inputs, mask=None, training=None, initial_state=None):\n\
    \        self.cell._dropout_mask = None\n        self.cell._recurrent_dropout_mask\
    \ = None\n        return super(SimpleRNN, self).call(inputs,\n               \
    \                            mask=mask,\n                                    \
    \       training=training,\n                                           initial_state=initial_state)\n\
    \n    @property\n    def units(self):\n        return self.cell.units\n\n    @property\n\
    \    def activation(self):\n        return self.cell.activation\n\n    @property\n\
    \    def use_bias(self):\n        return self.cell.use_bias\n\n    @property\n\
    \    def kernel_initializer(self):\n        return self.cell.kernel_initializer\n\
    \n    @property\n    def recurrent_initializer(self):\n        return self.cell.recurrent_initializer\n\
    \n    @property\n    def bias_initializer(self):\n        return self.cell.bias_initializer\n\
    \n    @property\n    def kernel_regularizer(self):\n        return self.cell.kernel_regularizer\n\
    \n    @property\n    def recurrent_regularizer(self):\n        return self.cell.recurrent_regularizer\n\
    \n    @property\n    def bias_regularizer(self):\n        return self.cell.bias_regularizer\n\
    \n    @property\n    def kernel_constraint(self):\n        return self.cell.kernel_constraint\n\
    \n    @property\n    def recurrent_constraint(self):\n        return self.cell.recurrent_constraint\n\
    \n    @property\n    def bias_constraint(self):\n        return self.cell.bias_constraint\n\
    \n    @property\n    def dropout(self):\n        return self.cell.dropout\n\n\
    \    @property\n    def recurrent_dropout(self):\n        return self.cell.recurrent_dropout\n\
    \n    def get_config(self):\n        config = {'units': self.units,\n        \
    \          'activation': activations.serialize(self.activation),\n           \
    \       'use_bias': self.use_bias,\n                  'kernel_initializer':\n\
    \                      initializers.serialize(self.kernel_initializer),\n    \
    \              'recurrent_initializer':\n                      initializers.serialize(self.recurrent_initializer),\n\
    \                  'bias_initializer': initializers.serialize(self.bias_initializer),\n\
    \                  'kernel_regularizer':\n                      regularizers.serialize(self.kernel_regularizer),\n\
    \                  'recurrent_regularizer':\n                      regularizers.serialize(self.recurrent_regularizer),\n\
    \                  'bias_regularizer': regularizers.serialize(self.bias_regularizer),\n\
    \                  'activity_regularizer':\n                      regularizers.serialize(self.activity_regularizer),\n\
    \                  'kernel_constraint': constraints.serialize(self.kernel_constraint),\n\
    \                  'recurrent_constraint':\n                      constraints.serialize(self.recurrent_constraint),\n\
    \                  'bias_constraint': constraints.serialize(self.bias_constraint),\n\
    \                  'dropout': self.dropout,\n                  'recurrent_dropout':\
    \ self.recurrent_dropout}\n        base_config = super(SimpleRNN, self).get_config()\n\
    \        del base_config['cell']\n        return dict(list(base_config.items())\
    \ + list(config.items()))\n\n    @classmethod\n    def from_config(cls, config):\n\
    \        if 'implementation' in config:\n            config.pop('implementation')\n\
    \        return cls(**config)\n"
  sourcefile: D:\Python36\lib\site-packages\keras\layers\recurrent.py
- doc: "Cell class for SimpleRNN.\n\n# Arguments\n    units: Positive integer, dimensionality\
    \ of the output space.\n    activation: Activation function to use\n        (see\
    \ [activations](../activations.md)).\n        Default: hyperbolic tangent (`tanh`).\n\
    \        If you pass `None`, no activation is applied\n        (ie. \"linear\"\
    \ activation: `a(x) = x`).\n    use_bias: Boolean, whether the layer uses a bias\
    \ vector.\n    kernel_initializer: Initializer for the `kernel` weights matrix,\n\
    \        used for the linear transformation of the inputs\n        (see [initializers](../initializers.md)).\n\
    \    recurrent_initializer: Initializer for the `recurrent_kernel`\n        weights\
    \ matrix,\n        used for the linear transformation of the recurrent state\n\
    \        (see [initializers](../initializers.md)).\n    bias_initializer: Initializer\
    \ for the bias vector\n        (see [initializers](../initializers.md)).\n   \
    \ kernel_regularizer: Regularizer function applied to\n        the `kernel` weights\
    \ matrix\n        (see [regularizer](../regularizers.md)).\n    recurrent_regularizer:\
    \ Regularizer function applied to\n        the `recurrent_kernel` weights matrix\n\
    \        (see [regularizer](../regularizers.md)).\n    bias_regularizer: Regularizer\
    \ function applied to the bias vector\n        (see [regularizer](../regularizers.md)).\n\
    \    kernel_constraint: Constraint function applied to\n        the `kernel` weights\
    \ matrix\n        (see [constraints](../constraints.md)).\n    recurrent_constraint:\
    \ Constraint function applied to\n        the `recurrent_kernel` weights matrix\n\
    \        (see [constraints](../constraints.md)).\n    bias_constraint: Constraint\
    \ function applied to the bias vector\n        (see [constraints](../constraints.md)).\n\
    \    dropout: Float between 0 and 1.\n        Fraction of the units to drop for\n\
    \        the linear transformation of the inputs.\n    recurrent_dropout: Float\
    \ between 0 and 1.\n        Fraction of the units to drop for\n        the linear\
    \ transformation of the recurrent state."
  kind: Layer
  name: SimpleRNNCell
  parameters:
  - {kind: any, name: units}
  - {defaultValue: tanh, kind: any, name: activation}
  - {defaultValue: 'True', kind: any, name: use_bias}
  - {defaultValue: glorot_uniform, kind: any, name: kernel_initializer}
  - {defaultValue: orthogonal, kind: any, name: recurrent_initializer}
  - {defaultValue: zeros, kind: any, name: bias_initializer}
  - {defaultValue: None, kind: any, name: kernel_regularizer}
  - {defaultValue: None, kind: any, name: recurrent_regularizer}
  - {defaultValue: None, kind: any, name: bias_regularizer}
  - {defaultValue: None, kind: any, name: kernel_constraint}
  - {defaultValue: None, kind: any, name: recurrent_constraint}
  - {defaultValue: None, kind: any, name: bias_constraint}
  - {defaultValue: '0.0', kind: any, name: dropout}
  - {defaultValue: '0.0', kind: any, name: recurrent_dropout}
  - {defaultValue: 'true', name: trainable, type: bool}
  source: "class SimpleRNNCell(Layer):\n    \"\"\"Cell class for SimpleRNN.\n\n  \
    \  # Arguments\n        units: Positive integer, dimensionality of the output\
    \ space.\n        activation: Activation function to use\n            (see [activations](../activations.md)).\n\
    \            Default: hyperbolic tangent (`tanh`).\n            If you pass `None`,\
    \ no activation is applied\n            (ie. \"linear\" activation: `a(x) = x`).\n\
    \        use_bias: Boolean, whether the layer uses a bias vector.\n        kernel_initializer:\
    \ Initializer for the `kernel` weights matrix,\n            used for the linear\
    \ transformation of the inputs\n            (see [initializers](../initializers.md)).\n\
    \        recurrent_initializer: Initializer for the `recurrent_kernel`\n     \
    \       weights matrix,\n            used for the linear transformation of the\
    \ recurrent state\n            (see [initializers](../initializers.md)).\n   \
    \     bias_initializer: Initializer for the bias vector\n            (see [initializers](../initializers.md)).\n\
    \        kernel_regularizer: Regularizer function applied to\n            the\
    \ `kernel` weights matrix\n            (see [regularizer](../regularizers.md)).\n\
    \        recurrent_regularizer: Regularizer function applied to\n            the\
    \ `recurrent_kernel` weights matrix\n            (see [regularizer](../regularizers.md)).\n\
    \        bias_regularizer: Regularizer function applied to the bias vector\n \
    \           (see [regularizer](../regularizers.md)).\n        kernel_constraint:\
    \ Constraint function applied to\n            the `kernel` weights matrix\n  \
    \          (see [constraints](../constraints.md)).\n        recurrent_constraint:\
    \ Constraint function applied to\n            the `recurrent_kernel` weights matrix\n\
    \            (see [constraints](../constraints.md)).\n        bias_constraint:\
    \ Constraint function applied to the bias vector\n            (see [constraints](../constraints.md)).\n\
    \        dropout: Float between 0 and 1.\n            Fraction of the units to\
    \ drop for\n            the linear transformation of the inputs.\n        recurrent_dropout:\
    \ Float between 0 and 1.\n            Fraction of the units to drop for\n    \
    \        the linear transformation of the recurrent state.\n    \"\"\"\n\n   \
    \ def __init__(self, units,\n                 activation='tanh',\n           \
    \      use_bias=True,\n                 kernel_initializer='glorot_uniform',\n\
    \                 recurrent_initializer='orthogonal',\n                 bias_initializer='zeros',\n\
    \                 kernel_regularizer=None,\n                 recurrent_regularizer=None,\n\
    \                 bias_regularizer=None,\n                 kernel_constraint=None,\n\
    \                 recurrent_constraint=None,\n                 bias_constraint=None,\n\
    \                 dropout=0.,\n                 recurrent_dropout=0.,\n      \
    \           **kwargs):\n        super(SimpleRNNCell, self).__init__(**kwargs)\n\
    \        self.units = units\n        self.activation = activations.get(activation)\n\
    \        self.use_bias = use_bias\n\n        self.kernel_initializer = initializers.get(kernel_initializer)\n\
    \        self.recurrent_initializer = initializers.get(recurrent_initializer)\n\
    \        self.bias_initializer = initializers.get(bias_initializer)\n\n      \
    \  self.kernel_regularizer = regularizers.get(kernel_regularizer)\n        self.recurrent_regularizer\
    \ = regularizers.get(recurrent_regularizer)\n        self.bias_regularizer = regularizers.get(bias_regularizer)\n\
    \n        self.kernel_constraint = constraints.get(kernel_constraint)\n      \
    \  self.recurrent_constraint = constraints.get(recurrent_constraint)\n       \
    \ self.bias_constraint = constraints.get(bias_constraint)\n\n        self.dropout\
    \ = min(1., max(0., dropout))\n        self.recurrent_dropout = min(1., max(0.,\
    \ recurrent_dropout))\n        self.state_size = self.units\n        self.output_size\
    \ = self.units\n        self._dropout_mask = None\n        self._recurrent_dropout_mask\
    \ = None\n\n    def build(self, input_shape):\n        self.kernel = self.add_weight(shape=(input_shape[-1],\
    \ self.units),\n                                      name='kernel',\n       \
    \                               initializer=self.kernel_initializer,\n       \
    \                               regularizer=self.kernel_regularizer,\n       \
    \                               constraint=self.kernel_constraint)\n        self.recurrent_kernel\
    \ = self.add_weight(\n            shape=(self.units, self.units),\n          \
    \  name='recurrent_kernel',\n            initializer=self.recurrent_initializer,\n\
    \            regularizer=self.recurrent_regularizer,\n            constraint=self.recurrent_constraint)\n\
    \        if self.use_bias:\n            self.bias = self.add_weight(shape=(self.units,),\n\
    \                                        name='bias',\n                      \
    \                  initializer=self.bias_initializer,\n                      \
    \                  regularizer=self.bias_regularizer,\n                      \
    \                  constraint=self.bias_constraint)\n        else:\n         \
    \   self.bias = None\n        self.built = True\n\n    def call(self, inputs,\
    \ states, training=None):\n        prev_output = states[0]\n        if 0 < self.dropout\
    \ < 1 and self._dropout_mask is None:\n            self._dropout_mask = _generate_dropout_mask(\n\
    \                K.ones_like(inputs),\n                self.dropout,\n       \
    \         training=training)\n        if (0 < self.recurrent_dropout < 1 and\n\
    \                self._recurrent_dropout_mask is None):\n            self._recurrent_dropout_mask\
    \ = _generate_dropout_mask(\n                K.ones_like(prev_output),\n     \
    \           self.recurrent_dropout,\n                training=training)\n\n  \
    \      dp_mask = self._dropout_mask\n        rec_dp_mask = self._recurrent_dropout_mask\n\
    \n        if dp_mask is not None:\n            h = K.dot(inputs * dp_mask, self.kernel)\n\
    \        else:\n            h = K.dot(inputs, self.kernel)\n        if self.bias\
    \ is not None:\n            h = K.bias_add(h, self.bias)\n\n        if rec_dp_mask\
    \ is not None:\n            prev_output *= rec_dp_mask\n        output = h + K.dot(prev_output,\
    \ self.recurrent_kernel)\n        if self.activation is not None:\n          \
    \  output = self.activation(output)\n\n        # Properly set learning phase on\
    \ output tensor.\n        if 0 < self.dropout + self.recurrent_dropout:\n    \
    \        if training is None:\n                output._uses_learning_phase = True\n\
    \        return output, [output]\n\n    def get_config(self):\n        config\
    \ = {'units': self.units,\n                  'activation': activations.serialize(self.activation),\n\
    \                  'use_bias': self.use_bias,\n                  'kernel_initializer':\n\
    \                      initializers.serialize(self.kernel_initializer),\n    \
    \              'recurrent_initializer':\n                      initializers.serialize(self.recurrent_initializer),\n\
    \                  'bias_initializer': initializers.serialize(self.bias_initializer),\n\
    \                  'kernel_regularizer':\n                      regularizers.serialize(self.kernel_regularizer),\n\
    \                  'recurrent_regularizer':\n                      regularizers.serialize(self.recurrent_regularizer),\n\
    \                  'bias_regularizer': regularizers.serialize(self.bias_regularizer),\n\
    \                  'kernel_constraint': constraints.serialize(self.kernel_constraint),\n\
    \                  'recurrent_constraint':\n                      constraints.serialize(self.recurrent_constraint),\n\
    \                  'bias_constraint': constraints.serialize(self.bias_constraint),\n\
    \                  'dropout': self.dropout,\n                  'recurrent_dropout':\
    \ self.recurrent_dropout}\n        base_config = super(SimpleRNNCell, self).get_config()\n\
    \        return dict(list(base_config.items()) + list(config.items()))\n"
  sourcefile: D:\Python36\lib\site-packages\keras\layers\recurrent.py
- doc: "Softmax activation function.\n\n# Input shape\n    Arbitrary. Use the keyword\
    \ argument `input_shape`\n    (tuple of integers, does not include the samples\
    \ axis)\n    when using this layer as the first layer in a model.\n\n# Output\
    \ shape\n    Same shape as the input.\n\n# Arguments\n    axis: Integer, axis\
    \ along which the softmax normalization is applied."
  kind: Layer
  name: Softmax
  parameters:
  - {defaultValue: '-1', kind: any, name: axis}
  - {defaultValue: 'true', name: trainable, type: bool}
  source: "class Softmax(Layer):\n    \"\"\"Softmax activation function.\n\n    #\
    \ Input shape\n        Arbitrary. Use the keyword argument `input_shape`\n   \
    \     (tuple of integers, does not include the samples axis)\n        when using\
    \ this layer as the first layer in a model.\n\n    # Output shape\n        Same\
    \ shape as the input.\n\n    # Arguments\n        axis: Integer, axis along which\
    \ the softmax normalization is applied.\n    \"\"\"\n\n    def __init__(self,\
    \ axis=-1, **kwargs):\n        super(Softmax, self).__init__(**kwargs)\n     \
    \   self.supports_masking = True\n        self.axis = axis\n\n    def call(self,\
    \ inputs):\n        return activations.softmax(inputs, axis=self.axis)\n\n   \
    \ def get_config(self):\n        config = {'axis': self.axis}\n        base_config\
    \ = super(Softmax, self).get_config()\n        return dict(list(base_config.items())\
    \ + list(config.items()))\n\n    def compute_output_shape(self, input_shape):\n\
    \        return input_shape\n"
  sourcefile: D:\Python36\lib\site-packages\keras\layers\advanced_activations.py
- doc: "Spatial 1D version of Dropout.\n\nThis version performs the same function\
    \ as Dropout, however it drops\nentire 1D feature maps instead of individual elements.\
    \ If adjacent frames\nwithin feature maps are strongly correlated (as is normally\
    \ the case in\nearly convolution layers) then regular dropout will not regularize\
    \ the\nactivations and will otherwise just result in an effective learning rate\n\
    decrease. In this case, SpatialDropout1D will help promote independence\nbetween\
    \ feature maps and should be used instead.\n\n# Arguments\n    rate: float between\
    \ 0 and 1. Fraction of the input units to drop.\n\n# Input shape\n    3D tensor\
    \ with shape:\n    `(samples, timesteps, channels)`\n\n# Output shape\n    Same\
    \ as input\n\n# References\n    - [Efficient Object Localization Using Convolutional\
    \ Networks]\n      (https://arxiv.org/abs/1411.4280)"
  kind: Layer
  name: SpatialDropout1D
  parameters:
  - {kind: any, name: rate}
  - {defaultValue: 'true', name: trainable, type: bool}
  source: "class SpatialDropout1D(Dropout):\n    \"\"\"Spatial 1D version of Dropout.\n\
    \n    This version performs the same function as Dropout, however it drops\n \
    \   entire 1D feature maps instead of individual elements. If adjacent frames\n\
    \    within feature maps are strongly correlated (as is normally the case in\n\
    \    early convolution layers) then regular dropout will not regularize the\n\
    \    activations and will otherwise just result in an effective learning rate\n\
    \    decrease. In this case, SpatialDropout1D will help promote independence\n\
    \    between feature maps and should be used instead.\n\n    # Arguments\n   \
    \     rate: float between 0 and 1. Fraction of the input units to drop.\n\n  \
    \  # Input shape\n        3D tensor with shape:\n        `(samples, timesteps,\
    \ channels)`\n\n    # Output shape\n        Same as input\n\n    # References\n\
    \        - [Efficient Object Localization Using Convolutional Networks]\n    \
    \      (https://arxiv.org/abs/1411.4280)\n    \"\"\"\n\n    @interfaces.legacy_spatialdropout1d_support\n\
    \    def __init__(self, rate, **kwargs):\n        super(SpatialDropout1D, self).__init__(rate,\
    \ **kwargs)\n        self.input_spec = InputSpec(ndim=3)\n\n    def _get_noise_shape(self,\
    \ inputs):\n        input_shape = K.shape(inputs)\n        noise_shape = (input_shape[0],\
    \ 1, input_shape[2])\n        return noise_shape\n"
  sourcefile: D:\Python36\lib\site-packages\keras\layers\core.py
- doc: "Spatial 2D version of Dropout.\n\nThis version performs the same function\
    \ as Dropout, however it drops\nentire 2D feature maps instead of individual elements.\
    \ If adjacent pixels\nwithin feature maps are strongly correlated (as is normally\
    \ the case in\nearly convolution layers) then regular dropout will not regularize\
    \ the\nactivations and will otherwise just result in an effective learning rate\n\
    decrease. In this case, SpatialDropout2D will help promote independence\nbetween\
    \ feature maps and should be used instead.\n\n# Arguments\n    rate: float between\
    \ 0 and 1. Fraction of the input units to drop.\n    data_format: 'channels_first'\
    \ or 'channels_last'.\n        In 'channels_first' mode, the channels dimension\n\
    \        (the depth) is at index 1,\n        in 'channels_last' mode is it at\
    \ index 3.\n        It defaults to the `image_data_format` value found in your\n\
    \        Keras config file at `~/.keras/keras.json`.\n        If you never set\
    \ it, then it will be \"channels_last\".\n\n# Input shape\n    4D tensor with\
    \ shape:\n    `(samples, channels, rows, cols)` if data_format='channels_first'\n\
    \    or 4D tensor with shape:\n    `(samples, rows, cols, channels)` if data_format='channels_last'.\n\
    \n# Output shape\n    Same as input\n\n# References\n    - [Efficient Object Localization\
    \ Using Convolutional Networks]\n      (https://arxiv.org/abs/1411.4280)"
  kind: Layer
  name: SpatialDropout2D
  parameters:
  - {kind: any, name: rate}
  - {defaultValue: None, kind: any, name: data_format}
  - {defaultValue: 'true', name: trainable, type: bool}
  source: "class SpatialDropout2D(Dropout):\n    \"\"\"Spatial 2D version of Dropout.\n\
    \n    This version performs the same function as Dropout, however it drops\n \
    \   entire 2D feature maps instead of individual elements. If adjacent pixels\n\
    \    within feature maps are strongly correlated (as is normally the case in\n\
    \    early convolution layers) then regular dropout will not regularize the\n\
    \    activations and will otherwise just result in an effective learning rate\n\
    \    decrease. In this case, SpatialDropout2D will help promote independence\n\
    \    between feature maps and should be used instead.\n\n    # Arguments\n   \
    \     rate: float between 0 and 1. Fraction of the input units to drop.\n    \
    \    data_format: 'channels_first' or 'channels_last'.\n            In 'channels_first'\
    \ mode, the channels dimension\n            (the depth) is at index 1,\n     \
    \       in 'channels_last' mode is it at index 3.\n            It defaults to\
    \ the `image_data_format` value found in your\n            Keras config file at\
    \ `~/.keras/keras.json`.\n            If you never set it, then it will be \"\
    channels_last\".\n\n    # Input shape\n        4D tensor with shape:\n       \
    \ `(samples, channels, rows, cols)` if data_format='channels_first'\n        or\
    \ 4D tensor with shape:\n        `(samples, rows, cols, channels)` if data_format='channels_last'.\n\
    \n    # Output shape\n        Same as input\n\n    # References\n        - [Efficient\
    \ Object Localization Using Convolutional Networks]\n          (https://arxiv.org/abs/1411.4280)\n\
    \    \"\"\"\n\n    @interfaces.legacy_spatialdropoutNd_support\n    def __init__(self,\
    \ rate, data_format=None, **kwargs):\n        super(SpatialDropout2D, self).__init__(rate,\
    \ **kwargs)\n        self.data_format = K.normalize_data_format(data_format)\n\
    \        self.input_spec = InputSpec(ndim=4)\n\n    def _get_noise_shape(self,\
    \ inputs):\n        input_shape = K.shape(inputs)\n        if self.data_format\
    \ == 'channels_first':\n            noise_shape = (input_shape[0], input_shape[1],\
    \ 1, 1)\n        else:\n            noise_shape = (input_shape[0], 1, 1, input_shape[3])\n\
    \        return noise_shape\n"
  sourcefile: D:\Python36\lib\site-packages\keras\layers\core.py
- doc: "Spatial 3D version of Dropout.\n\nThis version performs the same function\
    \ as Dropout, however it drops\nentire 3D feature maps instead of individual elements.\
    \ If adjacent voxels\nwithin feature maps are strongly correlated (as is normally\
    \ the case in\nearly convolution layers) then regular dropout will not regularize\
    \ the\nactivations and will otherwise just result in an effective learning rate\n\
    decrease. In this case, SpatialDropout3D will help promote independence\nbetween\
    \ feature maps and should be used instead.\n\n# Arguments\n    rate: float between\
    \ 0 and 1. Fraction of the input units to drop.\n    data_format: 'channels_first'\
    \ or 'channels_last'.\n        In 'channels_first' mode, the channels dimension\
    \ (the depth)\n        is at index 1, in 'channels_last' mode is it at index 4.\n\
    \        It defaults to the `image_data_format` value found in your\n        Keras\
    \ config file at `~/.keras/keras.json`.\n        If you never set it, then it\
    \ will be \"channels_last\".\n\n# Input shape\n    5D tensor with shape:\n   \
    \ `(samples, channels, dim1, dim2, dim3)` if data_format='channels_first'\n  \
    \  or 5D tensor with shape:\n    `(samples, dim1, dim2, dim3, channels)` if data_format='channels_last'.\n\
    \n# Output shape\n    Same as input\n\n# References\n    - [Efficient Object Localization\
    \ Using Convolutional Networks]\n      (https://arxiv.org/abs/1411.4280)"
  kind: Layer
  name: SpatialDropout3D
  parameters:
  - {kind: any, name: rate}
  - {defaultValue: None, kind: any, name: data_format}
  - {defaultValue: 'true', name: trainable, type: bool}
  source: "class SpatialDropout3D(Dropout):\n    \"\"\"Spatial 3D version of Dropout.\n\
    \n    This version performs the same function as Dropout, however it drops\n \
    \   entire 3D feature maps instead of individual elements. If adjacent voxels\n\
    \    within feature maps are strongly correlated (as is normally the case in\n\
    \    early convolution layers) then regular dropout will not regularize the\n\
    \    activations and will otherwise just result in an effective learning rate\n\
    \    decrease. In this case, SpatialDropout3D will help promote independence\n\
    \    between feature maps and should be used instead.\n\n    # Arguments\n   \
    \     rate: float between 0 and 1. Fraction of the input units to drop.\n    \
    \    data_format: 'channels_first' or 'channels_last'.\n            In 'channels_first'\
    \ mode, the channels dimension (the depth)\n            is at index 1, in 'channels_last'\
    \ mode is it at index 4.\n            It defaults to the `image_data_format` value\
    \ found in your\n            Keras config file at `~/.keras/keras.json`.\n   \
    \         If you never set it, then it will be \"channels_last\".\n\n    # Input\
    \ shape\n        5D tensor with shape:\n        `(samples, channels, dim1, dim2,\
    \ dim3)` if data_format='channels_first'\n        or 5D tensor with shape:\n \
    \       `(samples, dim1, dim2, dim3, channels)` if data_format='channels_last'.\n\
    \n    # Output shape\n        Same as input\n\n    # References\n        - [Efficient\
    \ Object Localization Using Convolutional Networks]\n          (https://arxiv.org/abs/1411.4280)\n\
    \    \"\"\"\n\n    @interfaces.legacy_spatialdropoutNd_support\n    def __init__(self,\
    \ rate, data_format=None, **kwargs):\n        super(SpatialDropout3D, self).__init__(rate,\
    \ **kwargs)\n        self.data_format = K.normalize_data_format(data_format)\n\
    \        self.input_spec = InputSpec(ndim=5)\n\n    def _get_noise_shape(self,\
    \ inputs):\n        input_shape = K.shape(inputs)\n        if self.data_format\
    \ == 'channels_first':\n            noise_shape = (input_shape[0], input_shape[1],\
    \ 1, 1, 1)\n        else:\n            noise_shape = (input_shape[0], 1, 1, 1,\
    \ input_shape[4])\n        return noise_shape\n"
  sourcefile: D:\Python36\lib\site-packages\keras\layers\core.py
- doc: "Wrapper allowing a stack of RNN cells to behave as a single cell.\n\nUsed\
    \ to implement efficient stacked RNNs.\n\n# Arguments\n    cells: List of RNN\
    \ cell instances.\n\n# Examples\n\n```python\n    cells = [\n        keras.layers.LSTMCell(output_dim),\n\
    \        keras.layers.LSTMCell(output_dim),\n        keras.layers.LSTMCell(output_dim),\n\
    \    ]\n\n    inputs = keras.Input((timesteps, input_dim))\n    x = keras.layers.RNN(cells)(inputs)\n\
    ```"
  kind: Layer
  name: StackedRNNCells
  parameters:
  - {kind: any, name: cells}
  - {defaultValue: 'true', name: trainable, type: bool}
  source: "class StackedRNNCells(Layer):\n    \"\"\"Wrapper allowing a stack of RNN\
    \ cells to behave as a single cell.\n\n    Used to implement efficient stacked\
    \ RNNs.\n\n    # Arguments\n        cells: List of RNN cell instances.\n\n   \
    \ # Examples\n\n    ```python\n        cells = [\n            keras.layers.LSTMCell(output_dim),\n\
    \            keras.layers.LSTMCell(output_dim),\n            keras.layers.LSTMCell(output_dim),\n\
    \        ]\n\n        inputs = keras.Input((timesteps, input_dim))\n        x\
    \ = keras.layers.RNN(cells)(inputs)\n    ```\n    \"\"\"\n\n    def __init__(self,\
    \ cells, **kwargs):\n        for cell in cells:\n            if not hasattr(cell,\
    \ 'call'):\n                raise ValueError('All cells must have a `call` method.\
    \ '\n                                 'received cells:', cells)\n            if\
    \ not hasattr(cell, 'state_size'):\n                raise ValueError('All cells\
    \ must have a '\n                                 '`state_size` attribute. '\n\
    \                                 'received cells:', cells)\n        self.cells\
    \ = cells\n        # reverse_state_order determines whether the state size will\
    \ be in a\n        # reverse order of the cells' state. User might want to set\
    \ this to True\n        # to keep the existing behavior. This is only useful when\
    \ use\n        # `RNN(return_state=True)` since the state will be returned as\
    \ the same\n        # order of state_size.\n        self.reverse_state_order =\
    \ kwargs.pop('reverse_state_order', False)\n        if self.reverse_state_order:\n\
    \            warnings.warn('`reverse_state_order=True` in `StackedRNNCells` '\n\
    \                          'will soon be deprecated. Please update the code to\
    \ '\n                          'work with the natural order of states if you '\n\
    \                          'reply on the RNN states, '\n                     \
    \     'eg `RNN(return_state=True)`.')\n        super(StackedRNNCells, self).__init__(**kwargs)\n\
    \n    @property\n    def state_size(self):\n        # States are a flat list of\
    \ the individual cell state size.\n        # e.g. states of a 2-layer LSTM would\
    \ be `[h1, c1, h2, c2]`.\n        # (assuming one LSTM has states [h, c])\n  \
    \      # In the case of reverse_state_order=True, the state_size will be\n   \
    \     # `[h2, c2, h1, c1]`.\n        state_size = []\n        for cell in self.cells[::-1]\
    \ if self.reverse_state_order else self.cells:\n            if hasattr(cell.state_size,\
    \ '__len__'):\n                state_size += list(cell.state_size)\n         \
    \   else:\n                state_size.append(cell.state_size)\n        return\
    \ tuple(state_size)\n\n    @property\n    def output_size(self):\n        if getattr(self.cells[-1],\
    \ 'output_size', None) is not None:\n            return self.cells[-1].output_size\n\
    \        if hasattr(self.cells[-1].state_size, '__len__'):\n            return\
    \ self.cells[-1].state_size[0]\n        else:\n            return self.cells[-1].state_size\n\
    \n    def call(self, inputs, states, constants=None, **kwargs):\n        # Recover\
    \ per-cell states.\n        nested_states = []\n        for cell in self.cells[::-1]\
    \ if self.reverse_state_order else self.cells:\n            if hasattr(cell.state_size,\
    \ '__len__'):\n                nested_states.append(states[:len(cell.state_size)])\n\
    \                states = states[len(cell.state_size):]\n            else:\n \
    \               nested_states.append([states[0]])\n                states = states[1:]\n\
    \        if self.reverse_state_order:\n            nested_states = nested_states[::-1]\n\
    \n        # Call the cells in order and store the returned states.\n        new_nested_states\
    \ = []\n        for cell, states in zip(self.cells, nested_states):\n        \
    \    if has_arg(cell.call, 'constants'):\n                inputs, states = cell.call(inputs,\
    \ states,\n                                           constants=constants,\n \
    \                                          **kwargs)\n            else:\n    \
    \            inputs, states = cell.call(inputs, states, **kwargs)\n          \
    \  new_nested_states.append(states)\n\n        # Format the new states as a flat\
    \ list\n        # in reverse cell order.\n        new_states = []\n        if\
    \ self.reverse_state_order:\n            new_nested_states = new_nested_states[::-1]\n\
    \        for cell_states in new_nested_states:\n            new_states += cell_states\n\
    \        return inputs, new_states\n\n    def build(self, input_shape):\n    \
    \    if isinstance(input_shape, list):\n            constants_shape = input_shape[1:]\n\
    \            input_shape = input_shape[0]\n        for cell in self.cells:\n \
    \           if isinstance(cell, Layer):\n                if has_arg(cell.call,\
    \ 'constants'):\n                    cell.build([input_shape] + constants_shape)\n\
    \                else:\n                    cell.build(input_shape)\n        \
    \    if getattr(cell, 'output_size', None) is not None:\n                output_dim\
    \ = cell.output_size\n            elif hasattr(cell.state_size, '__len__'):\n\
    \                output_dim = cell.state_size[0]\n            else:\n        \
    \        output_dim = cell.state_size\n            input_shape = (input_shape[0],\
    \ output_dim)\n        self.built = True\n\n    def get_config(self):\n      \
    \  cells = []\n        for cell in self.cells:\n            cells.append({'class_name':\
    \ cell.__class__.__name__,\n                          'config': cell.get_config()})\n\
    \        config = {'cells': cells}\n        base_config = super(StackedRNNCells,\
    \ self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))\n\
    \n    @classmethod\n    def from_config(cls, config, custom_objects=None):\n \
    \       from . import deserialize as deserialize_layer\n        cells = []\n \
    \       for cell_config in config.pop('cells'):\n            cells.append(deserialize_layer(cell_config,\n\
    \                                           custom_objects=custom_objects))\n\
    \        return cls(cells, **config)\n\n    @property\n    def trainable_weights(self):\n\
    \        if not self.trainable:\n            return []\n        weights = []\n\
    \        for cell in self.cells:\n            if isinstance(cell, Layer):\n  \
    \              weights += cell.trainable_weights\n        return weights\n\n \
    \   @property\n    def non_trainable_weights(self):\n        weights = []\n  \
    \      for cell in self.cells:\n            if isinstance(cell, Layer):\n    \
    \            weights += cell.non_trainable_weights\n        if not self.trainable:\n\
    \            trainable_weights = []\n            for cell in self.cells:\n   \
    \             if isinstance(cell, Layer):\n                    trainable_weights\
    \ += cell.trainable_weights\n            return trainable_weights + weights\n\
    \        return weights\n\n    def get_weights(self):\n        \"\"\"Retrieves\
    \ the weights of the model.\n\n        # Returns\n            A flat list of Numpy\
    \ arrays.\n        \"\"\"\n        weights = []\n        for cell in self.cells:\n\
    \            if isinstance(cell, Layer):\n                weights += cell.weights\n\
    \        return K.batch_get_value(weights)\n\n    def set_weights(self, weights):\n\
    \        \"\"\"Sets the weights of the model.\n\n        # Arguments\n       \
    \     weights: A list of Numpy arrays with shapes and types matching\n       \
    \         the output of `model.get_weights()`.\n        \"\"\"\n        tuples\
    \ = []\n        for cell in self.cells:\n            if isinstance(cell, Layer):\n\
    \                num_param = len(cell.weights)\n                weights = weights[:num_param]\n\
    \                for sw, w in zip(cell.weights, weights):\n                  \
    \  tuples.append((sw, w))\n                weights = weights[num_param:]\n   \
    \     K.batch_set_value(tuples)\n\n    @property\n    def losses(self):\n    \
    \    losses = []\n        for cell in self.cells:\n            if isinstance(cell,\
    \ Layer):\n                cell_losses = cell.losses\n                losses +=\
    \ cell_losses\n        return losses\n\n    def get_losses_for(self, inputs=None):\n\
    \        losses = []\n        for cell in self.cells:\n            if isinstance(cell,\
    \ Layer):\n                cell_losses = cell.get_losses_for(inputs)\n       \
    \         losses += cell_losses\n        return losses\n"
  sourcefile: D:\Python36\lib\site-packages\keras\layers\recurrent.py
- doc: "Layer that subtracts two inputs.\n\nIt takes as input a list of tensors of\
    \ size 2,\nboth of the same shape, and returns a single tensor, (inputs[0] - inputs[1]),\n\
    also of the same shape.\n\n# Examples\n\n```python\n    import keras\n\n    input1\
    \ = keras.layers.Input(shape=(16,))\n    x1 = keras.layers.Dense(8, activation='relu')(input1)\n\
    \    input2 = keras.layers.Input(shape=(32,))\n    x2 = keras.layers.Dense(8,\
    \ activation='relu')(input2)\n    # Equivalent to subtracted = keras.layers.subtract([x1,\
    \ x2])\n    subtracted = keras.layers.Subtract()([x1, x2])\n\n    out = keras.layers.Dense(4)(subtracted)\n\
    \    model = keras.models.Model(inputs=[input1, input2], outputs=out)\n```"
  kind: Layer
  name: Subtract
  parameters:
  - {defaultValue: 'true', name: trainable, type: bool}
  source: "class Subtract(_Merge):\n    \"\"\"Layer that subtracts two inputs.\n\n\
    \    It takes as input a list of tensors of size 2,\n    both of the same shape,\
    \ and returns a single tensor, (inputs[0] - inputs[1]),\n    also of the same\
    \ shape.\n\n    # Examples\n\n    ```python\n        import keras\n\n        input1\
    \ = keras.layers.Input(shape=(16,))\n        x1 = keras.layers.Dense(8, activation='relu')(input1)\n\
    \        input2 = keras.layers.Input(shape=(32,))\n        x2 = keras.layers.Dense(8,\
    \ activation='relu')(input2)\n        # Equivalent to subtracted = keras.layers.subtract([x1,\
    \ x2])\n        subtracted = keras.layers.Subtract()([x1, x2])\n\n        out\
    \ = keras.layers.Dense(4)(subtracted)\n        model = keras.models.Model(inputs=[input1,\
    \ input2], outputs=out)\n    ```\n    \"\"\"\n\n    def build(self, input_shape):\n\
    \        super(Subtract, self).build(input_shape)\n        if len(input_shape)\
    \ != 2:\n            raise ValueError('A `Subtract` layer should be called '\n\
    \                             'on exactly 2 inputs')\n\n    def _merge_function(self,\
    \ inputs):\n        if len(inputs) != 2:\n            raise ValueError('A `Subtract`\
    \ layer should be called '\n                             'on exactly 2 inputs')\n\
    \        return inputs[0] - inputs[1]\n"
  sourcefile: D:\Python36\lib\site-packages\keras\layers\merge.py
- doc: "Thresholded Rectified Linear Unit.\n\nIt follows:\n`f(x) = x for x > theta`,\n\
    `f(x) = 0 otherwise`.\n\n# Input shape\n    Arbitrary. Use the keyword argument\
    \ `input_shape`\n    (tuple of integers, does not include the samples axis)\n\
    \    when using this layer as the first layer in a model.\n\n# Output shape\n\
    \    Same shape as the input.\n\n# Arguments\n    theta: float >= 0. Threshold\
    \ location of activation.\n\n# References\n    - [Zero-Bias Autoencoders and the\
    \ Benefits of Co-Adapting Features]\n      (https://arxiv.org/abs/1402.3337)"
  kind: Layer
  name: ThresholdedReLU
  parameters:
  - {defaultValue: '1.0', kind: any, name: theta}
  - {defaultValue: 'true', name: trainable, type: bool}
  source: "class ThresholdedReLU(Layer):\n    \"\"\"Thresholded Rectified Linear Unit.\n\
    \n    It follows:\n    `f(x) = x for x > theta`,\n    `f(x) = 0 otherwise`.\n\n\
    \    # Input shape\n        Arbitrary. Use the keyword argument `input_shape`\n\
    \        (tuple of integers, does not include the samples axis)\n        when\
    \ using this layer as the first layer in a model.\n\n    # Output shape\n    \
    \    Same shape as the input.\n\n    # Arguments\n        theta: float >= 0. Threshold\
    \ location of activation.\n\n    # References\n        - [Zero-Bias Autoencoders\
    \ and the Benefits of Co-Adapting Features]\n          (https://arxiv.org/abs/1402.3337)\n\
    \    \"\"\"\n\n    def __init__(self, theta=1.0, **kwargs):\n        super(ThresholdedReLU,\
    \ self).__init__(**kwargs)\n        self.supports_masking = True\n        self.theta\
    \ = K.cast_to_floatx(theta)\n\n    def call(self, inputs, mask=None):\n      \
    \  return inputs * K.cast(K.greater(inputs, self.theta), K.floatx())\n\n    def\
    \ get_config(self):\n        config = {'theta': float(self.theta)}\n        base_config\
    \ = super(ThresholdedReLU, self).get_config()\n        return dict(list(base_config.items())\
    \ + list(config.items()))\n\n    def compute_output_shape(self, input_shape):\n\
    \        return input_shape\n"
  sourcefile: D:\Python36\lib\site-packages\keras\layers\advanced_activations.py
- doc: "This wrapper applies a layer to every temporal slice of an input.\n\nThe input\
    \ should be at least 3D, and the dimension of index one\nwill be considered to\
    \ be the temporal dimension.\n\nConsider a batch of 32 samples,\nwhere each sample\
    \ is a sequence of 10 vectors of 16 dimensions.\nThe batch input shape of the\
    \ layer is then `(32, 10, 16)`,\nand the `input_shape`, not including the samples\
    \ dimension, is `(10, 16)`.\n\nYou can then use `TimeDistributed` to apply a `Dense`\
    \ layer\nto each of the 10 timesteps, independently:\n\n```python\n    # as the\
    \ first layer in a model\n    model = Sequential()\n    model.add(TimeDistributed(Dense(8),\
    \ input_shape=(10, 16)))\n    # now model.output_shape == (None, 10, 8)\n```\n\
    \nThe output will then have shape `(32, 10, 8)`.\n\nIn subsequent layers, there\
    \ is no need for the `input_shape`:\n\n```python\n    model.add(TimeDistributed(Dense(32)))\n\
    \    # now model.output_shape == (None, 10, 32)\n```\n\nThe output will then have\
    \ shape `(32, 10, 32)`.\n\n`TimeDistributed` can be used with arbitrary layers,\
    \ not just `Dense`,\nfor instance with a `Conv2D` layer:\n\n```python\n    model\
    \ = Sequential()\n    model.add(TimeDistributed(Conv2D(64, (3, 3)),\n        \
    \                      input_shape=(10, 299, 299, 3)))\n```\n\n# Arguments\n \
    \   layer: a layer instance."
  kind: Layer
  name: TimeDistributed
  parameters:
  - {kind: any, name: layer}
  - {defaultValue: 'true', name: trainable, type: bool}
  source: "class TimeDistributed(Wrapper):\n    \"\"\"This wrapper applies a layer\
    \ to every temporal slice of an input.\n\n    The input should be at least 3D,\
    \ and the dimension of index one\n    will be considered to be the temporal dimension.\n\
    \n    Consider a batch of 32 samples,\n    where each sample is a sequence of\
    \ 10 vectors of 16 dimensions.\n    The batch input shape of the layer is then\
    \ `(32, 10, 16)`,\n    and the `input_shape`, not including the samples dimension,\
    \ is `(10, 16)`.\n\n    You can then use `TimeDistributed` to apply a `Dense`\
    \ layer\n    to each of the 10 timesteps, independently:\n\n    ```python\n  \
    \      # as the first layer in a model\n        model = Sequential()\n       \
    \ model.add(TimeDistributed(Dense(8), input_shape=(10, 16)))\n        # now model.output_shape\
    \ == (None, 10, 8)\n    ```\n\n    The output will then have shape `(32, 10, 8)`.\n\
    \n    In subsequent layers, there is no need for the `input_shape`:\n\n    ```python\n\
    \        model.add(TimeDistributed(Dense(32)))\n        # now model.output_shape\
    \ == (None, 10, 32)\n    ```\n\n    The output will then have shape `(32, 10,\
    \ 32)`.\n\n    `TimeDistributed` can be used with arbitrary layers, not just `Dense`,\n\
    \    for instance with a `Conv2D` layer:\n\n    ```python\n        model = Sequential()\n\
    \        model.add(TimeDistributed(Conv2D(64, (3, 3)),\n                     \
    \             input_shape=(10, 299, 299, 3)))\n    ```\n\n    # Arguments\n  \
    \      layer: a layer instance.\n    \"\"\"\n\n    def __init__(self, layer, **kwargs):\n\
    \        super(TimeDistributed, self).__init__(layer, **kwargs)\n        self.supports_masking\
    \ = True\n\n    def _get_shape_tuple(self, init_tuple, tensor, start_idx, int_shape=None):\n\
    \        \"\"\"Finds non-specific dimensions in the static shapes\n        and\
    \ replaces them by the corresponding dynamic shapes of the tensor.\n\n       \
    \ # Arguments\n            init_tuple: a tuple, the first part of the output shape\n\
    \            tensor: the tensor from which to get the (static and dynamic) shapes\n\
    \                as the last part of the output shape\n            start_idx:\
    \ int, which indicate the first dimension to take from\n                the static\
    \ shape of the tensor\n            int_shape: an alternative static shape to take\
    \ as the last part\n                of the output shape\n\n        # Returns\n\
    \            The new int_shape with the first part from init_tuple\n         \
    \   and the last part from either `int_shape` (if provided)\n            or K.int_shape(tensor),\
    \ where every `None` is replaced by\n            the corresponding dimension from\
    \ K.shape(tensor)\n        \"\"\"\n        # replace all None in int_shape by\
    \ K.shape\n        if int_shape is None:\n            int_shape = K.int_shape(tensor)[start_idx:]\n\
    \        if not any(not s for s in int_shape):\n            return init_tuple\
    \ + int_shape\n        tensor_shape = K.shape(tensor)\n        int_shape = list(int_shape)\n\
    \        for i, s in enumerate(int_shape):\n            if not s:\n          \
    \      int_shape[i] = tensor_shape[start_idx + i]\n        return init_tuple +\
    \ tuple(int_shape)\n\n    def build(self, input_shape):\n        assert len(input_shape)\
    \ >= 3\n        self.input_spec = InputSpec(shape=input_shape)\n        child_input_shape\
    \ = (input_shape[0],) + input_shape[2:]\n        if not self.layer.built:\n  \
    \          self.layer.build(child_input_shape)\n            self.layer.built =\
    \ True\n        super(TimeDistributed, self).build()\n\n    def compute_output_shape(self,\
    \ input_shape):\n        child_input_shape = (input_shape[0],) + input_shape[2:]\n\
    \        child_output_shape = self.layer.compute_output_shape(child_input_shape)\n\
    \        timesteps = input_shape[1]\n        return (child_output_shape[0], timesteps)\
    \ + child_output_shape[1:]\n\n    def call(self, inputs, training=None, mask=None):\n\
    \        kwargs = {}\n        if has_arg(self.layer.call, 'training'):\n     \
    \       kwargs['training'] = training\n        uses_learning_phase = False\n\n\
    \        input_shape = K.int_shape(inputs)\n        if input_shape[0]:\n     \
    \       # batch size matters, use rnn-based implementation\n            def step(x,\
    \ _):\n                global uses_learning_phase\n                output = self.layer.call(x,\
    \ **kwargs)\n                if hasattr(output, '_uses_learning_phase'):\n   \
    \                 uses_learning_phase = (output._uses_learning_phase or\n    \
    \                                       uses_learning_phase)\n               \
    \ return output, []\n\n            _, outputs, _ = K.rnn(step, inputs,\n     \
    \                             initial_states=[],\n                           \
    \       input_length=input_shape[1],\n                                  unroll=False)\n\
    \            y = outputs\n        else:\n            # No batch size specified,\
    \ therefore the layer will be able\n            # to process batches of any size.\n\
    \            # We can go with reshape-based implementation for performance.\n\
    \            input_length = input_shape[1]\n            if not input_length:\n\
    \                input_length = K.shape(inputs)[1]\n            inner_input_shape\
    \ = self._get_shape_tuple((-1,), inputs, 2)\n            # Shape: (num_samples\
    \ * timesteps, ...). And track the\n            # transformation in self._input_map.\n\
    \            input_uid = object_list_uid(inputs)\n            inputs = K.reshape(inputs,\
    \ inner_input_shape)\n            self._input_map[input_uid] = inputs\n      \
    \      # (num_samples * timesteps, ...)\n            if has_arg(self.layer.call,\
    \ 'mask') and mask is not None:\n                inner_mask_shape = self._get_shape_tuple((-1,),\
    \ mask, 2)\n                kwargs['mask'] = K.reshape(mask, inner_mask_shape)\n\
    \            y = self.layer.call(inputs, **kwargs)\n            if hasattr(y,\
    \ '_uses_learning_phase'):\n                uses_learning_phase = y._uses_learning_phase\n\
    \            # Shape: (num_samples, timesteps, ...)\n            output_shape\
    \ = self.compute_output_shape(input_shape)\n            output_shape = self._get_shape_tuple(\n\
    \                (-1, input_length), y, 1, output_shape[2:])\n            y =\
    \ K.reshape(y, output_shape)\n\n        # Apply activity regularizer if any:\n\
    \        if (hasattr(self.layer, 'activity_regularizer') and\n           self.layer.activity_regularizer\
    \ is not None):\n            regularization_loss = self.layer.activity_regularizer(y)\n\
    \            self.add_loss(regularization_loss, inputs)\n\n        if uses_learning_phase:\n\
    \            y._uses_learning_phase = True\n        return y\n\n    def compute_mask(self,\
    \ inputs, mask=None):\n        \"\"\"Computes an output mask tensor for Embedding\
    \ layer\n        based on the inputs, mask, and the inner layer.\n\n        If\
    \ batch size is specified:\n        Simply return the input `mask`. (An rnn-based\
    \ implementation with\n        more than one rnn inputs is required but not supported\
    \ in Keras yet.)\n\n        Otherwise we call `compute_mask` of the inner layer\
    \ at each time step.\n        If the output mask at each time step is not `None`:\n\
    \        (E.g., inner layer is Masking or RNN)\n        Concatenate all of them\
    \ and return the concatenation.\n        If the output mask at each time step\
    \ is `None` and\n        the input mask is not `None`:\n        (E.g., inner layer\
    \ is Dense)\n        Reduce the input_mask to 2 dimensions and return it.\n  \
    \      Otherwise (both the output mask and the input mask are `None`):\n     \
    \   (E.g., `mask` is not used at all)\n        Return `None`.\n\n        # Arguments\n\
    \            inputs: Tensor\n            mask: Tensor\n        # Returns\n   \
    \         None or a tensor\n        \"\"\"\n        # cases need to call the layer.compute_mask\
    \ when input_mask is None:\n        # Masking layer and Embedding layer with mask_zero\n\
    \        input_shape = K.int_shape(inputs)\n        if input_shape[0]:\n     \
    \       # batch size matters, we currently do not handle mask explicitly\n   \
    \         return mask\n        inner_mask = mask\n        if inner_mask is not\
    \ None:\n            inner_mask_shape = self._get_shape_tuple((-1,), mask, 2)\n\
    \            inner_mask = K.reshape(inner_mask, inner_mask_shape)\n        input_uid\
    \ = object_list_uid(inputs)\n        inner_inputs = self._input_map[input_uid]\n\
    \        output_mask = self.layer.compute_mask(inner_inputs, inner_mask)\n   \
    \     if output_mask is None:\n            if mask is None:\n                return\
    \ None\n            # input_mask is not None, and output_mask is None:\n     \
    \       # we should return a not-None mask\n            output_mask = mask\n \
    \           for _ in range(2, len(K.int_shape(mask))):\n                output_mask\
    \ = K.any(output_mask, axis=-1)\n        else:\n            # output_mask is not\
    \ None. We need to reshape it\n            input_length = input_shape[1]\n   \
    \         if not input_length:\n                input_length = K.shape(inputs)[1]\n\
    \            output_mask_int_shape = K.int_shape(output_mask)\n            if\
    \ output_mask_int_shape is None:\n                # if the output_mask does not\
    \ have a static shape,\n                # its shape must be the same as mask's\n\
    \                if mask is not None:\n                    output_mask_int_shape\
    \ = K.int_shape(mask)\n                else:\n                    output_mask_int_shape\
    \ = K.compute_output_shape(input_shape)[:-1]\n            output_mask_shape =\
    \ self._get_shape_tuple(\n                (-1, input_length), output_mask, 1,\
    \ output_mask_int_shape[1:])\n            output_mask = K.reshape(output_mask,\
    \ output_mask_shape)\n        return output_mask\n"
  sourcefile: D:\Python36\lib\site-packages\keras\layers\wrappers.py
- doc: "Upsampling layer for 1D inputs.\n\nRepeats each temporal step `size` times\
    \ along the time axis.\n\n# Arguments\n    size: integer. Upsampling factor.\n\
    \n# Input shape\n    3D tensor with shape: `(batch, steps, features)`.\n\n# Output\
    \ shape\n    3D tensor with shape: `(batch, upsampled_steps, features)`."
  kind: Layer
  name: UpSampling1D
  parameters:
  - {defaultValue: '2', kind: any, name: size}
  - {defaultValue: 'true', name: trainable, type: bool}
  source: "class UpSampling1D(_UpSampling):\n    \"\"\"Upsampling layer for 1D inputs.\n\
    \n    Repeats each temporal step `size` times along the time axis.\n\n    # Arguments\n\
    \        size: integer. Upsampling factor.\n\n    # Input shape\n        3D tensor\
    \ with shape: `(batch, steps, features)`.\n\n    # Output shape\n        3D tensor\
    \ with shape: `(batch, upsampled_steps, features)`.\n    \"\"\"\n\n    @interfaces.legacy_upsampling1d_support\n\
    \    def __init__(self, size=2, **kwargs):\n        super(UpSampling1D, self).__init__((int(size),),\
    \ 'channels_last', **kwargs)\n\n    def call(self, inputs):\n        output =\
    \ K.repeat_elements(inputs, self.size[0], axis=1)\n        return output\n\n \
    \   def get_config(self):\n        config = super(UpSampling1D, self).get_config()\n\
    \        config['size'] = self.size[0]\n        config.pop('data_format')\n  \
    \      return config\n"
  sourcefile: D:\Python36\lib\site-packages\keras\layers\convolutional.py
- doc: "Upsampling layer for 2D inputs.\n\nRepeats the rows and columns of the data\n\
    by size[0] and size[1] respectively.\n\n# Arguments\n    size: int, or tuple of\
    \ 2 integers.\n        The upsampling factors for rows and columns.\n    data_format:\
    \ A string,\n        one of `\"channels_last\"` or `\"channels_first\"`.\n   \
    \     The ordering of the dimensions in the inputs.\n        `\"channels_last\"\
    ` corresponds to inputs with shape\n        `(batch, height, width, channels)`\
    \ while `\"channels_first\"`\n        corresponds to inputs with shape\n     \
    \   `(batch, channels, height, width)`.\n        It defaults to the `image_data_format`\
    \ value found in your\n        Keras config file at `~/.keras/keras.json`.\n \
    \       If you never set it, then it will be \"channels_last\".\n    interpolation:\
    \ A string, one of `nearest` or `bilinear`.\n        Note that CNTK does not support\
    \ yet the `bilinear` upscaling\n        and that with Theano, only `size=(2, 2)`\
    \ is possible.\n\n# Input shape\n    4D tensor with shape:\n    - If `data_format`\
    \ is `\"channels_last\"`:\n        `(batch, rows, cols, channels)`\n    - If `data_format`\
    \ is `\"channels_first\"`:\n        `(batch, channels, rows, cols)`\n\n# Output\
    \ shape\n    4D tensor with shape:\n    - If `data_format` is `\"channels_last\"\
    `:\n        `(batch, upsampled_rows, upsampled_cols, channels)`\n    - If `data_format`\
    \ is `\"channels_first\"`:\n        `(batch, channels, upsampled_rows, upsampled_cols)`"
  kind: Layer
  name: UpSampling2D
  parameters:
  - {defaultValue: '(2, 2)', kind: any, name: size}
  - {defaultValue: None, kind: any, name: data_format}
  - {defaultValue: nearest, kind: any, name: interpolation}
  - {defaultValue: 'true', name: trainable, type: bool}
  source: "class UpSampling2D(_UpSampling):\n    \"\"\"Upsampling layer for 2D inputs.\n\
    \n    Repeats the rows and columns of the data\n    by size[0] and size[1] respectively.\n\
    \n    # Arguments\n        size: int, or tuple of 2 integers.\n            The\
    \ upsampling factors for rows and columns.\n        data_format: A string,\n \
    \           one of `\"channels_last\"` or `\"channels_first\"`.\n            The\
    \ ordering of the dimensions in the inputs.\n            `\"channels_last\"` corresponds\
    \ to inputs with shape\n            `(batch, height, width, channels)` while `\"\
    channels_first\"`\n            corresponds to inputs with shape\n            `(batch,\
    \ channels, height, width)`.\n            It defaults to the `image_data_format`\
    \ value found in your\n            Keras config file at `~/.keras/keras.json`.\n\
    \            If you never set it, then it will be \"channels_last\".\n       \
    \ interpolation: A string, one of `nearest` or `bilinear`.\n            Note that\
    \ CNTK does not support yet the `bilinear` upscaling\n            and that with\
    \ Theano, only `size=(2, 2)` is possible.\n\n    # Input shape\n        4D tensor\
    \ with shape:\n        - If `data_format` is `\"channels_last\"`:\n          \
    \  `(batch, rows, cols, channels)`\n        - If `data_format` is `\"channels_first\"\
    `:\n            `(batch, channels, rows, cols)`\n\n    # Output shape\n      \
    \  4D tensor with shape:\n        - If `data_format` is `\"channels_last\"`:\n\
    \            `(batch, upsampled_rows, upsampled_cols, channels)`\n        - If\
    \ `data_format` is `\"channels_first\"`:\n            `(batch, channels, upsampled_rows,\
    \ upsampled_cols)`\n    \"\"\"\n\n    @interfaces.legacy_upsampling2d_support\n\
    \    def __init__(self, size=(2, 2), data_format=None, interpolation='nearest',\n\
    \                 **kwargs):\n        normalized_size = conv_utils.normalize_tuple(size,\
    \ 2, 'size')\n        super(UpSampling2D, self).__init__(normalized_size, data_format,\
    \ **kwargs)\n        if interpolation not in ['nearest', 'bilinear']:\n      \
    \      raise ValueError('interpolation should be one '\n                     \
    \        'of \"nearest\" or \"bilinear\".')\n        self.interpolation = interpolation\n\
    \n    def call(self, inputs):\n        return K.resize_images(inputs, self.size[0],\
    \ self.size[1],\n                               self.data_format, self.interpolation)\n\
    \n    def get_config(self):\n        config = super(UpSampling2D, self).get_config()\n\
    \        config['interpolation'] = self.interpolation\n        return config\n"
  sourcefile: D:\Python36\lib\site-packages\keras\layers\convolutional.py
- doc: "Upsampling layer for 3D inputs.\n\nRepeats the 1st, 2nd and 3rd dimensions\n\
    of the data by size[0], size[1] and size[2] respectively.\n\n# Arguments\n   \
    \ size: int, or tuple of 3 integers.\n        The upsampling factors for dim1,\
    \ dim2 and dim3.\n    data_format: A string,\n        one of `\"channels_last\"\
    ` or `\"channels_first\"`.\n        The ordering of the dimensions in the inputs.\n\
    \        `\"channels_last\"` corresponds to inputs with shape\n        `(batch,\
    \ spatial_dim1, spatial_dim2, spatial_dim3, channels)`\n        while `\"channels_first\"\
    ` corresponds to inputs with shape\n        `(batch, channels, spatial_dim1, spatial_dim2,\
    \ spatial_dim3)`.\n        It defaults to the `image_data_format` value found\
    \ in your\n        Keras config file at `~/.keras/keras.json`.\n        If you\
    \ never set it, then it will be \"channels_last\".\n\n# Input shape\n    5D tensor\
    \ with shape:\n    - If `data_format` is `\"channels_last\"`:\n        `(batch,\
    \ dim1, dim2, dim3, channels)`\n    - If `data_format` is `\"channels_first\"\
    `:\n        `(batch, channels, dim1, dim2, dim3)`\n\n# Output shape\n    5D tensor\
    \ with shape:\n    - If `data_format` is `\"channels_last\"`:\n        `(batch,\
    \ upsampled_dim1, upsampled_dim2, upsampled_dim3, channels)`\n    - If `data_format`\
    \ is `\"channels_first\"`:\n        `(batch, channels, upsampled_dim1, upsampled_dim2,\
    \ upsampled_dim3)`"
  kind: Layer
  name: UpSampling3D
  parameters:
  - {defaultValue: '(2, 2, 2)', kind: any, name: size}
  - {defaultValue: None, kind: any, name: data_format}
  - {defaultValue: 'true', name: trainable, type: bool}
  source: "class UpSampling3D(_UpSampling):\n    \"\"\"Upsampling layer for 3D inputs.\n\
    \n    Repeats the 1st, 2nd and 3rd dimensions\n    of the data by size[0], size[1]\
    \ and size[2] respectively.\n\n    # Arguments\n        size: int, or tuple of\
    \ 3 integers.\n            The upsampling factors for dim1, dim2 and dim3.\n \
    \       data_format: A string,\n            one of `\"channels_last\"` or `\"\
    channels_first\"`.\n            The ordering of the dimensions in the inputs.\n\
    \            `\"channels_last\"` corresponds to inputs with shape\n          \
    \  `(batch, spatial_dim1, spatial_dim2, spatial_dim3, channels)`\n           \
    \ while `\"channels_first\"` corresponds to inputs with shape\n            `(batch,\
    \ channels, spatial_dim1, spatial_dim2, spatial_dim3)`.\n            It defaults\
    \ to the `image_data_format` value found in your\n            Keras config file\
    \ at `~/.keras/keras.json`.\n            If you never set it, then it will be\
    \ \"channels_last\".\n\n    # Input shape\n        5D tensor with shape:\n   \
    \     - If `data_format` is `\"channels_last\"`:\n            `(batch, dim1, dim2,\
    \ dim3, channels)`\n        - If `data_format` is `\"channels_first\"`:\n    \
    \        `(batch, channels, dim1, dim2, dim3)`\n\n    # Output shape\n       \
    \ 5D tensor with shape:\n        - If `data_format` is `\"channels_last\"`:\n\
    \            `(batch, upsampled_dim1, upsampled_dim2, upsampled_dim3, channels)`\n\
    \        - If `data_format` is `\"channels_first\"`:\n            `(batch, channels,\
    \ upsampled_dim1, upsampled_dim2, upsampled_dim3)`\n    \"\"\"\n\n    @interfaces.legacy_upsampling3d_support\n\
    \    def __init__(self, size=(2, 2, 2), data_format=None, **kwargs):\n       \
    \ normalized_size = conv_utils.normalize_tuple(size, 3, 'size')\n        super(UpSampling3D,\
    \ self).__init__(normalized_size, data_format, **kwargs)\n\n    def call(self,\
    \ inputs):\n        return K.resize_volumes(inputs,\n                        \
    \        self.size[0], self.size[1], self.size[2],\n                         \
    \       self.data_format)\n"
  sourcefile: D:\Python36\lib\site-packages\keras\layers\convolutional.py
- doc: "Abstract wrapper base class.\n\nWrappers take another layer and augment it\
    \ in various ways.\nDo not use this class as a layer, it is only an abstract base\
    \ class.\nTwo usable wrappers are the `TimeDistributed` and `Bidirectional` wrappers.\n\
    \n# Arguments\n    layer: The layer to be wrapped."
  kind: Layer
  name: Wrapper
  parameters:
  - {kind: any, name: layer}
  - {defaultValue: 'true', name: trainable, type: bool}
  source: "class Wrapper(Layer):\n    \"\"\"Abstract wrapper base class.\n\n    Wrappers\
    \ take another layer and augment it in various ways.\n    Do not use this class\
    \ as a layer, it is only an abstract base class.\n    Two usable wrappers are\
    \ the `TimeDistributed` and `Bidirectional` wrappers.\n\n    # Arguments\n   \
    \     layer: The layer to be wrapped.\n    \"\"\"\n\n    def __init__(self, layer,\
    \ **kwargs):\n        self.layer = layer\n        # Tracks mapping of Wrapper\
    \ inputs to inner layer inputs. Useful when\n        # the inner layer has update\
    \ ops that depend on its inputs (as opposed\n        # to the inputs to the Wrapper\
    \ layer).\n        self._input_map = {}\n        super(Wrapper, self).__init__(**kwargs)\n\
    \n    def build(self, input_shape=None):\n        self.built = True\n\n    @property\n\
    \    def activity_regularizer(self):\n        if hasattr(self.layer, 'activity_regularizer'):\n\
    \            return self.layer.activity_regularizer\n        else:\n         \
    \   return None\n\n    @property\n    def trainable(self):\n        return self.layer.trainable\n\
    \n    @trainable.setter\n    def trainable(self, value):\n        self.layer.trainable\
    \ = value\n\n    @property\n    def trainable_weights(self):\n        return self.layer.trainable_weights\n\
    \n    @property\n    def non_trainable_weights(self):\n        return self.layer.non_trainable_weights\n\
    \n    @property\n    def updates(self):\n        if hasattr(self.layer, 'updates'):\n\
    \            return self.layer.updates\n        return []\n\n    def get_updates_for(self,\
    \ inputs=None):\n        # If the wrapper modifies the inputs, use the modified\
    \ inputs to\n        # get the updates from the inner layer.\n        inner_inputs\
    \ = inputs\n        if inputs is not None:\n            uid = object_list_uid(inputs)\n\
    \            if uid in self._input_map:\n                inner_inputs = self._input_map[uid]\n\
    \n        updates = self.layer.get_updates_for(inner_inputs)\n        updates\
    \ += super(Wrapper, self).get_updates_for(inputs)\n        return updates\n\n\
    \    @property\n    def losses(self):\n        if hasattr(self.layer, 'losses'):\n\
    \            return self.layer.losses\n        return []\n\n    def get_losses_for(self,\
    \ inputs=None):\n        if inputs is None:\n            losses = self.layer.get_losses_for(None)\n\
    \            return losses + super(Wrapper, self).get_losses_for(None)\n     \
    \   return super(Wrapper, self).get_losses_for(inputs)\n\n    def get_weights(self):\n\
    \        return self.layer.get_weights()\n\n    def set_weights(self, weights):\n\
    \        self.layer.set_weights(weights)\n\n    def get_config(self):\n      \
    \  config = {'layer': {'class_name': self.layer.__class__.__name__,\n        \
    \                    'config': self.layer.get_config()}}\n        base_config\
    \ = super(Wrapper, self).get_config()\n        return dict(list(base_config.items())\
    \ + list(config.items()))\n\n    @classmethod\n    def from_config(cls, config,\
    \ custom_objects=None):\n        from . import deserialize as deserialize_layer\n\
    \        layer = deserialize_layer(config.pop('layer'),\n                    \
    \              custom_objects=custom_objects)\n        return cls(layer, **config)\n"
  sourcefile: D:\Python36\lib\site-packages\keras\layers\wrappers.py
- doc: "Zero-padding layer for 1D input (e.g. temporal sequence).\n\n# Arguments\n\
    \    padding: int, or tuple of int (length 2), or dictionary.\n        - If int:\n\
    \        How many zeros to add at the beginning and end of\n        the padding\
    \ dimension (axis 1).\n        - If tuple of int (length 2):\n        How many\
    \ zeros to add at the beginning and at the end of\n        the padding dimension\
    \ (`(left_pad, right_pad)`).\n\n# Input shape\n    3D tensor with shape `(batch,\
    \ axis_to_pad, features)`\n\n# Output shape\n    3D tensor with shape `(batch,\
    \ padded_axis, features)`"
  kind: Layer
  name: ZeroPadding1D
  parameters:
  - {defaultValue: '1', kind: any, name: padding}
  - {defaultValue: 'true', name: trainable, type: bool}
  source: "class ZeroPadding1D(_ZeroPadding):\n    \"\"\"Zero-padding layer for 1D\
    \ input (e.g. temporal sequence).\n\n    # Arguments\n        padding: int, or\
    \ tuple of int (length 2), or dictionary.\n            - If int:\n           \
    \ How many zeros to add at the beginning and end of\n            the padding dimension\
    \ (axis 1).\n            - If tuple of int (length 2):\n            How many zeros\
    \ to add at the beginning and at the end of\n            the padding dimension\
    \ (`(left_pad, right_pad)`).\n\n    # Input shape\n        3D tensor with shape\
    \ `(batch, axis_to_pad, features)`\n\n    # Output shape\n        3D tensor with\
    \ shape `(batch, padded_axis, features)`\n    \"\"\"\n\n    def __init__(self,\
    \ padding=1, **kwargs):\n        normalized_padding = (conv_utils.normalize_tuple(padding,\
    \ 2, 'padding'),)\n        super(ZeroPadding1D, self).__init__(normalized_padding,\n\
    \                                            'channels_last',\n              \
    \                              **kwargs)\n\n    def call(self, inputs):\n    \
    \    return K.temporal_padding(inputs, padding=self.padding[0])\n\n    def get_config(self):\n\
    \        config = super(ZeroPadding1D, self).get_config()\n        config['padding']\
    \ = config['padding'][0]\n        config.pop('data_format')\n        return config\n"
  sourcefile: D:\Python36\lib\site-packages\keras\layers\convolutional.py
- doc: "Zero-padding layer for 2D input (e.g. picture).\n\nThis layer can add rows\
    \ and columns of zeros\nat the top, bottom, left and right side of an image tensor.\n\
    \n# Arguments\n    padding: int, or tuple of 2 ints, or tuple of 2 tuples of 2\
    \ ints.\n        - If int: the same symmetric padding\n            is applied\
    \ to height and width.\n        - If tuple of 2 ints:\n            interpreted\
    \ as two different\n            symmetric padding values for height and width:\n\
    \            `(symmetric_height_pad, symmetric_width_pad)`.\n        - If tuple\
    \ of 2 tuples of 2 ints:\n            interpreted as\n            `((top_pad,\
    \ bottom_pad), (left_pad, right_pad))`\n    data_format: A string,\n        one\
    \ of `\"channels_last\"` or `\"channels_first\"`.\n        The ordering of the\
    \ dimensions in the inputs.\n        `\"channels_last\"` corresponds to inputs\
    \ with shape\n        `(batch, height, width, channels)` while `\"channels_first\"\
    `\n        corresponds to inputs with shape\n        `(batch, channels, height,\
    \ width)`.\n        It defaults to the `image_data_format` value found in your\n\
    \        Keras config file at `~/.keras/keras.json`.\n        If you never set\
    \ it, then it will be \"channels_last\".\n\n# Input shape\n    4D tensor with\
    \ shape:\n    - If `data_format` is `\"channels_last\"`:\n        `(batch, rows,\
    \ cols, channels)`\n    - If `data_format` is `\"channels_first\"`:\n        `(batch,\
    \ channels, rows, cols)`\n\n# Output shape\n    4D tensor with shape:\n    - If\
    \ `data_format` is `\"channels_last\"`:\n        `(batch, padded_rows, padded_cols,\
    \ channels)`\n    - If `data_format` is `\"channels_first\"`:\n        `(batch,\
    \ channels, padded_rows, padded_cols)`"
  kind: Layer
  name: ZeroPadding2D
  parameters:
  - {defaultValue: '(1, 1)', kind: any, name: padding}
  - {defaultValue: None, kind: any, name: data_format}
  - {defaultValue: 'true', name: trainable, type: bool}
  source: "class ZeroPadding2D(_ZeroPadding):\n    \"\"\"Zero-padding layer for 2D\
    \ input (e.g. picture).\n\n    This layer can add rows and columns of zeros\n\
    \    at the top, bottom, left and right side of an image tensor.\n\n    # Arguments\n\
    \        padding: int, or tuple of 2 ints, or tuple of 2 tuples of 2 ints.\n \
    \           - If int: the same symmetric padding\n                is applied to\
    \ height and width.\n            - If tuple of 2 ints:\n                interpreted\
    \ as two different\n                symmetric padding values for height and width:\n\
    \                `(symmetric_height_pad, symmetric_width_pad)`.\n            -\
    \ If tuple of 2 tuples of 2 ints:\n                interpreted as\n          \
    \      `((top_pad, bottom_pad), (left_pad, right_pad))`\n        data_format:\
    \ A string,\n            one of `\"channels_last\"` or `\"channels_first\"`.\n\
    \            The ordering of the dimensions in the inputs.\n            `\"channels_last\"\
    ` corresponds to inputs with shape\n            `(batch, height, width, channels)`\
    \ while `\"channels_first\"`\n            corresponds to inputs with shape\n \
    \           `(batch, channels, height, width)`.\n            It defaults to the\
    \ `image_data_format` value found in your\n            Keras config file at `~/.keras/keras.json`.\n\
    \            If you never set it, then it will be \"channels_last\".\n\n    #\
    \ Input shape\n        4D tensor with shape:\n        - If `data_format` is `\"\
    channels_last\"`:\n            `(batch, rows, cols, channels)`\n        - If `data_format`\
    \ is `\"channels_first\"`:\n            `(batch, channels, rows, cols)`\n\n  \
    \  # Output shape\n        4D tensor with shape:\n        - If `data_format` is\
    \ `\"channels_last\"`:\n            `(batch, padded_rows, padded_cols, channels)`\n\
    \        - If `data_format` is `\"channels_first\"`:\n            `(batch, channels,\
    \ padded_rows, padded_cols)`\n    \"\"\"\n\n    @interfaces.legacy_zeropadding2d_support\n\
    \    def __init__(self,\n                 padding=(1, 1),\n                 data_format=None,\n\
    \                 **kwargs):\n        if isinstance(padding, int):\n         \
    \   normalized_padding = ((padding, padding), (padding, padding))\n        elif\
    \ hasattr(padding, '__len__'):\n            if len(padding) != 2:\n          \
    \      raise ValueError('`padding` should have two elements. '\n             \
    \                    'Found: ' + str(padding))\n            height_padding = conv_utils.normalize_tuple(padding[0],\
    \ 2,\n                                                        '1st entry of padding')\n\
    \            width_padding = conv_utils.normalize_tuple(padding[1], 2,\n     \
    \                                                  '2nd entry of padding')\n \
    \           normalized_padding = (height_padding, width_padding)\n        else:\n\
    \            raise ValueError('`padding` should be either an int, '\n        \
    \                     'a tuple of 2 ints '\n                             '(symmetric_height_pad,\
    \ symmetric_width_pad), '\n                             'or a tuple of 2 tuples\
    \ of 2 ints '\n                             '((top_pad, bottom_pad), (left_pad,\
    \ right_pad)). '\n                             'Found: ' + str(padding))\n   \
    \     super(ZeroPadding2D, self).__init__(normalized_padding,\n              \
    \                              data_format,\n                                \
    \            **kwargs)\n\n    def call(self, inputs):\n        return K.spatial_2d_padding(inputs,\n\
    \                                    padding=self.padding,\n                 \
    \                   data_format=self.data_format)\n"
  sourcefile: D:\Python36\lib\site-packages\keras\layers\convolutional.py
- doc: "Zero-padding layer for 3D data (spatial or spatio-temporal).\n\n# Arguments\n\
    \    padding: int, or tuple of 3 ints, or tuple of 3 tuples of 2 ints.\n     \
    \   - If int: the same symmetric padding\n            is applied to height and\
    \ width.\n        - If tuple of 3 ints:\n            interpreted as two different\n\
    \            symmetric padding values for height and width:\n            `(symmetric_dim1_pad,\
    \ symmetric_dim2_pad, symmetric_dim3_pad)`.\n        - If tuple of 3 tuples of\
    \ 2 ints:\n            interpreted as\n            `((left_dim1_pad, right_dim1_pad),\n\
    \              (left_dim2_pad, right_dim2_pad),\n              (left_dim3_pad,\
    \ right_dim3_pad))`\n    data_format: A string,\n        one of `\"channels_last\"\
    ` or `\"channels_first\"`.\n        The ordering of the dimensions in the inputs.\n\
    \        `\"channels_last\"` corresponds to inputs with shape\n        `(batch,\
    \ spatial_dim1, spatial_dim2, spatial_dim3, channels)`\n        while `\"channels_first\"\
    ` corresponds to inputs with shape\n        `(batch, channels, spatial_dim1, spatial_dim2,\
    \ spatial_dim3)`.\n        It defaults to the `image_data_format` value found\
    \ in your\n        Keras config file at `~/.keras/keras.json`.\n        If you\
    \ never set it, then it will be \"channels_last\".\n\n# Input shape\n    5D tensor\
    \ with shape:\n    - If `data_format` is `\"channels_last\"`:\n        `(batch,\
    \ first_axis_to_pad, second_axis_to_pad, third_axis_to_pad,\n          depth)`\n\
    \    - If `data_format` is `\"channels_first\"`:\n        `(batch, depth,\n  \
    \        first_axis_to_pad, second_axis_to_pad, third_axis_to_pad)`\n\n# Output\
    \ shape\n    5D tensor with shape:\n    - If `data_format` is `\"channels_last\"\
    `:\n        `(batch, first_padded_axis, second_padded_axis, third_axis_to_pad,\n\
    \          depth)`\n    - If `data_format` is `\"channels_first\"`:\n        `(batch,\
    \ depth,\n          first_padded_axis, second_padded_axis, third_axis_to_pad)`"
  kind: Layer
  name: ZeroPadding3D
  parameters:
  - {defaultValue: '(1, 1, 1)', kind: any, name: padding}
  - {defaultValue: None, kind: any, name: data_format}
  - {defaultValue: 'true', name: trainable, type: bool}
  source: "class ZeroPadding3D(_ZeroPadding):\n    \"\"\"Zero-padding layer for 3D\
    \ data (spatial or spatio-temporal).\n\n    # Arguments\n        padding: int,\
    \ or tuple of 3 ints, or tuple of 3 tuples of 2 ints.\n            - If int: the\
    \ same symmetric padding\n                is applied to height and width.\n  \
    \          - If tuple of 3 ints:\n                interpreted as two different\n\
    \                symmetric padding values for height and width:\n            \
    \    `(symmetric_dim1_pad, symmetric_dim2_pad, symmetric_dim3_pad)`.\n       \
    \     - If tuple of 3 tuples of 2 ints:\n                interpreted as\n    \
    \            `((left_dim1_pad, right_dim1_pad),\n                  (left_dim2_pad,\
    \ right_dim2_pad),\n                  (left_dim3_pad, right_dim3_pad))`\n    \
    \    data_format: A string,\n            one of `\"channels_last\"` or `\"channels_first\"\
    `.\n            The ordering of the dimensions in the inputs.\n            `\"\
    channels_last\"` corresponds to inputs with shape\n            `(batch, spatial_dim1,\
    \ spatial_dim2, spatial_dim3, channels)`\n            while `\"channels_first\"\
    ` corresponds to inputs with shape\n            `(batch, channels, spatial_dim1,\
    \ spatial_dim2, spatial_dim3)`.\n            It defaults to the `image_data_format`\
    \ value found in your\n            Keras config file at `~/.keras/keras.json`.\n\
    \            If you never set it, then it will be \"channels_last\".\n\n    #\
    \ Input shape\n        5D tensor with shape:\n        - If `data_format` is `\"\
    channels_last\"`:\n            `(batch, first_axis_to_pad, second_axis_to_pad,\
    \ third_axis_to_pad,\n              depth)`\n        - If `data_format` is `\"\
    channels_first\"`:\n            `(batch, depth,\n              first_axis_to_pad,\
    \ second_axis_to_pad, third_axis_to_pad)`\n\n    # Output shape\n        5D tensor\
    \ with shape:\n        - If `data_format` is `\"channels_last\"`:\n          \
    \  `(batch, first_padded_axis, second_padded_axis, third_axis_to_pad,\n      \
    \        depth)`\n        - If `data_format` is `\"channels_first\"`:\n      \
    \      `(batch, depth,\n              first_padded_axis, second_padded_axis, third_axis_to_pad)`\n\
    \    \"\"\"\n\n    @interfaces.legacy_zeropadding3d_support\n    def __init__(self,\
    \ padding=(1, 1, 1), data_format=None, **kwargs):\n        if isinstance(padding,\
    \ int):\n            normalized_padding = 3 * ((padding, padding),)\n        elif\
    \ hasattr(padding, '__len__'):\n            if len(padding) != 3:\n          \
    \      raise ValueError('`padding` should have 3 elements. '\n               \
    \                  'Found: ' + str(padding))\n            dim1_padding = conv_utils.normalize_tuple(padding[0],\
    \ 2,\n                                                      '1st entry of padding')\n\
    \            dim2_padding = conv_utils.normalize_tuple(padding[1], 2,\n      \
    \                                                '2nd entry of padding')\n   \
    \         dim3_padding = conv_utils.normalize_tuple(padding[2], 2,\n         \
    \                                             '3rd entry of padding')\n      \
    \      normalized_padding = (dim1_padding, dim2_padding, dim3_padding)\n     \
    \   else:\n            raise ValueError(\n                '`padding` should be\
    \ either an int, a tuple of 3 ints '\n                '(symmetric_dim1_pad, symmetric_dim2_pad,\
    \ symmetric_dim3_pad), '\n                'or a tuple of 3 tuples of 2 ints '\n\
    \                '((left_dim1_pad, right_dim1_pad),'\n                ' (left_dim2_pad,\
    \ right_dim2_pad),'\n                ' (left_dim3_pad, right_dim2_pad)). '\n \
    \               'Found: ' + str(padding))\n        super(ZeroPadding3D, self).__init__(normalized_padding,\n\
    \                                            data_format,\n                  \
    \                          **kwargs)\n\n    def call(self, inputs):\n        return\
    \ K.spatial_3d_padding(inputs,\n                                    padding=self.padding,\n\
    \                                    data_format=self.data_format)\n"
  sourcefile: D:\Python36\lib\site-packages\keras\layers\convolutional.py
- doc: "Callback that accumulates epoch averages of metrics.\n\nThis callback is automatically\
    \ applied to every Keras model.\n\n# Arguments\n    stateful_metrics: Iterable\
    \ of string names of metrics that\n        should *not* be averaged over an epoch.\n\
    \        Metrics in this list will be logged as-is in `on_epoch_end`.\n      \
    \  All others will be averaged in `on_epoch_end`."
  kind: Callback
  name: BaseLogger
  parameters:
  - {defaultValue: None, kind: any, name: stateful_metrics}
  source: "class BaseLogger(Callback):\n    \"\"\"Callback that accumulates epoch\
    \ averages of metrics.\n\n    This callback is automatically applied to every\
    \ Keras model.\n\n    # Arguments\n        stateful_metrics: Iterable of string\
    \ names of metrics that\n            should *not* be averaged over an epoch.\n\
    \            Metrics in this list will be logged as-is in `on_epoch_end`.\n  \
    \          All others will be averaged in `on_epoch_end`.\n    \"\"\"\n\n    def\
    \ __init__(self, stateful_metrics=None):\n        if stateful_metrics:\n     \
    \       self.stateful_metrics = set(stateful_metrics)\n        else:\n       \
    \     self.stateful_metrics = set()\n\n    def on_epoch_begin(self, epoch, logs=None):\n\
    \        self.seen = 0\n        self.totals = {}\n\n    def on_batch_end(self,\
    \ batch, logs=None):\n        logs = logs or {}\n        batch_size = logs.get('size',\
    \ 0)\n        self.seen += batch_size\n\n        for k, v in logs.items():\n \
    \           if k in self.stateful_metrics:\n                self.totals[k] = v\n\
    \            else:\n                if k in self.totals:\n                   \
    \ self.totals[k] += v * batch_size\n                else:\n                  \
    \  self.totals[k] = v * batch_size\n\n    def on_epoch_end(self, epoch, logs=None):\n\
    \        if logs is not None:\n            for k in self.params['metrics']:\n\
    \                if k in self.totals:\n                    # Make value available\
    \ to next callbacks.\n                    if k in self.stateful_metrics:\n   \
    \                     logs[k] = self.totals[k]\n                    else:\n  \
    \                      logs[k] = self.totals[k] / self.seen\n"
  sourcefile: D:\Python36\lib\site-packages\keras\callbacks.py
- doc: "Callback that streams epoch results to a csv file.\n\nSupports all values\
    \ that can be represented as a string,\nincluding 1D iterables such as np.ndarray.\n\
    \n# Example\n\n```python\ncsv_logger = CSVLogger('training.log')\nmodel.fit(X_train,\
    \ Y_train, callbacks=[csv_logger])\n```\n\n# Arguments\n    filename: filename\
    \ of the csv file, e.g. 'run/log.csv'.\n    separator: string used to separate\
    \ elements in the csv file.\n    append: True: append if file exists (useful for\
    \ continuing\n        training). False: overwrite existing file,"
  kind: Callback
  name: CSVLogger
  parameters:
  - {kind: any, name: filename}
  - {defaultValue: ',', kind: any, name: separator}
  - {defaultValue: 'False', kind: any, name: append}
  source: "class CSVLogger(Callback):\n    \"\"\"Callback that streams epoch results\
    \ to a csv file.\n\n    Supports all values that can be represented as a string,\n\
    \    including 1D iterables such as np.ndarray.\n\n    # Example\n\n    ```python\n\
    \    csv_logger = CSVLogger('training.log')\n    model.fit(X_train, Y_train, callbacks=[csv_logger])\n\
    \    ```\n\n    # Arguments\n        filename: filename of the csv file, e.g.\
    \ 'run/log.csv'.\n        separator: string used to separate elements in the csv\
    \ file.\n        append: True: append if file exists (useful for continuing\n\
    \            training). False: overwrite existing file,\n    \"\"\"\n\n    def\
    \ __init__(self, filename, separator=',', append=False):\n        self.sep = separator\n\
    \        self.filename = filename\n        self.append = append\n        self.writer\
    \ = None\n        self.keys = None\n        self.append_header = True\n      \
    \  if six.PY2:\n            self.file_flags = 'b'\n            self._open_args\
    \ = {}\n        else:\n            self.file_flags = ''\n            self._open_args\
    \ = {'newline': '\\n'}\n        super(CSVLogger, self).__init__()\n\n    def on_train_begin(self,\
    \ logs=None):\n        if self.append:\n            if os.path.exists(self.filename):\n\
    \                with open(self.filename, 'r' + self.file_flags) as f:\n     \
    \               self.append_header = not bool(len(f.readline()))\n           \
    \ mode = 'a'\n        else:\n            mode = 'w'\n        self.csv_file = io.open(self.filename,\n\
    \                                mode + self.file_flags,\n                   \
    \             **self._open_args)\n\n    def on_epoch_end(self, epoch, logs=None):\n\
    \        logs = logs or {}\n\n        def handle_value(k):\n            is_zero_dim_ndarray\
    \ = isinstance(k, np.ndarray) and k.ndim == 0\n            if isinstance(k, six.string_types):\n\
    \                return k\n            elif isinstance(k, Iterable) and not is_zero_dim_ndarray:\n\
    \                return '\"[%s]\"' % (', '.join(map(str, k)))\n            else:\n\
    \                return k\n\n        if self.keys is None:\n            self.keys\
    \ = sorted(logs.keys())\n\n        if self.model.stop_training:\n            #\
    \ We set NA so that csv parsers do not fail for this last epoch.\n           \
    \ logs = dict([(k, logs[k] if k in logs else 'NA') for k in self.keys])\n\n  \
    \      if not self.writer:\n            class CustomDialect(csv.excel):\n    \
    \            delimiter = self.sep\n            fieldnames = ['epoch'] + self.keys\n\
    \            if six.PY2:\n                fieldnames = [unicode(x) for x in fieldnames]\n\
    \            self.writer = csv.DictWriter(self.csv_file,\n                   \
    \                      fieldnames=fieldnames,\n                              \
    \           dialect=CustomDialect)\n            if self.append_header:\n     \
    \           self.writer.writeheader()\n\n        row_dict = OrderedDict({'epoch':\
    \ epoch})\n        row_dict.update((key, handle_value(logs[key])) for key in self.keys)\n\
    \        self.writer.writerow(row_dict)\n        self.csv_file.flush()\n\n   \
    \ def on_train_end(self, logs=None):\n        self.csv_file.close()\n        self.writer\
    \ = None\n"
  sourcefile: D:\Python36\lib\site-packages\keras\callbacks.py
- doc: "This callback implements a cyclical learning rate policy (CLR).\nThe method\
    \ cycles the learning rate between two boundaries with\nsome constant frequency,\
    \ as detailed in this paper (https://arxiv.org/abs/1506.01186).\nThe amplitude\
    \ of the cycle can be scaled on a per-iteration or\nper-cycle basis.\nThis class\
    \ has three built-in policies, as put forth in the paper.\n\"triangular\":\n \
    \   A basic triangular cycle w/ no amplitude scaling.\n\"triangular2\":\n    A\
    \ basic triangular cycle that scales initial amplitude by half each cycle.\n\"\
    exp_range\":\n    A cycle that scales initial amplitude by gamma**(cycle iterations)\
    \ at each\n    cycle iteration.\nFor more detail, please see paper.\n\n# Example\n\
    \    ```python\n        clr = CyclicLR(base_lr=0.001, max_lr=0.006,\n        \
    \                    step_size=2000., mode='triangular')\n        model.fit(X_train,\
    \ Y_train, callbacks=[clr])\n    ```\n\nClass also supports custom scaling functions:\n\
    \    ```python\n        clr_fn = lambda x: 0.5*(1+np.sin(x*np.pi/2.))\n      \
    \  clr = CyclicLR(base_lr=0.001, max_lr=0.006,\n                            step_size=2000.,\
    \ scale_fn=clr_fn,\n                            scale_mode='cycle')\n        model.fit(X_train,\
    \ Y_train, callbacks=[clr])\n    ```\n# Arguments\n    base_lr: initial learning\
    \ rate which is the\n        lower boundary in the cycle.\n    max_lr: upper boundary\
    \ in the cycle. Functionally,\n        it defines the cycle amplitude (max_lr\
    \ - base_lr).\n        The lr at any cycle is the sum of base_lr\n        and\
    \ some scaling of the amplitude; therefore\n        max_lr may not actually be\
    \ reached depending on\n        scaling function.\n    step_size: number of training\
    \ iterations per\n        half cycle. Authors suggest setting step_size\n    \
    \    2-8 x training iterations in epoch.\n    mode: one of {triangular, triangular2,\
    \ exp_range}.\n        Default 'triangular'.\n        Values correspond to policies\
    \ detailed above.\n        If scale_fn is not None, this argument is ignored.\n\
    \    gamma: constant in 'exp_range' scaling function:\n        gamma**(cycle iterations)\n\
    \    scale_fn: Custom scaling policy defined by a single\n        argument lambda\
    \ function, where\n        0 <= scale_fn(x) <= 1 for all x >= 0.\n        mode\
    \ paramater is ignored\n    scale_mode: {'cycle', 'iterations'}.\n        Defines\
    \ whether scale_fn is evaluated on\n        cycle number or cycle iterations (training\n\
    \        iterations since start of cycle). Default is 'cycle'."
  kind: Callback
  name: CyclicLR
  parameters:
  - {defaultValue: '0.001', kind: any, name: base_lr}
  - {defaultValue: '0.006', kind: any, name: max_lr}
  - {defaultValue: '2000.0', kind: any, name: step_size}
  - {defaultValue: triangular, kind: any, name: mode}
  - {defaultValue: '1.0', kind: any, name: gamma}
  - {defaultValue: None, kind: any, name: scale_fn}
  - {defaultValue: cycle, kind: any, name: scale_mode}
  source: "class CyclicLR(Callback):\n    \"\"\"This callback implements a cyclical\
    \ learning rate policy (CLR).\n    The method cycles the learning rate between\
    \ two boundaries with\n    some constant frequency, as detailed in this paper\
    \ (https://arxiv.org/abs/1506.01186).\n    The amplitude of the cycle can be scaled\
    \ on a per-iteration or\n    per-cycle basis.\n    This class has three built-in\
    \ policies, as put forth in the paper.\n    \"triangular\":\n        A basic triangular\
    \ cycle w/ no amplitude scaling.\n    \"triangular2\":\n        A basic triangular\
    \ cycle that scales initial amplitude by half each cycle.\n    \"exp_range\":\n\
    \        A cycle that scales initial amplitude by gamma**(cycle iterations) at\
    \ each\n        cycle iteration.\n    For more detail, please see paper.\n\n \
    \   # Example\n        ```python\n            clr = CyclicLR(base_lr=0.001, max_lr=0.006,\n\
    \                                step_size=2000., mode='triangular')\n       \
    \     model.fit(X_train, Y_train, callbacks=[clr])\n        ```\n\n    Class also\
    \ supports custom scaling functions:\n        ```python\n            clr_fn =\
    \ lambda x: 0.5*(1+np.sin(x*np.pi/2.))\n            clr = CyclicLR(base_lr=0.001,\
    \ max_lr=0.006,\n                                step_size=2000., scale_fn=clr_fn,\n\
    \                                scale_mode='cycle')\n            model.fit(X_train,\
    \ Y_train, callbacks=[clr])\n        ```\n    # Arguments\n        base_lr: initial\
    \ learning rate which is the\n            lower boundary in the cycle.\n     \
    \   max_lr: upper boundary in the cycle. Functionally,\n            it defines\
    \ the cycle amplitude (max_lr - base_lr).\n            The lr at any cycle is\
    \ the sum of base_lr\n            and some scaling of the amplitude; therefore\n\
    \            max_lr may not actually be reached depending on\n            scaling\
    \ function.\n        step_size: number of training iterations per\n          \
    \  half cycle. Authors suggest setting step_size\n            2-8 x training iterations\
    \ in epoch.\n        mode: one of {triangular, triangular2, exp_range}.\n    \
    \        Default 'triangular'.\n            Values correspond to policies detailed\
    \ above.\n            If scale_fn is not None, this argument is ignored.\n   \
    \     gamma: constant in 'exp_range' scaling function:\n            gamma**(cycle\
    \ iterations)\n        scale_fn: Custom scaling policy defined by a single\n \
    \           argument lambda function, where\n            0 <= scale_fn(x) <= 1\
    \ for all x >= 0.\n            mode paramater is ignored\n        scale_mode:\
    \ {'cycle', 'iterations'}.\n            Defines whether scale_fn is evaluated\
    \ on\n            cycle number or cycle iterations (training\n            iterations\
    \ since start of cycle). Default is 'cycle'.\n    \"\"\"\n\n    def __init__(self,\
    \ base_lr=0.001, max_lr=0.006, step_size=2000., mode='triangular',\n         \
    \        gamma=1., scale_fn=None, scale_mode='cycle'):\n        super(CyclicLR,\
    \ self).__init__()\n\n        self.base_lr = base_lr\n        self.max_lr = max_lr\n\
    \        self.step_size = step_size\n        self.mode = mode\n        self.gamma\
    \ = gamma\n        if scale_fn == None:\n            if self.mode == 'triangular':\n\
    \                self.scale_fn = lambda x: 1.\n                self.scale_mode\
    \ = 'cycle'\n            elif self.mode == 'triangular2':\n                self.scale_fn\
    \ = lambda x: 1 / (2. ** (x - 1))\n                self.scale_mode = 'cycle'\n\
    \            elif self.mode == 'exp_range':\n                self.scale_fn = lambda\
    \ x: gamma ** (x)\n                self.scale_mode = 'iterations'\n        else:\n\
    \            self.scale_fn = scale_fn\n            self.scale_mode = scale_mode\n\
    \        self.clr_iterations = 0.\n        self.trn_iterations = 0.\n        self.history\
    \ = {}\n\n        self._reset()\n\n    def _reset(self, new_base_lr=None, new_max_lr=None,\n\
    \               new_step_size=None):\n        \"\"\"Resets cycle iterations.\n\
    \        Optional boundary/step size adjustment.\n        \"\"\"\n        if new_base_lr\
    \ != None:\n            self.base_lr = new_base_lr\n        if new_max_lr != None:\n\
    \            self.max_lr = new_max_lr\n        if new_step_size != None:\n   \
    \         self.step_size = new_step_size\n        self.clr_iterations = 0.\n\n\
    \    def clr(self):\n        cycle = np.floor(1 + self.clr_iterations / (2 * self.step_size))\n\
    \        x = np.abs(self.clr_iterations / self.step_size - 2 * cycle + 1)\n  \
    \      if self.scale_mode == 'cycle':\n            return self.base_lr + (self.max_lr\
    \ - self.base_lr) * np.maximum(0, (1 - x)) * self.scale_fn(cycle)\n        else:\n\
    \            return self.base_lr + (self.max_lr - self.base_lr) * np.maximum(0,\
    \ (1 - x)) * self.scale_fn(\n                self.clr_iterations)\n\n    def on_train_begin(self,\
    \ logs={}):\n        logs = logs or {}\n\n        if self.clr_iterations == 0:\n\
    \            K.set_value(self.model.optimizer.lr, self.base_lr)\n        else:\n\
    \            K.set_value(self.model.optimizer.lr, self.clr())\n\n    def on_batch_end(self,\
    \ epoch, logs=None):\n\n        logs = logs or {}\n        self.trn_iterations\
    \ += 1\n        self.clr_iterations += 1\n\n        self.history.setdefault('lr',\
    \ []).append(K.get_value(self.model.optimizer.lr))\n        self.history.setdefault('iterations',\
    \ []).append(self.trn_iterations)\n\n        for k, v in logs.items():\n     \
    \       self.history.setdefault(k, []).append(v)\n\n        K.set_value(self.model.optimizer.lr,\
    \ self.clr())\n"
  sourcefile: D:\Python36\lib\site-packages\musket_core\clr_callback.py
- doc: "Stop training when a monitored quantity has stopped improving.\n\n# Arguments\n\
    \    monitor: quantity to be monitored.\n    min_delta: minimum change in the\
    \ monitored quantity\n        to qualify as an improvement, i.e. an absolute\n\
    \        change of less than min_delta, will count as no\n        improvement.\n\
    \    patience: number of epochs with no improvement\n        after which training\
    \ will be stopped.\n    verbose: verbosity mode.\n    mode: one of {auto, min,\
    \ max}. In `min` mode,\n        training will stop when the quantity\n       \
    \ monitored has stopped decreasing; in `max`\n        mode it will stop when the\
    \ quantity\n        monitored has stopped increasing; in `auto`\n        mode,\
    \ the direction is automatically inferred\n        from the name of the monitored\
    \ quantity.\n    baseline: Baseline value for the monitored quantity to reach.\n\
    \        Training will stop if the model doesn't show improvement\n        over\
    \ the baseline.\n    restore_best_weights: whether to restore model weights from\n\
    \        the epoch with the best value of the monitored quantity.\n        If\
    \ False, the model weights obtained at the last step of\n        training are\
    \ used."
  kind: Callback
  name: EarlyStopping
  parameters:
  - {defaultValue: val_loss, kind: any, name: monitor}
  - {defaultValue: '0', kind: any, name: min_delta}
  - {defaultValue: '0', kind: any, name: patience}
  - {defaultValue: '0', kind: any, name: verbose}
  - {defaultValue: auto, kind: any, name: mode}
  - {defaultValue: None, kind: any, name: baseline}
  - {defaultValue: 'False', kind: any, name: restore_best_weights}
  source: "class EarlyStopping(Callback):\n    \"\"\"Stop training when a monitored\
    \ quantity has stopped improving.\n\n    # Arguments\n        monitor: quantity\
    \ to be monitored.\n        min_delta: minimum change in the monitored quantity\n\
    \            to qualify as an improvement, i.e. an absolute\n            change\
    \ of less than min_delta, will count as no\n            improvement.\n       \
    \ patience: number of epochs with no improvement\n            after which training\
    \ will be stopped.\n        verbose: verbosity mode.\n        mode: one of {auto,\
    \ min, max}. In `min` mode,\n            training will stop when the quantity\n\
    \            monitored has stopped decreasing; in `max`\n            mode it will\
    \ stop when the quantity\n            monitored has stopped increasing; in `auto`\n\
    \            mode, the direction is automatically inferred\n            from the\
    \ name of the monitored quantity.\n        baseline: Baseline value for the monitored\
    \ quantity to reach.\n            Training will stop if the model doesn't show\
    \ improvement\n            over the baseline.\n        restore_best_weights: whether\
    \ to restore model weights from\n            the epoch with the best value of\
    \ the monitored quantity.\n            If False, the model weights obtained at\
    \ the last step of\n            training are used.\n    \"\"\"\n\n    def __init__(self,\n\
    \                 monitor='val_loss',\n                 min_delta=0,\n       \
    \          patience=0,\n                 verbose=0,\n                 mode='auto',\n\
    \                 baseline=None,\n                 restore_best_weights=False):\n\
    \        super(EarlyStopping, self).__init__()\n\n        self.monitor = monitor\n\
    \        self.baseline = baseline\n        self.patience = patience\n        self.verbose\
    \ = verbose\n        self.min_delta = min_delta\n        self.wait = 0\n     \
    \   self.stopped_epoch = 0\n        self.restore_best_weights = restore_best_weights\n\
    \        self.best_weights = None\n\n        if mode not in ['auto', 'min', 'max']:\n\
    \            warnings.warn('EarlyStopping mode %s is unknown, '\n            \
    \              'fallback to auto mode.' % mode,\n                          RuntimeWarning)\n\
    \            mode = 'auto'\n\n        if mode == 'min':\n            self.monitor_op\
    \ = np.less\n        elif mode == 'max':\n            self.monitor_op = np.greater\n\
    \        else:\n            if 'acc' in self.monitor:\n                self.monitor_op\
    \ = np.greater\n            else:\n                self.monitor_op = np.less\n\
    \n        if self.monitor_op == np.greater:\n            self.min_delta *= 1\n\
    \        else:\n            self.min_delta *= -1\n\n    def on_train_begin(self,\
    \ logs=None):\n        # Allow instances to be re-used\n        self.wait = 0\n\
    \        self.stopped_epoch = 0\n        if self.baseline is not None:\n     \
    \       self.best = self.baseline\n        else:\n            self.best = np.Inf\
    \ if self.monitor_op == np.less else -np.Inf\n\n    def on_epoch_end(self, epoch,\
    \ logs=None):\n        current = self.get_monitor_value(logs)\n        if current\
    \ is None:\n            return\n\n        if self.monitor_op(current - self.min_delta,\
    \ self.best):\n            self.best = current\n            self.wait = 0\n  \
    \          if self.restore_best_weights:\n                self.best_weights =\
    \ self.model.get_weights()\n        else:\n            self.wait += 1\n      \
    \      if self.wait >= self.patience:\n                self.stopped_epoch = epoch\n\
    \                self.model.stop_training = True\n                if self.restore_best_weights:\n\
    \                    if self.verbose > 0:\n                        print('Restoring\
    \ model weights from the end of '\n                              'the best epoch')\n\
    \                    self.model.set_weights(self.best_weights)\n\n    def on_train_end(self,\
    \ logs=None):\n        if self.stopped_epoch > 0 and self.verbose > 0:\n     \
    \       print('Epoch %05d: early stopping' % (self.stopped_epoch + 1))\n\n   \
    \ def get_monitor_value(self, logs):\n        monitor_value = logs.get(self.monitor)\n\
    \        if monitor_value is None:\n            warnings.warn(\n             \
    \   'Early stopping conditioned on metric `%s` '\n                'which is not\
    \ available. Available metrics are: %s' %\n                (self.monitor, ','.join(list(logs.keys()))),\
    \ RuntimeWarning\n            )\n        return monitor_value\n"
  sourcefile: D:\Python36\lib\site-packages\keras\callbacks.py
- doc: 'Callback that records events into a `History` object.


    This callback is automatically applied to

    every Keras model. The `History` object

    gets returned by the `fit` method of models.'
  kind: Callback
  name: History
  parameters: []
  source: "class History(Callback):\n    \"\"\"Callback that records events into a\
    \ `History` object.\n\n    This callback is automatically applied to\n    every\
    \ Keras model. The `History` object\n    gets returned by the `fit` method of\
    \ models.\n    \"\"\"\n\n    def on_train_begin(self, logs=None):\n        self.epoch\
    \ = []\n        self.history = {}\n\n    def on_epoch_end(self, epoch, logs=None):\n\
    \        logs = logs or {}\n        self.epoch.append(epoch)\n        for k, v\
    \ in logs.items():\n            self.history.setdefault(k, []).append(v)\n"
  sourcefile: D:\Python36\lib\site-packages\keras\callbacks.py
- doc: "This callback allows learning rate variations within or across epochs.\n#\
    \ Example\n    ```yaml\n          LRVariator:\n            absSize: 100\n    \
    \        toVal: 0.002\n            style: 2\n            then:\n             \
    \ LRVariator:\n                relSize: 0.001\n                toVal: 0.001\n\
    \                style: 0.5\n                then:\n                  ReduceLROnPlateau:\n\
    \                    patience: 8\n                    factor: 0.5\n          \
    \          monitor: val_binary_accuracy\n                    mode: auto\n    \
    \                cooldown: 5\n                    verbose: 1\n    ```\n\n# Arguments\n\
    \    fromVal: start value. If the param is omited, its value is taken from the\
    \ keras model\n    toVal: end value\n    style: shape of the variation graphic.\
    \ One of\n      - linear\n      - const\n      - cos+ ascending cosine segment:\
    \ -1 * cos(2x/pi) + 1 for x in [0;1]\n      - cos- descending cosine segment:\
    \ cos(2x/pi) for x in [0;1]\n      - cos  same as 'cos-'\n      - sin+ ascending\
    \ sine segment: sin(2x/pi) x in [0;1]\n      - sin- descending sine segment: -1\
    \ * sin(2x/pi) + 1 for x in [0;1]\n      - sin  same as 'sin+'\n      - any positive\
    \ float or integer value 'a'. x^a for x in [0;1]\n    args: see CallbackModule\
    \ for details"
  kind: Callback
  name: LRVariator
  parameters:
  - {defaultValue: None, kind: any, name: fromVal}
  - {defaultValue: '0.006', kind: any, name: toVal}
  - {defaultValue: linear, kind: any, name: style}
  source: "class LRVariator(CallbackModule):\n    \"\"\" This callback allows learning\
    \ rate variations within or across epochs.\n        # Example\n            ```yaml\n\
    \                  LRVariator:\n                    absSize: 100\n           \
    \         toVal: 0.002\n                    style: 2\n                    then:\n\
    \                      LRVariator:\n                        relSize: 0.001\n \
    \                       toVal: 0.001\n                        style: 0.5\n   \
    \                     then:\n                          ReduceLROnPlateau:\n  \
    \                          patience: 8\n                            factor: 0.5\n\
    \                            monitor: val_binary_accuracy\n                  \
    \          mode: auto\n                            cooldown: 5\n             \
    \               verbose: 1\n            ```\n\n        # Arguments\n         \
    \   fromVal: start value. If the param is omited, its value is taken from the\
    \ keras model\n            toVal: end value\n            style: shape of the variation\
    \ graphic. One of\n              - linear\n              - const\n           \
    \   - cos+ ascending cosine segment: -1 * cos(2x/pi) + 1 for x in [0;1]\n    \
    \          - cos- descending cosine segment: cos(2x/pi) for x in [0;1]\n     \
    \         - cos  same as 'cos-'\n              - sin+ ascending sine segment:\
    \ sin(2x/pi) x in [0;1]\n              - sin- descending sine segment: -1 * sin(2x/pi)\
    \ + 1 for x in [0;1]\n              - sin  same as 'sin+'\n              - any\
    \ positive float or integer value 'a'. x^a for x in [0;1]\n            args: see\
    \ CallbackModule for details\n        \"\"\"\n\n    def __init__(self, fromVal=None,\
    \ toVal=0.006, style=\"linear\", **args):\n        super(LRVariator, self).__init__(**args)\n\
    \n        self.fromVal = fromVal\n        self.toVal = toVal\n        self.style\
    \ = style\n        self.lrComputer = None\n        self.core = None\n\n      \
    \  if self.style not in lambdas:\n            lambdasList = \", \".join([f\"'{x}'\"\
    \ for x in lambdas])\n            msg = f\"LRVariator 'style' must be a positive\
    \ number or one of {lambdasList}, but {self.style} have been recieved\"\n    \
    \        if not isinstance(self.style,int) and not isinstance(self.style,float):\n\
    \                raise ValueError(msg)\n            elif self.style <= 0:\n  \
    \              raise ValueError(msg)\n\n\n    def on_batch_end_action(self, logs\
    \ = None):\n        lr = self.get_lr()\n        K.set_value(self.model.optimizer.lr,\
    \ lr)\n        print(f\"    lr: {lr}\")\n\n\n    def get_lr(self):\n        if\
    \ self.lrComputer is None:\n            if self.core is None:\n              \
    \  if self.fromVal is None:\n                    self.fromVal = K.get_value(self.model.optimizer.lr)\n\
    \n                if self.style in lambdas:\n                    self.core = lambdas[self.style]\n\
    \                elif self.style == 1:\n                    self.core = lambdas[\"\
    linear\"]\n                elif isinstance(self.style, int):\n               \
    \     pow = int(self.style)\n                    self.core = lambda x: x ** pow\n\
    \                elif isinstance(self.style, float):\n                    pow\
    \ = float(self.style)\n                    self.core = lambda x: math.pow(x, pow)\n\
    \n            def lrComputerBody(x):\n                point = (x - self.startStep)\
    \ / (self.ownSteps - 1)\n                ratio = self.core(point)\n          \
    \      dif = self.toVal - self.fromVal\n                result = self.fromVal\
    \ + ratio * dif\n                result = max(result, 0.0)\n                return\
    \ result\n\n\n            self.lrComputer = lambda x: lrComputerBody(x)\n\n  \
    \      lr = self.lrComputer(self.cyclicStep)\n        return lr\n"
  sourcefile: D:\Python36\lib\site-packages\musket_core\lr_variation_callback.py
- doc: "Callback for creating simple, custom callbacks on-the-fly.\n\nThis callback\
    \ is constructed with anonymous functions that will be called\nat the appropriate\
    \ time. Note that the callbacks expects positional\narguments, as:\n\n - `on_epoch_begin`\
    \ and `on_epoch_end` expect two positional arguments:\n    `epoch`, `logs`\n -\
    \ `on_batch_begin` and `on_batch_end` expect two positional arguments:\n    `batch`,\
    \ `logs`\n - `on_train_begin` and `on_train_end` expect one positional argument:\n\
    \    `logs`\n\n# Arguments\n    on_epoch_begin: called at the beginning of every\
    \ epoch.\n    on_epoch_end: called at the end of every epoch.\n    on_batch_begin:\
    \ called at the beginning of every batch.\n    on_batch_end: called at the end\
    \ of every batch.\n    on_train_begin: called at the beginning of model training.\n\
    \    on_train_end: called at the end of model training.\n\n# Example\n\n```python\n\
    # Print the batch number at the beginning of every batch.\nbatch_print_callback\
    \ = LambdaCallback(\n    on_batch_begin=lambda batch,logs: print(batch))\n\n#\
    \ Stream the epoch loss to a file in JSON format. The file content\n# is not well-formed\
    \ JSON but rather has a JSON object per line.\nimport json\njson_log = open('loss_log.json',\
    \ mode='wt', buffering=1)\njson_logging_callback = LambdaCallback(\n    on_epoch_end=lambda\
    \ epoch, logs: json_log.write(\n        json.dumps({'epoch': epoch, 'loss': logs['loss']})\
    \ + '\\n'),\n    on_train_end=lambda logs: json_log.close()\n)\n\n# Terminate\
    \ some processes after having finished model training.\nprocesses = ...\ncleanup_callback\
    \ = LambdaCallback(\n    on_train_end=lambda logs: [\n        p.terminate() for\
    \ p in processes if p.is_alive()])\n\nmodel.fit(...,\n          callbacks=[batch_print_callback,\n\
    \                     json_logging_callback,\n                     cleanup_callback])\n\
    ```"
  kind: Callback
  name: LambdaCallback
  parameters:
  - {defaultValue: None, kind: any, name: on_epoch_begin}
  - {defaultValue: None, kind: any, name: on_epoch_end}
  - {defaultValue: None, kind: any, name: on_batch_begin}
  - {defaultValue: None, kind: any, name: on_batch_end}
  - {defaultValue: None, kind: any, name: on_train_begin}
  - {defaultValue: None, kind: any, name: on_train_end}
  source: "class LambdaCallback(Callback):\n    r\"\"\"Callback for creating simple,\
    \ custom callbacks on-the-fly.\n\n    This callback is constructed with anonymous\
    \ functions that will be called\n    at the appropriate time. Note that the callbacks\
    \ expects positional\n    arguments, as:\n\n     - `on_epoch_begin` and `on_epoch_end`\
    \ expect two positional arguments:\n        `epoch`, `logs`\n     - `on_batch_begin`\
    \ and `on_batch_end` expect two positional arguments:\n        `batch`, `logs`\n\
    \     - `on_train_begin` and `on_train_end` expect one positional argument:\n\
    \        `logs`\n\n    # Arguments\n        on_epoch_begin: called at the beginning\
    \ of every epoch.\n        on_epoch_end: called at the end of every epoch.\n \
    \       on_batch_begin: called at the beginning of every batch.\n        on_batch_end:\
    \ called at the end of every batch.\n        on_train_begin: called at the beginning\
    \ of model training.\n        on_train_end: called at the end of model training.\n\
    \n    # Example\n\n    ```python\n    # Print the batch number at the beginning\
    \ of every batch.\n    batch_print_callback = LambdaCallback(\n        on_batch_begin=lambda\
    \ batch,logs: print(batch))\n\n    # Stream the epoch loss to a file in JSON format.\
    \ The file content\n    # is not well-formed JSON but rather has a JSON object\
    \ per line.\n    import json\n    json_log = open('loss_log.json', mode='wt',\
    \ buffering=1)\n    json_logging_callback = LambdaCallback(\n        on_epoch_end=lambda\
    \ epoch, logs: json_log.write(\n            json.dumps({'epoch': epoch, 'loss':\
    \ logs['loss']}) + '\\n'),\n        on_train_end=lambda logs: json_log.close()\n\
    \    )\n\n    # Terminate some processes after having finished model training.\n\
    \    processes = ...\n    cleanup_callback = LambdaCallback(\n        on_train_end=lambda\
    \ logs: [\n            p.terminate() for p in processes if p.is_alive()])\n\n\
    \    model.fit(...,\n              callbacks=[batch_print_callback,\n        \
    \                 json_logging_callback,\n                         cleanup_callback])\n\
    \    ```\n    \"\"\"\n\n    def __init__(self,\n                 on_epoch_begin=None,\n\
    \                 on_epoch_end=None,\n                 on_batch_begin=None,\n\
    \                 on_batch_end=None,\n                 on_train_begin=None,\n\
    \                 on_train_end=None,\n                 **kwargs):\n        super(LambdaCallback,\
    \ self).__init__()\n        self.__dict__.update(kwargs)\n        if on_epoch_begin\
    \ is not None:\n            self.on_epoch_begin = on_epoch_begin\n        else:\n\
    \            self.on_epoch_begin = lambda epoch, logs: None\n        if on_epoch_end\
    \ is not None:\n            self.on_epoch_end = on_epoch_end\n        else:\n\
    \            self.on_epoch_end = lambda epoch, logs: None\n        if on_batch_begin\
    \ is not None:\n            self.on_batch_begin = on_batch_begin\n        else:\n\
    \            self.on_batch_begin = lambda batch, logs: None\n        if on_batch_end\
    \ is not None:\n            self.on_batch_end = on_batch_end\n        else:\n\
    \            self.on_batch_end = lambda batch, logs: None\n        if on_train_begin\
    \ is not None:\n            self.on_train_begin = on_train_begin\n        else:\n\
    \            self.on_train_begin = lambda logs: None\n        if on_train_end\
    \ is not None:\n            self.on_train_end = on_train_end\n        else:\n\
    \            self.on_train_end = lambda logs: None\n"
  sourcefile: D:\Python36\lib\site-packages\keras\callbacks.py
- doc: "Learning rate scheduler.\n\n# Arguments\n    schedule: a function that takes\
    \ an epoch index as input\n        (integer, indexed from 0) and current learning\
    \ rate\n        and returns a new learning rate as output (float).\n    verbose:\
    \ int. 0: quiet, 1: update messages."
  kind: Callback
  name: LearningRateScheduler
  parameters:
  - {kind: any, name: schedule}
  - {defaultValue: '0', kind: any, name: verbose}
  source: "class LearningRateScheduler(Callback):\n    \"\"\"Learning rate scheduler.\n\
    \n    # Arguments\n        schedule: a function that takes an epoch index as input\n\
    \            (integer, indexed from 0) and current learning rate\n           \
    \ and returns a new learning rate as output (float).\n        verbose: int. 0:\
    \ quiet, 1: update messages.\n    \"\"\"\n\n    def __init__(self, schedule, verbose=0):\n\
    \        super(LearningRateScheduler, self).__init__()\n        self.schedule\
    \ = schedule\n        self.verbose = verbose\n\n    def on_epoch_begin(self, epoch,\
    \ logs=None):\n        if not hasattr(self.model.optimizer, 'lr'):\n         \
    \   raise ValueError('Optimizer must have a \"lr\" attribute.')\n        lr =\
    \ float(K.get_value(self.model.optimizer.lr))\n        try:  # new API\n     \
    \       lr = self.schedule(epoch, lr)\n        except TypeError:  # old API for\
    \ backward compatibility\n            lr = self.schedule(epoch)\n        if not\
    \ isinstance(lr, (float, np.float32, np.float64)):\n            raise ValueError('The\
    \ output of the \"schedule\" function '\n                             'should\
    \ be float.')\n        K.set_value(self.model.optimizer.lr, lr)\n        if self.verbose\
    \ > 0:\n            print('\\nEpoch %05d: LearningRateScheduler setting learning\
    \ '\n                  'rate to %s.' % (epoch + 1, lr))\n\n    def on_epoch_end(self,\
    \ epoch, logs=None):\n        logs = logs or {}\n        logs['lr'] = K.get_value(self.model.optimizer.lr)\n"
  sourcefile: D:\Python36\lib\site-packages\keras\callbacks.py
- doc: "Save the model after every epoch.\n\n`filepath` can contain named formatting\
    \ options,\nwhich will be filled the value of `epoch` and\nkeys in `logs` (passed\
    \ in `on_epoch_end`).\n\nFor example: if `filepath` is `weights.{epoch:02d}-{val_loss:.2f}.hdf5`,\n\
    then the model checkpoints will be saved with the epoch number and\nthe validation\
    \ loss in the filename.\n\n# Arguments\n    filepath: string, path to save the\
    \ model file.\n    monitor: quantity to monitor.\n    verbose: verbosity mode,\
    \ 0 or 1.\n    save_best_only: if `save_best_only=True`,\n        the latest best\
    \ model according to\n        the quantity monitored will not be overwritten.\n\
    \    mode: one of {auto, min, max}.\n        If `save_best_only=True`, the decision\n\
    \        to overwrite the current save file is made\n        based on either the\
    \ maximization or the\n        minimization of the monitored quantity. For `val_acc`,\n\
    \        this should be `max`, for `val_loss` this should\n        be `min`, etc.\
    \ In `auto` mode, the direction is\n        automatically inferred from the name\
    \ of the monitored quantity.\n    save_weights_only: if True, then only the model's\
    \ weights will be\n        saved (`model.save_weights(filepath)`), else the full\
    \ model\n        is saved (`model.save(filepath)`).\n    period: Interval (number\
    \ of epochs) between checkpoints."
  kind: Callback
  name: ModelCheckpoint
  parameters:
  - {kind: any, name: filepath}
  - {defaultValue: val_loss, kind: any, name: monitor}
  - {defaultValue: '0', kind: any, name: verbose}
  - {defaultValue: 'False', kind: any, name: save_best_only}
  - {defaultValue: 'False', kind: any, name: save_weights_only}
  - {defaultValue: auto, kind: any, name: mode}
  - {defaultValue: '1', kind: any, name: period}
  source: "class ModelCheckpoint(Callback):\n    \"\"\"Save the model after every\
    \ epoch.\n\n    `filepath` can contain named formatting options,\n    which will\
    \ be filled the value of `epoch` and\n    keys in `logs` (passed in `on_epoch_end`).\n\
    \n    For example: if `filepath` is `weights.{epoch:02d}-{val_loss:.2f}.hdf5`,\n\
    \    then the model checkpoints will be saved with the epoch number and\n    the\
    \ validation loss in the filename.\n\n    # Arguments\n        filepath: string,\
    \ path to save the model file.\n        monitor: quantity to monitor.\n      \
    \  verbose: verbosity mode, 0 or 1.\n        save_best_only: if `save_best_only=True`,\n\
    \            the latest best model according to\n            the quantity monitored\
    \ will not be overwritten.\n        mode: one of {auto, min, max}.\n         \
    \   If `save_best_only=True`, the decision\n            to overwrite the current\
    \ save file is made\n            based on either the maximization or the\n   \
    \         minimization of the monitored quantity. For `val_acc`,\n           \
    \ this should be `max`, for `val_loss` this should\n            be `min`, etc.\
    \ In `auto` mode, the direction is\n            automatically inferred from the\
    \ name of the monitored quantity.\n        save_weights_only: if True, then only\
    \ the model's weights will be\n            saved (`model.save_weights(filepath)`),\
    \ else the full model\n            is saved (`model.save(filepath)`).\n      \
    \  period: Interval (number of epochs) between checkpoints.\n    \"\"\"\n\n  \
    \  def __init__(self, filepath, monitor='val_loss', verbose=0,\n             \
    \    save_best_only=False, save_weights_only=False,\n                 mode='auto',\
    \ period=1):\n        super(ModelCheckpoint, self).__init__()\n        self.monitor\
    \ = monitor\n        self.verbose = verbose\n        self.filepath = filepath\n\
    \        self.save_best_only = save_best_only\n        self.save_weights_only\
    \ = save_weights_only\n        self.period = period\n        self.epochs_since_last_save\
    \ = 0\n\n        if mode not in ['auto', 'min', 'max']:\n            warnings.warn('ModelCheckpoint\
    \ mode %s is unknown, '\n                          'fallback to auto mode.' %\
    \ (mode),\n                          RuntimeWarning)\n            mode = 'auto'\n\
    \n        if mode == 'min':\n            self.monitor_op = np.less\n         \
    \   self.best = np.Inf\n        elif mode == 'max':\n            self.monitor_op\
    \ = np.greater\n            self.best = -np.Inf\n        else:\n            if\
    \ 'acc' in self.monitor or self.monitor.startswith('fmeasure'):\n            \
    \    self.monitor_op = np.greater\n                self.best = -np.Inf\n     \
    \       else:\n                self.monitor_op = np.less\n                self.best\
    \ = np.Inf\n\n    def on_epoch_end(self, epoch, logs=None):\n        logs = logs\
    \ or {}\n        self.epochs_since_last_save += 1\n        if self.epochs_since_last_save\
    \ >= self.period:\n            self.epochs_since_last_save = 0\n            filepath\
    \ = self.filepath.format(epoch=epoch + 1, **logs)\n            if self.save_best_only:\n\
    \                current = logs.get(self.monitor)\n                if current\
    \ is None:\n                    warnings.warn('Can save best model only with %s\
    \ available, '\n                                  'skipping.' % (self.monitor),\
    \ RuntimeWarning)\n                else:\n                    if self.monitor_op(current,\
    \ self.best):\n                        if self.verbose > 0:\n                \
    \            print('\\nEpoch %05d: %s improved from %0.5f to %0.5f,'\n       \
    \                           ' saving model to %s'\n                          \
    \        % (epoch + 1, self.monitor, self.best,\n                            \
    \         current, filepath))\n                        self.best = current\n \
    \                       if self.save_weights_only:\n                         \
    \   self.model.save_weights(filepath, overwrite=True)\n                      \
    \  else:\n                            self.model.save(filepath, overwrite=True)\n\
    \                    else:\n                        if self.verbose > 0:\n   \
    \                         print('\\nEpoch %05d: %s did not improve from %0.5f'\
    \ %\n                                  (epoch + 1, self.monitor, self.best))\n\
    \            else:\n                if self.verbose > 0:\n                   \
    \ print('\\nEpoch %05d: saving model to %s' % (epoch + 1, filepath))\n       \
    \         if self.save_weights_only:\n                    self.model.save_weights(filepath,\
    \ overwrite=True)\n                else:\n                    self.model.save(filepath,\
    \ overwrite=True)\n"
  sourcefile: D:\Python36\lib\site-packages\keras\callbacks.py
- doc: "Callback that prints metrics to stdout.\n\n# Arguments\n    count_mode: One\
    \ of \"steps\" or \"samples\".\n        Whether the progress bar should\n    \
    \    count samples seen or steps (batches) seen.\n    stateful_metrics: Iterable\
    \ of string names of metrics that\n        should *not* be averaged over an epoch.\n\
    \        Metrics in this list will be logged as-is.\n        All others will be\
    \ averaged over time (e.g. loss, etc).\n\n# Raises\n    ValueError: In case of\
    \ invalid `count_mode`."
  kind: Callback
  name: ProgbarLogger
  parameters:
  - {defaultValue: samples, kind: any, name: count_mode}
  - {defaultValue: None, kind: any, name: stateful_metrics}
  source: "class ProgbarLogger(Callback):\n    \"\"\"Callback that prints metrics\
    \ to stdout.\n\n    # Arguments\n        count_mode: One of \"steps\" or \"samples\"\
    .\n            Whether the progress bar should\n            count samples seen\
    \ or steps (batches) seen.\n        stateful_metrics: Iterable of string names\
    \ of metrics that\n            should *not* be averaged over an epoch.\n     \
    \       Metrics in this list will be logged as-is.\n            All others will\
    \ be averaged over time (e.g. loss, etc).\n\n    # Raises\n        ValueError:\
    \ In case of invalid `count_mode`.\n    \"\"\"\n\n    def __init__(self, count_mode='samples',\n\
    \                 stateful_metrics=None):\n        super(ProgbarLogger, self).__init__()\n\
    \        if count_mode == 'samples':\n            self.use_steps = False\n   \
    \     elif count_mode == 'steps':\n            self.use_steps = True\n       \
    \ else:\n            raise ValueError('Unknown `count_mode`: ' + str(count_mode))\n\
    \        if stateful_metrics:\n            self.stateful_metrics = set(stateful_metrics)\n\
    \        else:\n            self.stateful_metrics = set()\n\n    def on_train_begin(self,\
    \ logs=None):\n        self.verbose = self.params['verbose']\n        self.epochs\
    \ = self.params['epochs']\n\n    def on_epoch_begin(self, epoch, logs=None):\n\
    \        if self.verbose:\n            print('Epoch %d/%d' % (epoch + 1, self.epochs))\n\
    \            if self.use_steps:\n                target = self.params['steps']\n\
    \            else:\n                target = self.params['samples']\n        \
    \    self.target = target\n            self.progbar = Progbar(target=self.target,\n\
    \                                   verbose=self.verbose,\n                  \
    \                 stateful_metrics=self.stateful_metrics)\n        self.seen =\
    \ 0\n\n    def on_batch_begin(self, batch, logs=None):\n        if self.seen <\
    \ self.target:\n            self.log_values = []\n\n    def on_batch_end(self,\
    \ batch, logs=None):\n        logs = logs or {}\n        batch_size = logs.get('size',\
    \ 0)\n        if self.use_steps:\n            self.seen += 1\n        else:\n\
    \            self.seen += batch_size\n\n        for k in self.params['metrics']:\n\
    \            if k in logs:\n                self.log_values.append((k, logs[k]))\n\
    \n        # Skip progbar update for the last batch;\n        # will be handled\
    \ by on_epoch_end.\n        if self.verbose and self.seen < self.target:\n   \
    \         self.progbar.update(self.seen, self.log_values)\n\n    def on_epoch_end(self,\
    \ epoch, logs=None):\n        logs = logs or {}\n        for k in self.params['metrics']:\n\
    \            if k in logs:\n                self.log_values.append((k, logs[k]))\n\
    \        if self.verbose:\n            self.progbar.update(self.seen, self.log_values)\n"
  sourcefile: D:\Python36\lib\site-packages\keras\callbacks.py
- doc: "Reduce learning rate when a metric has stopped improving.\n\nModels often\
    \ benefit from reducing the learning rate by a factor\nof 2-10 once learning stagnates.\
    \ This callback monitors a\nquantity and if no improvement is seen for a 'patience'\
    \ number\nof epochs, the learning rate is reduced.\n\n# Example\n\n```python\n\
    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n              \
    \                patience=5, min_lr=0.001)\nmodel.fit(X_train, Y_train, callbacks=[reduce_lr])\n\
    ```\n\n# Arguments\n    monitor: quantity to be monitored.\n    factor: factor\
    \ by which the learning rate will\n        be reduced. new_lr = lr * factor\n\
    \    patience: number of epochs with no improvement\n        after which learning\
    \ rate will be reduced.\n    verbose: int. 0: quiet, 1: update messages.\n   \
    \ mode: one of {auto, min, max}. In `min` mode,\n        lr will be reduced when\
    \ the quantity\n        monitored has stopped decreasing; in `max`\n        mode\
    \ it will be reduced when the quantity\n        monitored has stopped increasing;\
    \ in `auto`\n        mode, the direction is automatically inferred\n        from\
    \ the name of the monitored quantity.\n    min_delta: threshold for measuring\
    \ the new optimum,\n        to only focus on significant changes.\n    cooldown:\
    \ number of epochs to wait before resuming\n        normal operation after lr\
    \ has been reduced.\n    min_lr: lower bound on the learning rate."
  kind: Callback
  name: ReduceLROnPlateau
  parameters:
  - {defaultValue: val_loss, kind: any, name: monitor}
  - {defaultValue: '0.1', kind: any, name: factor}
  - {defaultValue: '10', kind: any, name: patience}
  - {defaultValue: '0', kind: any, name: verbose}
  - {defaultValue: auto, kind: any, name: mode}
  - {defaultValue: '0.0001', kind: any, name: min_delta}
  - {defaultValue: '0', kind: any, name: cooldown}
  - {defaultValue: '0', kind: any, name: min_lr}
  source: "class ReduceLROnPlateau(Callback):\n    \"\"\"Reduce learning rate when\
    \ a metric has stopped improving.\n\n    Models often benefit from reducing the\
    \ learning rate by a factor\n    of 2-10 once learning stagnates. This callback\
    \ monitors a\n    quantity and if no improvement is seen for a 'patience' number\n\
    \    of epochs, the learning rate is reduced.\n\n    # Example\n\n    ```python\n\
    \    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n         \
    \                         patience=5, min_lr=0.001)\n    model.fit(X_train, Y_train,\
    \ callbacks=[reduce_lr])\n    ```\n\n    # Arguments\n        monitor: quantity\
    \ to be monitored.\n        factor: factor by which the learning rate will\n \
    \           be reduced. new_lr = lr * factor\n        patience: number of epochs\
    \ with no improvement\n            after which learning rate will be reduced.\n\
    \        verbose: int. 0: quiet, 1: update messages.\n        mode: one of {auto,\
    \ min, max}. In `min` mode,\n            lr will be reduced when the quantity\n\
    \            monitored has stopped decreasing; in `max`\n            mode it will\
    \ be reduced when the quantity\n            monitored has stopped increasing;\
    \ in `auto`\n            mode, the direction is automatically inferred\n     \
    \       from the name of the monitored quantity.\n        min_delta: threshold\
    \ for measuring the new optimum,\n            to only focus on significant changes.\n\
    \        cooldown: number of epochs to wait before resuming\n            normal\
    \ operation after lr has been reduced.\n        min_lr: lower bound on the learning\
    \ rate.\n    \"\"\"\n\n    def __init__(self, monitor='val_loss', factor=0.1,\
    \ patience=10,\n                 verbose=0, mode='auto', min_delta=1e-4, cooldown=0,\
    \ min_lr=0,\n                 **kwargs):\n        super(ReduceLROnPlateau, self).__init__()\n\
    \n        self.monitor = monitor\n        if factor >= 1.0:\n            raise\
    \ ValueError('ReduceLROnPlateau '\n                             'does not support\
    \ a factor >= 1.0.')\n        if 'epsilon' in kwargs:\n            min_delta =\
    \ kwargs.pop('epsilon')\n            warnings.warn('`epsilon` argument is deprecated\
    \ and '\n                          'will be removed, use `min_delta` instead.')\n\
    \        self.factor = factor\n        self.min_lr = min_lr\n        self.min_delta\
    \ = min_delta\n        self.patience = patience\n        self.verbose = verbose\n\
    \        self.cooldown = cooldown\n        self.cooldown_counter = 0  # Cooldown\
    \ counter.\n        self.wait = 0\n        self.best = 0\n        self.mode =\
    \ mode\n        self.monitor_op = None\n        self._reset()\n\n    def _reset(self):\n\
    \        \"\"\"Resets wait counter and cooldown counter.\n        \"\"\"\n   \
    \     if self.mode not in ['auto', 'min', 'max']:\n            warnings.warn('Learning\
    \ Rate Plateau Reducing mode %s is unknown, '\n                          'fallback\
    \ to auto mode.' % (self.mode),\n                          RuntimeWarning)\n \
    \           self.mode = 'auto'\n        if (self.mode == 'min' or\n          \
    \ (self.mode == 'auto' and 'acc' not in self.monitor)):\n            self.monitor_op\
    \ = lambda a, b: np.less(a, b - self.min_delta)\n            self.best = np.Inf\n\
    \        else:\n            self.monitor_op = lambda a, b: np.greater(a, b + self.min_delta)\n\
    \            self.best = -np.Inf\n        self.cooldown_counter = 0\n        self.wait\
    \ = 0\n\n    def on_train_begin(self, logs=None):\n        self._reset()\n\n \
    \   def on_epoch_end(self, epoch, logs=None):\n        logs = logs or {}\n   \
    \     logs['lr'] = K.get_value(self.model.optimizer.lr)\n        current = logs.get(self.monitor)\n\
    \        if current is None:\n            warnings.warn(\n                'Reduce\
    \ LR on plateau conditioned on metric `%s` '\n                'which is not available.\
    \ Available metrics are: %s' %\n                (self.monitor, ','.join(list(logs.keys()))),\
    \ RuntimeWarning\n            )\n\n        else:\n            if self.in_cooldown():\n\
    \                self.cooldown_counter -= 1\n                self.wait = 0\n\n\
    \            if self.monitor_op(current, self.best):\n                self.best\
    \ = current\n                self.wait = 0\n            elif not self.in_cooldown():\n\
    \                self.wait += 1\n                if self.wait >= self.patience:\n\
    \                    old_lr = float(K.get_value(self.model.optimizer.lr))\n  \
    \                  if old_lr > self.min_lr:\n                        new_lr =\
    \ old_lr * self.factor\n                        new_lr = max(new_lr, self.min_lr)\n\
    \                        K.set_value(self.model.optimizer.lr, new_lr)\n      \
    \                  if self.verbose > 0:\n                            print('\\\
    nEpoch %05d: ReduceLROnPlateau reducing '\n                                  'learning\
    \ rate to %s.' % (epoch + 1, new_lr))\n                        self.cooldown_counter\
    \ = self.cooldown\n                        self.wait = 0\n\n    def in_cooldown(self):\n\
    \        return self.cooldown_counter > 0\n"
  sourcefile: D:\Python36\lib\site-packages\keras\callbacks.py
- doc: "Callback used to stream events to a server.\n\nRequires the `requests` library.\n\
    Events are sent to `root + '/publish/epoch/end/'` by default. Calls are\nHTTP\
    \ POST, with a `data` argument which is a\nJSON-encoded dictionary of event data.\n\
    If send_as_json is set to True, the content type of the request will be\napplication/json.\
    \ Otherwise the serialized JSON will be send within a form\n\n# Arguments\n  \
    \  root: String; root url of the target server.\n    path: String; path relative\
    \ to `root` to which the events will be sent.\n    field: String; JSON field under\
    \ which the data will be stored.\n        The field is used only if the payload\
    \ is sent within a form\n        (i.e. send_as_json is set to False).\n    headers:\
    \ Dictionary; optional custom HTTP headers.\n    send_as_json: Boolean; whether\
    \ the request should be send as\n        application/json."
  kind: Callback
  name: RemoteMonitor
  parameters:
  - {defaultValue: 'http://localhost:9000', kind: any, name: root}
  - {defaultValue: /publish/epoch/end/, kind: any, name: path}
  - {defaultValue: data, kind: any, name: field}
  - {defaultValue: None, kind: any, name: headers}
  - {defaultValue: 'False', kind: any, name: send_as_json}
  source: "class RemoteMonitor(Callback):\n    \"\"\"Callback used to stream events\
    \ to a server.\n\n    Requires the `requests` library.\n    Events are sent to\
    \ `root + '/publish/epoch/end/'` by default. Calls are\n    HTTP POST, with a\
    \ `data` argument which is a\n    JSON-encoded dictionary of event data.\n   \
    \ If send_as_json is set to True, the content type of the request will be\n  \
    \  application/json. Otherwise the serialized JSON will be send within a form\n\
    \n    # Arguments\n        root: String; root url of the target server.\n    \
    \    path: String; path relative to `root` to which the events will be sent.\n\
    \        field: String; JSON field under which the data will be stored.\n    \
    \        The field is used only if the payload is sent within a form\n       \
    \     (i.e. send_as_json is set to False).\n        headers: Dictionary; optional\
    \ custom HTTP headers.\n        send_as_json: Boolean; whether the request should\
    \ be send as\n            application/json.\n    \"\"\"\n\n    def __init__(self,\n\
    \                 root='http://localhost:9000',\n                 path='/publish/epoch/end/',\n\
    \                 field='data',\n                 headers=None,\n            \
    \     send_as_json=False):\n        super(RemoteMonitor, self).__init__()\n\n\
    \        self.root = root\n        self.path = path\n        self.field = field\n\
    \        self.headers = headers\n        self.send_as_json = send_as_json\n\n\
    \    def on_epoch_end(self, epoch, logs=None):\n        if requests is None:\n\
    \            raise ImportError('RemoteMonitor requires '\n                   \
    \           'the `requests` library.')\n        logs = logs or {}\n        send\
    \ = {}\n        send['epoch'] = epoch\n        for k, v in logs.items():\n   \
    \         if isinstance(v, (np.ndarray, np.generic)):\n                send[k]\
    \ = v.item()\n            else:\n                send[k] = v\n        try:\n \
    \           if self.send_as_json:\n                requests.post(self.root + self.path,\
    \ json=send, headers=self.headers)\n            else:\n                requests.post(self.root\
    \ + self.path,\n                              {self.field: json.dumps(send)},\n\
    \                              headers=self.headers)\n        except requests.exceptions.RequestException:\n\
    \            warnings.warn('Warning: could not reach RemoteMonitor '\n       \
    \                   'root server at ' + str(self.root))\n"
  sourcefile: D:\Python36\lib\site-packages\keras\callbacks.py
- doc: "TensorBoard basic visualizations.\n\n[TensorBoard](https://www.tensorflow.org/get_started/summaries_and_tensorboard)\n\
    is a visualization tool provided with TensorFlow.\n\nThis callback writes a log\
    \ for TensorBoard, which allows\nyou to visualize dynamic graphs of your training\
    \ and test\nmetrics, as well as activation histograms for the different\nlayers\
    \ in your model.\n\nIf you have installed TensorFlow with pip, you should be able\n\
    to launch TensorBoard from the command line:\n```sh\ntensorboard --logdir=/full_path_to_your_logs\n\
    ```\n\nWhen using a backend other than TensorFlow, TensorBoard will still work\n\
    (if you have TensorFlow installed), but the only feature available will\nbe the\
    \ display of the losses and metrics plots.\n\n# Arguments\n    log_dir: the path\
    \ of the directory where to save the log\n        files to be parsed by TensorBoard.\n\
    \    histogram_freq: frequency (in epochs) at which to compute activation\n  \
    \      and weight histograms for the layers of the model. If set to 0,\n     \
    \   histograms won't be computed. Validation data (or split) must be\n       \
    \ specified for histogram visualizations.\n    write_graph: whether to visualize\
    \ the graph in TensorBoard.\n        The log file can become quite large when\n\
    \        write_graph is set to True.\n    write_grads: whether to visualize gradient\
    \ histograms in TensorBoard.\n        `histogram_freq` must be greater than 0.\n\
    \    batch_size: size of batch of inputs to feed to the network\n        for histograms\
    \ computation.\n    write_images: whether to write model weights to visualize\
    \ as\n        image in TensorBoard.\n    embeddings_freq: frequency (in epochs)\
    \ at which selected embedding\n        layers will be saved. If set to 0, embeddings\
    \ won't be computed.\n        Data to be visualized in TensorBoard's Embedding\
    \ tab must be passed\n        as `embeddings_data`.\n    embeddings_layer_names:\
    \ a list of names of layers to keep eye on. If\n        None or empty list all\
    \ the embedding layer will be watched.\n    embeddings_metadata: a dictionary\
    \ which maps layer name to a file name\n        in which metadata for this embedding\
    \ layer is saved. See the\n        [details](https://www.tensorflow.org/how_tos/embedding_viz/#metadata_optional)\n\
    \        about metadata files format. In case if the same metadata file is\n \
    \       used for all embedding layers, string can be passed.\n    embeddings_data:\
    \ data to be embedded at layers specified in\n        `embeddings_layer_names`.\
    \ Numpy array (if the model has a single\n        input) or list of Numpy arrays\
    \ (if the model has multiple inputs).\n        Learn [more about embeddings]\n\
    \        (https://www.tensorflow.org/programmers_guide/embedding).\n    update_freq:\
    \ `'batch'` or `'epoch'` or integer. When using `'batch'`, writes\n        the\
    \ losses and metrics to TensorBoard after each batch. The same\n        applies\
    \ for `'epoch'`. If using an integer, let's say `10000`,\n        the callback\
    \ will write the metrics and losses to TensorBoard every\n        10000 samples.\
    \ Note that writing too frequently to TensorBoard\n        can slow down your\
    \ training."
  kind: Callback
  name: TensorBoard
  parameters:
  - {defaultValue: ./logs, kind: any, name: log_dir}
  - {defaultValue: '0', kind: any, name: histogram_freq}
  - {defaultValue: '32', kind: any, name: batch_size}
  - {defaultValue: 'True', kind: any, name: write_graph}
  - {defaultValue: 'False', kind: any, name: write_grads}
  - {defaultValue: 'False', kind: any, name: write_images}
  - {defaultValue: '0', kind: any, name: embeddings_freq}
  - {defaultValue: None, kind: any, name: embeddings_layer_names}
  - {defaultValue: None, kind: any, name: embeddings_metadata}
  - {defaultValue: None, kind: any, name: embeddings_data}
  - {defaultValue: epoch, kind: any, name: update_freq}
  source: "class TensorBoard(Callback):\n    \"\"\"TensorBoard basic visualizations.\n\
    \n    [TensorBoard](https://www.tensorflow.org/get_started/summaries_and_tensorboard)\n\
    \    is a visualization tool provided with TensorFlow.\n\n    This callback writes\
    \ a log for TensorBoard, which allows\n    you to visualize dynamic graphs of\
    \ your training and test\n    metrics, as well as activation histograms for the\
    \ different\n    layers in your model.\n\n    If you have installed TensorFlow\
    \ with pip, you should be able\n    to launch TensorBoard from the command line:\n\
    \    ```sh\n    tensorboard --logdir=/full_path_to_your_logs\n    ```\n\n    When\
    \ using a backend other than TensorFlow, TensorBoard will still work\n    (if\
    \ you have TensorFlow installed), but the only feature available will\n    be\
    \ the display of the losses and metrics plots.\n\n    # Arguments\n        log_dir:\
    \ the path of the directory where to save the log\n            files to be parsed\
    \ by TensorBoard.\n        histogram_freq: frequency (in epochs) at which to compute\
    \ activation\n            and weight histograms for the layers of the model. If\
    \ set to 0,\n            histograms won't be computed. Validation data (or split)\
    \ must be\n            specified for histogram visualizations.\n        write_graph:\
    \ whether to visualize the graph in TensorBoard.\n            The log file can\
    \ become quite large when\n            write_graph is set to True.\n        write_grads:\
    \ whether to visualize gradient histograms in TensorBoard.\n            `histogram_freq`\
    \ must be greater than 0.\n        batch_size: size of batch of inputs to feed\
    \ to the network\n            for histograms computation.\n        write_images:\
    \ whether to write model weights to visualize as\n            image in TensorBoard.\n\
    \        embeddings_freq: frequency (in epochs) at which selected embedding\n\
    \            layers will be saved. If set to 0, embeddings won't be computed.\n\
    \            Data to be visualized in TensorBoard's Embedding tab must be passed\n\
    \            as `embeddings_data`.\n        embeddings_layer_names: a list of\
    \ names of layers to keep eye on. If\n            None or empty list all the embedding\
    \ layer will be watched.\n        embeddings_metadata: a dictionary which maps\
    \ layer name to a file name\n            in which metadata for this embedding\
    \ layer is saved. See the\n            [details](https://www.tensorflow.org/how_tos/embedding_viz/#metadata_optional)\n\
    \            about metadata files format. In case if the same metadata file is\n\
    \            used for all embedding layers, string can be passed.\n        embeddings_data:\
    \ data to be embedded at layers specified in\n            `embeddings_layer_names`.\
    \ Numpy array (if the model has a single\n            input) or list of Numpy\
    \ arrays (if the model has multiple inputs).\n            Learn [more about embeddings]\n\
    \            (https://www.tensorflow.org/programmers_guide/embedding).\n     \
    \   update_freq: `'batch'` or `'epoch'` or integer. When using `'batch'`, writes\n\
    \            the losses and metrics to TensorBoard after each batch. The same\n\
    \            applies for `'epoch'`. If using an integer, let's say `10000`,\n\
    \            the callback will write the metrics and losses to TensorBoard every\n\
    \            10000 samples. Note that writing too frequently to TensorBoard\n\
    \            can slow down your training.\n    \"\"\"\n\n    def __init__(self,\
    \ log_dir='./logs',\n                 histogram_freq=0,\n                 batch_size=32,\n\
    \                 write_graph=True,\n                 write_grads=False,\n   \
    \              write_images=False,\n                 embeddings_freq=0,\n    \
    \             embeddings_layer_names=None,\n                 embeddings_metadata=None,\n\
    \                 embeddings_data=None,\n                 update_freq='epoch'):\n\
    \        super(TensorBoard, self).__init__()\n        global tf, projector\n \
    \       try:\n            import tensorflow as tf\n            from tensorflow.contrib.tensorboard.plugins\
    \ import projector\n        except ImportError:\n            raise ImportError('You\
    \ need the TensorFlow module installed to '\n                              'use\
    \ TensorBoard.')\n\n        if K.backend() != 'tensorflow':\n            if histogram_freq\
    \ != 0:\n                warnings.warn('You are not using the TensorFlow backend.\
    \ '\n                              'histogram_freq was set to 0')\n          \
    \      histogram_freq = 0\n            if write_graph:\n                warnings.warn('You\
    \ are not using the TensorFlow backend. '\n                              'write_graph\
    \ was set to False')\n                write_graph = False\n            if write_images:\n\
    \                warnings.warn('You are not using the TensorFlow backend. '\n\
    \                              'write_images was set to False')\n            \
    \    write_images = False\n            if embeddings_freq != 0:\n            \
    \    warnings.warn('You are not using the TensorFlow backend. '\n            \
    \                  'embeddings_freq was set to 0')\n                embeddings_freq\
    \ = 0\n\n        self.log_dir = log_dir\n        self.histogram_freq = histogram_freq\n\
    \        self.merged = None\n        self.write_graph = write_graph\n        self.write_grads\
    \ = write_grads\n        self.write_images = write_images\n        self.embeddings_freq\
    \ = embeddings_freq\n        self.embeddings_layer_names = embeddings_layer_names\n\
    \        self.embeddings_metadata = embeddings_metadata or {}\n        self.batch_size\
    \ = batch_size\n        self.embeddings_data = embeddings_data\n        if update_freq\
    \ == 'batch':\n            # It is the same as writing as frequently as possible.\n\
    \            self.update_freq = 1\n        else:\n            self.update_freq\
    \ = update_freq\n        self.samples_seen = 0\n        self.samples_seen_at_last_write\
    \ = 0\n\n    def set_model(self, model):\n        self.model = model\n       \
    \ if K.backend() == 'tensorflow':\n            self.sess = K.get_session()\n \
    \       if self.histogram_freq and self.merged is None:\n            for layer\
    \ in self.model.layers:\n\n                for weight in layer.weights:\n    \
    \                mapped_weight_name = weight.name.replace(':', '_')\n        \
    \            tf.summary.histogram(mapped_weight_name, weight)\n              \
    \      if self.write_grads:\n                        grads = model.optimizer.get_gradients(model.total_loss,\n\
    \                                                              weight)\n\n   \
    \                     def is_indexed_slices(grad):\n                         \
    \   return type(grad).__name__ == 'IndexedSlices'\n                        grads\
    \ = [\n                            grad.values if is_indexed_slices(grad) else\
    \ grad\n                            for grad in grads]\n                     \
    \   tf.summary.histogram('{}_grad'.format(mapped_weight_name),\n             \
    \                                grads)\n                    if self.write_images:\n\
    \                        w_img = tf.squeeze(weight)\n                        shape\
    \ = K.int_shape(w_img)\n                        if len(shape) == 2:  # dense layer\
    \ kernel case\n                            if shape[0] > shape[1]:\n         \
    \                       w_img = tf.transpose(w_img)\n                        \
    \        shape = K.int_shape(w_img)\n                            w_img = tf.reshape(w_img,\
    \ [1,\n                                                       shape[0],\n    \
    \                                                   shape[1],\n              \
    \                                         1])\n                        elif len(shape)\
    \ == 3:  # convnet case\n                            if K.image_data_format()\
    \ == 'channels_last':\n                                # switch to channels_first\
    \ to display\n                                # every kernel as a separate image\n\
    \                                w_img = tf.transpose(w_img, perm=[2, 0, 1])\n\
    \                                shape = K.int_shape(w_img)\n                \
    \            w_img = tf.reshape(w_img, [shape[0],\n                          \
    \                             shape[1],\n                                    \
    \                   shape[2],\n                                              \
    \         1])\n                        elif len(shape) == 1:  # bias case\n  \
    \                          w_img = tf.reshape(w_img, [1,\n                   \
    \                                    shape[0],\n                             \
    \                          1,\n                                              \
    \         1])\n                        else:\n                            # not\
    \ possible to handle 3D convnets etc.\n                            continue\n\n\
    \                        shape = K.int_shape(w_img)\n                        assert\
    \ len(shape) == 4 and shape[-1] in [1, 3, 4]\n                        tf.summary.image(mapped_weight_name,\
    \ w_img)\n\n                if hasattr(layer, 'output'):\n                   \
    \ if isinstance(layer.output, list):\n                        for i, output in\
    \ enumerate(layer.output):\n                            tf.summary.histogram('{}_out_{}'.format(layer.name,\
    \ i),\n                                                 output)\n            \
    \        else:\n                        tf.summary.histogram('{}_out'.format(layer.name),\n\
    \                                             layer.output)\n        self.merged\
    \ = tf.summary.merge_all()\n\n        if self.write_graph:\n            self.writer\
    \ = tf.summary.FileWriter(self.log_dir,\n                                    \
    \            self.sess.graph)\n        else:\n            self.writer = tf.summary.FileWriter(self.log_dir)\n\
    \n        if self.embeddings_freq and self.embeddings_data is not None:\n    \
    \        self.embeddings_data = standardize_input_data(self.embeddings_data,\n\
    \                                                          model.input_names)\n\
    \n            embeddings_layer_names = self.embeddings_layer_names\n\n       \
    \     if not embeddings_layer_names:\n                embeddings_layer_names =\
    \ [layer.name for layer in self.model.layers\n                               \
    \           if type(layer).__name__ == 'Embedding']\n            self.assign_embeddings\
    \ = []\n            embeddings_vars = {}\n\n            self.batch_id = batch_id\
    \ = tf.placeholder(tf.int32)\n            self.step = step = tf.placeholder(tf.int32)\n\
    \n            for layer in self.model.layers:\n                if layer.name in\
    \ embeddings_layer_names:\n                    embedding_input = self.model.get_layer(layer.name).output\n\
    \                    embedding_size = np.prod(embedding_input.shape[1:])\n   \
    \                 embedding_input = tf.reshape(embedding_input,\n            \
    \                                     (step, int(embedding_size)))\n         \
    \           shape = (self.embeddings_data[0].shape[0], int(embedding_size))\n\
    \                    embedding = tf.Variable(tf.zeros(shape),\n              \
    \                              name=layer.name + '_embedding')\n             \
    \       embeddings_vars[layer.name] = embedding\n                    batch = tf.assign(embedding[batch_id:batch_id\
    \ + step],\n                                      embedding_input)\n         \
    \           self.assign_embeddings.append(batch)\n\n            self.saver = tf.train.Saver(list(embeddings_vars.values()))\n\
    \n            embeddings_metadata = {}\n\n            if not isinstance(self.embeddings_metadata,\
    \ str):\n                embeddings_metadata = self.embeddings_metadata\n    \
    \        else:\n                embeddings_metadata = {layer_name: self.embeddings_metadata\n\
    \                                       for layer_name in embeddings_vars.keys()}\n\
    \n            config = projector.ProjectorConfig()\n\n            for layer_name,\
    \ tensor in embeddings_vars.items():\n                embedding = config.embeddings.add()\n\
    \                embedding.tensor_name = tensor.name\n\n                if layer_name\
    \ in embeddings_metadata:\n                    embedding.metadata_path = embeddings_metadata[layer_name]\n\
    \n            projector.visualize_embeddings(self.writer, config)\n\n    def on_epoch_end(self,\
    \ epoch, logs=None):\n        logs = logs or {}\n\n        if not self.validation_data\
    \ and self.histogram_freq:\n            raise ValueError(\"If printing histograms,\
    \ validation_data must be \"\n                             \"provided, and cannot\
    \ be a generator.\")\n        if self.embeddings_data is None and self.embeddings_freq:\n\
    \            raise ValueError(\"To visualize embeddings, embeddings_data must\
    \ \"\n                             \"be provided.\")\n        if self.validation_data\
    \ and self.histogram_freq:\n            if epoch % self.histogram_freq == 0:\n\
    \n                val_data = self.validation_data\n                tensors = (self.model.inputs\
    \ +\n                           self.model.targets +\n                       \
    \    self.model.sample_weights)\n\n                if self.model.uses_learning_phase:\n\
    \                    tensors += [K.learning_phase()]\n\n                assert\
    \ len(val_data) == len(tensors)\n                val_size = val_data[0].shape[0]\n\
    \                i = 0\n                while i < val_size:\n                \
    \    step = min(self.batch_size, val_size - i)\n                    if self.model.uses_learning_phase:\n\
    \                        # do not slice the learning phase\n                 \
    \       batch_val = [x[i:i + step] for x in val_data[:-1]]\n                 \
    \       batch_val.append(val_data[-1])\n                    else:\n          \
    \              batch_val = [x[i:i + step] for x in val_data]\n               \
    \     assert len(batch_val) == len(tensors)\n                    feed_dict = dict(zip(tensors,\
    \ batch_val))\n                    result = self.sess.run([self.merged], feed_dict=feed_dict)\n\
    \                    summary_str = result[0]\n                    self.writer.add_summary(summary_str,\
    \ epoch)\n                    i += self.batch_size\n\n        if self.embeddings_freq\
    \ and self.embeddings_data is not None:\n            if epoch % self.embeddings_freq\
    \ == 0:\n                # We need a second forward-pass here because we're passing\n\
    \                # the `embeddings_data` explicitly. This design allows to pass\n\
    \                # arbitrary data as `embeddings_data` and results from the fact\n\
    \                # that we need to know the size of the `tf.Variable`s which\n\
    \                # hold the embeddings in `set_model`. At this point, however,\n\
    \                # the `validation_data` is not yet set.\n\n                #\
    \ More details in this discussion:\n                # https://github.com/keras-team/keras/pull/7766#issuecomment-329195622\n\
    \n                embeddings_data = self.embeddings_data\n                n_samples\
    \ = embeddings_data[0].shape[0]\n\n                i = 0\n                while\
    \ i < n_samples:\n                    step = min(self.batch_size, n_samples -\
    \ i)\n                    batch = slice(i, i + step)\n\n                    if\
    \ type(self.model.input) == list:\n                        feed_dict = {_input:\
    \ embeddings_data[idx][batch]\n                                     for idx, _input\
    \ in enumerate(self.model.input)}\n                    else:\n               \
    \         feed_dict = {self.model.input: embeddings_data[0][batch]}\n\n      \
    \              feed_dict.update({self.batch_id: i, self.step: step})\n\n     \
    \               if self.model.uses_learning_phase:\n                        feed_dict[K.learning_phase()]\
    \ = False\n\n                    self.sess.run(self.assign_embeddings, feed_dict=feed_dict)\n\
    \                    self.saver.save(self.sess,\n                            \
    \        os.path.join(self.log_dir,\n                                        \
    \         'keras_embedding.ckpt'),\n                                    epoch)\n\
    \n                    i += self.batch_size\n\n        if self.update_freq == 'epoch':\n\
    \            index = epoch\n        else:\n            index = self.samples_seen\n\
    \        self._write_logs(logs, index)\n\n    def _write_logs(self, logs, index):\n\
    \        for name, value in logs.items():\n            if name in ['batch', 'size']:\n\
    \                continue\n            summary = tf.Summary()\n            summary_value\
    \ = summary.value.add()\n            if isinstance(value, np.ndarray):\n     \
    \           summary_value.simple_value = value.item()\n            else:\n   \
    \             summary_value.simple_value = value\n            summary_value.tag\
    \ = name\n            self.writer.add_summary(summary, index)\n        self.writer.flush()\n\
    \n    def on_train_end(self, _):\n        self.writer.close()\n\n    def on_batch_end(self,\
    \ batch, logs=None):\n        if self.update_freq != 'epoch':\n            self.samples_seen\
    \ += logs['size']\n            samples_seen_since = self.samples_seen - self.samples_seen_at_last_write\n\
    \            if samples_seen_since >= self.update_freq:\n                self._write_logs(logs,\
    \ self.samples_seen)\n                self.samples_seen_at_last_write = self.samples_seen\n"
  sourcefile: D:\Python36\lib\site-packages\keras\callbacks.py
- doc: "Callback that terminates training when a NaN loss is encountered.\n    "
  kind: Callback
  name: TerminateOnNaN
  parameters: []
  source: "class TerminateOnNaN(Callback):\n    \"\"\"Callback that terminates training\
    \ when a NaN loss is encountered.\n    \"\"\"\n\n    def on_batch_end(self, batch,\
    \ logs=None):\n        logs = logs or {}\n        loss = logs.get('loss')\n  \
    \      if loss is not None:\n            if np.isnan(loss) or np.isinf(loss):\n\
    \                print('Batch %d: Invalid loss, terminating training' % (batch))\n\
    \                self.model.stop_training = True\n"
  sourcefile: D:\Python36\lib\site-packages\keras\callbacks.py
- kind: LayerOrPreprocessor
  name: split
  parameters:
  - {name: body, type: 'Layer[]'}
  sourcefile: D:\Python36\lib\site-packages\musket_core\net_declaration.py
- kind: LayerOrPreprocessor
  name: split-concat
  parameters:
  - {name: body, type: 'Layer[]'}
  sourcefile: D:\Python36\lib\site-packages\musket_core\net_declaration.py
- kind: LayerOrPreprocessor
  name: split-concatenate
  parameters:
  - {name: body, type: 'Layer[]'}
  sourcefile: D:\Python36\lib\site-packages\musket_core\net_declaration.py
- kind: LayerOrPreprocessor
  name: split-add
  parameters:
  - {name: body, type: 'Layer[]'}
  sourcefile: D:\Python36\lib\site-packages\musket_core\net_declaration.py
- kind: LayerOrPreprocessor
  name: split-substract
  parameters:
  - {name: body, type: 'Layer[]'}
  sourcefile: D:\Python36\lib\site-packages\musket_core\net_declaration.py
- kind: LayerOrPreprocessor
  name: split-mult
  parameters:
  - {name: body, type: 'Layer[]'}
  sourcefile: D:\Python36\lib\site-packages\musket_core\net_declaration.py
- kind: LayerOrPreprocessor
  name: split-min
  parameters:
  - {name: body, type: 'Layer[]'}
  sourcefile: D:\Python36\lib\site-packages\musket_core\net_declaration.py
- kind: LayerOrPreprocessor
  name: split-max
  parameters:
  - {name: body, type: 'Layer[]'}
  sourcefile: D:\Python36\lib\site-packages\musket_core\net_declaration.py
- kind: LayerOrPreprocessor
  name: split-dot
  parameters:
  - {name: body, type: 'Layer[]'}
  sourcefile: D:\Python36\lib\site-packages\musket_core\net_declaration.py
- kind: LayerOrPreprocessor
  name: split-dot-normalize
  parameters:
  - {name: body, type: 'Layer[]'}
  sourcefile: D:\Python36\lib\site-packages\musket_core\net_declaration.py
- kind: LayerOrPreprocessor
  name: seq
  parameters:
  - {name: body, type: 'Layer[]'}
  sourcefile: D:\Python36\lib\site-packages\musket_core\net_declaration.py
- kind: LayerOrPreprocessor
  name: input
  parameters:
  - {name: body, type: 'Layer[]'}
  sourcefile: D:\Python36\lib\site-packages\musket_core\net_declaration.py
- kind: LayerOrPreprocessor
  name: cache
  parameters:
  - {defaultValue: true, name: split, type: bool}
  sourcefile: D:\Python36\lib\site-packages\musket_core\net_declaration.py
- kind: LayerOrPreprocessor
  name: disk-cache
  parameters:
  - {defaultValue: true, name: split, type: bool}
  sourcefile: D:\Python36\lib\site-packages\musket_core\net_declaration.py
- kind: preprocessor
  name: split-preprocessor
  parameters:
  - {name: body, type: 'Preprocessor[]'}
  sourcefile: D:\Python36\lib\site-packages\musket_core\net_declaration.py
- kind: preprocessor
  name: split-concat-preprocessor
  parameters:
  - {name: body, type: 'Preprocessor[]'}
  sourcefile: D:\Python36\lib\site-packages\musket_core\net_declaration.py
- kind: preprocessor
  name: transform-preprocessor
  parameters:
  - {name: body, type: 'Preprocessor[]'}
  sourcefile: D:\Python36\lib\site-packages\musket_core\net_declaration.py
- kind: preprocessor
  name: seq-preprocessor
  parameters:
  - {name: body, type: 'Preprocessor[]'}
  sourcefile: D:\Python36\lib\site-packages\musket_core\net_declaration.py
- kind: LayerOrPreprocessor
  name: augmentation
  parameters:
  - {name: body, type: 'Preprocessor[]'}
  - {name: weights, type: 'int[]'}
  - {defaultValue: 0, name: seed, type: int}
  sourcefile: D:\Python36\lib\site-packages\musket_core\net_declaration.py
- kind: LayerOrPreprocessor
  name: pass
  parameters: []
  sourcefile: D:\Python36\lib\site-packages\musket_core\net_declaration.py
- kind: LayerOrPreprocessor
  name: transform-concat
  parameters:
  - {name: body, type: 'Layer[]'}
  sourcefile: D:\Python36\lib\site-packages\musket_core\net_declaration.py
- kind: LayerOrPreprocessor
  name: transform
  parameters:
  - {name: body, type: 'Layer[]'}
  sourcefile: D:\Python36\lib\site-packages\musket_core\net_declaration.py
- kind: LayerOrPreprocessor
  name: transform-add
  parameters:
  - {name: body, type: 'Layer[]'}
  sourcefile: D:\Python36\lib\site-packages\musket_core\net_declaration.py
- kind: LayerOrPreprocessor
  name: transform-mult
  parameters:
  - {name: body, type: 'Layer[]'}
  sourcefile: D:\Python36\lib\site-packages\musket_core\net_declaration.py
- kind: LayerOrPreprocessor
  name: transform-dot
  parameters:
  - {name: body, type: 'Layer[]'}
  sourcefile: D:\Python36\lib\site-packages\musket_core\net_declaration.py
- kind: LayerOrPreprocessor
  name: repeat(0)
  parameters:
  - {name: body, type: 'Layer[]'}
  sourcefile: D:\Python36\lib\site-packages\musket_core\net_declaration.py
- kind: LayerOrPreprocessor
  name: repeat(1)
  parameters:
  - {name: body, type: 'Layer[]'}
  sourcefile: D:\Python36\lib\site-packages\musket_core\net_declaration.py
- kind: LayerOrPreprocessor
  name: repeat(2)
  parameters:
  - {name: body, type: 'Layer[]'}
  sourcefile: D:\Python36\lib\site-packages\musket_core\net_declaration.py
- kind: LayerOrPreprocessor
  name: repeat(3)
  parameters:
  - {name: body, type: 'Layer[]'}
  sourcefile: D:\Python36\lib\site-packages\musket_core\net_declaration.py
- kind: LayerOrPreprocessor
  name: repeat(4)
  parameters:
  - {name: body, type: 'Layer[]'}
  sourcefile: D:\Python36\lib\site-packages\musket_core\net_declaration.py
- kind: LayerOrPreprocessor
  name: repeat(5)
  parameters:
  - {name: body, type: 'Layer[]'}
  sourcefile: D:\Python36\lib\site-packages\musket_core\net_declaration.py
- kind: LayerOrPreprocessor
  name: repeat(6)
  parameters:
  - {name: body, type: 'Layer[]'}
  sourcefile: D:\Python36\lib\site-packages\musket_core\net_declaration.py
- kind: LayerOrPreprocessor
  name: repeat(7)
  parameters:
  - {name: body, type: 'Layer[]'}
  sourcefile: D:\Python36\lib\site-packages\musket_core\net_declaration.py
- kind: LayerOrPreprocessor
  name: repeat(8)
  parameters:
  - {name: body, type: 'Layer[]'}
  sourcefile: D:\Python36\lib\site-packages\musket_core\net_declaration.py
- kind: LayerOrPreprocessor
  name: repeat(9)
  parameters:
  - {name: body, type: 'Layer[]'}
  sourcefile: D:\Python36\lib\site-packages\musket_core\net_declaration.py
- kind: LayerOrPreprocessor
  name: repeat(10)
  parameters:
  - {name: body, type: 'Layer[]'}
  sourcefile: D:\Python36\lib\site-packages\musket_core\net_declaration.py
- kind: LayerOrPreprocessor
  name: repeat(11)
  parameters:
  - {name: body, type: 'Layer[]'}
  sourcefile: D:\Python36\lib\site-packages\musket_core\net_declaration.py
- kind: LayerOrPreprocessor
  name: repeat(12)
  parameters:
  - {name: body, type: 'Layer[]'}
  sourcefile: D:\Python36\lib\site-packages\musket_core\net_declaration.py
- kind: LayerOrPreprocessor
  name: repeat(13)
  parameters:
  - {name: body, type: 'Layer[]'}
  sourcefile: D:\Python36\lib\site-packages\musket_core\net_declaration.py
- kind: LayerOrPreprocessor
  name: repeat(14)
  parameters:
  - {name: body, type: 'Layer[]'}
  sourcefile: D:\Python36\lib\site-packages\musket_core\net_declaration.py
- kind: LayerOrPreprocessor
  name: repeat(15)
  parameters:
  - {name: body, type: 'Layer[]'}
  sourcefile: D:\Python36\lib\site-packages\musket_core\net_declaration.py
- kind: LayerOrPreprocessor
  name: repeat(16)
  parameters:
  - {name: body, type: 'Layer[]'}
  sourcefile: D:\Python36\lib\site-packages\musket_core\net_declaration.py
- kind: LayerOrPreprocessor
  name: repeat(17)
  parameters:
  - {name: body, type: 'Layer[]'}
  sourcefile: D:\Python36\lib\site-packages\musket_core\net_declaration.py
- kind: LayerOrPreprocessor
  name: repeat(18)
  parameters:
  - {name: body, type: 'Layer[]'}
  sourcefile: D:\Python36\lib\site-packages\musket_core\net_declaration.py
- kind: LayerOrPreprocessor
  name: repeat(19)
  parameters:
  - {name: body, type: 'Layer[]'}
  sourcefile: D:\Python36\lib\site-packages\musket_core\net_declaration.py
- doc: null
  kind: metric_or_loss
  name: macro_f1
  parameters:
  - {kind: any, name: y_true}
  - {kind: any, name: y_pred}
  source: "def macro_f1(y_true, y_pred):\n    # y_pred = K.round(y_pred)\n    # y_pred\
    \ = K.cast(K.greater(K.clip(y_pred, 0, 1), THRESHOLD), K.floatx())\n    tp = K.sum(K.cast(y_true\
    \ * y_pred, 'float'), axis=0)\n    tn = K.sum(K.cast((1 - y_true) * (1 - y_pred),\
    \ 'float'), axis=0)\n    fp = K.sum(K.cast((1 - y_true) * y_pred, 'float'), axis=0)\n\
    \    fn = K.sum(K.cast(y_true * (1 - y_pred), 'float'), axis=0)\n\n    p = tp\
    \ / (tp + fp + K.epsilon())\n    r = tp / (tp + fn + K.epsilon())\n    r = tp\
    \ / (tp + fn + K.epsilon())\n\n    f1 = 2 * p * r / (p + r + K.epsilon())\n  \
    \  f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n    return K.mean(f1)\n"
  sourcefile: D:\Python36\lib\site-packages\musket_core\losses.py
- doc: null
  kind: metric_or_loss
  name: f1_loss
  parameters:
  - {kind: any, name: y_true}
  - {kind: any, name: y_pred}
  source: "def f1_loss(y_true, y_pred):\n    tp = K.sum(K.cast(y_true * y_pred, 'float'),\
    \ axis=0)\n    tn = K.sum(K.cast((1 - y_true) * (1 - y_pred), 'float'), axis=0)\n\
    \    fp = K.sum(K.cast((1 - y_true) * y_pred, 'float'), axis=0)\n    fn = K.sum(K.cast(y_true\
    \ * (1 - y_pred), 'float'), axis=0)\n\n    p = tp / (tp + fp + K.epsilon())\n\
    \    r = tp / (tp + fn + K.epsilon())\n\n    f1 = 2 * p * r / (p + r + K.epsilon())\n\
    \    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n    return 1 - K.mean(f1)\n"
  sourcefile: D:\Python36\lib\site-packages\musket_core\losses.py
- doc: null
  kind: metric_or_loss
  name: dice
  parameters:
  - {kind: any, name: 'true'}
  - {kind: any, name: pred}
  source: "def dice(true, pred):\n    true = tf.to_float(true>0.5)\n    pred = tf.to_float(pred>0.5)\n\
    \n    intersection =K.sum (true * pred)\n    im_sum = K.sum(true) + K.sum(pred)\n\
    \n    return 2.0 * intersection / (im_sum + EPS)\n"
  sourcefile: D:\Python36\lib\site-packages\musket_core\losses.py
- doc: IoU = (|X & Y|)/ (|X or Y|)
  kind: metric_or_loss
  name: iou_coef
  parameters:
  - {kind: any, name: y_true}
  - {kind: any, name: y_pred}
  - {defaultValue: '1', kind: any, name: smooth}
  source: "def iou_coef(y_true, y_pred, smooth=1):\n    \"\"\"\n    IoU = (|X & Y|)/\
    \ (|X or Y|)\n    \"\"\"\n    intersection = K.sum(y_true * y_pred, axis=[1, 2,\
    \ 3])\n    union = K.sum(y_true, axis=[1, 2, 3]) + K.sum(y_pred, axis=[1, 2, 3])\n\
    \    return 2.0*K.mean((intersection + smooth) / (union + smooth), axis=0)\n"
  sourcefile: D:\Python36\lib\site-packages\musket_core\losses.py
- doc: IoU = (|X & Y|)/ (|X or Y|)
  kind: metric_or_loss
  name: iou_coef
  parameters:
  - {kind: any, name: y_true}
  - {kind: any, name: y_pred}
  - {defaultValue: '1', kind: any, name: smooth}
  source: "def iou_coef(y_true, y_pred, smooth=1):\n    \"\"\"\n    IoU = (|X & Y|)/\
    \ (|X or Y|)\n    \"\"\"\n    intersection = K.sum(y_true * y_pred, axis=[1, 2,\
    \ 3])\n    union = K.sum(y_true, axis=[1, 2, 3]) + K.sum(y_pred, axis=[1, 2, 3])\n\
    \    return 2.0*K.mean((intersection + smooth) / (union + smooth), axis=0)\n"
  sourcefile: D:\Python36\lib\site-packages\musket_core\losses.py
- doc: IoU = (|X & Y|)/ (|X or Y|)
  kind: metric_or_loss
  name: iot_coef
  parameters:
  - {kind: any, name: y_true}
  - {kind: any, name: y_pred}
  - {defaultValue: '1', kind: any, name: smooth}
  source: "def iot_coef(y_true, y_pred, smooth=1):\n    \"\"\"\n    IoU = (|X & Y|)/\
    \ (|X or Y|)\n    \"\"\"\n    y_pred=tf.to_int32(y_pred>0.5)\n    y_true = tf.to_int32(y_true>\
    \ 0.5)\n\n    intersection = K.sum(y_true * y_pred, axis=[1, 2, 3])\n    union\
    \ = K.sum(y_true, axis=[1, 2, 3]) + K.sum(y_pred, axis=[1, 2, 3])\n    return\
    \ 2.0*K.mean((intersection + smooth) / (union + smooth), axis=0)\n"
  sourcefile: D:\Python36\lib\site-packages\musket_core\losses.py
- doc: null
  kind: metric_or_loss
  name: lovasz_loss
  parameters:
  - {kind: any, name: y_true}
  - {kind: any, name: y_pred}
  source: "def lovasz_loss(y_true, y_pred):\n    y_true, y_pred = K.cast(K.squeeze(y_true,\
    \ -1), 'int32'), K.cast(K.squeeze(y_pred, -1), 'float32')\n    #logits = K.log(y_pred\
    \ / (1. - y_pred))\n    logits = y_pred #Jiaxin\n    loss = lovasz_hinge(logits,\
    \ y_true, per_image = True, ignore = None)\n    return loss\n"
  sourcefile: D:\Python36\lib\site-packages\musket_core\losses.py
- doc: null
  kind: metric_or_loss
  name: iou_coef_loss
  parameters:
  - {kind: any, name: y_true}
  - {kind: any, name: y_pred}
  source: "def iou_coef_loss(y_true, y_pred):\n    return -iou_coef(y_true, y_pred)\n"
  sourcefile: D:\Python36\lib\site-packages\musket_core\losses.py
- doc: null
  kind: metric_or_loss
  name: dice_coef_loss
  parameters:
  - {kind: any, name: y_true}
  - {kind: any, name: y_pred}
  source: "def dice_coef_loss(y_true, y_pred):\n    return 1-dice_coef(y_true, y_pred)\n"
  sourcefile: D:\Python36\lib\site-packages\musket_core\losses.py
- doc: "Jaccard = (|X & Y|)/ (|X|+ |Y| - |X & Y|)\n        = sum(|A*B|)/(sum(|A|)+sum(|B|)-sum(|A*B|))\n\
    \nThe jaccard distance loss is usefull for unbalanced datasets. This has been\n\
    shifted so it converges on 0 and is smoothed to avoid exploding or disapearing\n\
    gradient.\n\nRef: https://en.wikipedia.org/wiki/Jaccard_index\n\n@url: https://gist.github.com/wassname/f1452b748efcbeb4cb9b1d059dce6f96\n\
    @author: wassname"
  kind: metric_or_loss
  name: jaccard_distance_loss
  parameters:
  - {kind: any, name: y_true}
  - {kind: any, name: y_pred}
  - {defaultValue: '100', kind: any, name: smooth}
  source: "def jaccard_distance_loss(y_true, y_pred, smooth=100):\n    \"\"\"\n  \
    \  Jaccard = (|X & Y|)/ (|X|+ |Y| - |X & Y|)\n            = sum(|A*B|)/(sum(|A|)+sum(|B|)-sum(|A*B|))\n\
    \n    The jaccard distance loss is usefull for unbalanced datasets. This has been\n\
    \    shifted so it converges on 0 and is smoothed to avoid exploding or disapearing\n\
    \    gradient.\n\n    Ref: https://en.wikipedia.org/wiki/Jaccard_index\n\n   \
    \ @url: https://gist.github.com/wassname/f1452b748efcbeb4cb9b1d059dce6f96\n  \
    \  @author: wassname\n    \"\"\"\n    intersection = K.sum(K.abs(y_true * y_pred),\
    \ axis=-1)\n    sum_ = K.sum(K.abs(y_true) + K.abs(y_pred), axis=-1)\n    jac\
    \ = (intersection + smooth) / (sum_ - intersection + smooth)\n    return (1 -\
    \ jac) * smooth\n"
  sourcefile: D:\Python36\lib\site-packages\musket_core\losses.py
- doc: null
  kind: metric_or_loss
  name: focal_loss
  parameters:
  - {kind: any, name: y_true}
  - {kind: any, name: y_pred}
  source: "def focal_loss(y_true, y_pred):\n    gamma=2#0.75\n    alpha=0.25\n\n \
    \   yc = tf.clip_by_value(y_pred, 1e-15, 1 - 1e-15)\n    pt_1 = tf.where(tf.equal(y_true,\
    \ 1), yc, tf.ones_like(yc))\n    pt_0 = tf.where(tf.equal(y_true, 0), yc, tf.zeros_like(yc))\n\
    \    return (-K.sum(alpha * K.pow(1. - pt_1, gamma) * K.log(pt_1)) - K.sum(\n\
    \        (1 - alpha) * K.pow(pt_0, gamma) * K.log(1. - pt_0)))\n"
  sourcefile: D:\Python36\lib\site-packages\musket_core\losses.py
- doc: null
  kind: metric_or_loss
  name: l2_loss
  parameters:
  - {kind: any, name: y_true}
  - {kind: any, name: y_pred}
  source: "def l2_loss(y_true, y_pred):\n    diff = y_true - y_pred\n\n    return\
    \ K.sum(diff * diff)\n"
  sourcefile: D:\Python36\lib\site-packages\musket_core\losses.py
- doc: 'Calculates the Matthews correlation coefficient measure for quality

    of binary classification problems.'
  kind: metric_or_loss
  name: matthews_correlation
  parameters:
  - {kind: any, name: y_true}
  - {kind: any, name: y_pred}
  source: "def matthews_correlation(y_true, y_pred):\n    '''Calculates the Matthews\
    \ correlation coefficient measure for quality\n    of binary classification problems.\n\
    \    '''\n    y_pred_pos = K.round(K.clip(y_pred, 0, 1))\n    y_pred_neg = 1 -\
    \ y_pred_pos\n\n    y_pos = K.round(K.clip(y_true, 0, 1))\n    y_neg = 1 - y_pos\n\
    \n    tp = K.sum(y_pos * y_pred_pos)\n    tn = K.sum(y_neg * y_pred_neg)\n\n \
    \   fp = K.sum(y_neg * y_pred_pos)\n    fn = K.sum(y_pos * y_pred_neg)\n\n   \
    \ numerator = (tp * tn - fp * fn)\n    denominator = K.sqrt((tp + fp) * (tp +\
    \ fn) * (tn + fp) * (tn + fn))\n\n    return numerator / (denominator + K.epsilon())\n"
  sourcefile: D:\Python36\lib\site-packages\musket_core\losses.py
- doc: expects probability-like input, e.g. softmax output
  kind: metric_or_loss
  name: log_loss
  parameters:
  - {kind: any, name: y_true}
  - {kind: any, name: y_pred}
  source: "def log_loss(y_true, y_pred):\n    '''\n    expects probability-like input,\
    \ e.g. softmax output\n    '''\n    y_pred = y_pred / K.expand_dims(K.sum(y_pred,\
    \ axis=1))\n    epsilon = 10.**(-15)\n    ub = 1.0 - epsilon\n    lb = epsilon\n\
    \    y = K.maximum(K.minimum(y_pred,ub),lb)\n    logs = K.log(y)\n    components\
    \ = y_true * logs\n    sum = K.sum(components)\n    result = sum * -1.\n    result\
    \ /= K.cast(K.shape(y_true)[0], \"float\")\n    return result\n"
  sourcefile: D:\Python36\lib\site-packages\musket_core\losses.py
- doc: null
  kind: metric_or_loss
  name: relu6
  parameters:
  - {kind: any, name: x}
  source: "def relu6(x):\n    return K.relu(x, max_value=6)\n"
  sourcefile: D:\Python36\lib\site-packages\musket_core\generic_config.py
